// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A simple tool that generates the syntect plugin's manifest.
extern crate syntect;
extern crate toml;
extern crate xi_core_lib as xi_core;

use std::fs::{self, File};
use std::io::{self, Write};
use std::path::{Path, PathBuf};

use crate::xi_core::plugin_manifest::*;
use crate::xi_core::LanguageDefinition;
use syntect::dumps::dump_to_file;
use syntect::parsing::{SyntaxReference, SyntaxSetBuilder};
use toml::Value;

const OUT_FILE_NAME: &str = "manifest.toml";

/// Extracts the name and version from Cargo.toml
fn parse_name_and_version() -> Result<(String, String), io::Error> {
    eprintln!("exe: {:?}", ::std::env::current_exe());
    let path = PathBuf::from("./Cargo.toml");
    let toml_str = fs::read_to_string(path)?;
    let value = toml_str.parse::<Value>().unwrap();
    let package_table = value["package"].as_table().unwrap();
    let name = package_table["name"].as_str().unwrap().to_string();
    let version = package_table["version"].as_str().unwrap().to_string();
    Ok((name, version))
}

fn main() -> Result<(), io::Error> {
    let package_dir = "syntect-resources/Packages";
    let packpath = "assets/default.packdump";
    let metasource = "syntect-resources/DefaultPackage";
    let metapath = "assets/default_meta.packdump";

    let mut builder = SyntaxSetBuilder::new();
    builder.add_plain_text_syntax();
    builder.add_from_folder(package_dir, true).unwrap();
    builder.add_from_folder(metasource, false).unwrap();
    let syntax_set = builder.build();

    dump_to_file(&syntax_set, packpath).unwrap();
    dump_to_file(&syntax_set.metadata(), metapath).unwrap();

    let lang_defs = syntax_set
        .syntaxes()
        .iter()
        .filter(|syntax| !syntax.file_extensions.is_empty())
        .map(lang_from_syn)
        .collect::<Vec<_>>();

    let (name, version) = parse_name_and_version()?;
    let exec_path = PathBuf::from(format!("./bin/{}", &name));

    let mani = PluginDescription {
        name,
        version,
        scope: PluginScope::Global,
        exec_path,
        activations: vec![PluginActivation::Autorun],
        commands: vec![],
        languages: lang_defs,
    };

    let toml_str = toml::to_string(&mani).unwrap();
    let file_path = Path::new(OUT_FILE_NAME);
    let mut f = File::create(file_path)?;

    f.write_all(toml_str.as_ref())
}

fn lang_from_syn<'a>(src: &'a SyntaxReference) -> LanguageDefinition {
    let mut extensions = src.file_extensions.clone();

    // add support for .xiconfig
    if extensions.contains(&String::from("toml")) {
        extensions.push(String::from("xiconfig"));
    }

    LanguageDefinition {
        name: src.name.as_str().into(),
        extensions,
        first_line_match: src.first_line_match.clone(),
        scope: src.scope.to_string(),
        default_config: None,
    }
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A syntax highlighting plugin based on syntect.
extern crate serde_json;
extern crate syntect;
extern crate xi_core_lib as xi_core;
extern crate xi_plugin_lib;
extern crate xi_rope;
extern crate xi_trace;

mod stackmap;

use std::collections::HashMap;
use std::ops::Range;
use std::path::Path;
use std::str::FromStr;
use std::sync::MutexGuard;

use crate::xi_core::plugin_rpc::ScopeSpan;
use crate::xi_core::{ConfigTable, LanguageId, ViewId};
use xi_plugin_lib::{mainloop, Cache, Error, Plugin, StateCache, View};
use xi_rope::{DeltaBuilder, Interval, Rope, RopeDelta, RopeInfo};
use xi_trace::{trace, trace_block};

use syntect::dumps::from_binary;
use syntect::parsing::{
    ParseState, ScopeRepository, ScopeStack, ScopedMetadata, SyntaxSet, SCOPE_REPO,
};

use crate::stackmap::{LookupResult, StackMap};

const LINES_PER_RPC: usize = 10;
const INDENTATION_PRIORITY: u64 = 100;

type EditBuilder = DeltaBuilder<RopeInfo>;

/// Edit types that will get processed.
#[derive(PartialEq, Clone, Copy)]
pub enum EditType {
    Insert,
    Newline,
    Other,
}

impl FromStr for EditType {
    type Err = ();

    fn from_str(s: &str) -> Result<EditType, ()> {
        match s {
            "insert" => Ok(EditType::Insert),
            "newline" => Ok(EditType::Newline),
            "other" => Ok(EditType::Other),
            _ => Err(()),
        }
    }
}

#[derive(PartialEq, Clone)]
enum IndentationTask {
    Newline(usize),
    Edit(usize),
    Batch(Range<usize>),
}

/// The state for syntax highlighting of one file.
struct PluginState {
    stack_idents: StackMap,
    offset: usize,
    initial_state: LineState,
    spans_start: usize,
    // unflushed spans
    spans: Vec<ScopeSpan>,
    new_scopes: Vec<Vec<String>>,
    // keeps track of the lines (start, end) that might need indentation after edit
    indentation_state: Vec<IndentationTask>,
}

type LockedRepo = MutexGuard<'static, ScopeRepository>;

/// The syntax highlighting state corresponding to the beginning of a line
/// (as stored in the state cache).
// Note: this needs to be option because the caching layer relies on Default.
// We can't implement that because the actual initial state depends on the
// syntax. There are other ways to handle this, but this will do for now.
type LineState = Option<(ParseState, ScopeStack)>;

/// The state of syntax highlighting for a collection of buffers.
struct Syntect<'a> {
    view_state: HashMap<ViewId, PluginState>,
    syntax_set: &'a SyntaxSet,
}

impl<'a> PluginState {
    fn new() -> Self {
        PluginState {
            stack_idents: StackMap::default(),
            offset: 0,
            initial_state: None,
            spans_start: 0,
            spans: Vec::new(),
            new_scopes: Vec::new(),
            indentation_state: Vec::new(),
        }
    }

    /// Compute syntax for one line, optionally also accumulating the style spans.
    ///
    /// NOTE: `accumulate_spans` should be true if we're doing syntax highlighting,
    /// and want to update the client. It should be `false` if we need syntax
    /// information for another purpose, such as auto-indent.
    fn compute_syntax(
        &mut self,
        line: &str,
        state: LineState,
        syntax_set: &SyntaxSet,
        accumulate_spans: bool,
    ) -> LineState {
        let (mut parse_state, mut scope_state) =
            state.or_else(|| self.initial_state.clone()).unwrap();
        let ops = parse_state.parse_line(&line, syntax_set);

        let mut prev_cursor = 0;
        let repo = SCOPE_REPO.lock().unwrap();
        for (cursor, batch) in ops {
            if !scope_state.is_empty() {
                let scope_id = self.identifier_for_stack(&scope_state, &repo);
                let start = self.offset - self.spans_start + prev_cursor;
                let end = start + (cursor - prev_cursor);
                if accumulate_spans && start != end {
                    let span = ScopeSpan { start, end, scope_id };
                    self.spans.push(span);
                }
            }
            prev_cursor = cursor;
            scope_state.apply(&batch);
        }

        if accumulate_spans {
            // add span for final state
            let start = self.offset - self.spans_start + prev_cursor;
            let end = start + (line.len() - prev_cursor);
            let scope_id = self.identifier_for_stack(&scope_state, &repo);
            let span = ScopeSpan { start, end, scope_id };
            self.spans.push(span);
        }
        Some((parse_state, scope_state))
    }

    /// Returns the unique identifier for this `ScopeStack`. We use identifiers
    /// so we aren't constantly sending long stack names to the peer.
    fn identifier_for_stack(&mut self, stack: &ScopeStack, repo: &LockedRepo) -> u32 {
        let identifier = self.stack_idents.get_value(stack.as_slice());
        match identifier {
            LookupResult::Existing(id) => id,
            LookupResult::New(id) => {
                let stack_strings =
                    stack.as_slice().iter().map(|slice| repo.to_string(*slice)).collect::<Vec<_>>();
                self.new_scopes.push(stack_strings);
                id
            }
        }
    }

    // Return true if there's any more work to be done.
    fn highlight_one_line(&mut self, ctx: &mut MyView, syntax_set: &SyntaxSet) -> bool {
        if let Some(line_num) = ctx.get_frontier() {
            let (line_num, offset, state) = ctx.get_prev(line_num);
            if offset != self.offset {
                self.flush_spans(ctx);
                self.offset = offset;
                self.spans_start = offset;
            }
            let new_frontier = match ctx.get_line(line_num) {
                Ok("") => None,
                Ok(s) => {
                    let new_state = self.compute_syntax(s, state, syntax_set, true);
                    self.offset += s.len();
                    if s.as_bytes().last() == Some(&b'\n') {
                        Some((new_state, line_num + 1))
                    } else {
                        None
                    }
                }
                Err(_) => None,
            };
            let mut converged = false;
            if let Some((ref new_state, new_line_num)) = new_frontier {
                if let Some(old_state) = ctx.get(new_line_num) {
                    converged = old_state.as_ref().unwrap().0 == new_state.as_ref().unwrap().0;
                }
            }
            if !converged {
                if let Some((new_state, new_line_num)) = new_frontier {
                    ctx.set(new_line_num, new_state);
                    ctx.update_frontier(new_line_num);
                    return true;
                }
            }
            ctx.close_frontier();
        }
        false
    }

    fn flush_spans(&mut self, ctx: &mut MyView) {
        let _t = trace_block("PluginState::flush_spans", &["syntect"]);
        if !self.new_scopes.is_empty() {
            ctx.add_scopes(&self.new_scopes);
            self.new_scopes.clear();
        }
        if self.spans_start != self.offset {
            ctx.update_spans(self.spans_start, self.offset - self.spans_start, &self.spans);
            self.spans.clear();
        }
        self.spans_start = self.offset;
    }

    pub fn indent_lines(&mut self, view: &mut MyView, syntax_set: &SyntaxSet) {
        let mut builder = DeltaBuilder::new(view.get_buf_size());

        for indentation_task in self.indentation_state.to_vec() {
            match indentation_task {
                IndentationTask::Newline(line) => self
                    .autoindent_line(view, &mut builder, syntax_set, line)
                    .expect("auto-indent error on newline"),
                IndentationTask::Edit(line) => self
                    .check_indent_active_edit(view, &mut builder, syntax_set, line)
                    .expect("auto-indent error on insert"),
                IndentationTask::Batch(range) => self
                    .bulk_autoindent(view, &mut builder, syntax_set, range)
                    .expect("auto-indent error on other"),
            };
        }

        if !builder.is_empty() {
            view.edit(builder.build(), INDENTATION_PRIORITY, false, false, String::from("syntect"));
        }

        self.indentation_state.clear();
    }

    /// Returns the metadata relevant to the given line. Computes the syntax
    /// for this line (during normal editing this is only likely for line 0) if
    /// necessary; in general reuses the syntax state calculated for highlighting.
    fn get_metadata(
        &mut self,
        view: &mut MyView,
        syntax_set: &'a SyntaxSet,
        line: usize,
    ) -> Option<ScopedMetadata<'a>> {
        let text = view.get_line(line).unwrap_or("");
        let scope = self.compute_syntax(&text, None, syntax_set, false).map(|(_, scope)| scope)?;
        Some(syntax_set.metadata().metadata_for_scope(scope.as_slice()))
    }

    /// Checks for possible auto-indent changes after an appropriate edit.
    fn consider_indentation(&mut self, view: &mut MyView, delta: &RopeDelta, edit_type: EditType) {
        for region in delta.iter_inserts() {
            let line_of_edit = view.line_of_offset(region.new_offset).unwrap();
            let last_line_of_edit = view.line_of_offset(region.new_offset + region.len).unwrap();
            match edit_type {
                EditType::Newline => {
                    self.indentation_state.push(IndentationTask::Newline(line_of_edit + 1))
                }
                EditType::Insert => {
                    let range = region.new_offset..region.new_offset + region.len;
                    let is_whitespace = {
                        let insert_region =
                            view.get_region(range).expect("view must return region");
                        insert_region.as_bytes().iter().all(u8::is_ascii_whitespace)
                    };
                    if !is_whitespace {
                        self.indentation_state.push(IndentationTask::Edit(line_of_edit));
                    }
                }
                EditType::Other => {
                    // we are mainly interested in auto-indenting after paste
                    let range = Range { start: line_of_edit, end: last_line_of_edit };
                    self.indentation_state.push(IndentationTask::Batch(range));
                }
            };
        }
    }

    fn bulk_autoindent(
        &mut self,
        view: &mut MyView,
        builder: &mut EditBuilder,
        syntax_set: &SyntaxSet,
        range: Range<usize>,
    ) -> Result<(), Error> {
        let _t = trace_block("Syntect::bulk_autoindent", &["syntect"]);
        let tab_size = view.get_config().tab_size;
        let use_spaces = view.get_config().translate_tabs_to_spaces;

        let mut base_indent = if range.start > 0 {
            self.previous_nonblank_line(view, range.start)?
                .map(|l| self.indent_level_of_line(view, l))
                .unwrap_or(0)
        } else {
            0
        };

        for line in range.start..=range.end {
            let current_line_indent = self.indent_level_of_line(view, line);

            if line > 0 {
                let increase_level = self.test_increase(view, syntax_set, line)?;
                let decrease_level = self.test_decrease(view, syntax_set, line)?;
                let increase = if increase_level { tab_size } else { 0 };
                let decrease = if decrease_level { tab_size } else { 0 };
                let final_level = base_indent + increase - decrease;
                base_indent = final_level;
            }

            if base_indent != current_line_indent {
                let edit_start = view.offset_of_line(line)?;
                let edit_len = {
                    let line = view.get_line(line)?;
                    line.as_bytes().iter().take_while(|b| **b == b' ' || **b == b'\t').count()
                };

                let indent_text =
                    if use_spaces { n_spaces(base_indent) } else { n_tabs(base_indent / tab_size) };

                let iv = Interval::new(edit_start, edit_start + edit_len);
                builder.replace(iv, indent_text.into());
            }
        }

        Ok(())
    }

    /// Called when freshly computing a line's indent level, such as after
    /// a newline, or when re-indenting a block.
    fn autoindent_line(
        &mut self,
        view: &mut MyView,
        builder: &mut EditBuilder,
        syntax_set: &SyntaxSet,
        line: usize,
    ) -> Result<(), Error> {
        let _t = trace_block("Syntect::autoindent", &["syntect"]);
        debug_assert!(line > 0);
        let tab_size = view.get_config().tab_size;
        let current_indent = self.indent_level_of_line(view, line);
        let base_indent = self
            .previous_nonblank_line(view, line)?
            .map(|l| self.indent_level_of_line(view, l))
            .unwrap_or(0);
        let increase_level = self.test_increase(view, syntax_set, line)?;
        let decrease_level = self.test_decrease(view, syntax_set, line)?;
        let increase = if increase_level { tab_size } else { 0 };
        let decrease = if decrease_level { tab_size } else { 0 };
        let final_level = base_indent + increase - decrease;

        if final_level != current_indent {
            self.set_indent(view, builder, line, final_level)
        } else {
            Ok(())
        }
    }

    /// Called when actively editing a line; chiefly checks for whether or not
    /// the current line should be de-indented, such as after a closing '}'.
    fn check_indent_active_edit(
        &mut self,
        view: &mut MyView,
        builder: &mut EditBuilder,
        syntax_set: &SyntaxSet,
        line: usize,
    ) -> Result<(), Error> {
        let _t = trace_block("Syntect::check_indent_active_line", &["syntect"]);
        if line == 0 {
            return Ok(());
        }
        let tab_size = view.get_config().tab_size;
        let current_indent = self.indent_level_of_line(view, line);
        if line == 0 || current_indent == 0 {
            return Ok(());
        }
        let just_increased = self.test_increase(view, syntax_set, line)?;
        let decrease = self.test_decrease(view, syntax_set, line)?;
        let prev_line = self.previous_nonblank_line(view, line)?;
        let mut indent_level = prev_line.map(|l| self.indent_level_of_line(view, l)).unwrap_or(0);
        if decrease {
            // the first line after an increase should just match the previous line
            if !just_increased {
                indent_level = indent_level.saturating_sub(tab_size);
            }
            // we don't want to change indent level if this line doesn't
            // match `test_decrease`, because the user could have changed
            // it manually, and we respect that.
            if indent_level != current_indent {
                return self.set_indent(view, builder, line, indent_level);
            }
        }
        Ok(())
    }

    fn set_indent(
        &self,
        view: &mut MyView,
        builder: &mut EditBuilder,
        line: usize,
        level: usize,
    ) -> Result<(), Error> {
        let edit_start = view.offset_of_line(line)?;
        let edit_len = {
            let line = view.get_line(line)?;
            line.as_bytes().iter().take_while(|b| **b == b' ' || **b == b'\t').count()
        };

        let use_spaces = view.get_config().translate_tabs_to_spaces;
        let tab_size = view.get_config().tab_size;

        let indent_text = if use_spaces { n_spaces(level) } else { n_tabs(level / tab_size) };

        let iv = Interval::new(edit_start, edit_start + edit_len);
        builder.replace(iv, indent_text.into());
        Ok(())
    }

    /// Test whether the indent level should be increased for this line,
    /// by testing the _previous_ line against a regex.
    fn test_increase(
        &mut self,
        view: &mut MyView,
        syntax_set: &SyntaxSet,
        line: usize,
    ) -> Result<bool, Error> {
        debug_assert!(line > 0, "increasing indent requires a previous line");
        let prev_line = match self.previous_nonblank_line(view, line) {
            Ok(Some(l)) => l,
            Ok(None) => return Ok(false),
            Err(e) => return Err(e),
        };
        let metadata =
            self.get_metadata(view, syntax_set, prev_line).ok_or(Error::PeerDisconnect)?;
        let line = view.get_line(prev_line)?;

        let comment_str = match metadata.line_comment().map(|s| s.to_owned()) {
            Some(s) => s,
            None => return Ok(metadata.increase_indent(line)),
        };

        // if the previous line is a comment, the indent level should not be increased
        if line.trim().starts_with(&comment_str.trim()) {
            Ok(false)
        } else {
            Ok(metadata.increase_indent(line))
        }
    }

    /// Test whether the indent level for this line should be decreased, by
    /// checking this line against a regex.
    fn test_decrease(
        &mut self,
        view: &mut MyView,
        syntax_set: &SyntaxSet,
        line: usize,
    ) -> Result<bool, Error> {
        if line == 0 {
            return Ok(false);
        }
        let metadata = self.get_metadata(view, syntax_set, line).ok_or(Error::PeerDisconnect)?;
        let line = view.get_line(line)?;
        Ok(metadata.decrease_indent(line))
    }

    fn previous_nonblank_line(
        &self,
        view: &mut MyView,
        line: usize,
    ) -> Result<Option<usize>, Error> {
        debug_assert!(line > 0);
        let mut line = line;
        while line > 0 {
            line -= 1;
            let text = view.get_line(line)?;
            if !text.bytes().all(|b| b.is_ascii_whitespace()) {
                return Ok(Some(line));
            }
        }
        Ok(None)
    }

    fn indent_level_of_line(&self, view: &mut MyView, line: usize) -> usize {
        let tab_size = view.get_config().tab_size;
        let line = view.get_line(line).unwrap_or("");
        line.as_bytes()
            .iter()
            .take_while(|b| **b == b' ' || **b == b'\t')
            .map(|b| if b == &b' ' { 1 } else { tab_size })
            .sum()
    }

    fn reindent(&mut self, view: &mut MyView, syntax_set: &SyntaxSet, lines: &[(usize, usize)]) {
        let mut builder = DeltaBuilder::new(view.get_buf_size());

        for (start, end) in lines {
            let range = Range { start: *start, end: *end - 1 };
            self.bulk_autoindent(view, &mut builder, syntax_set, range).expect("error on reindent");
        }

        view.edit(builder.build(), INDENTATION_PRIORITY, false, false, String::from("syntect"));
    }

    fn toggle_comment(
        &mut self,
        view: &mut MyView,
        syntax_set: &SyntaxSet,
        lines: &[(usize, usize)],
    ) {
        let _t = trace_block("Syntect::toggle_comment", &["syntect"]);
        if lines.is_empty() {
            return;
        }

        let mut builder = DeltaBuilder::new(view.get_buf_size());

        for (start, end) in lines {
            let range = Range { start: *start, end: *end };
            self.toggle_comment_line_range(view, syntax_set, &mut builder, range);
        }

        if builder.is_empty() {
            eprintln!("no delta for lines {:?}", &lines);
        } else {
            view.edit(builder.build(), INDENTATION_PRIORITY, false, true, String::from("syntect"));
        }
    }

    fn toggle_comment_line_range(
        &mut self,
        view: &mut MyView,
        syntax_set: &SyntaxSet,
        builder: &mut EditBuilder,
        line_range: Range<usize>,
    ) {
        let comment_str = match self
            .get_metadata(view, syntax_set, line_range.start)
            .and_then(|s| s.line_comment().map(|s| s.to_owned()))
        {
            Some(s) => s,
            None => return,
        };

        match view
            .get_line(line_range.start)
            .map(|l| comment_str.trim() == l.trim() || l.trim().starts_with(&comment_str))
        {
            Ok(true) => self.remove_comment_marker(view, builder, line_range, &comment_str),
            Ok(false) => self.insert_comment_marker(view, builder, line_range, &comment_str),
            Err(e) => eprintln!("toggle comment error: {:?}", e),
        }
    }

    fn insert_comment_marker(
        &self,
        view: &mut MyView,
        builder: &mut EditBuilder,
        line_range: Range<usize>,
        comment_str: &str,
    ) {
        // when commenting out multiple lines, we insert all comment markers at
        // the same indent level: that of the least indented line.
        let line_offset = line_range
            .clone()
            .map(|num| {
                view.get_line(num)
                    .ok()
                    .and_then(|line| line.as_bytes().iter().position(|b| *b != b' ' && *b != b'\t'))
                    .unwrap_or(0)
            })
            .min()
            .unwrap_or(0);

        let comment_txt = Rope::from(&comment_str);
        for num in line_range {
            let offset = view.offset_of_line(num).unwrap();
            let line = view.get_line(num).unwrap();
            if line.trim().starts_with(&comment_str) {
                continue;
            }

            let iv = Interval::new(offset + line_offset, offset + line_offset);
            builder.replace(iv, comment_txt.clone());
        }
    }

    fn remove_comment_marker(
        &self,
        view: &mut MyView,
        builder: &mut EditBuilder,
        lines: Range<usize>,
        comment_str: &str,
    ) {
        for num in lines {
            let offset = view.offset_of_line(num).unwrap();
            let line = view.get_line(num).unwrap();
            let (comment_start, len) = match line.find(&comment_str) {
                Some(off) => (offset + off, comment_str.len()),
                None if line.trim() == comment_str.trim() => (offset, comment_str.trim().len()),
                None => continue,
            };

            let iv = Interval::new(comment_start, comment_start + len);
            builder.delete(iv);
        }
    }
}

type MyView = View<StateCache<LineState>>;

impl<'a> Syntect<'a> {
    fn new(syntax_set: &'a SyntaxSet) -> Self {
        Syntect { view_state: HashMap::new(), syntax_set }
    }

    /// Wipes any existing state and starts highlighting with `syntax`.
    fn do_highlighting(&mut self, view: &mut MyView) {
        let initial_state = {
            let language_id = view.get_language_id();
            let syntax = self
                .syntax_set
                .find_syntax_by_name(language_id.as_ref())
                .unwrap_or_else(|| self.syntax_set.find_syntax_plain_text());
            Some((ParseState::new(syntax), ScopeStack::new()))
        };

        let state = self.view_state.get_mut(&view.get_id()).unwrap();
        state.initial_state = initial_state;
        state.spans = Vec::new();
        state.new_scopes = Vec::new();
        state.offset = 0;
        state.spans_start = 0;
        view.get_cache().clear();
        view.schedule_idle();
    }
}

impl<'a> Plugin for Syntect<'a> {
    type Cache = StateCache<LineState>;

    fn new_view(&mut self, view: &mut View<Self::Cache>) {
        let _t = trace_block("Syntect::new_view", &["syntect"]);
        let view_id = view.get_id();
        let state = PluginState::new();
        self.view_state.insert(view_id, state);
        self.do_highlighting(view);
    }

    fn did_close(&mut self, view: &View<Self::Cache>) {
        self.view_state.remove(&view.get_id());
    }

    fn did_save(&mut self, view: &mut View<Self::Cache>, _old: Option<&Path>) {
        let _t = trace_block("Syntect::did_save", &["syntect"]);
        self.do_highlighting(view);
    }

    fn config_changed(&mut self, _view: &mut View<Self::Cache>, _changes: &ConfigTable) {}

    fn language_changed(&mut self, view: &mut View<Self::Cache>, _old_lang: LanguageId) {
        self.do_highlighting(view);
    }

    fn update(
        &mut self,
        view: &mut View<Self::Cache>,
        delta: Option<&RopeDelta>,
        edit_type: String,
        author: String,
    ) {
        let _t = trace_block("Syntect::update", &["syntect"]);
        view.schedule_idle();
        let should_auto_indent = view.get_config().auto_indent;
        let edit_type = edit_type.parse::<EditType>().ok();
        if should_auto_indent
            && author == "core"
            && (edit_type == Some(EditType::Newline)
                || edit_type == Some(EditType::Insert)
                || edit_type == Some(EditType::Other))
        {
            if let Some(delta) = delta {
                let state = self.view_state.get_mut(&view.get_id()).unwrap();
                state.consider_indentation(view, delta, edit_type.unwrap());
            }
        }
    }

    fn custom_command(
        &mut self,
        view: &mut View<Self::Cache>,
        method: &str,
        params: serde_json::Value,
    ) {
        match method {
            "toggle_comment" => {
                let lines: Vec<(usize, usize)> = serde_json::from_value(params).unwrap();
                let state = self.view_state.get_mut(&view.get_id()).unwrap();
                state.toggle_comment(view, self.syntax_set, &lines);
            }
            "reindent" => {
                let lines: Vec<(usize, usize)> = serde_json::from_value(params).unwrap();
                let state = self.view_state.get_mut(&view.get_id()).unwrap();
                state.reindent(view, self.syntax_set, &lines);
            }
            other => eprintln!("syntect received unexpected command {}", other),
        }
    }

    fn idle(&mut self, view: &mut View<Self::Cache>) {
        let state = self.view_state.get_mut(&view.get_id()).unwrap();
        state.indent_lines(view, self.syntax_set);

        for _ in 0..LINES_PER_RPC {
            if !state.highlight_one_line(view, self.syntax_set) {
                state.flush_spans(view);
                return;
            }
            if view.request_is_pending() {
                trace("yielding for request", &["syntect"]);
                break;
            }
        }
        state.flush_spans(view);
        view.schedule_idle();
    }
}

fn main() {
    let mut syntax_set: SyntaxSet = from_binary(include_bytes!("../assets/default.packdump"));
    let metadata = from_binary(include_bytes!("../assets/default_meta.packdump"));
    syntax_set.set_metadata(metadata);
    let mut state = Syntect::new(&syntax_set);
    mainloop(&mut state).unwrap();
}

fn n_spaces(n: usize) -> &'static str {
    // when someone opens an issue complaining about this we know we've made it
    const MAX_SPACES: usize = 160;
    static MANY_SPACES: [u8; MAX_SPACES] = [b' '; MAX_SPACES];
    unsafe { ::std::str::from_utf8_unchecked(&MANY_SPACES[..n.min(MAX_SPACES)]) }
}

fn n_tabs(n: usize) -> &'static str {
    const MAX_TABS: usize = 40;
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! StackMap is a simple nested map type (a trie) used to map `StackScope`s to
//! u32s so they can be efficiently sent to xi-core.
//!
//! For discussion of this approach, see [this
//! issue](https://github.com/google/xi-editor/issues/284).
use std::collections::HashMap;

use syntect::parsing::Scope;

#[derive(Debug, Default)]
struct Node {
    value: Option<u32>,
    children: HashMap<Scope, Node>,
}

#[derive(Debug, Default)]
/// Nested lookup table for stacks of scopes.
pub struct StackMap {
    next_id: u32,
    scopes: Node,
}

#[derive(Debug, PartialEq)]
/// Result type for `StackMap` lookups. Used to communicate to the user
/// whether or not a new identifier has been assigned, which will need to
/// be communicated to the peer.
pub enum LookupResult {
    Existing(u32),
    New(u32),
}

impl Node {
    pub fn new(value: u32) -> Self {
        Node { value: Some(value), children: HashMap::new() }
    }

    fn get_value(&mut self, stack: &[Scope], next_id: u32) -> LookupResult {
        // if this is last item on the stack, get the value, inserting if necessary.
        let first = stack.first().unwrap();
        if stack.len() == 1 {
            if !self.children.contains_key(first) {
                self.children.insert(first.to_owned(), Node::new(next_id));
                return LookupResult::New(next_id);
            }

            // if key exists, value still might not be assigned:
            let needs_value = self.children[first].value.is_none();
            if needs_value {
                let node = self.children.get_mut(first).unwrap();
                node.value = Some(next_id);
                return LookupResult::New(next_id);
            } else {
                let value = self.children[first].value.unwrap();
                return LookupResult::Existing(value);
            }
        }
        // not the last item: recurse, creating node as necessary
        if self.children.get(first).is_none() {
            self.children.insert(first.to_owned(), Node::default());
        }
        self.children.get_mut(first).unwrap().get_value(&stack[1..], next_id)
    }
}

impl StackMap {
    /// Returns the identifier for this stack, creating it if needed.
    pub fn get_value(&mut self, stack: &[Scope]) -> LookupResult {
        assert!(!stack.is_empty());
        let result = self.scopes.get_value(stack, self.next_id);
        if result.is_new() {
            self.next_id += 1;
        }
        result
    }
}

impl LookupResult {
    pub fn is_new(&self) -> bool {
        matches!(*self, LookupResult::New(_))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::str::FromStr;
    use syntect::parsing::ScopeStack;

    #[test]
    fn test_get_value() {
        let mut stackmap = StackMap::default();
        let stack = ScopeStack::from_str("text.rust.test scope.level.three").unwrap();
        assert_eq!(stack.as_slice().len(), 2);
        assert_eq!(stackmap.get_value(stack.as_slice()), LookupResult::New(0));
        assert_eq!(stackmap.get_value(stack.as_slice()), LookupResult::Existing(0));
        // we don't assign values to intermediate scopes during traversal
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A sample plugin, intended as an illustration and a template for plugin
//! developers.
extern crate xi_core_lib as xi_core;
extern crate xi_plugin_lib;
extern crate xi_rope;

use std::path::Path;

use crate::xi_core::ConfigTable;
use xi_plugin_lib::{mainloop, ChunkCache, Error, Plugin, View};
use xi_rope::delta::Builder as EditBuilder;
use xi_rope::interval::Interval;
use xi_rope::rope::RopeDelta;

/// A type that implements the `Plugin` trait, and interacts with xi-core.
///
/// Currently, this plugin has a single noteworthy behaviour,
/// intended to demonstrate how to edit a document; when the plugin is active,
/// and the user inserts an exclamation mark, the plugin will capitalize the
/// preceding word.
struct SamplePlugin;

//NOTE: implementing the `Plugin` trait is the sole requirement of a plugin.
// For more documentation, see `rust/plugin-lib` in this repo.
impl Plugin for SamplePlugin {
    type Cache = ChunkCache;

    fn new_view(&mut self, view: &mut View<Self::Cache>) {
        eprintln!("new view {}", view.get_id());
    }

    fn did_close(&mut self, view: &View<Self::Cache>) {
        eprintln!("close view {}", view.get_id());
    }

    fn did_save(&mut self, view: &mut View<Self::Cache>, _old: Option<&Path>) {
        eprintln!("saved view {}", view.get_id());
    }

    fn config_changed(&mut self, _view: &mut View<Self::Cache>, _changes: &ConfigTable) {}

    fn update(
        &mut self,
        view: &mut View<Self::Cache>,
        delta: Option<&RopeDelta>,
        _edit_type: String,
        _author: String,
    ) {
        //NOTE: example simple conditional edit. If this delta is
        //an insert of a single '!', we capitalize the preceding word.
        if let Some(delta) = delta {
            let (iv, _) = delta.summary();
            let text: String = delta.as_simple_insert().map(String::from).unwrap_or_default();
            if text == "!" {
                let _ = self.capitalize_word(view, iv.end());
            }
        }
    }
}

impl SamplePlugin {
    /// Uppercases the word preceding `end_offset`.
    fn capitalize_word(&self, view: &mut View<ChunkCache>, end_offset: usize) -> Result<(), Error> {
        //NOTE: this makes it clear to me that we need a better API for edits
        let line_nb = view.line_of_offset(end_offset)?;
        let line_start = view.offset_of_line(line_nb)?;

        let mut cur_utf8_ix = 0;
        let mut word_start = 0;
        for c in view.get_line(line_nb)?.chars() {
            if c.is_whitespace() {
                word_start = cur_utf8_ix;
            }

            cur_utf8_ix += c.len_utf8();

            if line_start + cur_utf8_ix == end_offset {
                break;
            }
        }

        let new_text = view.get_line(line_nb)?[word_start..end_offset - line_start].to_uppercase();
        let buf_size = view.get_buf_size();
        let mut builder = EditBuilder::new(buf_size);
        let iv = Interval::new(line_start + word_start, end_offset);
        builder.replace(iv, new_text.into());
        view.edit(builder.build(), 0, false, true, "sample".into());
        Ok(())
    }
}

// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Handles syntax highlighting and other styling.
//!
//! Plugins provide syntax highlighting information in the form of 'scopes'.
//! Scope information originating from any number of plugins can be resolved
//! into styles using a theme, augmented with additional style definitions.

use std::collections::{BTreeMap, HashMap, HashSet};
use syntect::highlighting::StyleModifier;
use syntect::parsing::Scope;

use xi_rope::spans::{Spans, SpansBuilder};
use xi_rope::{Interval, RopeDelta};
use xi_trace::trace_block;

use crate::plugins::PluginPid;
use crate::styles::{Style, ThemeStyleMap};

/// A collection of layers containing scope information.
#[derive(Default)]
pub struct Layers {
    layers: BTreeMap<PluginPid, ScopeLayer>,
    deleted: HashSet<PluginPid>,
    merged: Spans<Style>,
}

/// A collection of scope spans from a single source.
pub struct ScopeLayer {
    stack_lookup: Vec<Vec<Scope>>,
    style_lookup: Vec<Style>,
    // TODO: this might be efficient (in memory at least) if we use
    // a prefix tree.
    /// style state of existing scope spans, so we can more efficiently
    /// compute styles of child spans.
    style_cache: HashMap<Vec<Scope>, StyleModifier>,
    /// Human readable scope names, for debugging
    scope_spans: Spans<u32>,
    style_spans: Spans<Style>,
}

impl Layers {
    pub fn get_merged(&self) -> &Spans<Style> {
        &self.merged
    }

    /// Adds the provided scopes to the layer's lookup table.
    pub fn add_scopes(
        &mut self,
        layer: PluginPid,
        scopes: Vec<Vec<String>>,
        style_map: &ThemeStyleMap,
    ) {
        let _t = trace_block("Layers::AddScopes", &["core"]);
        if self.create_if_missing(layer).is_err() {
            return;
        }
        self.layers.get_mut(&layer).unwrap().add_scopes(scopes, style_map);
    }

    /// Applies the delta to all layers, inserting empty intervals
    /// for any regions inserted in the delta.
    ///
    /// This is useful for clearing spans, and for updating spans
    /// as edits occur.
    pub fn update_all(&mut self, delta: &RopeDelta) {
        self.merged.apply_shape(delta);

        for layer in self.layers.values_mut() {
            layer.blank_scopes(delta);
        }
        let (iv, _len) = delta.summary();
        self.resolve_styles(iv);
    }

    /// Updates the scope spans for a given layer.
    pub fn update_layer(&mut self, layer: PluginPid, iv: Interval, spans: Spans<u32>) {
        if self.create_if_missing(layer).is_err() {
            return;
        }
        self.layers.get_mut(&layer).unwrap().update_scopes(iv, &spans);
        self.resolve_styles(iv);
    }

    /// Removes a given layer. This will remove all styles derived from
    /// that layer's scopes.
    pub fn remove_layer(&mut self, layer: PluginPid) -> Option<ScopeLayer> {
        self.deleted.insert(layer);
        let layer = self.layers.remove(&layer);
        if layer.is_some() {
            let iv_all = Interval::new(0, self.merged.len());
            //TODO: should Spans<T> have a clear() method?
            self.merged = SpansBuilder::new(self.merged.len()).build();
            self.resolve_styles(iv_all);
        }
        layer
    }

    pub fn theme_changed(&mut self, style_map: &ThemeStyleMap) {
        for layer in self.layers.values_mut() {
            layer.theme_changed(style_map);
        }
        self.merged = SpansBuilder::new(self.merged.len()).build();
        let iv_all = Interval::new(0, self.merged.len());
        self.resolve_styles(iv_all);
    }

    /// Resolves styles from all layers for the given interval, updating
    /// the master style spans.
    fn resolve_styles(&mut self, iv: Interval) {
        if self.layers.is_empty() {
            return;
        }
        let mut layer_iter = self.layers.values();
        let mut resolved = layer_iter.next().unwrap().style_spans.subseq(iv);

        for other in layer_iter {
            let spans = other.style_spans.subseq(iv);
            assert_eq!(resolved.len(), spans.len());
            resolved = resolved.merge(&spans, |a, b| match b {
                Some(b) => a.merge(b),
                None => a.to_owned(),
            });
        }
        self.merged.edit(iv, resolved);
    }

    /// Prints scopes and style information for the given `Interval`.
    pub fn debug_print_spans(&self, iv: Interval) {
        for (id, layer) in &self.layers {
            let spans = layer.scope_spans.subseq(iv);
            let styles = layer.style_spans.subseq(iv);
            if spans.iter().next().is_some() {
                info!("scopes for layer {:?}:", id);
                for (iv, val) in spans.iter() {
                    info!("{}: {:?}", iv, layer.stack_lookup[*val as usize]);
                }
                info!("styles:");
                for (iv, val) in styles.iter() {
                    info!("{}: {:?}", iv, val);
                }
            }
        }
    }

    /// Returns an `Err` if this layer has been deleted; the caller should return.
    fn create_if_missing(&mut self, layer_id: PluginPid) -> Result<(), ()> {
        if self.deleted.contains(&layer_id) {
            return Err(());
        }
        if !self.layers.contains_key(&layer_id) {
            self.layers.insert(layer_id, ScopeLayer::new(self.merged.len()));
        }
        Ok(())
    }
}

impl Default for ScopeLayer {
    fn default() -> Self {
        ScopeLayer {
            stack_lookup: Vec::new(),
            style_lookup: Vec::new(),
            style_cache: HashMap::new(),
            scope_spans: Spans::default(),
            style_spans: Spans::default(),
        }
    }
}

impl ScopeLayer {
    pub fn new(len: usize) -> Self {
        ScopeLayer {
            stack_lookup: Vec::new(),
            style_lookup: Vec::new(),
            style_cache: HashMap::new(),
            scope_spans: SpansBuilder::new(len).build(),
            style_spans: SpansBuilder::new(len).build(),
        }
    }

    fn theme_changed(&mut self, style_map: &ThemeStyleMap) {
        // recompute styles with the new theme
        let cur_stacks = self.stack_lookup.clone();
        self.style_lookup = self.styles_for_stacks(&cur_stacks, style_map);
        let iv_all = Interval::new(0, self.style_spans.len());
        self.style_spans = SpansBuilder::new(self.style_spans.len()).build();
        // this feels unnecessary but we can't pass in a reference to self
        // and I don't want to get fancy unless there's an actual perf problem
        let scopes = self.scope_spans.clone();
        self.update_styles(iv_all, &scopes)
    }

    fn add_scopes(&mut self, scopes: Vec<Vec<String>>, style_map: &ThemeStyleMap) {
        let mut stacks = Vec::with_capacity(scopes.len());
        for stack in scopes {
            let scopes = stack
                .iter()
                .map(|s| Scope::new(&s))
                .filter(|result| match *result {
                    Err(ref err) => {
                        warn!("failed to resolve scope {}\nErr: {:?}", &stack.join(" "), err);
                        false
                    }
                    _ => true,
                })
                .map(|s| s.unwrap())
                .collect::<Vec<_>>();
            stacks.push(scopes);
        }

        let mut new_styles = self.styles_for_stacks(stacks.as_slice(), style_map);
        self.stack_lookup.append(&mut stacks);
        self.style_lookup.append(&mut new_styles);
    }

    fn styles_for_stacks(
        &mut self,
        stacks: &[Vec<Scope>],
        style_map: &ThemeStyleMap,
    ) -> Vec<Style> {
        //let style_map = style_map.borrow();
        let highlighter = style_map.get_highlighter();
        let mut new_styles = Vec::new();

        for stack in stacks {
            let mut last_style: Option<StyleModifier> = None;
            let mut upper_bound_of_last = stack.len() as usize;

            // walk backwards through stack to see if we have an existing
            // style for any child stacks.
            for i in 0..stack.len() - 1 {
                let prev_range = 0..stack.len() - (i + 1);
                if let Some(s) = self.style_cache.get(&stack[prev_range]) {
                    last_style = Some(*s);
                    upper_bound_of_last = stack.len() - (i + 1);
                    break;
                }
            }
            let mut base_style_mod = last_style.unwrap_or_default();

            // apply the stack, generating children as needed.
            for i in upper_bound_of_last..stack.len() {
                let style_mod = highlighter.style_mod_for_stack(&stack[0..=i]);
                base_style_mod = base_style_mod.apply(style_mod);
            }

            let style = Style::from_syntect_style_mod(&base_style_mod);
            self.style_cache.insert(stack.clone(), base_style_mod);

            new_styles.push(style);
        }
        new_styles
    }

    fn update_scopes(&mut self, iv: Interval, spans: &Spans<u32>) {
        self.scope_spans.edit(iv, spans.to_owned());
        self.update_styles(iv, spans);
    }

    /// Applies `delta`, which is presumed to contain empty spans.
    /// This is only used when we receive an edit, to adjust current span
    /// positions.
    fn blank_scopes(&mut self, delta: &RopeDelta) {
        self.style_spans.apply_shape(delta);
        self.scope_spans.apply_shape(delta);
    }

    /// Updates `self.style_spans`, mapping scopes to styles and combining
    /// adjacent and equal spans.
    fn update_styles(&mut self, iv: Interval, spans: &Spans<u32>) {
        // NOTE: This is a tradeoff. Keeping both u32 and Style spans for each
        // layer makes debugging simpler and reduces the total number of spans
        // on the wire (because we combine spans that resolve to the same style)
        // but it does require additional computation + memory up front.
        let mut sb = SpansBuilder::new(spans.len());
        let mut spans_iter = spans.iter();
        let mut prev = spans_iter.next();
        {
            // distinct adjacent scopes can often resolve to the same style,
            // so we combine them when building the styles.
            let style_eq = |i1: &u32, i2: &u32| {
                self.style_lookup[*i1 as usize] == self.style_lookup[*i2 as usize]
            };

            while let Some((p_iv, p_val)) = prev {
                match spans_iter.next() {
                    Some((n_iv, n_val)) if n_iv.start() == p_iv.end() && style_eq(p_val, n_val) => {
                        prev = Some((p_iv.union(n_iv), p_val));
                    }
                    other => {
                        sb.add_span(p_iv, self.style_lookup[*p_val as usize].to_owned());
                        prev = other;
                    }
                }
            }
        }
        self.style_spans.edit(iv, sb.build());
    }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Very basic syntax detection.

use std::borrow::Borrow;
use std::collections::{BTreeMap, HashMap};
use std::path::Path;
use std::sync::Arc;

use crate::config::Table;

/// The canonical identifier for a particular `LanguageDefinition`.
#[derive(Debug, Default, Clone, Serialize, Deserialize, PartialEq, Eq, Hash, PartialOrd, Ord)]
#[allow(clippy::rc_buffer)] // suppress clippy;  TODO consider addressing
                            // the warning by changing String to str
pub struct LanguageId(Arc<String>);

/// Describes a `LanguageDefinition`. Although these are provided by plugins,
/// they are a fundamental concept in core, used to determine things like
/// plugin activations and active user config tables.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LanguageDefinition {
    pub name: LanguageId,
    pub extensions: Vec<String>,
    pub first_line_match: Option<String>,
    pub scope: String,
    #[serde(skip)]
    pub default_config: Option<Table>,
}

/// A repository of all loaded `LanguageDefinition`s.
#[derive(Debug, Default)]
pub struct Languages {
    // NOTE: BTreeMap is used for sorting the languages by name alphabetically
    named: BTreeMap<LanguageId, Arc<LanguageDefinition>>,
    extensions: HashMap<String, Arc<LanguageDefinition>>,
}

impl Languages {
    pub fn new(language_defs: &[LanguageDefinition]) -> Self {
        let mut named = BTreeMap::new();
        let mut extensions = HashMap::new();
        for lang in language_defs.iter() {
            let lang_arc = Arc::new(lang.clone());
            named.insert(lang.name.clone(), lang_arc.clone());
            for ext in &lang.extensions {
                extensions.insert(ext.clone(), lang_arc.clone());
            }
        }
        Languages { named, extensions }
    }

    pub fn language_for_path(&self, path: &Path) -> Option<Arc<LanguageDefinition>> {
        path.extension()
            .or_else(|| path.file_name())
            .and_then(|ext| self.extensions.get(ext.to_str().unwrap_or_default()))
            .map(Arc::clone)
    }

    pub fn language_for_name<S>(&self, name: S) -> Option<Arc<LanguageDefinition>>
    where
        S: AsRef<str>,
    {
        self.named.get(name.as_ref()).map(Arc::clone)
    }

    /// Returns a Vec of any `LanguageDefinition`s which exist
    /// in `self` but not `other`.
    pub fn difference(&self, other: &Languages) -> Vec<Arc<LanguageDefinition>> {
        self.named
            .iter()
            .filter(|(k, _)| !other.named.contains_key(*k))
            .map(|(_, v)| v.clone())
            .collect()
    }

    pub fn iter(&self) -> impl Iterator<Item = &Arc<LanguageDefinition>> {
        self.named.values()
    }
}

impl AsRef<str> for LanguageId {
    fn as_ref(&self) -> &str {
        self.0.as_ref()
    }
}

// let's us use &str to query a HashMap with `LanguageId` keys
impl Borrow<str> for LanguageId {
    fn borrow(&self) -> &str {
        &self.0.as_ref()
    }
}

impl<'a> From<&'a str> for LanguageId {
    fn from(src: &'a str) -> LanguageId {
        LanguageId(Arc::new(src.into()))
    }
}

// for testing
#[cfg(test)]
impl LanguageDefinition {
    pub(crate) fn simple(name: &str, exts: &[&str], scope: &str, config: Option<Table>) -> Self {
        LanguageDefinition {
            name: name.into(),
            extensions: exts.iter().map(|s| (*s).into()).collect(),
            first_line_match: None,
            scope: scope.into(),
            default_config: config,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    pub fn language_for_path() {
        let ld_rust = LanguageDefinition {
            name: LanguageId::from("Rust"),
            extensions: vec![String::from("rs")],
            scope: String::from("source.rust"),
            first_line_match: None,
            default_config: None,
        };
        let ld_commit_msg = LanguageDefinition {
            name: LanguageId::from("Git Commit"),
            extensions: vec![
                String::from("COMMIT_EDITMSG"),
                String::from("MERGE_MSG"),
                String::from("TAG_EDITMSG"),
            ],
            scope: String::from("text.git.commit"),
            first_line_match: None,
            default_config: None,
        };
        let languages = Languages::new(&[ld_rust.clone(), ld_commit_msg.clone()]);

        assert_eq!(
            ld_rust.name,
            languages.language_for_path(Path::new("/path/test.rs")).unwrap().name
        );
        assert_eq!(
            ld_commit_msg.name,
            languages.language_for_path(Path::new("/path/COMMIT_EDITMSG")).unwrap().name
        );
        assert_eq!(
            ld_commit_msg.name,
            languages.language_for_path(Path::new("/path/MERGE_MSG")).unwrap().name
        );
        assert_eq!(
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Management of annotations.

use serde::de::{Deserialize, Deserializer};
use serde::ser::{Serialize, SerializeSeq, Serializer};
use serde_json::{self, Value};

use std::collections::HashMap;

use crate::line_offset::LineOffset;
use crate::plugins::PluginId;
use crate::view::View;
use crate::xi_rope::spans::Spans;
use crate::xi_rope::{Interval, Rope};

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub enum AnnotationType {
    Selection,
    Find,
    Other(String),
}

impl AnnotationType {
    fn as_str(&self) -> &str {
        match self {
            AnnotationType::Find => "find",
            AnnotationType::Selection => "selection",
            AnnotationType::Other(ref s) => s,
        }
    }
}

/// Location and range of an annotation ([start_line, start_col, end_line, end_col]).
/// Location and range of an annotation
#[derive(Debug, Default, Clone, Copy, PartialEq)]
pub struct AnnotationRange {
    pub start_line: usize,
    pub start_col: usize,
    pub end_line: usize,
    pub end_col: usize,
}

impl Serialize for AnnotationRange {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let mut seq = serializer.serialize_seq(Some(4))?;
        seq.serialize_element(&self.start_line)?;
        seq.serialize_element(&self.start_col)?;
        seq.serialize_element(&self.end_line)?;
        seq.serialize_element(&self.end_col)?;
        seq.end()
    }
}

impl<'de> Deserialize<'de> for AnnotationRange {
    fn deserialize<D>(deserializer: D) -> Result<AnnotationRange, D::Error>
    where
        D: Deserializer<'de>,
    {
        let mut range = AnnotationRange { ..Default::default() };
        let seq = <[usize; 4]>::deserialize(deserializer)?;

        range.start_line = seq[0];
        range.start_col = seq[1];
        range.end_line = seq[2];
        range.end_col = seq[3];

        Ok(range)
    }
}

/// A set of annotations of a given type.
#[derive(Debug, Clone)]
pub struct Annotations {
    pub items: Spans<Value>,
    pub annotation_type: AnnotationType,
}

impl Annotations {
    /// Update the annotations in `interval` with the provided `items`.
    pub fn update(&mut self, interval: Interval, items: Spans<Value>) {
        self.items.edit(interval, items);
    }

    /// Remove annotations intersecting `interval`.
    pub fn invalidate(&mut self, interval: Interval) {
        self.items.delete_after(interval);
    }
}

/// A region of an `Annotation`.
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct AnnotationSlice {
    annotation_type: AnnotationType,
    /// Annotation occurrences, guaranteed non-descending start order.
    ranges: Vec<AnnotationRange>,
    /// If present, one payload per range.
    payloads: Option<Vec<Value>>,
}

impl AnnotationSlice {
    pub fn new(
        annotation_type: AnnotationType,
        ranges: Vec<AnnotationRange>,
        payloads: Option<Vec<Value>>,
    ) -> Self {
        AnnotationSlice { annotation_type, ranges, payloads }
    }

    /// Returns json representation.
    pub fn to_json(&self) -> Value {
        json!({
            "type": self.annotation_type.as_str(),
            "ranges": self.ranges,
            "payloads": self.payloads,
            "n": self.ranges.len()
        })
    }
}

/// A trait for types (like `Selection`) that have a distinct representation
/// in core but are presented to the frontend as annotations.
pub trait ToAnnotation {
    /// Returns annotations that overlap the provided interval.
    fn get_annotations(&self, interval: Interval, view: &View, text: &Rope) -> AnnotationSlice;
}

/// All the annotations for a given view
pub struct AnnotationStore {
    store: HashMap<PluginId, Vec<Annotations>>,
}

impl AnnotationStore {
    pub fn new() -> Self {
        AnnotationStore { store: HashMap::new() }
    }

    /// Invalidates and removes all annotations in the range of the interval.
    pub fn invalidate(&mut self, interval: Interval) {
        self.store
            .values_mut()
            .map(|v| v.iter_mut())
            .flatten()
            .for_each(|a| a.invalidate(interval));
    }

    /// Applies an update from a plugin to a set of annotations
    pub fn update(&mut self, source: PluginId, interval: Interval, item: Annotations) {
        if !self.store.contains_key(&source) {
            self.store.insert(source, vec![item]);
            return;
        }

        let entry = self.store.get_mut(&source).unwrap();
        if let Some(annotation) =
            entry.iter_mut().find(|a| a.annotation_type == item.annotation_type)
        {
            annotation.update(interval, item.items);
        } else {
            entry.push(item);
        }
    }

    /// Returns an iterator which produces, for each type of annotation,
    /// those annotations which intersect the given interval.
    pub fn iter_range<'c>(
        &'c self,
        view: &'c View,
        text: &'c Rope,
        interval: Interval,
    ) -> impl Iterator<Item = AnnotationSlice> + 'c {
        self.store.iter().flat_map(move |(_plugin, value)| {
            value.iter().map(move |annotation| {
                // .filter() used instead of .subseq() because subseq() filters out spans with length 0
                let payloads = annotation
                    .items
                    .iter()
                    .filter(|(i, _p)| i.start() <= interval.end() && i.end() >= interval.start())
                    .map(|(_i, p)| p.clone())
                    .collect::<Vec<Value>>();

                let ranges = annotation
                    .items
                    .iter()
                    .filter(|(i, _p)| i.start() <= interval.end() && i.end() >= interval.start())
                    .map(|(i, _p)| {
                        let (start_line, start_col) = view.offset_to_line_col(text, i.start());
                        let (end_line, end_col) = view.offset_to_line_col(text, i.end());

                        AnnotationRange { start_line, start_col, end_line, end_col }
                    })
                    .collect::<Vec<AnnotationRange>>();

                AnnotationSlice {
                    annotation_type: annotation.annotation_type.clone(),
                    ranges,
                    payloads: Some(payloads),
                }
            })
        })
    }

    /// Removes any annotations provided by this plugin
    pub fn clear(&mut self, plugin: PluginId) {
        self.store.remove(&plugin);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::plugins::PluginPid;
    use crate::xi_rope::spans::SpansBuilder;

    #[test]
    fn test_annotation_range_serialization() {
        let range = AnnotationRange { start_line: 1, start_col: 3, end_line: 4, end_col: 1 };

        assert_eq!(json!(range).to_string(), "[1,3,4,1]")
    }

    #[test]
    fn test_annotation_range_deserialization() {
        let range: AnnotationRange = serde_json::from_str("[1,3,4,1]").unwrap();
        assert_eq!(range, AnnotationRange { start_line: 1, start_col: 3, end_line: 4, end_col: 1 })
    }

    #[test]
    fn test_annotation_slice_json() {
        let range = AnnotationRange { start_line: 1, start_col: 3, end_line: 4, end_col: 1 };

        let slice = AnnotationSlice {
            annotation_type: AnnotationType::Find,
            ranges: vec![range],
            payloads: None,
        };

        assert_eq!(
            slice.to_json().to_string(),
            "{\"n\":1,\"payloads\":null,\"ranges\":[[1,3,4,1]],\"type\":\"find\"}"
        )
    }

    #[test]
    fn test_annotation_store_update() {
        let mut store = AnnotationStore::new();

        let mut sb = SpansBuilder::new(10);
        sb.add_span(Interval::new(1, 5), json!(null));

        assert_eq!(store.store.len(), 0);

        store.update(
            PluginPid(1),
            Interval::new(1, 5),
            Annotations { annotation_type: AnnotationType::Find, items: sb.build() },
        );

        assert_eq!(store.store.len(), 1);

        sb = SpansBuilder::new(10);
        sb.add_span(Interval::new(6, 8), json!(null));

        store.update(
            PluginPid(2),
            Interval::new(6, 8),
            Annotations { annotation_type: AnnotationType::Find, items: sb.build() },
        );

        assert_eq!(store.store.len(), 2);
    }

    #[test]
    fn test_annotation_store_clear() {
        let mut store = AnnotationStore::new();

        let mut sb = SpansBuilder::new(10);
        sb.add_span(Interval::new(1, 5), json!(null));

        assert_eq!(store.store.len(), 0);

        store.update(
            PluginPid(1),
            Interval::new(1, 5),
            Annotations { annotation_type: AnnotationType::Find, items: sb.build() },
        );

        assert_eq!(store.store.len(), 1);

        sb = SpansBuilder::new(10);
        sb.add_span(Interval::new(6, 8), json!(null));

        store.update(
            PluginPid(2),
            Interval::new(6, 8),
            Annotations { annotation_type: AnnotationType::Find, items: sb.build() },
        );

        assert_eq!(store.store.len(), 2);

        store.clear(PluginPid(1));

        assert_eq!(store.store.len(), 1);

        store.clear(PluginPid(1));
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Utilities for detecting and working with line endings

extern crate xi_rope;

use memchr::memchr2;
use xi_rope::Rope;

/// An enumeration of valid line endings
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum LineEnding {
    CrLf, // DOS style, \r\n
    Lf,   // *nix style, \n
}

/// A struct representing a mixed line ending error.
#[derive(Debug)]
pub struct MixedLineEndingError;

impl LineEnding {
    /// Breaks a rope down into chunks, and checks each chunk for line endings
    pub fn parse(rope: &Rope) -> Result<Option<Self>, MixedLineEndingError> {
        let mut crlf = false;
        let mut lf = false;

        for chunk in rope.iter_chunks(..) {
            match LineEnding::parse_chunk(&chunk) {
                Ok(Some(LineEnding::CrLf)) => crlf = true,
                Ok(Some(LineEnding::Lf)) => lf = true,
                Ok(None) => (),
                Err(e) => return Err(e),
            }
        }

        match (crlf, lf) {
            (true, false) => Ok(Some(LineEnding::CrLf)),
            (false, true) => Ok(Some(LineEnding::Lf)),
            (false, false) => Ok(None),
            _ => Err(MixedLineEndingError),
        }
    }

    /// Checks a chunk for line endings, assuming \n or \r\n
    pub fn parse_chunk(chunk: &str) -> Result<Option<Self>, MixedLineEndingError> {
        let bytes = chunk.as_bytes();
        let newline = memchr2(b'\n', b'\r', bytes);
        match newline {
            Some(x) if bytes[x] == b'\r' && bytes.len() > x + 1 && bytes[x + 1] == b'\n' => {
                Ok(Some(LineEnding::CrLf))
            }
            Some(x) if bytes[x] == b'\n' => Ok(Some(LineEnding::Lf)),
            Some(_) => Err(MixedLineEndingError),
            _ => Ok(None),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn crlf() {
        let result = LineEnding::parse_chunk("\r\n");
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), Some(LineEnding::CrLf));
    }

    #[test]
    fn lf() {
        let result = LineEnding::parse_chunk("\n");
        assert!(result.is_ok());
        assert_eq!(result.unwrap(), Some(LineEnding::Lf));
    }

    #[test]
    fn legacy_mac_errors() {
        assert!(LineEnding::parse_chunk("\r").is_err());
    }

    #[test]
    fn bad_space() {
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Architecture for synchronizing a CRDT with the ledger. Separated into a
//! module so that it is easier to add other sync stores later.

use std::io::Write;
use std::sync::mpsc::{Receiver, RecvError, Sender};

use log;

use apps_ledger_services_public::*;
use fidl::{self, Future, Promise};
use fuchsia::read_entire_vmo;
use magenta::{Channel, ChannelOpts, HandleBase};
use serde_json;

use super::ledger::{self, ledger_crash_callback};
use tabs::{BufferContainerRef, BufferIdentifier};
use xi_rope::engine::Engine;

// TODO switch these to bincode
fn state_to_buf(state: &Engine) -> Vec<u8> {
    serde_json::to_vec(state).unwrap()
}

fn buf_to_state(buf: &[u8]) -> Result<Engine, serde_json::Error> {
    serde_json::from_slice(buf)
}

/// Stores state needed by the container to perform synchronization.
pub struct SyncStore {
    page: Page_Proxy,
    key: Vec<u8>,
    updates: Sender<SyncMsg>,
    transaction_pending: bool,
    buffer: BufferIdentifier,
}

impl SyncStore {
    /// - `page` is a reference to the Ledger page to store data under.
    /// - `key` is the key the `Syncable` managed by this `SyncStore` will be stored under.
    ///    This example only supports storing things under a single key per page.
    /// - `updates` is a channel to a `SyncUpdater` that will handle events.
    ///
    /// Returns a sync store and schedules the loading of initial
    /// state and subscribes to state updates for this document.
    pub fn new(
        mut page: Page_Proxy,
        key: Vec<u8>,
        updates: Sender<SyncMsg>,
        buffer: BufferIdentifier,
    ) -> SyncStore {
        let (s1, s2) = Channel::create(ChannelOpts::Normal).unwrap();
        let watcher_client = PageWatcher_Client::from_handle(s1.into_handle());
        let watcher_client_ptr =
            ::fidl::InterfacePtr { inner: watcher_client, version: PageWatcher_Metadata::VERSION };

        let watcher = PageWatcherServer { updates: updates.clone(), buffer: buffer.clone() };
        let _ = fidl::Server::new(watcher, s2).spawn();

        let (mut snap, snap_request) = PageSnapshot_new_pair();
        page.get_snapshot(snap_request, Some(key.clone()), Some(watcher_client_ptr))
            .with(ledger_crash_callback);

        let initial_state_chan = updates.clone();
        let initial_buffer = buffer.clone();
        snap.get(key.clone()).with(move |raw_res| {
            match raw_res.map(|res| ledger::value_result(res)) {
                Ok(Ok(Some(buf))) => {
                    initial_state_chan
                        .send(SyncMsg::NewState {
                            buffer: initial_buffer,
                            new_buf: buf,
                            done: None,
                        })
                        .unwrap();
                }
                Ok(Ok(None)) => (), // No initial state saved yet
                Err(err) => error!("FIDL failed on initial response: {:?}", err),
                Ok(Err(err)) => error!("Ledger failed to retrieve key: {:?}", err),
            }
        });

        SyncStore { page, key, updates, buffer, transaction_pending: false }
    }

    /// Called whenever this app changed its own state and would like to
    /// persist the changes to the ledger. Changes can't be committed
    /// immediately since we have to wait for PageWatcher changes that may not
    /// have arrived yet.
    pub fn state_changed(&mut self) {
        if !self.transaction_pending {
            self.transaction_pending = true;
            let ready_future = self.page.start_transaction();
            let done_chan = self.updates.clone();
            let buffer = self.buffer.clone();
            ready_future.with(move |res| match res {
                Ok(ledger::OK) => {
                    done_chan.send(SyncMsg::TransactionReady { buffer }).unwrap();
                }
                Ok(err_status) => error!("Ledger failed to start transaction: {:?}", err_status),
                Err(err) => error!("FIDL failed on starting transaction: {:?}", err),
            });
        }
    }

    /// Should be called in SyncContainer::transaction_ready to persist the current state.
    pub fn commit_transaction(&mut self, state: &Engine) {
        assert!(self.transaction_pending, "must call state_changed (and wait) before commit");
        self.page.put(self.key.clone(), state_to_buf(state)).with(ledger_crash_callback);
        self.page.commit().with(ledger_crash_callback);
        self.transaction_pending = false;
    }
}

/// All the different asynchronous events the updater thread needs to listen for and act on
pub enum SyncMsg {
    NewState {
        buffer: BufferIdentifier,
        new_buf: Vec<u8>,
        done: Option<Promise<Option<PageSnapshot_Server>, fidl::Error>>,
    },
    TransactionReady {
        buffer: BufferIdentifier,
    },
    /// Shut down the updater thread
    Stop,
}

/// We want to be able to register to receive events from inside the
/// `SyncStore`/`SyncContainer` but from there we don't have access to the
/// Mutex that holds the container, so we give channel Senders to all the
/// futures so that they can all trigger events in one place that does have
/// the right reference.
///
/// Additionally, the individual `Editor`s aren't wrapped in a `Mutex` so we
/// have to hold a `BufferContainerRef` and use `BufferIdentifier`s with one
/// `SyncUpdater` for all buffers.
pub struct SyncUpdater<W: Write> {
    container_ref: BufferContainerRef<W>,
    chan: Receiver<SyncMsg>,
}

impl<W: Write + Send + 'static> SyncUpdater<W> {
    pub fn new(container_ref: BufferContainerRef<W>, chan: Receiver<SyncMsg>) -> SyncUpdater<W> {
        SyncUpdater { container_ref, chan }
    }

    /// Run this in a thread, it will return when it encounters an error
    /// reading the channel or when the `Stop` message is recieved.
    pub fn work(&self) -> Result<(), RecvError> {
        loop {
            let msg = self.chan.recv()?;
            match msg {
                SyncMsg::Stop => return Ok(()),
                SyncMsg::TransactionReady { buffer } => {
                    let mut container = self.container_ref.lock();
                    // if the buffer was closed, hopefully the page connection was as well, which I hope aborts transactions
                    if let Some(mut editor) = container.editor_for_buffer_mut(&buffer) {
                        editor.transaction_ready();
                    }
                }
                SyncMsg::NewState { new_buf, done, buffer } => {
                    let mut container = self.container_ref.lock();
                    match (container.editor_for_buffer_mut(&buffer), buf_to_state(&new_buf)) {
                        (Some(mut editor), Ok(new_state)) => {
                            editor.merge_new_state(new_state);
                            if let Some(promise) = done {
                                promise.set_ok(None);
                            }
                        }
                        (None, _) => (), // buffer was closed
                        (_, Err(err)) => error!("Ledger was set to invalid state: {:?}", err),
                    }
                }
            }
        }
    }
}

struct PageWatcherServer {
    updates: Sender<SyncMsg>,
    buffer: BufferIdentifier,
}

impl PageWatcher for PageWatcherServer {
    fn on_change(
        &mut self,
        page_change: PageChange,
        result_state: ResultState,
    ) -> Future<Option<PageSnapshot_Server>, fidl::Error> {
        let (future, done) = Future::make_promise();

        let value_opt = page_change.changes.get(0).and_then(|c| c.value.as_ref());
        if let (ledger::RESULT_COMPLETED, Some(value_vmo)) = (result_state, value_opt) {
            let new_buf = read_entire_vmo(value_vmo).expect("failed to read key Vmo");
            self.updates
                .send(SyncMsg::NewState { buffer: self.buffer.clone(), new_buf, done: Some(done) })
                .unwrap();
        } else {
            error!("Xi state corrupted, should have one key but has multiple.");
            // I don't think this should be a FIDL-level error, so set okay
            done.set_ok(None);
        }

        future
    }
}

impl PageWatcher_Stub for PageWatcherServer {
    // Use default dispatching, but we could override it here.
}
impl_fidl_stub!(PageWatcherServer: PageWatcher_Stub);

// ============= Conflict resolution

pub fn start_conflict_resolver_factory(ledger: &mut Ledger_Proxy, key: Vec<u8>) {
    let (s1, s2) = Channel::create(ChannelOpts::Normal).unwrap();
    let resolver_client = ConflictResolverFactory_Client::from_handle(s1.into_handle());
    let resolver_client_ptr = ::fidl::InterfacePtr {
        inner: resolver_client,
        version: ConflictResolverFactory_Metadata::VERSION,
    };

    let _ = fidl::Server::new(ConflictResolverFactoryServer { key }, s2).spawn();

    ledger.set_conflict_resolver_factory(Some(resolver_client_ptr)).with(ledger_crash_callback);
}

struct ConflictResolverFactoryServer {
    key: Vec<u8>,
}

impl ConflictResolverFactory for ConflictResolverFactoryServer {
    fn get_policy(&mut self, _page_id: Vec<u8>) -> Future<MergePolicy, ::fidl::Error> {
        Future::done(Ok(MergePolicy_Custom))
    }

    /// Our resolvers are the same for every page
    fn new_conflict_resolver(&mut self, _page_id: Vec<u8>, resolver: ConflictResolver_Server) {
        let _ = fidl::Server::new(
            ConflictResolverServer { key: self.key.clone() },
            resolver.into_channel(),
        )
        .spawn();
    }
}

impl ConflictResolverFactory_Stub for ConflictResolverFactoryServer {
    // Use default dispatching, but we could override it here.
}
impl_fidl_stub!(ConflictResolverFactoryServer: ConflictResolverFactory_Stub);

fn state_from_snapshot<F>(
    snapshot: ::fidl::InterfacePtr<PageSnapshot_Client>,
    key: Vec<u8>,
    done: F,
) where
    F: Send + FnOnce(Result<Option<Engine>, ()>) + 'static,
{
    assert_eq!(PageSnapshot_Metadata::VERSION, snapshot.version);
    let mut snapshot_proxy = PageSnapshot_new_Proxy(snapshot.inner);
    // TODO get a reference when too big
    snapshot_proxy.get(key).with(move |raw_res| {
        let state = match raw_res.map(|res| ledger::value_result(res)) {
            // the .ok() has the behavior of acting like invalid state is empty
            // and thus deleting invalid state and overwriting it with good state
            Ok(Ok(Some(buf))) => Ok(buf_to_state(&buf).ok()),
            Ok(Ok(None)) => {
                info!("No state in conflicting page");
                Ok(None)
            }
            Err(err) => {
                warn!("FIDL failed on initial response: {:?}", err);
                Err(())
            }
            Ok(Err(err)) => {
                warn!("Ledger failed to retrieve key: {:?}", err);
                Err(())
            }
        };
        done(state);
    });
}

struct ConflictResolverServer {
    key: Vec<u8>,
}

impl ConflictResolver for ConflictResolverServer {
    fn resolve(
        &mut self,
        left: ::fidl::InterfacePtr<PageSnapshot_Client>,
        right: ::fidl::InterfacePtr<PageSnapshot_Client>,
        _common_version: Option<::fidl::InterfacePtr<PageSnapshot_Client>>,
        result_provider: ::fidl::InterfacePtr<MergeResultProvider_Client>,
    ) {
        // TODO in the futures-rs future, do this in parallel with Future combinators
        let key2 = self.key.clone();
        state_from_snapshot(left, self.key.clone(), move |e1_opt| {
            let key3 = key2.clone();
            state_from_snapshot(right, key2, move |e2_opt| {
                let result_opt = match (e1_opt, e2_opt) {
                    (Ok(Some(mut e1)), Ok(Some(e2))) => {
                        e1.merge(&e2);
                        Some(e1)
                    }
                    // one engine didn't exist yet, I'm not sure if Ledger actually generates a conflict in this case
                    (Ok(Some(e)), Ok(None)) | (Ok(None), Ok(Some(e))) => Some(e),
                    // failed to get one of the engines, we can't do the merge properly
                    (Err(()), _) | (_, Err(())) => None,
                    // if state is invalid or missing on both sides, can't merge
                    (Ok(None), Ok(None)) => None,
                };
                if let Some(out_state) = result_opt {
                    let buf = state_to_buf(&out_state);
                    // TODO use a reference here when buf is too big
                    let new_value = Some(Box::new(BytesOrReference::Bytes(buf)));
                    let merged = MergedValue {
                        key: key3,
                        source: ValueSource_New,
                        new_value,
                        priority: Priority_Eager,
                    };
                    assert_eq!(MergeResultProvider_Metadata::VERSION, result_provider.version);
                    let mut result_provider_proxy =
                        MergeResultProvider_new_Proxy(result_provider.inner);
                    result_provider_proxy.merge(vec![merged]);
                    result_provider_proxy.done().with(ledger_crash_callback);
                }
            });
        });
    }
}

impl ConflictResolver_Stub for ConflictResolverServer {
    // Use default dispatching, but we could override it here.
}
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

pub mod ledger;
pub mod sync;

use magenta::{Status, Vmo};

// TODO: move this into magenta-rs?
pub fn read_entire_vmo(vmo: &Vmo) -> Result<Vec<u8>, Status> {
    let size = vmo.get_size()?;
    // TODO: how fishy is this cast to usize?
    let mut buffer: Vec<u8> = Vec::with_capacity(size as usize);
    // TODO: consider using unsafe .set_len() to get uninitialized memory
    for _ in 0..size {
        buffer.push(0);
    }
    let bytes_read = vmo.read(buffer.as_mut_slice(), 0)?;
    buffer.truncate(bytes_read);
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Utility functions to make it easier to work with Ledger in Rust
// TODO merge with equivalent module in fuchsia/rust_ledger_example into a library?

use apps_ledger_services_public::*;
use fidl::Error;
use fuchsia::read_entire_vmo;
use magenta::{self, Vmo};
use sha2::{Digest, Sha256};

// Rust emits a warning if matched-on constants aren't all-caps
pub const OK: Status = Status_Ok;
pub const KEY_NOT_FOUND: Status = Status_KeyNotFound;
pub const NEEDS_FETCH: Status = Status_NeedsFetch;
pub const RESULT_COMPLETED: ResultState = ResultState_Completed;

pub fn ledger_crash_callback(res: Result<Status, Error>) {
    let status = res.expect("ledger call failed to respond with a status");
    assert_eq!(status, Status_Ok, "ledger call failed");
}

#[derive(Debug)]
pub enum ValueError {
    NeedsFetch,
    LedgerFail(Status),
    Vmo(magenta::Status),
}

/// Convert the low level result of getting a key from the ledger into a
/// higher level Rust representation.
pub fn value_result(res: (Status, Option<Vmo>)) -> Result<Option<Vec<u8>>, ValueError> {
    match res {
        (OK, Some(vmo)) => {
            let buffer = read_entire_vmo(&vmo).map_err(ValueError::Vmo)?;
            Ok(Some(buffer))
        }
        (KEY_NOT_FOUND, _) => Ok(None),
        (NEEDS_FETCH, _) => Err(ValueError::NeedsFetch),
        (status, _) => Err(ValueError::LedgerFail(status)),
    }
}

/// Ledger page ids are exactly 16 bytes, so we need a way of determining
/// a unique 16 byte ID that won't collide based on some data we have
pub fn gen_page_id(input_data: &[u8]) -> [u8; 16] {
    let mut hasher = Sha256::default();
    hasher.input(input_data);
    let full_hash = hasher.result();
    let full_slice = full_hash.as_slice();

    // magic incantation to get the first 16 bytes of the hash
    let mut arr: [u8; 16] = Default::default();
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! The main library for xi-core.

#![allow(
    clippy::boxed_local,
    clippy::cast_lossless,
    clippy::collapsible_if,
    clippy::let_and_return,
    clippy::map_entry,
    clippy::match_as_ref,
    clippy::match_bool,
    clippy::needless_pass_by_value,
    clippy::new_without_default,
    clippy::or_fun_call,
    clippy::ptr_arg,
    clippy::too_many_arguments,
    clippy::unreadable_literal,
    clippy::get_unwrap
)]

#[macro_use]
extern crate log;
extern crate regex;
extern crate serde;
#[macro_use]
extern crate serde_json;
#[macro_use]
extern crate serde_derive;
extern crate memchr;
#[cfg(feature = "notify")]
extern crate notify;
extern crate syntect;
extern crate time;
extern crate toml;

extern crate xi_rope;
extern crate xi_rpc;
extern crate xi_trace;
extern crate xi_unicode;

#[cfg(feature = "ledger")]
mod ledger_includes {
    extern crate fuchsia_zircon;
    extern crate fuchsia_zircon_sys;
    extern crate mxruntime;
    #[macro_use]
    extern crate fidl;
    extern crate apps_ledger_services_public;
    extern crate sha2;
}
#[cfg(feature = "ledger")]
use ledger_includes::*;

pub mod annotations;
pub mod backspace;
pub mod client;
pub mod config;
pub mod core;
pub mod edit_ops;
pub mod edit_types;
pub mod editor;
pub mod event_context;
pub mod file;
pub mod find;
#[cfg(feature = "ledger")]
pub mod fuchsia;
pub mod index_set;
pub mod layers;
pub mod line_cache_shadow;
pub mod line_ending;
pub mod line_offset;
pub mod linewrap;
pub mod movement;
pub mod plugins;
pub mod recorder;
pub mod selection;
pub mod styles;
pub mod syntax;
pub mod tabs;
pub mod view;
#[cfg(feature = "notify")]
pub mod watcher;
pub mod whitespace;
pub mod width_cache;
pub mod word_boundaries;

pub mod rpc;

#[cfg(feature = "ledger")]
use apps_ledger_services_public::Ledger_Proxy;

pub use crate::config::{BufferItems as BufferConfig, Table as ConfigTable};
pub use crate::core::{WeakXiCore, XiCore};
pub use crate::editor::EditType;
pub use crate::plugins::manifest as plugin_manifest;
pub use crate::plugins::rpc as plugin_rpc;
pub use crate::plugins::PluginPid;
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Management of styles.

use std::collections::{BTreeMap, HashMap, HashSet};
use std::ffi::OsStr;
use std::fmt;
use std::fs;
use std::iter::FromIterator;
use std::path::{Path, PathBuf};

use serde_json::{self, Value};
use syntect::dumps::{dump_to_file, from_dump_file};
use syntect::highlighting::StyleModifier as SynStyleModifier;
use syntect::highlighting::{Color, Highlighter, Theme, ThemeSet};
use syntect::LoadingError;

pub use syntect::highlighting::ThemeSettings;

pub const N_RESERVED_STYLES: usize = 8;
const SYNTAX_PRIORITY_DEFAULT: u16 = 200;
const SYNTAX_PRIORITY_LOWEST: u16 = 0;
pub const DEFAULT_THEME: &str = "InspiredGitHub";

#[derive(Clone, PartialEq, Eq, Default, Hash, Serialize, Deserialize)]
/// A mergeable style. All values except priority are optional.
///
/// Note: A `None` value represents the absense of preference; in the case of
/// boolean options, `Some(false)` means that this style will override a lower
/// priority value in the same field.
pub struct Style {
    /// The priority of this style, in the range (0, 1000). Used to resolve
    /// conflicting fields when merging styles. The higher priority wins.
    #[serde(skip_serializing)]
    pub priority: u16,
    /// The foreground text color, in ARGB.
    pub fg_color: Option<u32>,
    /// The background text color, in ARGB.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub bg_color: Option<u32>,
    /// The font-weight, in the range 100-900, interpreted like the CSS
    /// font-weight property.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub weight: Option<u16>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub underline: Option<bool>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub italic: Option<bool>,
}

impl Style {
    /// Creates a new `Style` by converting from a `Syntect::StyleModifier`.
    pub fn from_syntect_style_mod(style: &SynStyleModifier) -> Self {
        let font_style = style.font_style.map(|s| s.bits()).unwrap_or_default();
        let weight = if (font_style & 1) != 0 { Some(700) } else { None };
        let underline = if (font_style & 2) != 0 { Some(true) } else { None };
        let italic = if (font_style & 4) != 0 { Some(true) } else { None };

        Self::new(
            SYNTAX_PRIORITY_DEFAULT,
            style.foreground.map(Self::rgba_from_syntect_color),
            style.background.map(Self::rgba_from_syntect_color),
            weight,
            underline,
            italic,
        )
    }

    pub fn new<O32, O16, OB>(
        priority: u16,
        fg_color: O32,
        bg_color: O32,
        weight: O16,
        underline: OB,
        italic: OB,
    ) -> Self
    where
        O32: Into<Option<u32>>,
        O16: Into<Option<u16>>,
        OB: Into<Option<bool>>,
    {
        assert!(priority <= 1000);
        Style {
            priority,
            fg_color: fg_color.into(),
            bg_color: bg_color.into(),
            weight: weight.into(),
            underline: underline.into(),
            italic: italic.into(),
        }
    }

    /// Returns the default style for the given `Theme`.
    pub fn default_for_theme(theme: &Theme) -> Self {
        let fg = theme.settings.foreground.unwrap_or(Color::BLACK);
        Style::new(
            SYNTAX_PRIORITY_LOWEST,
            Some(Self::rgba_from_syntect_color(fg)),
            None,
            None,
            None,
            None,
        )
    }

    /// Creates a new style by combining attributes of `self` and `other`.
    /// If both styles define an attribute, the highest priority wins; `other`
    /// wins in the case of a tie.
    ///
    /// Note: when merging multiple styles, apply them in increasing priority.
    pub fn merge(&self, other: &Style) -> Style {
        let (p1, p2) = if self.priority > other.priority { (self, other) } else { (other, self) };

        Style::new(
            p1.priority,
            p1.fg_color.or(p2.fg_color),
            p1.bg_color.or(p2.bg_color),
            p1.weight.or(p2.weight),
            p1.underline.or(p2.underline),
            p1.italic.or(p2.italic),
        )
    }

    /// Encode this `Style`, setting the `id` property.
    ///
    /// Note: this should only be used when sending the `def_style` RPC.
    pub fn to_json(&self, id: usize) -> Value {
        let mut as_val = serde_json::to_value(self).expect("failed to encode style");
        as_val["id"] = id.into();
        as_val
    }

    fn rgba_from_syntect_color(color: Color) -> u32 {
        let Color { r, g, b, a } = color;
        ((a as u32) << 24) | ((r as u32) << 16) | ((g as u32) << 8) | (b as u32)
    }
}

/// A map from styles to client identifiers for a given `Theme`.
pub struct ThemeStyleMap {
    themes: ThemeSet,
    theme_name: String,
    theme: Theme,

    // Keeps a list of default themes.
    default_themes: Vec<String>,
    default_style: Style,
    map: HashMap<Style, usize>,

    // Maintains the map of found themes and their paths.
    path_map: BTreeMap<String, PathBuf>,

    // It's not obvious we actually have to store the style, we seem to only need it
    // as the key in the map.
    styles: Vec<Style>,
    themes_dir: Option<PathBuf>,
    cache_dir: Option<PathBuf>,
    caching_enabled: bool,
}

impl ThemeStyleMap {
    pub fn new(themes_dir: Option<PathBuf>) -> ThemeStyleMap {
        let themes = ThemeSet::load_defaults();
        let theme_name = DEFAULT_THEME.to_owned();
        let theme = themes.themes.get(&theme_name).expect("missing theme").to_owned();
        let default_themes = themes.themes.keys().cloned().collect();
        let default_style = Style::default_for_theme(&theme);
        let cache_dir = None;
        let caching_enabled = true;

        ThemeStyleMap {
            themes,
            theme_name,
            theme,
            default_themes,
            default_style,
            map: HashMap::new(),
            path_map: BTreeMap::new(),
            styles: Vec::new(),
            themes_dir,
            cache_dir,
            caching_enabled,
        }
    }

    pub fn get_default_style(&self) -> &Style {
        &self.default_style
    }

    pub fn get_highlighter(&self) -> Highlighter {
        Highlighter::new(&self.theme)
    }

    pub fn get_theme_name(&self) -> &str {
        &self.theme_name
    }

    pub fn get_theme_settings(&self) -> &ThemeSettings {
        &self.theme.settings
    }

    pub fn get_theme_names(&self) -> Vec<String> {
        self.path_map.keys().chain(self.default_themes.iter()).cloned().collect()
    }

    pub fn contains_theme(&self, k: &str) -> bool {
        self.themes.themes.contains_key(k)
    }

    pub fn set_theme(&mut self, theme_name: &str) -> Result<(), &'static str> {
        match self.load_theme(theme_name) {
            Ok(()) => {
                if let Some(new_theme) = self.themes.themes.get(theme_name) {
                    self.theme = new_theme.to_owned();
                    self.theme_name = theme_name.to_owned();
                    self.default_style = Style::default_for_theme(&self.theme);
                    self.map = HashMap::new();
                    self.styles = Vec::new();
                    Ok(())
                } else {
                    Err("unknown theme")
                }
            }
            Err(e) => {
                error!("Encountered error {:?} while trying to load {:?}", e, theme_name);
                Err("could not load theme")
            }
        }
    }

    pub fn merge_with_default(&self, style: &Style) -> Style {
        self.default_style.merge(style)
    }

    pub fn lookup(&self, style: &Style) -> Option<usize> {
        self.map.get(style).cloned()
    }

    pub fn add(&mut self, style: &Style) -> usize {
        let result = self.styles.len() + N_RESERVED_STYLES;
        self.map.insert(style.clone(), result);
        self.styles.push(style.clone());
        result
    }

    /// Delete key and the corresponding dump file from the themes map.
    pub(crate) fn remove_theme(&mut self, path: &Path) -> Option<String> {
        validate_theme_file(path).ok()?;

        let theme_name = path.file_stem().and_then(OsStr::to_str)?;
        self.themes.themes.remove(theme_name);
        self.path_map.remove(theme_name);

        let dump_p = self.get_dump_path(theme_name)?;
        if dump_p.exists() {
            let _ = fs::remove_file(dump_p);
        }

        Some(theme_name.to_string())
    }

    /// Cache all themes names and their paths inside the given directory.
    pub(crate) fn load_theme_dir(&mut self) {
        if let Some(themes_dir) = self.themes_dir.clone() {
            match ThemeSet::discover_theme_paths(themes_dir) {
                Ok(themes) => {
                    self.caching_enabled = self.caching_enabled && self.init_cache_dir();
                    // We look through the theme folder here and cache their names/paths to a
                    // path hashmap.
                    for theme_p in &themes {
                        match self.load_theme_info_from_path(theme_p) {
                            Ok(_) => (),
                            Err(e) => {
                                error!("Encountered error {:?} loading theme at {:?}", e, theme_p)
                            }
                        }
                    }
                }
                Err(e) => error!("Error loading themes dir: {:?}", e),
            }
        }
    }

    /// A wrapper around `from_dump_file`
    /// to validate the state of dump file.
    /// Invalidates if mod time of dump is less
    /// than the original one.
    fn try_load_from_dump(&self, theme_p: &Path) -> Option<(String, Theme)> {
        if !self.caching_enabled {
            return None;
        }

        let theme_name = theme_p.file_stem().and_then(OsStr::to_str)?;

        let dump_p = self.get_dump_path(theme_name)?;

        if !&dump_p.exists() {
            return None;
        }

        //NOTE: `try_load_from_dump` will return `None` if the file at
        //`dump_p` or `theme_p` is deleted before the execution of this fn.
        let mod_t = fs::metadata(&dump_p).and_then(|md| md.modified()).ok()?;
        let mod_t_orig = fs::metadata(theme_p).and_then(|md| md.modified()).ok()?;

        if mod_t >= mod_t_orig {
            from_dump_file(&dump_p).ok().map(|t| (theme_name.to_owned(), t))
        } else {
            // Delete dump file
            let _ = fs::remove_file(&dump_p);
            None
        }
    }

    /// Loads a theme's name and its respective path into the theme path map.
    pub(crate) fn load_theme_info_from_path(
        &mut self,
        theme_p: &Path,
    ) -> Result<String, LoadingError> {
        validate_theme_file(theme_p)?;
        let theme_name =
            theme_p.file_stem().and_then(OsStr::to_str).ok_or(LoadingError::BadPath)?;

        self.path_map.insert(theme_name.to_string(), theme_p.to_path_buf());

        Ok(theme_name.to_owned())
    }

    /// Loads theme using syntect's `get_theme` fn to our `theme` path map.
    /// Stores binary dump in a file with `tmdump` extension, only if
    /// caching is enabled.
    fn load_theme(&mut self, theme_name: &str) -> Result<(), LoadingError> {
        // If it is the current theme (the user has edited it), we load it again.
        // Otherwise, if it's a default theme or the theme has already been loaded, we can move on.
        if self.contains_theme(theme_name) && self.get_theme_name() != theme_name {
            return Ok(());
        }
        // If we haven't loaded the theme before, we try to load it from the dump if a dump
        // exists or load it from the theme file itself.
        let theme_p = &self.path_map.get(theme_name).cloned();
        if let Some(theme_p) = theme_p {
            match self.try_load_from_dump(theme_p) {
                Some((dump_theme_name, dump_theme_data)) => {
                    self.insert_to_map(dump_theme_name, dump_theme_data);
                }
                None => {
                    let theme = ThemeSet::get_theme(theme_p)?;
                    if self.caching_enabled {
                        if let Some(dump_p) = self.get_dump_path(theme_name) {
                            let _ = dump_to_file(&theme, dump_p);
                        }
                    }
                    self.insert_to_map(theme_name.to_owned(), theme);
                }
            }
            Ok(())
        } else {
            Err(LoadingError::BadPath)
        }
    }

    fn insert_to_map(&mut self, k: String, v: Theme) {
        self.themes.themes.insert(k, v);
    }

    /// Returns dump's path corresponding to the given theme name.
    fn get_dump_path(&self, theme_name: &str) -> Option<PathBuf> {
        self.cache_dir.as_ref().map(|p| p.join(theme_name).with_extension("tmdump"))
    }

    /// Compare the stored file paths in `self.state`
    /// to the present ones.
    pub(crate) fn sync_dir(&mut self, dir: Option<&Path>) {
        if let Some(themes_dir) = dir {
            if let Ok(paths) = ThemeSet::discover_theme_paths(themes_dir) {
                let current_state: HashSet<PathBuf> = HashSet::from_iter(paths.into_iter());
                let maintained_state: HashSet<PathBuf> =
                    HashSet::from_iter(self.path_map.values().cloned());

                let to_insert = current_state.difference(&maintained_state);
                for path in to_insert {
                    let _ = self.load_theme_info_from_path(path);
                }
                let to_remove = maintained_state.difference(&current_state);
                for path in to_remove {
                    self.remove_theme(path);
                }
            }
        }
    }
    /// Creates the cache dir returns true
    /// if it is successfully initialized or
    /// already exists.
    fn init_cache_dir(&mut self) -> bool {
        self.cache_dir = self.themes_dir.clone().map(|p| p.join("cache"));

        if let Some(ref p) = self.cache_dir {
            if p.exists() {
                return true;
            }
            fs::DirBuilder::new().create(&p).is_ok()
        } else {
            false
        }
    }
}

/// Used to remove files with extension other than `tmTheme`.
fn validate_theme_file(path: &Path) -> Result<bool, LoadingError> {
    path.extension().map(|e| e != "tmTheme").ok_or(LoadingError::BadPath)
}

impl fmt::Debug for Style {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        fn fmt_color(f: &mut fmt::Formatter, c: Option<u32>) -> fmt::Result {
            if let Some(c) = c {
                write!(f, "#{:X}", c)
            } else {
                write!(f, "None")
            }
        }

        write!(f, "Style( P{}, fg: ", self.priority)?;
        fmt_color(f, self.fg_color)?;
        write!(f, " bg: ")?;
        fmt_color(f, self.bg_color)?;

        if let Some(w) = self.weight {
            write!(f, " weight {}", w)?;
        }
        if let Some(i) = self.italic {
            write!(f, " ital: {}", i)?;
        }
        if let Some(u) = self.underline {
            write!(f, " uline: {}", u)?;
        }
        write!(f, " )")
    }
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A bunch of boilerplate for converting the `EditNotification`s we receive
//! from the client into the events we use internally.
//!
//! This simplifies code elsewhere, and makes it easier to route events to
//! the editor or view as appropriate.

use crate::movement::Movement;
use crate::rpc::{
    EditNotification, FindQuery, GestureType, LineRange, MouseAction, Position,
    SelectionGranularity, SelectionModifier,
};
use crate::view::Size;

/// Events that only modify view state
#[derive(Debug, PartialEq, Clone)]
pub(crate) enum ViewEvent {
    Move(Movement),
    ModifySelection(Movement),
    SelectAll,
    Scroll(LineRange),
    AddSelectionAbove,
    AddSelectionBelow,
    Click(MouseAction),
    Drag(MouseAction),
    Gesture { line: u64, col: u64, ty: GestureType },
    GotoLine { line: u64 },
    Find { chars: String, case_sensitive: bool, regex: bool, whole_words: bool },
    MultiFind { queries: Vec<FindQuery> },
    FindNext { wrap_around: bool, allow_same: bool, modify_selection: SelectionModifier },
    FindPrevious { wrap_around: bool, allow_same: bool, modify_selection: SelectionModifier },
    FindAll,
    HighlightFind { visible: bool },
    SelectionForFind { case_sensitive: bool },
    Replace { chars: String, preserve_case: bool },
    SelectionForReplace,
    SelectionIntoLines,
    CollapseSelections,
}

/// Events that modify the buffer
#[derive(Debug, PartialEq, Clone)]
pub(crate) enum BufferEvent {
    Delete { movement: Movement, kill: bool },
    Backspace,
    Transpose,
    Undo,
    Redo,
    Uppercase,
    Lowercase,
    Capitalize,
    Indent,
    Outdent,
    Insert(String),
    Paste(String),
    InsertNewline,
    InsertTab,
    Yank,
    ReplaceNext,
    ReplaceAll,
    DuplicateLine,
    IncreaseNumber,
    DecreaseNumber,
}

/// An event that needs special handling
#[derive(Debug, PartialEq, Clone)]
pub(crate) enum SpecialEvent {
    DebugRewrap,
    DebugWrapWidth,
    DebugPrintSpans,
    Resize(Size),
    RequestLines(LineRange),
    RequestHover { request_id: usize, position: Option<Position> },
    DebugToggleComment,
    Reindent,
    ToggleRecording(Option<String>),
    PlayRecording(String),
    ClearRecording(String),
}

#[derive(Debug, PartialEq, Clone)]
pub(crate) enum EventDomain {
    View(ViewEvent),
    Buffer(BufferEvent),
    Special(SpecialEvent),
}

impl From<BufferEvent> for EventDomain {
    fn from(src: BufferEvent) -> EventDomain {
        EventDomain::Buffer(src)
    }
}

impl From<ViewEvent> for EventDomain {
    fn from(src: ViewEvent) -> EventDomain {
        EventDomain::View(src)
    }
}

impl From<SpecialEvent> for EventDomain {
    fn from(src: SpecialEvent) -> EventDomain {
        EventDomain::Special(src)
    }
}

#[rustfmt::skip]
impl From<EditNotification> for EventDomain {
    fn from(src: EditNotification) -> EventDomain {
        use self::EditNotification::*;
        match src {
            Insert { chars } =>
                BufferEvent::Insert(chars).into(),
            Paste { chars } =>
                BufferEvent::Paste(chars).into(),
            DeleteForward =>
                BufferEvent::Delete {
                    movement: Movement::Right,
                    kill: false
                }.into(),
            DeleteBackward =>
                BufferEvent::Backspace.into(),
            DeleteWordForward =>
                BufferEvent::Delete {
                    movement: Movement::RightWord,
                    kill: false
                }.into(),
            DeleteWordBackward =>
                BufferEvent::Delete {
                    movement: Movement::LeftWord,
                    kill: false
                }.into(),
            DeleteToEndOfParagraph =>
                BufferEvent::Delete {
                    movement: Movement::EndOfParagraphKill,
                    kill: true
                }.into(),
            DeleteToBeginningOfLine =>
                BufferEvent::Delete {
                    movement: Movement::LeftOfLine,
                    kill: false
                }.into(),
            InsertNewline =>
                BufferEvent::InsertNewline.into(),
            InsertTab =>
                BufferEvent::InsertTab.into(),
            MoveUp =>
                ViewEvent::Move(Movement::Up).into(),
            MoveUpAndModifySelection =>
                ViewEvent::ModifySelection(Movement::Up).into(),
            MoveDown =>
                ViewEvent::Move(Movement::Down).into(),
            MoveDownAndModifySelection =>
                ViewEvent::ModifySelection(Movement::Down).into(),
            MoveLeft | MoveBackward =>
                ViewEvent::Move(Movement::Left).into(),
            MoveLeftAndModifySelection =>
                ViewEvent::ModifySelection(Movement::Left).into(),
            MoveRight | MoveForward  =>
                ViewEvent::Move(Movement::Right).into(),
            MoveRightAndModifySelection =>
                ViewEvent::ModifySelection(Movement::Right).into(),
            MoveWordLeft =>
                ViewEvent::Move(Movement::LeftWord).into(),
            MoveWordLeftAndModifySelection =>
                ViewEvent::ModifySelection(Movement::LeftWord).into(),
            MoveWordRight =>
                ViewEvent::Move(Movement::RightWord).into(),
            MoveWordRightAndModifySelection =>
                ViewEvent::ModifySelection(Movement::RightWord).into(),
            MoveToBeginningOfParagraph =>
                ViewEvent::Move(Movement::StartOfParagraph).into(),
            MoveToBeginningOfParagraphAndModifySelection =>
                ViewEvent::ModifySelection(Movement::StartOfParagraph).into(),
            MoveToEndOfParagraph =>
                ViewEvent::Move(Movement::EndOfParagraph).into(),
            MoveToEndOfParagraphAndModifySelection =>
                ViewEvent::ModifySelection(Movement::EndOfParagraph).into(),
            MoveToLeftEndOfLine =>
                ViewEvent::Move(Movement::LeftOfLine).into(),
            MoveToLeftEndOfLineAndModifySelection =>
                ViewEvent::ModifySelection(Movement::LeftOfLine).into(),
            MoveToRightEndOfLine =>
                ViewEvent::Move(Movement::RightOfLine).into(),
            MoveToRightEndOfLineAndModifySelection =>
                ViewEvent::ModifySelection(Movement::RightOfLine).into(),
            MoveToBeginningOfDocument =>
                ViewEvent::Move(Movement::StartOfDocument).into(),
            MoveToBeginningOfDocumentAndModifySelection =>
                ViewEvent::ModifySelection(Movement::StartOfDocument).into(),
            MoveToEndOfDocument =>
                ViewEvent::Move(Movement::EndOfDocument).into(),
            MoveToEndOfDocumentAndModifySelection =>
                ViewEvent::ModifySelection(Movement::EndOfDocument).into(),
            ScrollPageUp =>
                ViewEvent::Move(Movement::UpPage).into(),
            PageUpAndModifySelection =>
                ViewEvent::ModifySelection(Movement::UpPage).into(),
            ScrollPageDown =>
                ViewEvent::Move(Movement::DownPage).into(),
            PageDownAndModifySelection =>
                ViewEvent::ModifySelection(Movement::DownPage).into(),
            SelectAll => ViewEvent::SelectAll.into(),
            AddSelectionAbove => ViewEvent::AddSelectionAbove.into(),
            AddSelectionBelow => ViewEvent::AddSelectionBelow.into(),
            Scroll(range) => ViewEvent::Scroll(range).into(),
            Resize(size) => SpecialEvent::Resize(size).into(),
            GotoLine { line } => ViewEvent::GotoLine { line }.into(),
            RequestLines(range) => SpecialEvent::RequestLines(range).into(),
            Yank => BufferEvent::Yank.into(),
            Transpose => BufferEvent::Transpose.into(),
            Click(action) => ViewEvent::Click(action).into(),
            Drag(action) => ViewEvent::Drag(action).into(),
            Gesture { line, col,  ty } => {
                // Translate deprecated gesture types into the new format
                let new_ty = match ty {
                    GestureType::PointSelect => {
                        warn!("The point_select gesture is deprecated; use select instead");
                        GestureType::Select {granularity: SelectionGranularity::Point, multi: false}
                    }
                    GestureType::ToggleSel => {
                        warn!("The toggle_sel gesture is deprecated; use select instead");
                        GestureType::Select { granularity: SelectionGranularity::Point, multi: true}
                    }
                    GestureType::WordSelect => {
                        warn!("The word_select gesture is deprecated; use select instead");
                        GestureType::Select { granularity: SelectionGranularity::Word, multi: false}
                    }
                    GestureType::MultiWordSelect => {
                        warn!("The multi_word_select gesture is deprecated; use select instead");
                        GestureType::Select { granularity: SelectionGranularity::Word, multi: true}
                    }
                    GestureType::LineSelect => {
                        warn!("The line_select gesture is deprecated; use select instead");
                        GestureType::Select { granularity: SelectionGranularity::Line, multi: false}
                    }
                    GestureType::MultiLineSelect => {
                        warn!("The multi_line_select gesture is deprecated; use select instead");
                        GestureType::Select { granularity: SelectionGranularity::Line, multi: true}
                    }
                    GestureType::RangeSelect => {
                        warn!("The range_select gesture is deprecated; use select_extend instead");
                        GestureType::SelectExtend { granularity: SelectionGranularity::Point }
                    }
                    _ => ty
                };
                ViewEvent::Gesture { line, col, ty: new_ty }.into()
            },
            Undo => BufferEvent::Undo.into(),
            Redo => BufferEvent::Redo.into(),
            Find { chars, case_sensitive, regex, whole_words } =>
                ViewEvent::Find { chars, case_sensitive, regex, whole_words }.into(),
            MultiFind { queries } =>
                ViewEvent::MultiFind { queries }.into(),
            FindNext { wrap_around, allow_same, modify_selection } =>
                ViewEvent::FindNext { wrap_around, allow_same, modify_selection }.into(),
            FindPrevious { wrap_around, allow_same, modify_selection } =>
                ViewEvent::FindPrevious { wrap_around, allow_same, modify_selection }.into(),
            FindAll => ViewEvent::FindAll.into(),
            DebugRewrap => SpecialEvent::DebugRewrap.into(),
            DebugWrapWidth => SpecialEvent::DebugWrapWidth.into(),
            DebugPrintSpans => SpecialEvent::DebugPrintSpans.into(),
            Uppercase => BufferEvent::Uppercase.into(),
            Lowercase => BufferEvent::Lowercase.into(),
            Capitalize => BufferEvent::Capitalize.into(),
            Indent => BufferEvent::Indent.into(),
            Outdent => BufferEvent::Outdent.into(),
            Reindent => SpecialEvent::Reindent.into(),
            DebugToggleComment => SpecialEvent::DebugToggleComment.into(),
            HighlightFind { visible } => ViewEvent::HighlightFind { visible }.into(),
            SelectionForFind { case_sensitive } =>
                ViewEvent::SelectionForFind { case_sensitive }.into(),
            Replace { chars, preserve_case } =>
                ViewEvent::Replace { chars, preserve_case }.into(),
            ReplaceNext => BufferEvent::ReplaceNext.into(),
            ReplaceAll => BufferEvent::ReplaceAll.into(),
            SelectionForReplace => ViewEvent::SelectionForReplace.into(),
            RequestHover { request_id, position } =>
                SpecialEvent::RequestHover { request_id, position }.into(),
            SelectionIntoLines => ViewEvent::SelectionIntoLines.into(),
            DuplicateLine => BufferEvent::DuplicateLine.into(),
            IncreaseNumber => BufferEvent::IncreaseNumber.into(),
            DecreaseNumber => BufferEvent::DecreaseNumber.into(),
            ToggleRecording { recording_name } => SpecialEvent::ToggleRecording(recording_name).into(),
            PlayRecording { recording_name } => SpecialEvent::PlayRecording(recording_name).into(),
            ClearRecording { recording_name } => SpecialEvent::ClearRecording(recording_name).into(),
            CollapseSelections => ViewEvent::CollapseSelections.into(),
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Data structures representing (multiple) selections and cursors.

use std::cmp::{max, min};
use std::fmt;
use std::ops::Deref;

use crate::annotations::{AnnotationRange, AnnotationSlice, AnnotationType, ToAnnotation};
use crate::index_set::remove_n_at;
use crate::line_offset::LineOffset;
use crate::view::View;
use xi_rope::{Interval, Rope, RopeDelta, Transformer};

/// A type representing horizontal measurements. This is currently in units
/// that are not very well defined except that ASCII characters count as
/// 1 each. It will change.
pub type HorizPos = usize;

/// Indicates if an edit should try to drift inside or outside nearby selections. If the selection
/// is zero width, that is, it is a caret, this value will be ignored, the equivalent of the
/// `Default` value.
#[derive(Copy, Clone)]
pub enum InsertDrift {
    /// Indicates this edit should happen within any (non-caret) selections if possible.
    Inside,
    /// Indicates this edit should happen outside any selections if possible.
    Outside,
    /// Indicates to do whatever the `after` bool says to do
    Default,
}

/// A set of zero or more selection regions, representing a selection state.
#[derive(Default, Debug, Clone)]
pub struct Selection {
    // An invariant: regions[i].max() <= regions[i+1].min()
    // and < if either is_caret()
    regions: Vec<SelRegion>,
}

impl Selection {
    /// Creates a new empty selection.
    pub fn new() -> Selection {
        Selection::default()
    }

    /// Creates a selection with a single region.
    pub fn new_simple(region: SelRegion) -> Selection {
        Selection { regions: vec![region] }
    }

    /// Clear the selection.
    pub fn clear(&mut self) {
        self.regions.clear();
    }

    /// Collapse all selections into a single caret.
    pub fn collapse(&mut self) {
        self.regions.truncate(1);
        self.regions[0].start = self.regions[0].end;
    }

    // The smallest index so that offset > region.max() for all preceding
    // regions.
    pub fn search(&self, offset: usize) -> usize {
        if self.regions.is_empty() || offset > self.regions.last().unwrap().max() {
            return self.regions.len();
        }
        match self.regions.binary_search_by(|r| r.max().cmp(&offset)) {
            Ok(ix) => ix,
            Err(ix) => ix,
        }
    }

    /// Add a region to the selection. This method implements merging logic.
    ///
    /// Two non-caret regions merge if their interiors intersect; merely
    /// touching at the edges does not cause a merge. A caret merges with
    /// a non-caret if it is in the interior or on either edge. Two carets
    /// merge if they are the same offset.
    ///
    /// Performance note: should be O(1) if the new region strictly comes
    /// after all the others in the selection, otherwise O(n).
    pub fn add_region(&mut self, region: SelRegion) {
        let mut ix = self.search(region.min());
        if ix == self.regions.len() {
            self.regions.push(region);
            return;
        }
        let mut region = region;
        let mut end_ix = ix;
        if self.regions[ix].min() <= region.min() {
            if self.regions[ix].should_merge(region) {
                region = region.merge_with(self.regions[ix]);
            } else {
                ix += 1;
            }
            end_ix += 1;
        }
        while end_ix < self.regions.len() && region.should_merge(self.regions[end_ix]) {
            region = region.merge_with(self.regions[end_ix]);
            end_ix += 1;
        }
        if ix == end_ix {
            self.regions.insert(ix, region);
        } else {
            self.regions[ix] = region;
            remove_n_at(&mut self.regions, ix + 1, end_ix - ix - 1);
        }
    }

    /// Gets a slice of regions that intersect the given range. Regions that
    /// merely touch the range at the edges are also included, so it is the
    /// caller's responsibility to further trim them, in particular to only
    /// display one caret in the upstream/downstream cases.
    ///
    /// Performance note: O(log n).
    pub fn regions_in_range(&self, start: usize, end: usize) -> &[SelRegion] {
        let first = self.search(start);
        let mut last = self.search(end);
        if last < self.regions.len() && self.regions[last].min() <= end {
            last += 1;
        }
        &self.regions[first..last]
    }

    /// Deletes all the regions that intersect or (if delete_adjacent = true) touch the given range.
    pub fn delete_range(&mut self, start: usize, end: usize, delete_adjacent: bool) {
        let mut first = self.search(start);
        let mut last = self.search(end);
        if first >= self.regions.len() {
            return;
        }
        if !delete_adjacent && self.regions[first].max() == start {
            first += 1;
        }
        if last < self.regions.len()
            && ((delete_adjacent && self.regions[last].min() <= end)
                || (!delete_adjacent && self.regions[last].min() < end))
        {
            last += 1;
        }
        remove_n_at(&mut self.regions, first, last - first);
    }

    /// Add a region to the selection. This method does not merge regions and does not allow
    /// ambiguous regions (regions that overlap).
    ///
    /// On ambiguous regions, the region with the lower start position wins. That is, in such a
    /// case, the new region is either not added at all, because there is an ambiguous region with
    /// a lower start position, or existing regions that intersect with the new region but do
    /// not start before the new region, are deleted.
    pub fn add_range_distinct(&mut self, region: SelRegion) -> (usize, usize) {
        let mut ix = self.search(region.min());

        if ix < self.regions.len() && self.regions[ix].max() == region.min() {
            ix += 1;
        }

        if ix < self.regions.len() {
            // in case of ambiguous regions the region closer to the left wins
            let occ = &self.regions[ix];
            let is_eq = occ.min() == region.min() && occ.max() == region.max();
            let is_intersect_before = region.min() >= occ.min() && occ.max() > region.min();
            if is_eq || is_intersect_before {
                return (occ.min(), occ.max());
            }
        }

        // delete ambiguous regions to the right
        let mut last = self.search(region.max());
        if last < self.regions.len() && self.regions[last].min() < region.max() {
            last += 1;
        }
        remove_n_at(&mut self.regions, ix, last - ix);

        if ix == self.regions.len() {
            self.regions.push(region);
        } else {
            self.regions.insert(ix, region);
        }

        (self.regions[ix].min(), self.regions[ix].max())
    }

    /// Computes a new selection based on applying a delta to the old selection.
    ///
    /// When new text is inserted at a caret, the new caret can be either before
    /// or after the inserted text, depending on the `after` parameter.
    ///
    /// Whether or not the preceding selections are restored depends on the keep_selections
    /// value (only set to true on transpose).
    pub fn apply_delta(&self, delta: &RopeDelta, after: bool, drift: InsertDrift) -> Selection {
        let mut result = Selection::new();
        let mut transformer = Transformer::new(delta);
        for region in self.iter() {
            let is_caret = region.start == region.end;
            let is_region_forward = region.start < region.end;

            let (start_after, end_after) = match (drift, is_caret) {
                (InsertDrift::Inside, false) => (!is_region_forward, is_region_forward),
                (InsertDrift::Outside, false) => (is_region_forward, !is_region_forward),
                _ => (after, after),
            };

            let new_region = SelRegion::new(
                transformer.transform(region.start, start_after),
                transformer.transform(region.end, end_after),
            )
            .with_affinity(region.affinity);
            result.add_region(new_region);
        }
        result
    }
}

/// Implementing the `ToAnnotation` trait allows to convert selections to annotations.
impl ToAnnotation for Selection {
    fn get_annotations(&self, interval: Interval, view: &View, text: &Rope) -> AnnotationSlice {
        let regions = self.regions_in_range(interval.start(), interval.end());
        let ranges = regions
            .iter()
            .map(|region| {
                let (start_line, start_col) = view.offset_to_line_col(text, region.min());
                let (end_line, end_col) = view.offset_to_line_col(text, region.max());

                AnnotationRange { start_line, start_col, end_line, end_col }
            })
            .collect::<Vec<AnnotationRange>>();
        AnnotationSlice::new(AnnotationType::Selection, ranges, None)
    }
}

/// Implementing the Deref trait allows callers to easily test `is_empty`, iterate
/// through all ranges, etc.
impl Deref for Selection {
    type Target = [SelRegion];

    fn deref(&self) -> &[SelRegion] {
        &self.regions
    }
}

/// The "affinity" of a cursor which is sitting exactly on a line break.
///
/// We say "cursor" here rather than "caret" because (depending on presentation)
/// the front-end may draw a cursor even when the region is not a caret.
#[derive(Clone, Copy, PartialEq, Eq, Debug)]
pub enum Affinity {
    /// The cursor should be displayed downstream of the line break. For
    /// example, if the buffer is "abcd", and the cursor is on a line break
    /// after "ab", it should be displayed on the second line before "cd".
    Downstream,
    /// The cursor should be displayed upstream of the line break. For
    /// example, if the buffer is "abcd", and the cursor is on a line break
    /// after "ab", it should be displayed on the previous line after "ab".
    Upstream,
}

impl Default for Affinity {
    fn default() -> Affinity {
        Affinity::Downstream
    }
}

/// A type representing a single contiguous region of a selection. We use the
/// term "caret" (sometimes also "cursor", more loosely) to refer to a selection
/// region with an empty interior. A "non-caret region" is one with a non-empty
/// interior (i.e. `start != end`).
#[derive(Clone, Copy, PartialEq, Eq, Debug)]
pub struct SelRegion {
    /// The inactive edge of a selection, as a byte offset. When
    /// equal to end, the selection range acts as a caret.
    pub start: usize,

    /// The active edge of a selection, as a byte offset.
    pub end: usize,

    /// A saved horizontal position (used primarily for line up/down movement).
    pub horiz: Option<HorizPos>,

    /// The affinity of the cursor.
    pub affinity: Affinity,
}

impl SelRegion {
    /// Returns a new region.
    pub fn new(start: usize, end: usize) -> Self {
        Self { start, end, horiz: None, affinity: Affinity::default() }
    }

    /// Returns a new caret region (`start == end`).
    pub fn caret(pos: usize) -> Self {
        Self { start: pos, end: pos, horiz: None, affinity: Affinity::default() }
    }

    /// Returns a region with the given horizontal position.
    pub fn with_horiz(self, horiz: Option<HorizPos>) -> Self {
        Self { horiz, ..self }
    }

    /// Returns a region with the given affinity.
    pub fn with_affinity(self, affinity: Affinity) -> Self {
        Self { affinity, ..self }
    }

    /// Gets the earliest offset within the region, ie the minimum of both edges.
    pub fn min(self) -> usize {
        min(self.start, self.end)
    }

    /// Gets the latest offset within the region, ie the maximum of both edges.
    pub fn max(self) -> usize {
        max(self.start, self.end)
    }

    /// Determines whether the region is a caret (ie has an empty interior).
    pub fn is_caret(self) -> bool {
        self.start == self.end
    }

    /// Determines whether the region's affinity is upstream.
    pub fn is_upstream(self) -> bool {
        self.affinity == Affinity::Upstream
    }

    // Indicate whether this region should merge with the next.
    // Assumption: regions are sorted (self.min() <= other.min())
    fn should_merge(self, other: SelRegion) -> bool {
        other.min() < self.max()
            || ((self.is_caret() || other.is_caret()) && other.min() == self.max())
    }

    // Merge self with an overlapping region.
    // Retains direction of self.
    fn merge_with(self, other: SelRegion) -> SelRegion {
        let is_forward = self.end >= self.start;
        let new_min = min(self.min(), other.min());
        let new_max = max(self.max(), other.max());
        let (start, end) = if is_forward { (new_min, new_max) } else { (new_max, new_min) };
        // Could try to preserve horiz/affinity from one of the
        // sources, but very likely not worth it.
        SelRegion::new(start, end)
    }
}

impl<'a> From<&'a SelRegion> for Interval {
    fn from(src: &'a SelRegion) -> Interval {
        Interval::new(src.min(), src.max())
    }
}

impl From<Interval> for SelRegion {
    fn from(src: Interval) -> SelRegion {
        SelRegion::new(src.start, src.end)
    }
}

impl From<SelRegion> for Selection {
    fn from(region: SelRegion) -> Self {
        Self::new_simple(region)
    }
}

impl fmt::Display for Selection {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.regions.len() == 1 {
            self.regions[0].fmt(f)?;
        } else {
            write!(f, "[ {}", &self.regions[0])?;
            for region in &self.regions[1..] {
                write!(f, ", {}", region)?;
            }
            write!(f, " ]")?;
        }
        Ok(())
    }
}

impl fmt::Display for SelRegion {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if self.is_caret() {
            write!(f, "{}|", self.start)?;
        } else if self.start < self.end {
            write!(f, "{}..{}|", self.start, self.end)?;
        } else {
            write!(f, "|{}..{}", self.end, self.start)?;
        }
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::{InsertDrift, SelRegion, Selection};
    use std::ops::Deref;
    use xi_rope::{DeltaBuilder, Interval};

    fn r(start: usize, end: usize) -> SelRegion {
        SelRegion::new(start, end)
    }

    #[test]
    fn empty() {
        let s = Selection::new();
        assert!(s.is_empty());
        assert_eq!(s.deref(), &[]);
    }

    #[test]
    fn simple_region() {
        let s = Selection::new_simple(r(3, 5));
        assert!(!s.is_empty());
        assert_eq!(s.deref(), &[r(3, 5)]);
    }

    #[test]
    fn from_selregion() {
        let s: Selection = r(3, 5).into();
        assert!(!s.is_empty());
        assert_eq!(s.deref(), &[r(3, 5)]);
    }

    #[test]
    fn delete_range() {
        let mut s = Selection::new_simple(r(3, 5));
        s.delete_range(1, 2, true);
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.delete_range(1, 3, false);
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.delete_range(1, 3, true);
        assert_eq!(s.deref(), &[]);

        let mut s = Selection::new_simple(r(3, 5));
        s.delete_range(5, 6, false);
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.delete_range(5, 6, true);
        assert_eq!(s.deref(), &[]);

        let mut s = Selection::new_simple(r(3, 5));
        s.delete_range(2, 4, false);
        assert_eq!(s.deref(), &[]);
        assert_eq!(s.deref(), &[]);

        let mut s = Selection::new();
        s.add_region(r(3, 5));
        s.add_region(r(7, 8));
        s.delete_range(2, 10, false);
        assert_eq!(s.deref(), &[]);
    }

    #[test]
    fn simple_regions_in_range() {
        let s = Selection::new_simple(r(3, 5));
        assert_eq!(s.regions_in_range(0, 1), &[]);
        assert_eq!(s.regions_in_range(0, 2), &[]);
        assert_eq!(s.regions_in_range(0, 3), &[r(3, 5)]);
        assert_eq!(s.regions_in_range(0, 4), &[r(3, 5)]);
        assert_eq!(s.regions_in_range(5, 6), &[r(3, 5)]);
        assert_eq!(s.regions_in_range(6, 7), &[]);
    }

    #[test]
    fn caret_regions_in_range() {
        let s = Selection::new_simple(r(4, 4));
        assert_eq!(s.regions_in_range(0, 1), &[]);
        assert_eq!(s.regions_in_range(0, 2), &[]);
        assert_eq!(s.regions_in_range(0, 3), &[]);
        assert_eq!(s.regions_in_range(0, 4), &[r(4, 4)]);
        assert_eq!(s.regions_in_range(4, 4), &[r(4, 4)]);
        assert_eq!(s.regions_in_range(4, 5), &[r(4, 4)]);
        assert_eq!(s.regions_in_range(5, 6), &[]);
    }

    #[test]
    fn merge_regions() {
        let mut s = Selection::new();
        s.add_region(r(3, 5));
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.add_region(r(7, 9));
        assert_eq!(s.deref(), &[r(3, 5), r(7, 9)]);
        s.add_region(r(1, 3));
        assert_eq!(s.deref(), &[r(1, 3), r(3, 5), r(7, 9)]);
        s.add_region(r(4, 6));
        assert_eq!(s.deref(), &[r(1, 3), r(3, 6), r(7, 9)]);
        s.add_region(r(2, 8));
        assert_eq!(s.deref(), &[r(1, 9)]);
        s.add_region(r(10, 8));
        assert_eq!(s.deref(), &[r(10, 1)]);

        s.clear();
        assert_eq!(s.deref(), &[]);
        s.add_region(r(1, 4));
        s.add_region(r(4, 5));
        s.add_region(r(5, 6));
        s.add_region(r(6, 9));
        assert_eq!(s.deref(), &[r(1, 4), r(4, 5), r(5, 6), r(6, 9)]);
        s.add_region(r(2, 8));
        assert_eq!(s.deref(), &[r(1, 9)]);
    }

    #[test]
    fn merge_carets() {
        let mut s = Selection::new();
        s.add_region(r(1, 1));
        assert_eq!(s.deref(), &[r(1, 1)]);
        s.add_region(r(3, 3));
        assert_eq!(s.deref(), &[r(1, 1), r(3, 3)]);
        s.add_region(r(2, 2));
        assert_eq!(s.deref(), &[r(1, 1), r(2, 2), r(3, 3)]);
        s.add_region(r(1, 1));
        assert_eq!(s.deref(), &[r(1, 1), r(2, 2), r(3, 3)]);
    }

    #[test]
    fn merge_region_caret() {
        let mut s = Selection::new();
        s.add_region(r(3, 5));
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.add_region(r(3, 3));
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.add_region(r(4, 4));
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.add_region(r(5, 5));
        assert_eq!(s.deref(), &[r(3, 5)]);
        s.add_region(r(6, 6));
        assert_eq!(s.deref(), &[r(3, 5), r(6, 6)]);
    }

    #[test]
    fn merge_reverse() {
        let mut s = Selection::new();
        s.add_region(r(5, 3));
        assert_eq!(s.deref(), &[r(5, 3)]);
        s.add_region(r(9, 7));
        assert_eq!(s.deref(), &[r(5, 3), r(9, 7)]);
        s.add_region(r(3, 1));
        assert_eq!(s.deref(), &[r(3, 1), r(5, 3), r(9, 7)]);
        s.add_region(r(6, 4));
        assert_eq!(s.deref(), &[r(3, 1), r(6, 3), r(9, 7)]);
        s.add_region(r(8, 2));
        assert_eq!(s.deref(), &[r(9, 1)]);
    }

    #[test]
    fn apply_delta_outside_drift() {
        let mut s = Selection::new();
        s.add_region(r(0, 4));
        s.add_region(r(4, 8));
        assert_eq!(s.deref(), &[r(0, 4), r(4, 8)]);

        // simulate outside edit between two adjacent selections
        // like "texthere!" -> "text here!"
        // the space should be outside the selections
        let mut builder = DeltaBuilder::new("texthere!".len());
        builder.replace(Interval::new(4, 4), " ".into());
        let s2 = s.apply_delta(&builder.build(), true, InsertDrift::Outside);

        assert_eq!(s2.deref(), &[r(0, 4), r(5, 9)]);
    }

    #[test]
    fn apply_delta_inside_drift() {
        let mut s = Selection::new();
        s.add_region(r(1, 2));
        assert_eq!(s.deref(), &[r(1, 2)]);

        // simulate inside edit on either end of selection
        // like "abc" -> "abbbc"
        // if b was selected at beginning, inside edit should cause all bs to be selected after
        let mut builder = DeltaBuilder::new("abc".len());
        builder.replace(Interval::new(1, 1), "b".into());
        builder.replace(Interval::new(2, 2), "b".into());
        let s2 = s.apply_delta(&builder.build(), true, InsertDrift::Inside);

        assert_eq!(s2.deref(), &[r(1, 4)]);
    }

    #[test]
    fn apply_delta_drift_ignored_for_carets() {
        let mut s = Selection::new();
        s.add_region(r(1, 1));
        assert_eq!(s.deref(), &[r(1, 1)]);

        let mut builder = DeltaBuilder::new("ab".len());
        builder.replace(Interval::new(1, 1), "b".into());
        let s2 = s.apply_delta(&builder.build(), true, InsertDrift::Inside);
        assert_eq!(s2.deref(), &[r(2, 2)]);

        let mut builder = DeltaBuilder::new("ab".len());
        builder.replace(Interval::new(1, 1), "b".into());
        let s3 = s.apply_delta(&builder.build(), false, InsertDrift::Inside);
        assert_eq!(s3.deref(), &[r(1, 1)]);
    }

    #[test]
    fn display() {
        let mut s = Selection::new();
        s.add_region(r(1, 1));
        assert_eq!(s.to_string(), "1|");
        s.add_region(r(3, 5));
        s.add_region(r(8, 6));
        assert_eq!(s.to_string(), "[ 1|, 3..5|, |6..8 ]");
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Interactions with the file system.

use std::collections::HashMap;
use std::ffi::OsString;
use std::fmt;
use std::fs::{self, File};
use std::io::{self, Read, Write};
use std::path::{Path, PathBuf};
use std::str;
use std::time::SystemTime;

use xi_rope::Rope;
use xi_rpc::RemoteError;

use crate::tabs::BufferId;

#[cfg(feature = "notify")]
use crate::tabs::OPEN_FILE_EVENT_TOKEN;
#[cfg(feature = "notify")]
use crate::watcher::FileWatcher;
#[cfg(target_family = "unix")]
use std::{fs::Permissions, os::unix::fs::PermissionsExt};

const UTF8_BOM: &str = "\u{feff}";

/// Tracks all state related to open files.
pub struct FileManager {
    open_files: HashMap<PathBuf, BufferId>,
    file_info: HashMap<BufferId, FileInfo>,
    /// A monitor of filesystem events, for things like reloading changed files.
    #[cfg(feature = "notify")]
    watcher: FileWatcher,
}

#[derive(Debug)]
pub struct FileInfo {
    pub encoding: CharacterEncoding,
    pub path: PathBuf,
    pub mod_time: Option<SystemTime>,
    pub has_changed: bool,
    #[cfg(target_family = "unix")]
    pub permissions: Option<u32>,
}

pub enum FileError {
    Io(io::Error, PathBuf),
    UnknownEncoding(PathBuf),
    HasChanged(PathBuf),
}

#[derive(Debug, Clone, Copy)]
pub enum CharacterEncoding {
    Utf8,
    Utf8WithBom,
}

impl FileManager {
    #[cfg(feature = "notify")]
    pub fn new(watcher: FileWatcher) -> Self {
        FileManager { open_files: HashMap::new(), file_info: HashMap::new(), watcher }
    }

    #[cfg(not(feature = "notify"))]
    pub fn new() -> Self {
        FileManager { open_files: HashMap::new(), file_info: HashMap::new() }
    }

    #[cfg(feature = "notify")]
    pub fn watcher(&mut self) -> &mut FileWatcher {
        &mut self.watcher
    }

    pub fn get_info(&self, id: BufferId) -> Option<&FileInfo> {
        self.file_info.get(&id)
    }

    pub fn get_editor(&self, path: &Path) -> Option<BufferId> {
        self.open_files.get(path).cloned()
    }

    /// Returns `true` if this file is open and has changed on disk.
    /// This state is stashed.
    pub fn check_file(&mut self, path: &Path, id: BufferId) -> bool {
        if let Some(info) = self.file_info.get_mut(&id) {
            let mod_t = get_mod_time(path);
            if mod_t != info.mod_time {
                info.has_changed = true
            }
            return info.has_changed;
        }
        false
    }

    pub fn open(&mut self, path: &Path, id: BufferId) -> Result<Rope, FileError> {
        if !path.exists() {
            return Ok(Rope::from(""));
        }

        let (rope, info) = try_load_file(path)?;

        self.open_files.insert(path.to_owned(), id);
        if self.file_info.insert(id, info).is_none() {
            #[cfg(feature = "notify")]
            self.watcher.watch(path, false, OPEN_FILE_EVENT_TOKEN);
        }
        Ok(rope)
    }

    pub fn close(&mut self, id: BufferId) {
        if let Some(info) = self.file_info.remove(&id) {
            self.open_files.remove(&info.path);
            #[cfg(feature = "notify")]
            self.watcher.unwatch(&info.path, OPEN_FILE_EVENT_TOKEN);
        }
    }

    pub fn save(&mut self, path: &Path, text: &Rope, id: BufferId) -> Result<(), FileError> {
        let is_existing = self.file_info.contains_key(&id);
        if is_existing {
            self.save_existing(path, text, id)
        } else {
            self.save_new(path, text, id)
        }
    }

    fn save_new(&mut self, path: &Path, text: &Rope, id: BufferId) -> Result<(), FileError> {
        try_save(path, text, CharacterEncoding::Utf8, self.get_info(id))
            .map_err(|e| FileError::Io(e, path.to_owned()))?;
        let info = FileInfo {
            encoding: CharacterEncoding::Utf8,
            path: path.to_owned(),
            mod_time: get_mod_time(path),
            has_changed: false,
            #[cfg(target_family = "unix")]
            permissions: get_permissions(path),
        };
        self.open_files.insert(path.to_owned(), id);
        self.file_info.insert(id, info);
        #[cfg(feature = "notify")]
        self.watcher.watch(path, false, OPEN_FILE_EVENT_TOKEN);
        Ok(())
    }

    fn save_existing(&mut self, path: &Path, text: &Rope, id: BufferId) -> Result<(), FileError> {
        let prev_path = self.file_info[&id].path.clone();
        if prev_path != path {
            self.save_new(path, text, id)?;
            self.open_files.remove(&prev_path);
            #[cfg(feature = "notify")]
            self.watcher.unwatch(&prev_path, OPEN_FILE_EVENT_TOKEN);
        } else if self.file_info[&id].has_changed {
            return Err(FileError::HasChanged(path.to_owned()));
        } else {
            let encoding = self.file_info[&id].encoding;
            try_save(path, text, encoding, self.get_info(id))
                .map_err(|e| FileError::Io(e, path.to_owned()))?;
            self.file_info.get_mut(&id).unwrap().mod_time = get_mod_time(path);
        }
        Ok(())
    }
}

fn try_load_file<P>(path: P) -> Result<(Rope, FileInfo), FileError>
where
    P: AsRef<Path>,
{
    // TODO: support for non-utf8
    // it's arguable that the rope crate should have file loading functionality
    let mut f =
        File::open(path.as_ref()).map_err(|e| FileError::Io(e, path.as_ref().to_owned()))?;
    let mut bytes = Vec::new();
    f.read_to_end(&mut bytes).map_err(|e| FileError::Io(e, path.as_ref().to_owned()))?;

    let encoding = CharacterEncoding::guess(&bytes);
    let rope = try_decode(bytes, encoding, path.as_ref())?;
    let info = FileInfo {
        encoding,
        mod_time: get_mod_time(&path),
        #[cfg(target_family = "unix")]
        permissions: get_permissions(&path),
        path: path.as_ref().to_owned(),
        has_changed: false,
    };
    Ok((rope, info))
}

#[allow(unused)]
fn try_save(
    path: &Path,
    text: &Rope,
    encoding: CharacterEncoding,
    file_info: Option<&FileInfo>,
) -> io::Result<()> {
    let tmp_extension = path.extension().map_or_else(
        || OsString::from("swp"),
        |ext| {
            let mut ext = ext.to_os_string();
            ext.push(".swp");
            ext
        },
    );
    let tmp_path = &path.with_extension(tmp_extension);

    let mut f = File::create(tmp_path)?;
    match encoding {
        CharacterEncoding::Utf8WithBom => f.write_all(UTF8_BOM.as_bytes())?,
        CharacterEncoding::Utf8 => (),
    }

    for chunk in text.iter_chunks(..text.len()) {
        f.write_all(chunk.as_bytes())?;
    }

    fs::rename(tmp_path, path)?;

    #[cfg(target_family = "unix")]
    {
        if let Some(info) = file_info {
            fs::set_permissions(path, Permissions::from_mode(info.permissions.unwrap_or(0o644)))
                .unwrap_or_else(|e| {
                    warn!("Couldn't set permissions on file {} due to error {}", path.display(), e)
                });
        }
    }

    Ok(())
}

fn try_decode(bytes: Vec<u8>, encoding: CharacterEncoding, path: &Path) -> Result<Rope, FileError> {
    match encoding {
        CharacterEncoding::Utf8 => Ok(Rope::from(
            str::from_utf8(&bytes).map_err(|_e| FileError::UnknownEncoding(path.to_owned()))?,
        )),
        CharacterEncoding::Utf8WithBom => {
            let s = String::from_utf8(bytes)
                .map_err(|_e| FileError::UnknownEncoding(path.to_owned()))?;
            Ok(Rope::from(&s[UTF8_BOM.len()..]))
        }
    }
}

impl CharacterEncoding {
    fn guess(s: &[u8]) -> Self {
        if s.starts_with(UTF8_BOM.as_bytes()) {
            CharacterEncoding::Utf8WithBom
        } else {
            CharacterEncoding::Utf8
        }
    }
}

/// Returns the modification timestamp for the file at a given path,
/// if present.
fn get_mod_time<P: AsRef<Path>>(path: P) -> Option<SystemTime> {
    File::open(path).and_then(|f| f.metadata()).and_then(|meta| meta.modified()).ok()
}

/// Returns the file permissions for the file at a given path on UNIXy systems,
/// if present.
#[cfg(target_family = "unix")]
fn get_permissions<P: AsRef<Path>>(path: P) -> Option<u32> {
    File::open(path).and_then(|f| f.metadata()).map(|meta| meta.permissions().mode()).ok()
}

impl From<FileError> for RemoteError {
    fn from(src: FileError) -> RemoteError {
        //TODO: when we migrate to using the failure crate for error handling,
        // this should return a better message
        let code = src.error_code();
        let message = src.to_string();
        RemoteError::custom(code, message, None)
    }
}

impl FileError {
    fn error_code(&self) -> i64 {
        match self {
            FileError::Io(_, _) => 5,
            FileError::UnknownEncoding(_) => 6,
            FileError::HasChanged(_) => 7,
        }
    }
}

impl fmt::Display for FileError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            FileError::Io(ref e, ref p) => write!(f, "{}. File path: {:?}", e, p),
            FileError::UnknownEncoding(ref p) => write!(f, "Error decoding file: {:?}", p),
            FileError::HasChanged(ref p) => write!(
                f,
                "File has changed on disk. \
                 Please save elsewhere and reload the file. File path: {:?}",
                p
            ),
        }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Data structures for tracking the state of the front-end's line cache
//! and preparing render plans to update it.

use std::cmp::{max, min};
use std::fmt;

const SCROLL_SLOP: usize = 2;
const PRESERVE_EXTENT: usize = 1000;

/// The line cache shadow tracks the state of the line cache in the front-end.
/// Any content marked as valid here is up-to-date in the current state of the
/// view. Also, if `dirty` is false, then the entire line cache is valid.
#[derive(Debug)]
pub struct LineCacheShadow {
    spans: Vec<Span>,
    dirty: bool,
}

type Validity = u8;

pub const INVALID: Validity = 0;
pub const TEXT_VALID: Validity = 1;
pub const STYLES_VALID: Validity = 2;
pub const CURSOR_VALID: Validity = 4;
pub const ALL_VALID: Validity = 7;

pub struct Span {
    /// Number of lines in this span. Units are visual lines in the
    /// current state of the view.
    pub n: usize,
    /// Starting line number. Units are visual lines in the front end's
    /// current cache state (i.e. the last one rendered). Note: this is
    /// irrelevant if validity is 0.
    pub start_line_num: usize,
    /// Validity of lines in this span, consisting of the above constants or'ed.
    pub validity: Validity,
}

/// Builder for `LineCacheShadow` object.
pub struct Builder {
    spans: Vec<Span>,
    dirty: bool,
}

#[derive(Clone, Copy, PartialEq)]
pub enum RenderTactic {
    /// Discard all content for this span. Used to keep storage reasonable.
    Discard,
    /// Preserve existing content.
    Preserve,
    /// Render content if it is invalid.
    Render,
}

pub struct RenderPlan {
    /// Each span is a number of lines and a tactic.
    pub spans: Vec<(usize, RenderTactic)>,
}

pub struct PlanIterator<'a> {
    lc_shadow: &'a LineCacheShadow,
    plan: &'a RenderPlan,
    shadow_ix: usize,
    shadow_line_num: usize,
    plan_ix: usize,
    plan_line_num: usize,
}

pub struct PlanSegment {
    /// Line number of start of segment, visual lines in current view state.
    pub our_line_num: usize,
    /// Line number of start of segment, visual lines in client's cache, if validity != 0.
    pub their_line_num: usize,
    /// Number of visual lines in this segment.
    pub n: usize,
    /// Validity of this segment in client's cache.
    pub validity: Validity,
    /// Tactic for rendering this segment.
    pub tactic: RenderTactic,
}

impl Builder {
    pub fn new() -> Builder {
        Builder { spans: Vec::new(), dirty: false }
    }

    pub fn build(self) -> LineCacheShadow {
        LineCacheShadow { spans: self.spans, dirty: self.dirty }
    }

    pub fn add_span(&mut self, n: usize, start_line_num: usize, validity: Validity) {
        if n > 0 {
            if let Some(last) = self.spans.last_mut() {
                if last.validity == validity
                    && (validity == INVALID || last.start_line_num + last.n == start_line_num)
                {
                    last.n += n;
                    return;
                }
            }
            self.spans.push(Span { n, start_line_num, validity });
        }
    }

    pub fn set_dirty(&mut self, dirty: bool) {
        self.dirty = dirty;
    }
}

impl LineCacheShadow {
    pub fn edit(&mut self, start: usize, end: usize, replace: usize) {
        let mut b = Builder::new();
        let mut line_num = 0;
        let mut i = 0;
        while i < self.spans.len() {
            let span = &self.spans[i];
            if line_num + span.n <= start {
                b.add_span(span.n, span.start_line_num, span.validity);
                line_num += span.n;
                i += 1;
            } else {
                b.add_span(start - line_num, span.start_line_num, span.validity);
                break;
            }
        }
        b.add_span(replace, 0, INVALID);
        for span in &self.spans[i..] {
            if line_num + span.n > end {
                let offset = end.saturating_sub(line_num);
                b.add_span(span.n - offset, span.start_line_num + offset, span.validity);
            }
            line_num += span.n;
        }
        b.set_dirty(true);
        *self = b.build();
    }

    pub fn partial_invalidate(&mut self, start: usize, end: usize, invalid: Validity) {
        let mut clean = true;
        let mut line_num = 0;
        for span in &self.spans {
            if start < line_num + span.n && end > line_num && (span.validity & invalid) != 0 {
                clean = false;
                break;
            }
            line_num += span.n;
        }
        if clean {
            return;
        }

        let mut b = Builder::new();
        let mut line_num = 0;
        for span in &self.spans {
            if start > line_num {
                b.add_span(min(span.n, start - line_num), span.start_line_num, span.validity);
            }
            let invalid_start = max(start, line_num);
            let invalid_end = min(end, line_num + span.n);
            if invalid_end > invalid_start {
                b.add_span(
                    invalid_end - invalid_start,
                    span.start_line_num + (invalid_start - line_num),
                    span.validity & !invalid,
                );
            }
            if line_num + span.n > end {
                let offset = end.saturating_sub(line_num);
                b.add_span(span.n - offset, span.start_line_num + offset, span.validity);
            }
            line_num += span.n;
        }
        b.set_dirty(true);
        *self = b.build();
    }

    pub fn needs_render(&self, plan: &RenderPlan) -> bool {
        self.dirty
            || self
                .iter_with_plan(plan)
                .any(|seg| seg.tactic == RenderTactic::Render && seg.validity != ALL_VALID)
    }

    pub fn spans(&self) -> &[Span] {
        &self.spans
    }

    pub fn iter_with_plan<'a>(&'a self, plan: &'a RenderPlan) -> PlanIterator<'a> {
        PlanIterator {
            lc_shadow: self,
            plan,
            shadow_ix: 0,
            shadow_line_num: 0,
            plan_ix: 0,
            plan_line_num: 0,
        }
    }
}

impl Default for LineCacheShadow {
    fn default() -> LineCacheShadow {
        Builder::new().build()
    }
}

impl<'a> Iterator for PlanIterator<'a> {
    type Item = PlanSegment;

    fn next(&mut self) -> Option<PlanSegment> {
        if self.shadow_ix == self.lc_shadow.spans.len() || self.plan_ix == self.plan.spans.len() {
            return None;
        }
        let shadow_span = &self.lc_shadow.spans[self.shadow_ix];
        let plan_span = &self.plan.spans[self.plan_ix];
        let start = max(self.shadow_line_num, self.plan_line_num);
        let end = min(self.shadow_line_num + shadow_span.n, self.plan_line_num + plan_span.0);
        let result = PlanSegment {
            our_line_num: start,
            their_line_num: shadow_span.start_line_num + (start - self.shadow_line_num),
            n: end - start,
            validity: shadow_span.validity,
            tactic: plan_span.1,
        };

        if end == self.shadow_line_num + shadow_span.n {
            self.shadow_line_num = end;
            self.shadow_ix += 1;
        }
        if end == self.plan_line_num + plan_span.0 {
            self.plan_line_num = end;
            self.plan_ix += 1;
        }
        Some(result)
    }
}

impl RenderPlan {
    /// This function implements the policy of what to discard, what to preserve, and
    /// what to render.
    pub fn create(total_height: usize, first_line: usize, height: usize) -> RenderPlan {
        let mut spans = Vec::new();
        let mut last = 0;
        let first_line = min(first_line, total_height);
        if first_line > PRESERVE_EXTENT {
            last = first_line - PRESERVE_EXTENT;
            spans.push((last, RenderTactic::Discard));
        }
        if first_line > SCROLL_SLOP {
            let n = first_line - SCROLL_SLOP - last;
            spans.push((n, RenderTactic::Preserve));
            last += n;
        }
        let render_end = min(first_line + height + SCROLL_SLOP, total_height);
        spans.push((render_end - last, RenderTactic::Render));
        last = render_end;
        let preserve_end = min(first_line + height + PRESERVE_EXTENT, total_height);
        if preserve_end > last {
            spans.push((preserve_end - last, RenderTactic::Preserve));
            last = preserve_end;
        }
        if total_height > last {
            spans.push((total_height - last, RenderTactic::Discard));
        }
        RenderPlan { spans }
    }

    /// Upgrade a range of lines to the "Render" tactic.
    pub fn request_lines(&mut self, start: usize, end: usize) {
        let mut spans: Vec<(usize, RenderTactic)> = Vec::new();
        let mut i = 0;
        let mut line_num = 0;
        while i < self.spans.len() {
            let span = &self.spans[i];
            if line_num + span.0 <= start {
                spans.push(*span);
                line_num += span.0;
                i += 1;
            } else {
                if line_num < start {
                    spans.push((start - line_num, span.1));
                }
                break;
            }
        }
        spans.push((end - start, RenderTactic::Render));
        for span in &self.spans[i..] {
            if line_num + span.0 > end {
                let offset = end.saturating_sub(line_num);
                spans.push((span.0 - offset, span.1));
            }
            line_num += span.0;
        }
        self.spans = spans;
    }
}

impl fmt::Debug for Span {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        let validity = match self.validity {
            TEXT_VALID => "text",
            ALL_VALID => "all",
            _other => "mixed",
        };
        if self.validity == INVALID {
            write!(f, "({} invalid)", self.n)?;
        } else {
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Keeping track of available plugins.

use std::collections::HashMap;
use std::fs;
use std::io::{self, Read};
use std::path::{Path, PathBuf};
use std::sync::Arc;

use super::{PluginDescription, PluginName};
use crate::config::table_from_toml_str;
use crate::syntax::Languages;

/// A catalog of all available plugins.
#[derive(Debug, Clone, Default)]
pub struct PluginCatalog {
    items: HashMap<PluginName, Arc<PluginDescription>>,
    locations: HashMap<PathBuf, Arc<PluginDescription>>,
}

/// Errors that can occur while trying to load a plugin.
#[derive(Debug)]
pub enum PluginLoadError {
    Io(io::Error),
    /// Malformed manifest
    Parse(toml::de::Error),
}

#[allow(dead_code)]
impl<'a> PluginCatalog {
    /// Loads any plugins discovered in these paths, replacing any existing
    /// plugins.
    pub fn reload_from_paths(&mut self, paths: &[PathBuf]) {
        self.items.clear();
        self.locations.clear();
        self.load_from_paths(paths);
    }

    /// Loads plugins from paths and adds them to existing plugins.
    pub fn load_from_paths(&mut self, paths: &[PathBuf]) {
        let all_manifests = find_all_manifests(paths);
        for manifest_path in &all_manifests {
            match load_manifest(manifest_path) {
                Err(e) => warn!("error loading plugin {:?}", e),
                Ok(manifest) => {
                    info!("loaded {}", manifest.name);
                    let manifest = Arc::new(manifest);
                    self.items.insert(manifest.name.clone(), manifest.clone());
                    self.locations.insert(manifest_path.clone(), manifest);
                }
            }
        }
    }

    pub fn make_languages_map(&self) -> Languages {
        let all_langs =
            self.items.values().flat_map(|plug| plug.languages.iter().cloned()).collect::<Vec<_>>();
        Languages::new(all_langs.as_slice())
    }

    /// Returns an iterator over all plugins in the catalog, in arbitrary order.
    pub fn iter(&'a self) -> impl Iterator<Item = Arc<PluginDescription>> + 'a {
        self.items.values().cloned()
    }

    /// Returns an iterator over all plugin names in the catalog,
    /// in arbitrary order.
    pub fn iter_names(&'a self) -> impl Iterator<Item = &'a PluginName> {
        self.items.keys()
    }

    /// Returns the plugin located at the provided file path.
    pub fn get_from_path(&self, path: &PathBuf) -> Option<Arc<PluginDescription>> {
        self.items
            .values()
            .find(|&v| v.exec_path.to_str().unwrap().contains(path.to_str().unwrap()))
            .cloned()
    }

    /// Returns a reference to the named plugin if it exists in the catalog.
    pub fn get_named(&self, plugin_name: &str) -> Option<Arc<PluginDescription>> {
        self.items.get(plugin_name).map(Arc::clone)
    }

    /// Removes the named plugin.
    pub fn remove_named(&mut self, plugin_name: &str) {
        self.items.remove(plugin_name);
    }
}

fn find_all_manifests(paths: &[PathBuf]) -> Vec<PathBuf> {
    let mut manifest_paths = Vec::new();
    for path in paths.iter() {
        let manif_path = path.join("manifest.toml");
        if manif_path.exists() {
            manifest_paths.push(manif_path);
            continue;
        }

        let result = path.read_dir().map(|dir| {
            dir.flat_map(|item| item.map(|p| p.path()).ok())
                .map(|dir| dir.join("manifest.toml"))
                .filter(|f| f.exists())
                .for_each(|f| manifest_paths.push(f))
        });
        if let Err(e) = result {
            error!("error reading plugin path {:?}, {:?}", path, e);
        }
    }
    manifest_paths
}

fn load_manifest(path: &Path) -> Result<PluginDescription, PluginLoadError> {
    let mut file = fs::File::open(&path)?;
    let mut contents = String::new();
    file.read_to_string(&mut contents)?;
    let mut manifest: PluginDescription = toml::from_str(&contents)?;
    // normalize relative paths
    if manifest.exec_path.starts_with("./") {
        manifest.exec_path = path.parent().unwrap().join(manifest.exec_path).canonicalize()?;
    }

    for lang in &mut manifest.languages {
        let lang_config_path =
            path.parent().unwrap().join(&lang.name.as_ref()).with_extension("toml");
        if !lang_config_path.exists() {
            continue;
        }
        let lang_defaults = fs::read_to_string(&lang_config_path)?;
        let lang_defaults = table_from_toml_str(&lang_defaults)?;
        lang.default_config = Some(lang_defaults);
    }
    Ok(manifest)
}

impl From<io::Error> for PluginLoadError {
    fn from(err: io::Error) -> PluginLoadError {
        PluginLoadError::Io(err)
    }
}

impl From<toml::de::Error> for PluginLoadError {
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Structured representation of a plugin's features and capabilities.

use std::path::PathBuf;

use serde::{Deserialize, Deserializer, Serialize};
use serde_json::{self, Value};

use crate::syntax::{LanguageDefinition, LanguageId};

/// Describes attributes and capabilities of a plugin.
///
/// Note: - these will eventually be loaded from manifest files.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct PluginDescription {
    pub name: String,
    pub version: String,
    #[serde(default)]
    pub scope: PluginScope,
    // more metadata ...
    /// path to plugin executable
    #[serde(deserialize_with = "platform_exec_path")]
    pub exec_path: PathBuf,
    /// Events that cause this plugin to run
    #[serde(default)]
    pub activations: Vec<PluginActivation>,
    #[serde(default)]
    pub commands: Vec<Command>,
    #[serde(default)]
    pub languages: Vec<LanguageDefinition>,
}

fn platform_exec_path<'de, D: Deserializer<'de>>(deserializer: D) -> Result<PathBuf, D::Error> {
    let exec_path = PathBuf::deserialize(deserializer)?;
    if cfg!(windows) {
        Ok(exec_path.with_extension("exe"))
    } else {
        Ok(exec_path)
    }
}

/// `PluginActivation`s represent events that trigger running a plugin.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum PluginActivation {
    /// Always run this plugin, when available.
    Autorun,
    /// Run this plugin if the provided SyntaxDefinition is active.
    #[allow(dead_code)]
    OnSyntax(LanguageId),
    /// Run this plugin in response to a given command.
    #[allow(dead_code)]
    OnCommand,
}

/// Describes the scope of events a plugin receives.
#[derive(Debug, Clone, Deserialize, Serialize)]
#[serde(rename_all = "snake_case")]
pub enum PluginScope {
    /// The plugin receives events from multiple buffers.
    Global,
    /// The plugin receives events for a single buffer.
    BufferLocal,
    /// The plugin is launched in response to a command, and receives no
    /// further updates.
    SingleInvocation,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
/// Represents a custom command provided by a plugin.
pub struct Command {
    /// Human readable title, for display in (for example) a menu.
    pub title: String,
    /// A short description of the command.
    pub description: String,
    /// Template of the command RPC as it should be sent to the plugin.
    pub rpc_cmd: PlaceholderRpc,
    /// A list of `CommandArgument`s, which the client should use to build the RPC.
    pub args: Vec<CommandArgument>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
/// A user provided argument to a plugin command.
pub struct CommandArgument {
    /// A human readable name for this argument, for use as placeholder
    /// text or equivelant.
    pub title: String,
    /// A short (single sentence) description of this argument's use.
    pub description: String,
    pub key: String,
    pub arg_type: ArgumentType,
    #[serde(skip_serializing_if = "Option::is_none")]
    /// If `arg_type` is `Choice`, `options` must contain a list of options.
    pub options: Option<Vec<ArgumentOption>>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum ArgumentType {
    Number,
    Int,
    PosInt,
    Bool,
    String,
    Choice,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
/// Represents an option for a user-selectable argument.
pub struct ArgumentOption {
    pub title: String,
    pub value: Value,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "snake_case")]
/// A placeholder type which can represent a generic RPC.
///
/// This is the type used for custom plugin commands, which may have arbitrary
/// method names and parameters.
pub struct PlaceholderRpc {
    pub method: String,
    pub params: Value,
    pub rpc_type: RpcType,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum RpcType {
    Notification,
    Request,
}

impl Command {
    pub fn new<S, V>(title: S, description: S, rpc_cmd: PlaceholderRpc, args: V) -> Self
    where
        S: AsRef<str>,
        V: Into<Option<Vec<CommandArgument>>>,
    {
        let title = title.as_ref().to_owned();
        let description = description.as_ref().to_owned();
        let args = args.into().unwrap_or_else(Vec::new);
        Command { title, description, rpc_cmd, args }
    }
}

impl CommandArgument {
    pub fn new<S: AsRef<str>>(
        title: S,
        description: S,
        key: S,
        arg_type: ArgumentType,
        options: Option<Vec<ArgumentOption>>,
    ) -> Self {
        let key = key.as_ref().to_owned();
        let title = title.as_ref().to_owned();
        let description = description.as_ref().to_owned();
        if arg_type == ArgumentType::Choice {
            assert!(options.is_some())
        }
        CommandArgument { title, description, key, arg_type, options }
    }
}

impl ArgumentOption {
    pub fn new<S: AsRef<str>, V: Serialize>(title: S, value: V) -> Self {
        let title = title.as_ref().to_owned();
        let value = serde_json::to_value(value).unwrap();
        ArgumentOption { title, value }
    }
}

impl PlaceholderRpc {
    pub fn new<S, V>(method: S, params: V, request: bool) -> Self
    where
        S: AsRef<str>,
        V: Into<Option<Value>>,
    {
        let method = method.as_ref().to_owned();
        let params = params.into().unwrap_or(json!({}));
        let rpc_type = if request { RpcType::Request } else { RpcType::Notification };

        PlaceholderRpc { method, params, rpc_type }
    }

    pub fn is_request(&self) -> bool {
        self.rpc_type == RpcType::Request
    }

    /// Returns a reference to the placeholder's params.
    pub fn params_ref(&self) -> &Value {
        &self.params
    }

    /// Returns a mutable reference to the placeholder's params.
    pub fn params_ref_mut(&mut self) -> &mut Value {
        &mut self.params
    }

    /// Returns a reference to the placeholder's method.
    pub fn method_ref(&self) -> &str {
        &self.method
    }
}

impl PluginDescription {
    /// Returns `true` if this plugin is globally scoped, else `false`.
    pub fn is_global(&self) -> bool {
        matches!(self.scope, PluginScope::Global)
    }
}

impl Default for PluginScope {
    fn default() -> Self {
        PluginScope::BufferLocal
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json;

    #[test]
    fn platform_exec_path() {
        let json = r#"
        {
            "name": "test_plugin",
            "version": "0.0.0",
            "scope": "global",
            "exec_path": "path/to/binary",
            "activations": [],
            "commands": [],
            "languages": []
        }
        "#;

        let plugin_desc: PluginDescription = serde_json::from_str(&json).unwrap();
        if cfg!(windows) {
            assert!(plugin_desc.exec_path.ends_with("binary.exe"));
        } else {
            assert!(plugin_desc.exec_path.ends_with("binary"));
        }
    }

    #[test]
    fn test_serde_command() {
        let json = r#"
    {
        "title": "Test Command",
        "description": "Passes the current test",
        "rpc_cmd": {
            "rpc_type": "notification",
            "method": "test.cmd",
            "params": {
                "view": "",
                "non_arg": "plugin supplied value",
                "arg_one": "",
                "arg_two": ""
            }
        },
        "args": [
            {
                "title": "First argument",
                "description": "Indicates something",
                "key": "arg_one",
                "arg_type": "Bool"
            },
            {
                "title": "Favourite Number",
                "description": "A number used in a test.",
                "key": "arg_two",
                "arg_type": "Choice",
                "options": [
                    {"title": "Five", "value": 5},
                    {"title": "Ten", "value": 10}
                ]
            }
        ]
    }
        "#;

        let command: Command = serde_json::from_str(&json).unwrap();
        assert_eq!(command.title, "Test Command");
        assert_eq!(command.args[0].arg_type, ArgumentType::Bool);
        assert_eq!(command.rpc_cmd.params_ref()["non_arg"], "plugin supplied value");
        assert_eq!(command.args[1].options.clone().unwrap()[1].value, json!(10));
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Plugins and related functionality.

mod catalog;
pub mod manifest;
pub mod rpc;

use std::fmt;
use std::io::BufReader;
use std::path::Path;
use std::process::{Child, Command as ProcCommand, Stdio};
use std::sync::Arc;
use std::thread;

use serde_json::Value;

use xi_rpc::{self, RpcLoop, RpcPeer};

use crate::config::Table;
use crate::syntax::LanguageId;
use crate::tabs::ViewId;
use crate::WeakXiCore;

use self::rpc::{PluginBufferInfo, PluginUpdate};

pub(crate) use self::catalog::PluginCatalog;
pub use self::manifest::{Command, PlaceholderRpc, PluginDescription};

pub type PluginName = String;

/// A process-unique identifier for a running plugin.
///
/// Note: two instances of the same executable will have different identifiers.
/// Note: this identifier is distinct from the OS's process id.
#[derive(
    Serialize, Deserialize, Default, Debug, Clone, Copy, Hash, PartialEq, Eq, PartialOrd, Ord,
)]
pub struct PluginPid(pub(crate) usize);

pub type PluginId = PluginPid;

impl fmt::Display for PluginPid {
    fn fmt(&self, f: &mut fmt::Formatter) -> Result<(), fmt::Error> {
        write!(f, "plugin-{}", self.0)
    }
}

pub struct Plugin {
    peer: RpcPeer,
    pub(crate) id: PluginId,
    pub(crate) name: String,
    #[allow(dead_code)]
    process: Child,
}

impl Plugin {
    //TODO: initialize should be sent automatically during launch,
    //and should only send the plugin_id. We can just use the existing 'new_buffer'
    // RPC for adding views
    pub fn initialize(&self, info: Vec<PluginBufferInfo>) {
        self.peer.send_rpc_notification(
            "initialize",
            &json!({
                "plugin_id": self.id,
                "buffer_info": info,
            }),
        )
    }

    pub fn shutdown(&self) {
        self.peer.send_rpc_notification("shutdown", &json!({}));
    }

    // TODO: rethink naming, does this need to be a vec?
    pub fn new_buffer(&self, info: &PluginBufferInfo) {
        self.peer.send_rpc_notification("new_buffer", &json!({ "buffer_info": [info] }))
    }

    pub fn close_view(&self, view_id: ViewId) {
        self.peer.send_rpc_notification("did_close", &json!({ "view_id": view_id }))
    }

    pub fn did_save(&self, view_id: ViewId, path: &Path) {
        self.peer.send_rpc_notification(
            "did_save",
            &json!({
                "view_id": view_id,
                "path": path,
            }),
        )
    }

    pub fn update<F>(&self, update: &PluginUpdate, callback: F)
    where
        F: FnOnce(Result<Value, xi_rpc::Error>) + Send + 'static,
    {
        self.peer.send_rpc_request_async("update", &json!(update), Box::new(callback))
    }

    pub fn toggle_tracing(&self, enabled: bool) {
        self.peer.send_rpc_notification("tracing_config", &json!({ "enabled": enabled }))
    }

    pub fn collect_trace(&self) -> Result<Value, xi_rpc::Error> {
        self.peer.send_rpc_request("collect_trace", &json!({}))
    }

    pub fn config_changed(&self, view_id: ViewId, changes: &Table) {
        self.peer.send_rpc_notification(
            "config_changed",
            &json!({
                "view_id": view_id,
                "changes": changes,
            }),
        )
    }

    pub fn language_changed(&self, view_id: ViewId, new_lang: &LanguageId) {
        self.peer.send_rpc_notification(
            "language_changed",
            &json!({
                "view_id": view_id,
                "new_lang": new_lang,
            }),
        )
    }

    pub fn get_hover(&self, view_id: ViewId, request_id: usize, position: usize) {
        self.peer.send_rpc_notification(
            "get_hover",
            &json!({
                "view_id": view_id,
                "request_id": request_id,
                "position": position,
            }),
        )
    }

    pub fn dispatch_command(&self, view_id: ViewId, method: &str, params: &Value) {
        self.peer.send_rpc_notification(
            "custom_command",
            &json!({
                "view_id": view_id,
                "method": method,
                "params": params,
            }),
        )
    }
}

pub(crate) fn start_plugin_process(
    plugin_desc: Arc<PluginDescription>,
    id: PluginId,
    core: WeakXiCore,
) {
    let spawn_result = thread::Builder::new()
        .name(format!("<{}> core host thread", &plugin_desc.name))
        .spawn(move || {
            info!("starting plugin {}", &plugin_desc.name);
            let child = ProcCommand::new(&plugin_desc.exec_path)
                .stdin(Stdio::piped())
                .stdout(Stdio::piped())
                .spawn();

            match child {
                Ok(mut child) => {
                    let child_stdin = child.stdin.take().unwrap();
                    let child_stdout = child.stdout.take().unwrap();
                    let mut looper = RpcLoop::new(child_stdin);
                    let peer: RpcPeer = Box::new(looper.get_raw_peer());
                    let name = plugin_desc.name.clone();
                    peer.send_rpc_notification("ping", &Value::Array(Vec::new()));
                    let plugin = Plugin { peer, process: child, name, id };

                    // set tracing immediately
                    if xi_trace::is_enabled() {
                        plugin.toggle_tracing(true);
                    }

                    core.plugin_connect(Ok(plugin));
                    let mut core = core;
                    let err = looper.mainloop(|| BufReader::new(child_stdout), &mut core);
                    core.plugin_exit(id, err);
                }
                Err(err) => core.plugin_connect(Err(err)),
            }
        });
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! RPC types, corresponding to protocol requests, notifications & responses.

use std::borrow::Borrow;
use std::path::PathBuf;

use serde::de::{self, Deserialize, Deserializer};
use serde::ser::{self, Serialize, Serializer};
use serde_json::{self, Value};

use super::PluginPid;
use crate::annotations::AnnotationType;
use crate::config::Table;
use crate::syntax::LanguageId;
use crate::tabs::{BufferIdentifier, ViewId};
use xi_rope::{LinesMetric, Rope, RopeDelta};
use xi_rpc::RemoteError;

//TODO: At the moment (May 08, 2017) this is all very much in flux.
// At some point, it will be stabalized and then perhaps will live in another crate,
// shared with the plugin lib.

// ====================================================================
// core -> plugin RPC method types + responses
// ====================================================================

/// Buffer information sent on plugin init.
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PluginBufferInfo {
    /// The buffer's unique identifier.
    pub buffer_id: BufferIdentifier,
    /// The buffer's current views.
    pub views: Vec<ViewId>,
    pub rev: u64,
    pub buf_size: usize,
    pub nb_lines: usize,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub path: Option<String>,
    pub syntax: LanguageId,
    pub config: Table,
}

//TODO: very likely this should be merged with PluginDescription
//TODO: also this does not belong here.
/// Describes an available plugin to the client.
#[derive(Serialize, Deserialize, Debug)]
pub struct ClientPluginInfo {
    pub name: String,
    pub running: bool,
}

/// A simple update, sent to a plugin.
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PluginUpdate {
    pub view_id: ViewId,
    /// The delta representing changes to the document.
    ///
    /// Note: Is `Some` in the general case; only if the delta involves
    /// inserting more than some maximum number of bytes, will this be `None`,
    /// indicating the plugin should flush cache and fetch manually.
    pub delta: Option<RopeDelta>,
    /// The size of the document after applying this delta.
    pub new_len: usize,
    /// The total number of lines in the document after applying this delta.
    pub new_line_count: usize,
    pub rev: u64,
    /// The undo_group associated with this update. The plugin may pass
    /// this value back to core when making an edit, to associate the
    /// plugin's edit with this undo group. Core uses undo_group
    //  to undo actions occurred due to plugins after a user action
    // in a single step.
    pub undo_group: Option<usize>,
    pub edit_type: String,
    pub author: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EmptyStruct {}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
/// RPC requests sent from the host
pub enum HostRequest {
    Update(PluginUpdate),
    CollectTrace(EmptyStruct),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
/// RPC Notifications sent from the host
pub enum HostNotification {
    Ping(EmptyStruct),
    Initialize { plugin_id: PluginPid, buffer_info: Vec<PluginBufferInfo> },
    DidSave { view_id: ViewId, path: PathBuf },
    ConfigChanged { view_id: ViewId, changes: Table },
    NewBuffer { buffer_info: Vec<PluginBufferInfo> },
    DidClose { view_id: ViewId },
    GetHover { view_id: ViewId, request_id: usize, position: usize },
    Shutdown(EmptyStruct),
    TracingConfig { enabled: bool },
    LanguageChanged { view_id: ViewId, new_lang: LanguageId },
    CustomCommand { view_id: ViewId, method: String, params: Value },
}

// ====================================================================
// plugin -> core RPC method types
// ====================================================================

/// A simple edit, received from a plugin.
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct PluginEdit {
    pub rev: u64,
    pub delta: RopeDelta,
    /// the edit priority determines the resolution strategy when merging
    /// concurrent edits. The highest priority edit will be applied last.
    pub priority: u64,
    /// whether the inserted text prefers to be to the right of the cursor.
    pub after_cursor: bool,
    /// the originator of this edit: some identifier (plugin name, 'core', etc)
    /// undo_group associated with this edit
    pub undo_group: Option<usize>,
    pub author: String,
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy)]
pub struct ScopeSpan {
    pub start: usize,
    pub end: usize,
    pub scope_id: u32,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct DataSpan {
    pub start: usize,
    pub end: usize,
    pub data: Value,
}

/// The object returned by the `get_data` RPC.
#[derive(Debug, Serialize, Deserialize)]
pub struct GetDataResponse {
    pub chunk: String,
    pub offset: usize,
    pub first_line: usize,
    pub first_line_offset: usize,
}

/// The unit of measure when requesting data.
#[derive(Serialize, Deserialize, Debug, Clone, Copy)]
#[serde(rename_all = "snake_case")]
pub enum TextUnit {
    /// The requested offset is in bytes. The returned chunk will be valid
    /// UTF8, and is guaranteed to include the byte specified the offset.
    Utf8,
    /// The requested offset is a line number. The returned chunk will begin
    /// at the offset of the requested line.
    Line,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
/// RPC requests sent from plugins.
pub enum PluginRequest {
    GetData { start: usize, unit: TextUnit, max_size: usize, rev: u64 },
    LineCount,
    GetSelections,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
/// RPC commands sent from plugins.
pub enum PluginNotification {
    AddScopes {
        scopes: Vec<Vec<String>>,
    },
    UpdateSpans {
        start: usize,
        len: usize,
        spans: Vec<ScopeSpan>,
        rev: u64,
    },
    Edit {
        edit: PluginEdit,
    },
    Alert {
        msg: String,
    },
    AddStatusItem {
        key: String,
        value: String,
        alignment: String,
    },
    UpdateStatusItem {
        key: String,
        value: String,
    },
    RemoveStatusItem {
        key: String,
    },
    ShowHover {
        request_id: usize,
        result: Result<Hover, RemoteError>,
    },
    UpdateAnnotations {
        start: usize,
        len: usize,
        spans: Vec<DataSpan>,
        annotation_type: AnnotationType,
        rev: u64,
    },
}

/// Range expressed in terms of PluginPosition. Meant to be sent from
/// plugin to core.
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(rename_all = "snake_case")]
pub struct Range {
    pub start: usize,
    pub end: usize,
}

/// Hover Item sent from Plugin to Core
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(rename_all = "snake_case")]
pub struct Hover {
    pub content: String,
    pub range: Option<Range>,
}

/// Common wrapper for plugin-originating RPCs.
pub struct PluginCommand<T> {
    pub view_id: ViewId,
    pub plugin_id: PluginPid,
    pub cmd: T,
}

impl<T: Serialize> Serialize for PluginCommand<T> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let mut v = serde_json::to_value(&self.cmd).map_err(ser::Error::custom)?;
        v["params"]["view_id"] = json!(self.view_id);
        v["params"]["plugin_id"] = json!(self.plugin_id);
        v.serialize(serializer)
    }
}

impl<'de, T: Deserialize<'de>> Deserialize<'de> for PluginCommand<T> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        struct InnerIds {
            view_id: ViewId,
            plugin_id: PluginPid,
        }
        #[derive(Deserialize)]
        struct IdsWrapper {
            params: InnerIds,
        }

        let v = Value::deserialize(deserializer)?;
        let helper = IdsWrapper::deserialize(&v).map_err(de::Error::custom)?;
        let InnerIds { view_id, plugin_id } = helper.params;
        let cmd = T::deserialize(v).map_err(de::Error::custom)?;
        Ok(PluginCommand { view_id, plugin_id, cmd })
    }
}

impl PluginBufferInfo {
    pub fn new(
        buffer_id: BufferIdentifier,
        views: &[ViewId],
        rev: u64,
        buf_size: usize,
        nb_lines: usize,
        path: Option<PathBuf>,
        syntax: LanguageId,
        config: Table,
    ) -> Self {
        //TODO: do make any current assertions about paths being valid utf-8? do we want to?
        let path = path.map(|p| p.to_str().unwrap().to_owned());
        let views = views.to_owned();
        PluginBufferInfo { buffer_id, views, rev, buf_size, nb_lines, path, syntax, config }
    }
}

impl PluginUpdate {
    pub fn new<D>(
        view_id: ViewId,
        rev: u64,
        delta: D,
        new_len: usize,
        new_line_count: usize,
        undo_group: Option<usize>,
        edit_type: String,
        author: String,
    ) -> Self
    where
        D: Into<Option<RopeDelta>>,
    {
        let delta = delta.into();
        PluginUpdate { view_id, delta, new_len, new_line_count, rev, undo_group, edit_type, author }
    }
}

// maybe this should be in xi_rope? has a strong resemblance to the various
// concrete `Metric` types.
impl TextUnit {
    /// Converts an offset in some unit to a concrete byte offset. Returns
    /// `None` if the input offset is out of bounds in its unit space.
    pub fn resolve_offset<T: Borrow<Rope>>(self, text: T, offset: usize) -> Option<usize> {
        let text = text.borrow();
        match self {
            TextUnit::Utf8 => {
                if offset > text.len() {
                    None
                } else {
                    text.at_or_prev_codepoint_boundary(offset)
                }
            }
            TextUnit::Line => {
                let max_line_number = text.measure::<LinesMetric>() + 1;
                if offset > max_line_number {
                    None
                } else {
                    text.offset_of_line(offset).into()
                }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json;

    #[test]
    fn test_plugin_update() {
        let json = r#"{
            "view_id": "view-id-42",
            "delta": {"base_len": 6, "els": [{"copy": [0,5]}, {"insert":"rofls"}, {"copy": [5,6]}]},
            "new_len": 11,
            "new_line_count": 1,
            "rev": 5,
            "undo_group": 6,
            "edit_type": "something",
            "author": "me"
    }"#;

        let val: PluginUpdate = match serde_json::from_str(json) {
            Ok(val) => val,
            Err(err) => panic!("{:?}", err),
        };
        assert!(val.delta.is_some());
        assert!(val.delta.unwrap().as_simple_insert().is_some());
    }

    #[test]
    fn test_deserde_init() {
        let json = r#"
            {"buffer_id": 42,
             "views": ["view-id-4"],
             "rev": 1,
             "buf_size": 20,
             "nb_lines": 5,
             "path": "some_path",
             "syntax": "toml",
             "config": {"some_key": 420}}"#;

        let val: PluginBufferInfo = match serde_json::from_str(json) {
            Ok(val) => val,
            Err(err) => panic!("{:?}", err),
        };
        assert_eq!(val.rev, 1);
        assert_eq!(val.path, Some("some_path".to_owned()));
        assert_eq!(val.syntax, "toml".into());
    }

    #[test]
    fn test_de_plugin_rpc() {
        let json = r#"{"method": "alert", "params": {"view_id": "view-id-1", "plugin_id": 42, "msg": "ahhh!"}}"#;
        let de: PluginCommand<PluginNotification> = serde_json::from_str(json).unwrap();
        assert_eq!(de.view_id, ViewId(1));
        assert_eq!(de.plugin_id, PluginPid(42));
        match de.cmd {
            PluginNotification::Alert { ref msg } if msg == "ahhh!" => (),
            _ => panic!("{:?}", de.cmd),
        }
    }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::collections::HashMap;
use std::error::Error;
use std::fmt;
use std::fs;
use std::io::{self, Read};
use std::path::{Path, PathBuf};
use std::sync::Arc;

use serde::de::{self, Deserialize};
use serde_json::{self, Value};

use crate::syntax::{LanguageId, Languages};
use crate::tabs::{BufferId, ViewId};

/// Loads the included base config settings.
fn load_base_config() -> Table {
    fn load(default: &str) -> Table {
        table_from_toml_str(default).expect("default configs must load")
    }

    fn platform_overrides() -> Option<Table> {
        if cfg!(test) {
            // Exit early if we are in tests and never have platform overrides.
            // This makes sure we have a stable test environment.
            None
        } else if cfg!(windows) {
            let toml = include_str!("../assets/windows.toml");
            Some(load(toml))
        } else {
            // All other platorms
            None
        }
    }

    let base_toml: &str = include_str!("../assets/defaults.toml");
    let mut base = load(base_toml);
    if let Some(overrides) = platform_overrides() {
        for (k, v) in overrides.iter() {
            base.insert(k.to_owned(), v.to_owned());
        }
    }
    base
}

/// A map of config keys to settings
pub type Table = serde_json::Map<String, Value>;

/// A `ConfigDomain` describes a level or category of user settings.
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ConfigDomain {
    /// The general user preferences
    General,
    /// The overrides for a particular syntax.
    Language(LanguageId),
    /// The user overrides for a particular buffer
    UserOverride(BufferId),
    /// The system's overrides for a particular buffer. Only used internally.
    #[serde(skip_deserializing)]
    SysOverride(BufferId),
}

/// The external RPC sends `ViewId`s, which we convert to `BufferId`s
/// internally.
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ConfigDomainExternal {
    General,
    //TODO: remove this old name
    Syntax(LanguageId),
    Language(LanguageId),
    UserOverride(ViewId),
}

/// The errors that can occur when managing configs.
#[derive(Debug)]
pub enum ConfigError {
    /// The config domain was not recognized.
    UnknownDomain(String),
    /// A file-based config could not be loaded or parsed.
    Parse(PathBuf, toml::de::Error),
    /// The config table contained unexpected values
    UnexpectedItem(serde_json::Error),
    /// An Io Error
    Io(io::Error),
}

/// Represents the common pattern of default settings masked by
/// user settings.
#[derive(Debug)]
pub struct ConfigPair {
    /// A static default configuration, which will never change.
    base: Option<Arc<Table>>,
    /// A variable, user provided configuration. Items here take
    /// precedence over items in `base`.
    user: Option<Arc<Table>>,
    /// A snapshot of base + user.
    cache: Arc<Table>,
}

/// The language associated with a given buffer; this is always detected
/// but can also be manually set by the user.
#[derive(Debug, Clone)]
struct LanguageTag {
    detected: LanguageId,
    user: Option<LanguageId>,
}

#[derive(Debug)]
pub struct ConfigManager {
    /// A map of `ConfigPairs` (defaults + overrides) for all in-use domains.
    configs: HashMap<ConfigDomain, ConfigPair>,
    /// The currently loaded `Languages`.
    languages: Languages,
    /// The language assigned to each buffer.
    buffer_tags: HashMap<BufferId, LanguageTag>,
    /// The configs for any open buffers
    buffer_configs: HashMap<BufferId, BufferConfig>,
    /// If using file-based config, this is the base config directory
    /// (perhaps `$HOME/.config/xi`, by default).
    config_dir: Option<PathBuf>,
    /// An optional client-provided path for bundled resources, such
    /// as plugins and themes.
    extras_dir: Option<PathBuf>,
}

/// A collection of config tables representing a hierarchy, with each
/// table's keys superseding keys in preceding tables.
#[derive(Debug, Clone, Default)]
struct TableStack(Vec<Arc<Table>>);

/// A frozen collection of settings, and their sources.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config<T> {
    /// The underlying set of config tables that contributed to this
    /// `Config` instance. Used for diffing.
    #[serde(skip)]
    source: TableStack,
    /// The settings themselves, deserialized into some concrete type.
    pub items: T,
}

fn deserialize_tab_size<'de, D>(deserializer: D) -> Result<usize, D::Error>
where
    D: serde::Deserializer<'de>,
{
    let tab_size = usize::deserialize(deserializer)?;
    if tab_size == 0 {
        Err(de::Error::invalid_value(
            de::Unexpected::Unsigned(tab_size as u64),
            &"tab_size must be at least 1",
        ))
    } else {
        Ok(tab_size)
    }
}

/// The concrete type for buffer-related settings.
#[derive(Debug, Clone, Deserialize, Serialize, PartialEq)]
pub struct BufferItems {
    pub line_ending: String,
    #[serde(deserialize_with = "deserialize_tab_size")]
    pub tab_size: usize,
    pub translate_tabs_to_spaces: bool,
    pub use_tab_stops: bool,
    pub font_face: String,
    pub font_size: f32,
    pub auto_indent: bool,
    pub scroll_past_end: bool,
    pub wrap_width: usize,
    pub word_wrap: bool,
    pub autodetect_whitespace: bool,
    pub surrounding_pairs: Vec<(String, String)>,
    pub save_with_newline: bool,
}

pub type BufferConfig = Config<BufferItems>;

impl ConfigPair {
    /// Creates a new `ConfigPair` with the provided base config.
    fn with_base<T: Into<Option<Table>>>(table: T) -> Self {
        let base = table.into().map(Arc::new);
        let cache = base.clone().unwrap_or_default();
        ConfigPair { base, cache, user: None }
    }

    /// Returns a new `ConfigPair` with the provided base and the current
    /// user config.
    fn new_with_base<T: Into<Option<Table>>>(&self, table: T) -> Self {
        let mut new_self = ConfigPair::with_base(table);
        new_self.user = self.user.clone();
        new_self.rebuild();
        new_self
    }

    fn set_table(&mut self, user: Table) {
        self.user = Some(Arc::new(user));
        self.rebuild();
    }

    /// Returns the `Table` produced by updating `self.user` with the contents
    /// of `user`, deleting null entries.
    fn table_for_update(&self, user: Table) -> Table {
        let mut new_user: Table =
            self.user.as_ref().map(|arc| arc.as_ref().clone()).unwrap_or_default();
        for (k, v) in user {
            if v.is_null() {
                new_user.remove(&k);
            } else {
                new_user.insert(k, v);
            }
        }
        new_user
    }

    fn rebuild(&mut self) {
        let mut cache = self.base.clone().unwrap_or_default();
        if let Some(ref user) = self.user {
            for (k, v) in user.iter() {
                Arc::make_mut(&mut cache).insert(k.to_owned(), v.clone());
            }
        }
        self.cache = cache;
    }
}

impl ConfigManager {
    pub fn new(config_dir: Option<PathBuf>, extras_dir: Option<PathBuf>) -> Self {
        let base = load_base_config();
        let mut defaults = HashMap::new();
        defaults.insert(ConfigDomain::General, ConfigPair::with_base(base));
        ConfigManager {
            configs: defaults,
            buffer_tags: HashMap::new(),
            buffer_configs: HashMap::new(),
            languages: Languages::default(),
            config_dir,
            extras_dir,
        }
    }

    /// The path of the user's config file, if present.
    pub(crate) fn base_config_file_path(&self) -> Option<PathBuf> {
        let config_file = self.config_dir.as_ref().map(|p| p.join("preferences.xiconfig"));
        let exists = config_file.as_ref().map(|p| p.exists()).unwrap_or(false);
        if exists {
            config_file
        } else {
            None
        }
    }

    pub(crate) fn get_plugin_paths(&self) -> Vec<PathBuf> {
        let config_dir = self.config_dir.as_ref().map(|p| p.join("plugins"));
        [self.extras_dir.as_ref(), config_dir.as_ref()]
            .iter()
            .flat_map(|p| p.map(|p| p.to_owned()))
            .filter(|p| p.exists())
            .collect()
    }

    /// Adds a new buffer to the config manager, and returns the initial config
    /// `Table` for that buffer. The `path` argument is used to determine
    /// the buffer's default language.
    ///
    /// # Note: The caller is responsible for ensuring the config manager is
    /// notified every time a buffer is added or removed.
    ///
    /// # Panics:
    ///
    /// Panics if `id` already exists.
    pub(crate) fn add_buffer(&mut self, id: BufferId, path: Option<&Path>) -> Table {
        let lang =
            path.and_then(|p| self.language_for_path(p)).unwrap_or(LanguageId::from("Plain Text"));
        let lang_tag = LanguageTag::new(lang);
        assert!(self.buffer_tags.insert(id, lang_tag).is_none());
        self.update_buffer_config(id).expect("new buffer must always have config")
    }

    /// Updates the default language for the given buffer.
    ///
    /// # Panics:
    ///
    /// Panics if `id` does not exist.
    pub(crate) fn update_buffer_path(&mut self, id: BufferId, path: &Path) -> Option<Table> {
        assert!(self.buffer_tags.contains_key(&id));
        let lang = self.language_for_path(path).unwrap_or_default();
        let has_changed = self.buffer_tags.get_mut(&id).map(|tag| tag.set_detected(lang)).unwrap();

        if has_changed {
            self.update_buffer_config(id)
        } else {
            None
        }
    }

    /// Instructs the `ConfigManager` to stop tracking a given buffer.
    ///
    /// # Panics:
    ///
    /// Panics if `id` does not exist.
    pub(crate) fn remove_buffer(&mut self, id: BufferId) {
        self.buffer_tags.remove(&id).expect("remove key must exist");
        self.buffer_configs.remove(&id);
        // TODO: remove any overrides
    }

    /// Sets a specific language for the given buffer. This is used if the
    /// user selects a specific language in the frontend, for instance.
    pub(crate) fn override_language(
        &mut self,
        id: BufferId,
        new_lang: LanguageId,
    ) -> Option<Table> {
        let has_changed = self
            .buffer_tags
            .get_mut(&id)
            .map(|tag| tag.set_user(Some(new_lang)))
            .expect("buffer must exist");
        if has_changed {
            self.update_buffer_config(id)
        } else {
            None
        }
    }

    fn update_buffer_config(&mut self, id: BufferId) -> Option<Table> {
        let new_config = self.generate_buffer_config(id);
        let changes = new_config.changes_from(self.buffer_configs.get(&id));
        self.buffer_configs.insert(id, new_config);
        changes
    }

    fn update_all_buffer_configs(&mut self) -> Vec<(BufferId, Table)> {
        self.buffer_configs
            .keys()
            .cloned()
            .collect::<Vec<_>>()
            .into_iter()
            .flat_map(|k| self.update_buffer_config(k).map(|c| (k, c)))
            .collect::<Vec<_>>()
    }

    fn generate_buffer_config(&mut self, id: BufferId) -> BufferConfig {
        // it's possible for a buffer to be tagged with since-removed language
        let lang = self
            .buffer_tags
            .get(&id)
            .map(LanguageTag::resolve)
            .and_then(|name| self.languages.language_for_name(name))
            .map(|l| l.name.clone());
        let mut configs = Vec::new();

        configs.push(self.configs.get(&ConfigDomain::General));
        if let Some(s) = lang {
            configs.push(self.configs.get(&s.into()))
        };
        configs.push(self.configs.get(&ConfigDomain::SysOverride(id)));
        configs.push(self.configs.get(&ConfigDomain::UserOverride(id)));

        let configs = configs
            .iter()
            .flat_map(Option::iter)
            .map(|c| c.cache.clone())
            .rev()
            .collect::<Vec<_>>();

        let stack = TableStack(configs);
        stack.into_config()
    }

    /// Returns a reference to the `BufferConfig` for this buffer.
    ///
    /// # Panics:
    ///
    /// Panics if `id` does not exist. The caller is responsible for ensuring
    /// that the `ConfigManager` is kept up to date as buffers are added/removed.
    pub(crate) fn get_buffer_config(&self, id: BufferId) -> &BufferConfig {
        self.buffer_configs.get(&id).unwrap()
    }

    /// Returns the language associated with this buffer.
    ///
    /// # Panics:
    ///
    /// Panics if `id` does not exist.
    pub(crate) fn get_buffer_language(&self, id: BufferId) -> LanguageId {
        self.buffer_tags.get(&id).map(LanguageTag::resolve).unwrap()
    }

    /// Set the available `LanguageDefinition`s. Overrides any previous values.
    pub fn set_languages(&mut self, languages: Languages) {
        // remove base configs for any removed languages
        self.languages.difference(&languages).iter().for_each(|lang| {
            let domain: ConfigDomain = lang.name.clone().into();
            if let Some(pair) = self.configs.get_mut(&domain) {
                *pair = pair.new_with_base(None);
            }
        });

        for language in languages.iter() {
            let lang_id = language.name.clone();
            let domain: ConfigDomain = lang_id.into();
            let default_config = language.default_config.clone();
            self.configs
                .entry(domain.clone())
                .and_modify(|c| *c = c.new_with_base(default_config.clone()))
                .or_insert_with(|| ConfigPair::with_base(default_config));
            if let Some(table) = self.load_user_config_file(&domain) {
                // we can't report this error because we don't have a
                // handle to the peer :|
                let _ = self.set_user_config(domain, table);
            }
        }
        //FIXME these changes are happening silently, which won't work once
        //languages can by dynamically changed
        self.languages = languages;
        self.update_all_buffer_configs();
    }

    fn load_user_config_file(&self, domain: &ConfigDomain) -> Option<Table> {
        let path = self
            .config_dir
            .as_ref()
            .map(|p| p.join(domain.file_stem()).with_extension("xiconfig"))?;

        if !path.exists() {
            return None;
        }

        match try_load_from_file(&path) {
            Ok(t) => Some(t),
            Err(e) => {
                error!("Error loading config: {:?}", e);
                None
            }
        }
    }

    pub fn language_for_path(&self, path: &Path) -> Option<LanguageId> {
        self.languages.language_for_path(path).map(|lang| lang.name.clone())
    }

    /// Sets the config for the given domain, removing any existing config.
    /// Returns a `Vec` of individual buffer config changes that result from
    /// this update, or a `ConfigError` if `config` is poorly formed.
    pub fn set_user_config(
        &mut self,
        domain: ConfigDomain,
        config: Table,
    ) -> Result<Vec<(BufferId, Table)>, ConfigError> {
        self.check_table(&config)?;
        self.configs.entry(domain).or_insert_with(|| ConfigPair::with_base(None)).set_table(config);
        Ok(self.update_all_buffer_configs())
    }

    /// Returns the `Table` produced by applying `changes` to the current user
    /// config for the given `ConfigDomain`.
    ///
    /// # Note:
    ///
    /// When the user modifys a config _file_, the whole file is read,
    /// and we can just overwrite any existing user config with the newly
    /// loaded one.
    ///
    /// When the client modifies a config via the RPC mechanism, however,
    /// this isn't the case. Instead of sending all config settings with
    /// each update, the client just sends the keys/values they would like
    /// to change. When they would like to remove a previously set key,
    /// they send `Null` as the value for that key.
    ///
    /// This function creates a new table which is the product of updating
    /// any existing table by applying the client's changes. This new table can
    /// then be passed to `Self::set_user_config(..)`, as if it were loaded
    /// from disk.
    pub(crate) fn table_for_update(&mut self, domain: ConfigDomain, changes: Table) -> Table {
        self.configs
            .entry(domain)
            .or_insert_with(|| ConfigPair::with_base(None))
            .table_for_update(changes)
    }

    /// Returns the `ConfigDomain` relevant to a given file, if one exists.
    pub fn domain_for_path(&self, path: &Path) -> Option<ConfigDomain> {
        if path.extension().map(|e| e != "xiconfig").unwrap_or(true) {
            return None;
        }
        match path.file_stem().and_then(|s| s.to_str()) {
            Some("preferences") => Some(ConfigDomain::General),
            Some(name) if self.languages.language_for_name(&name).is_some() => {
                let lang =
                    self.languages.language_for_name(&name).map(|lang| lang.name.clone()).unwrap();
                Some(ConfigDomain::Language(lang))
            }
            //TODO: plugin configs
            _ => None,
        }
    }

    fn check_table(&self, table: &Table) -> Result<(), ConfigError> {
        let defaults = self
            .configs
            .get(&ConfigDomain::General)
            .and_then(|pair| pair.base.clone())
            .expect("general domain must have defaults");
        let mut defaults: Table = defaults.as_ref().clone();
        for (k, v) in table.iter() {
            // changes can include 'null', which means clear field
            if v.is_null() {
                continue;
            }
            defaults.insert(k.to_owned(), v.to_owned());
        }
        let _: BufferItems = serde_json::from_value(defaults.into())?;
        Ok(())
    }

    /// Path to themes sub directory inside config directory.
    /// Creates one if not present.
    pub(crate) fn get_themes_dir(&self) -> Option<PathBuf> {
        let themes_dir = self.config_dir.as_ref().map(|p| p.join("themes"));

        if let Some(p) = themes_dir {
            if p.exists() {
                return Some(p);
            }
            if fs::DirBuilder::new().create(&p).is_ok() {
                return Some(p);
            }
        }
        None
    }

    /// Path to plugins sub directory inside config directory.
    /// Creates one if not present.
    pub(crate) fn get_plugins_dir(&self) -> Option<PathBuf> {
        let plugins_dir = self.config_dir.as_ref().map(|p| p.join("plugins"));

        if let Some(p) = plugins_dir {
            if p.exists() {
                return Some(p);
            }
            if fs::DirBuilder::new().create(&p).is_ok() {
                return Some(p);
            }
        }
        None
    }
}

impl TableStack {
    /// Create a single table representing the final config values.
    fn collate(&self) -> Table {
        // NOTE: This is fairly expensive; a future optimization would borrow
        // from the underlying collections.
        let mut out = Table::new();
        for table in &self.0 {
            for (k, v) in table.iter() {
                if !out.contains_key(k) {
                    // cloning these objects feels a bit gross, we could
                    // improve this by implementing Deserialize for TableStack.
                    out.insert(k.to_owned(), v.to_owned());
                }
            }
        }
        out
    }

    /// Converts the underlying tables into a static `Config` instance.
    fn into_config<T>(self) -> Config<T>
    where
        for<'de> T: Deserialize<'de>,
    {
        let out = self.collate();
        let items: T = serde_json::from_value(out.into()).unwrap();
        let source = self;
        Config { source, items }
    }

    /// Walks the tables in priority order, returning the first
    /// occurance of `key`.
    fn get<S: AsRef<str>>(&self, key: S) -> Option<&Value> {
        for table in &self.0 {
            if let Some(v) = table.get(key.as_ref()) {
                return Some(v);
            }
        }
        None
    }

    /// Returns a new `Table` containing only those keys and values in `self`
    /// which have changed from `other`.
    fn diff(&self, other: &TableStack) -> Option<Table> {
        let mut out: Option<Table> = None;
        let this = self.collate();
        for (k, v) in this.iter() {
            if other.get(k) != Some(v) {
                let out: &mut Table = out.get_or_insert(Table::new());
                out.insert(k.to_owned(), v.to_owned());
            }
        }
        out
    }
}

impl<T> Config<T> {
    pub fn to_table(&self) -> Table {
        self.source.collate()
    }
}

impl<'de, T: Deserialize<'de>> Config<T> {
    /// Returns a `Table` of all the items in `self` which have different
    /// values than in `other`.
    pub fn changes_from(&self, other: Option<&Config<T>>) -> Option<Table> {
        match other {
            Some(other) => self.source.diff(&other.source),
            None => self.source.collate().into(),
        }
    }
}

impl ConfigDomain {
    fn file_stem(&self) -> &str {
        match self {
            ConfigDomain::General => "preferences",
            ConfigDomain::Language(lang) => lang.as_ref(),
            ConfigDomain::UserOverride(_) | ConfigDomain::SysOverride(_) => "we don't have files",
        }
    }
}

impl LanguageTag {
    fn new(detected: LanguageId) -> Self {
        LanguageTag { detected, user: None }
    }

    fn resolve(&self) -> LanguageId {
        self.user.as_ref().unwrap_or(&self.detected).clone()
    }

    /// Set the detected language. Returns `true` if this changes the resolved
    /// language.
    fn set_detected(&mut self, detected: LanguageId) -> bool {
        let before = self.resolve();
        self.detected = detected;
        before != self.resolve()
    }

    /// Set the user-specified language. Returns `true` if this changes
    /// the resolved language.
    #[allow(dead_code)]
    fn set_user(&mut self, new_lang: Option<LanguageId>) -> bool {
        let has_changed = self.user != new_lang;
        self.user = new_lang;
        has_changed
    }
}

impl<T: PartialEq> PartialEq for Config<T> {
    fn eq(&self, other: &Config<T>) -> bool {
        self.items == other.items
    }
}

impl From<LanguageId> for ConfigDomain {
    fn from(src: LanguageId) -> ConfigDomain {
        ConfigDomain::Language(src)
    }
}

impl From<BufferId> for ConfigDomain {
    fn from(src: BufferId) -> ConfigDomain {
        ConfigDomain::UserOverride(src)
    }
}

impl fmt::Display for ConfigError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        use self::ConfigError::*;
        match *self {
            UnknownDomain(ref s) => write!(f, "UnknownDomain: {}", s),
            Parse(ref p, ref e) => write!(f, "Parse ({:?}), {}", p, e),
            Io(ref e) => write!(f, "error loading config: {}", e),
            UnexpectedItem(ref e) => write!(f, "{}", e),
        }
    }
}

impl Error for ConfigError {}

impl From<io::Error> for ConfigError {
    fn from(src: io::Error) -> ConfigError {
        ConfigError::Io(src)
    }
}

impl From<serde_json::Error> for ConfigError {
    fn from(src: serde_json::Error) -> ConfigError {
        ConfigError::UnexpectedItem(src)
    }
}

/// Creates initial config directory structure
pub(crate) fn init_config_dir(dir: &Path) -> io::Result<()> {
    let builder = fs::DirBuilder::new();
    builder.create(dir)?;
    builder.create(dir.join("plugins"))?;
    Ok(())
}

/// Attempts to load a config from a file. The config's domain is determined
/// by the file name.
pub(crate) fn try_load_from_file(path: &Path) -> Result<Table, ConfigError> {
    let mut file = fs::File::open(&path)?;
    let mut contents = String::new();
    file.read_to_string(&mut contents)?;
    table_from_toml_str(&contents).map_err(|e| ConfigError::Parse(path.to_owned(), e))
}

pub(crate) fn table_from_toml_str(s: &str) -> Result<Table, toml::de::Error> {
    let table = toml::from_str(&s)?;
    let table = from_toml_value(table).as_object().unwrap().to_owned();
    Ok(table)
}

//adapted from https://docs.rs/crate/config/0.7.0/source/src/file/format/toml.rs
/// Converts between toml (used to write config files) and json
/// (used to store config values internally).
fn from_toml_value(value: toml::Value) -> Value {
    match value {
        toml::Value::String(value) => value.into(),
        toml::Value::Float(value) => value.into(),
        toml::Value::Integer(value) => value.into(),
        toml::Value::Boolean(value) => value.into(),
        toml::Value::Datetime(value) => value.to_string().into(),

        toml::Value::Table(table) => {
            let mut m = Table::new();
            for (key, value) in table {
                m.insert(key.clone(), from_toml_value(value));
            }
            m.into()
        }

        toml::Value::Array(array) => {
            let mut l = Vec::new();
            for value in array {
                l.push(from_toml_value(value));
            }
            l.into()
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::syntax::LanguageDefinition;

    #[test]
    fn test_overrides() {
        let user_config = table_from_toml_str(r#"tab_size = 42"#).unwrap();
        let rust_config = table_from_toml_str(r#"tab_size = 31"#).unwrap();

        let lang_def = rust_lang_def(None);
        let rust_id: LanguageId = "Rust".into();

        let buf_id_1 = BufferId(1); // no language
        let buf_id_2 = BufferId(2); // just rust
        let buf_id_3 = BufferId(3); // rust, + system overrides

        let mut manager = ConfigManager::new(None, None);
        manager.set_languages(Languages::new(&[lang_def]));
        manager.set_user_config(rust_id.clone().into(), rust_config).unwrap();
        manager.set_user_config(ConfigDomain::General, user_config).unwrap();

        let changes = json!({"tab_size": 67}).as_object().unwrap().to_owned();
        manager.set_user_config(ConfigDomain::SysOverride(buf_id_3), changes).unwrap();

        manager.add_buffer(buf_id_1, None);
        manager.add_buffer(buf_id_2, Some(Path::new("file.rs")));
        manager.add_buffer(buf_id_3, Some(Path::new("file2.rs")));

        // system override
        let config = manager.get_buffer_config(buf_id_1).to_owned();
        assert_eq!(config.source.0.len(), 1);
        assert_eq!(config.items.tab_size, 42);
        let config = manager.get_buffer_config(buf_id_2).to_owned();
        assert_eq!(config.items.tab_size, 31);
        let config = manager.get_buffer_config(buf_id_3).to_owned();
        assert_eq!(config.items.tab_size, 67);

        // user override trumps everything
        let changes = json!({"tab_size": 85}).as_object().unwrap().to_owned();
        manager.set_user_config(ConfigDomain::UserOverride(buf_id_3), changes).unwrap();
        let config = manager.get_buffer_config(buf_id_3);
        assert_eq!(config.items.tab_size, 85);
    }

    #[test]
    fn test_config_domain_serde() {
        assert_eq!(serde_json::to_string(&ConfigDomain::General).unwrap(), "\"general\"");
        let d = ConfigDomainExternal::UserOverride(ViewId(1));
        assert_eq!(serde_json::to_string(&d).unwrap(), "{\"user_override\":\"view-id-1\"}");
        let d = ConfigDomain::Language("Swift".into());
        assert_eq!(serde_json::to_string(&d).unwrap(), "{\"language\":\"Swift\"}");
    }

    #[test]
    fn test_diff() {
        let conf1 = r#"
tab_size = 42
translate_tabs_to_spaces = true
"#;
        let conf1 = table_from_toml_str(conf1).unwrap();

        let conf2 = r#"
tab_size = 6
translate_tabs_to_spaces = true
"#;
        let conf2 = table_from_toml_str(conf2).unwrap();

        let stack1 = TableStack(vec![Arc::new(conf1)]);
        let stack2 = TableStack(vec![Arc::new(conf2)]);
        let diff = stack1.diff(&stack2).unwrap();
        assert!(diff.len() == 1);
        assert_eq!(diff.get("tab_size"), Some(&42.into()));
    }

    #[test]
    fn test_updating_in_place() {
        let mut manager = ConfigManager::new(None, None);
        let buf_id = BufferId(1);
        manager.add_buffer(buf_id, None);
        assert_eq!(manager.get_buffer_config(buf_id).items.font_size, 14.);
        let changes = json!({"font_size": 69, "font_face": "nice"}).as_object().unwrap().to_owned();
        let table = manager.table_for_update(ConfigDomain::General, changes);
        manager.set_user_config(ConfigDomain::General, table).unwrap();
        assert_eq!(manager.get_buffer_config(buf_id).items.font_size, 69.);

        // null values in updates removes keys
        let changes = json!({ "font_size": Value::Null }).as_object().unwrap().to_owned();
        let table = manager.table_for_update(ConfigDomain::General, changes);
        manager.set_user_config(ConfigDomain::General, table).unwrap();
        assert_eq!(manager.get_buffer_config(buf_id).items.font_size, 14.);
        assert_eq!(manager.get_buffer_config(buf_id).items.font_face, "nice");
    }

    #[test]
    fn lang_overrides() {
        let mut manager = ConfigManager::new(None, None);
        let lang_defaults = json!({"font_size": 69, "font_face": "nice"});
        let lang_overrides = json!({"font_size": 420, "font_face": "cool"});
        let lang_def = rust_lang_def(lang_defaults.as_object().map(Table::clone));
        let lang_id: LanguageId = "Rust".into();
        let domain: ConfigDomain = lang_id.clone().into();

        manager.set_languages(Languages::new(&[lang_def.clone()]));
        assert_eq!(manager.languages.iter().count(), 1);

        let buf_id = BufferId(1);
        manager.add_buffer(buf_id, Some(Path::new("file.rs")));

        let config = manager.get_buffer_config(buf_id).to_owned();
        assert_eq!(config.source.0.len(), 2);
        assert_eq!(config.items.font_size, 69.);

        // removing language should remove default configs
        manager.set_languages(Languages::new(&[]));
        assert_eq!(manager.languages.iter().count(), 0);

        let config = manager.get_buffer_config(buf_id).to_owned();
        assert_eq!(config.source.0.len(), 1);
        assert_eq!(config.items.font_size, 14.);

        manager
            .set_user_config(domain.clone(), lang_overrides.as_object().map(Table::clone).unwrap())
            .unwrap();

        // user config for unknown language is ignored
        let config = manager.get_buffer_config(buf_id).to_owned();
        assert_eq!(config.items.font_size, 14.);

        // user config trumps defaults when language exists
        manager.set_languages(Languages::new(&[lang_def.clone()]));
        let config = manager.get_buffer_config(buf_id).to_owned();
        assert_eq!(config.items.font_size, 420.);

        let changes = json!({ "font_size": Value::Null }).as_object().unwrap().to_owned();

        // null key should void user setting, leave language default
        let table = manager.table_for_update(domain.clone(), changes);
        manager.set_user_config(domain.clone(), table).unwrap();
        let config = manager.get_buffer_config(buf_id).to_owned();
        assert_eq!(config.items.font_size, 69.);

        manager.set_languages(Languages::new(&[]));
        let config = manager.get_buffer_config(buf_id);
        assert_eq!(config.items.font_size, 14.);
    }
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::io;
use std::sync::{Arc, Mutex, MutexGuard, Weak};

use serde_json::Value;

use xi_rpc::{Error as RpcError, Handler, ReadError, RemoteError, RpcCtx};

use crate::plugin_rpc::{PluginCommand, PluginNotification, PluginRequest};
use crate::plugins::{Plugin, PluginId};
use crate::rpc::*;
use crate::tabs::{CoreState, ViewId};

/// A reference to the main core state.
///
/// # Note
///
/// Various items of initial setup are dependent on how the client
/// is configured, so we defer instantiating state until we have that
/// information.
pub enum XiCore {
    // TODO: profile startup, and determine what things (such as theme loading)
    // we should be doing before client_init.
    Waiting,
    Running(Arc<Mutex<CoreState>>),
}

/// A weak reference to the main state. This is passed to plugin threads.
#[derive(Clone)]
pub struct WeakXiCore(Weak<Mutex<CoreState>>);

#[allow(dead_code)]
impl XiCore {
    pub fn new() -> Self {
        XiCore::Waiting
    }

    /// Returns `true` if the `client_started` has not been received.
    fn is_waiting(&self) -> bool {
        matches!(*self, XiCore::Waiting)
    }

    /// Returns a guard to the core state. A convenience around `Mutex::lock`.
    ///
    /// # Panics
    ///
    /// Panics if core has not yet received the `client_started` message.
    pub fn inner(&self) -> MutexGuard<CoreState> {
        match self {
            XiCore::Running(ref inner) => inner.lock().unwrap(),
            XiCore::Waiting => panic!(
                "core does not start until client_started \
                 RPC is received"
            ),
        }
    }

    /// Returns a new reference to the core state, if core is running.
    fn weak_self(&self) -> Option<WeakXiCore> {
        match self {
            XiCore::Running(ref inner) => Some(WeakXiCore(Arc::downgrade(inner))),
            XiCore::Waiting => None,
        }
    }
}

/// Handler for messages originating with the frontend.
impl Handler for XiCore {
    type Notification = CoreNotification;
    type Request = CoreRequest;

    fn handle_notification(&mut self, ctx: &RpcCtx, rpc: Self::Notification) {
        use self::CoreNotification::*;

        // We allow tracing to be enabled before event `client_started`
        if let TracingConfig { enabled } = rpc {
            match enabled {
                true => xi_trace::enable_tracing(),
                false => xi_trace::disable_tracing(),
            }
            info!("tracing in core = {:?}", enabled);
            if self.is_waiting() {
                return;
            }
        }

        // wait for client_started before setting up inner
        if let ClientStarted { ref config_dir, ref client_extras_dir } = rpc {
            assert!(self.is_waiting(), "client_started can only be sent once");
            let state =
                CoreState::new(ctx.get_peer(), config_dir.clone(), client_extras_dir.clone());
            let state = Arc::new(Mutex::new(state));
            *self = XiCore::Running(state);
            let weak_self = self.weak_self().unwrap();
            self.inner().finish_setup(weak_self);
        }

        self.inner().client_notification(rpc);
    }

    fn handle_request(&mut self, _ctx: &RpcCtx, rpc: Self::Request) -> Result<Value, RemoteError> {
        self.inner().client_request(rpc)
    }

    fn idle(&mut self, _ctx: &RpcCtx, token: usize) {
        self.inner().handle_idle(token);
    }
}

impl WeakXiCore {
    /// Attempts to upgrade the weak reference. Essentially a wrapper
    /// for `Arc::upgrade`.
    fn upgrade(&self) -> Option<XiCore> {
        self.0.upgrade().map(XiCore::Running)
    }

    /// Called immediately after attempting to start a plugin,
    /// from the plugin's thread.
    pub fn plugin_connect(&self, plugin: Result<Plugin, io::Error>) {
        if let Some(core) = self.upgrade() {
            core.inner().plugin_connect(plugin)
        }
    }

    /// Called from a plugin runloop thread when the runloop exits.
    pub fn plugin_exit(&self, plugin: PluginId, error: Result<(), ReadError>) {
        if let Some(core) = self.upgrade() {
            core.inner().plugin_exit(plugin, error)
        }
    }

    /// Handles the result of an update sent to a plugin.
    ///
    /// All plugins must acknowledge when they are sent a new update, so that
    /// core can track which revisions are still 'live', that is can still
    /// be the base revision for a delta. Once a plugin has acknowledged a new
    /// revision, it can no longer send deltas against any older revision.
    pub fn handle_plugin_update(
        &self,
        plugin: PluginId,
        view: ViewId,
        response: Result<Value, RpcError>,
    ) {
        if let Some(core) = self.upgrade() {
            let _t = xi_trace::trace_block("WeakXiCore::plugin_update", &["core"]);
            core.inner().plugin_update(plugin, view, response);
        }
    }
}

/// Handler for messages originating from plugins.
impl Handler for WeakXiCore {
    type Notification = PluginCommand<PluginNotification>;
    type Request = PluginCommand<PluginRequest>;

    fn handle_notification(&mut self, ctx: &RpcCtx, rpc: Self::Notification) {
        let PluginCommand { view_id, plugin_id, cmd } = rpc;
        if let Some(core) = self.upgrade() {
            core.inner().plugin_notification(ctx, view_id, plugin_id, cmd)
        }
    }

    fn handle_request(&mut self, ctx: &RpcCtx, rpc: Self::Request) -> Result<Value, RemoteError> {
        let PluginCommand { view_id, plugin_id, cmd } = rpc;
        if let Some(core) = self.upgrade() {
            core.inner().plugin_request(ctx, view_id, plugin_id, cmd)
        } else {
            Err(RemoteError::custom(0, "core is missing", None))
        }
    }
}

#[cfg(test)]
/// Returns a non-functional `WeakXiRef`, needed to mock other types.
pub fn dummy_weak_core() -> WeakXiCore {
    use xi_rpc::test_utils::DummyPeer;
    use xi_rpc::Peer;
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Manages recording and enables playback for client sent events.
//!
//! Clients can store multiple, named recordings.

use std::collections::HashMap;

use xi_trace::trace_block;

use crate::edit_types::{BufferEvent, EventDomain};

/// A container that manages and holds all recordings for the current editing session
pub(crate) struct Recorder {
    active_recording: Option<String>,
    recording_buffer: Vec<EventDomain>,
    recordings: HashMap<String, Recording>,
}

impl Recorder {
    pub(crate) fn new() -> Recorder {
        Recorder {
            active_recording: None,
            recording_buffer: Vec::new(),
            recordings: HashMap::new(),
        }
    }

    pub(crate) fn is_recording(&self) -> bool {
        self.active_recording.is_some()
    }

    /// Starts or stops the specified recording.
    ///
    ///
    /// There are three outcome behaviors:
    /// - If the current recording name is specified, the active recording is saved
    /// - If no recording name is specified, the currently active recording is saved
    /// - If a recording name other than the active recording is specified,
    /// the current recording will be thrown out and will be switched to the new name
    ///
    /// In addition to the above:
    /// - If the recording was saved, there is no active recording
    /// - If the recording was switched, there will be a new active recording
    pub(crate) fn toggle_recording(&mut self, recording_name: Option<String>) {
        let is_recording = self.is_recording();
        let last_recording = self.active_recording.take();

        match (is_recording, &last_recording, &recording_name) {
            (true, Some(last_recording), None) => {
                self.save_recording_buffer(last_recording.clone())
            }
            (true, Some(last_recording), Some(recording_name)) => {
                if last_recording != recording_name {
                    self.recording_buffer.clear();
                } else {
                    self.save_recording_buffer(last_recording.clone());
                    return;
                }
            }
            _ => {}
        }

        self.active_recording = recording_name;
    }

    /// Saves an event into the currently active recording.
    ///
    /// Every sequential `BufferEvent::Insert` event will be merged together to cut down the number of
    /// `Editor::commit_delta` calls we need to make when playing back.
    pub(crate) fn record(&mut self, current_event: EventDomain) {
        assert!(self.is_recording());

        let recording_buffer = &mut self.recording_buffer;

        if recording_buffer.last().is_none() {
            recording_buffer.push(current_event);
            return;
        }

        {
            let last_event = recording_buffer.last_mut().unwrap();
            if let (
                EventDomain::Buffer(BufferEvent::Insert(old_characters)),
                EventDomain::Buffer(BufferEvent::Insert(new_characters)),
            ) = (last_event, &current_event)
            {
                old_characters.push_str(new_characters);
                return;
            }
        }

        recording_buffer.push(current_event);
    }

    /// Iterates over a specified recording's buffer and runs the specified action
    /// on each event.
    pub(crate) fn play<F>(&self, recording_name: &str, action: F)
    where
        F: FnMut(&EventDomain),
    {
        let is_current_recording: bool = self
            .active_recording
            .as_ref()
            .map_or(false, |current_recording| current_recording == recording_name);

        if is_current_recording {
            warn!("Cannot play recording while it's currently active!");
            return;
        }

        if let Some(recording) = self.recordings.get(recording_name) {
            recording.play(action);
        }
    }

    /// Completely removes the specified recording from the Recorder
    pub(crate) fn clear(&mut self, recording_name: &str) {
        self.recordings.remove(recording_name);
    }

    /// Cleans the recording buffer by filtering out any undo or redo events and then saving it
    /// with the specified name.
    ///
    /// A recording should not store any undos or redos--
    /// call this once a recording is 'finalized.'
    fn save_recording_buffer(&mut self, recording_name: String) {
        let mut saw_undo = false;
        let mut saw_redo = false;

        // Walk the recording backwards and remove any undo / redo events
        let filtered: Vec<EventDomain> = self
            .recording_buffer
            .clone()
            .into_iter()
            .rev()
            .filter(|event| {
                if let EventDomain::Buffer(event) = event {
                    return match event {
                        BufferEvent::Undo => {
                            saw_undo = !saw_redo;
                            saw_redo = false;
                            false
                        }
                        BufferEvent::Redo => {
                            saw_redo = !saw_undo;
                            saw_undo = false;
                            false
                        }
                        _ => {
                            let ret = !saw_undo;
                            saw_undo = false;
                            saw_redo = false;
                            ret
                        }
                    };
                }

                true
            })
            .collect::<Vec<EventDomain>>()
            .into_iter()
            .rev()
            .collect();

        let current_recording = Recording::new(filtered);
        self.recordings.insert(recording_name, current_recording);
        self.recording_buffer.clear();
    }
}

struct Recording {
    events: Vec<EventDomain>,
}

impl Recording {
    fn new(events: Vec<EventDomain>) -> Recording {
        Recording { events }
    }

    /// Iterates over the recording buffer and runs the specified action
    /// on each event.
    fn play<F>(&self, action: F)
    where
        F: FnMut(&EventDomain),
    {
        let _guard = trace_block("Recording::play", &["core", "recording"]);
        self.events.iter().for_each(action)
    }
}

// Tests for filtering undo / redo from the recording buffer
// A = Event
// B = Event
// U = Undo
// R = Redo
#[cfg(test)]
mod tests {
    use crate::edit_types::{BufferEvent, EventDomain};
    use crate::recorder::Recorder;

    #[test]
    fn play_recording() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();
        let mut expected_events: Vec<EventDomain> = vec![
            BufferEvent::Indent.into(),
            BufferEvent::Outdent.into(),
            BufferEvent::DuplicateLine.into(),
            BufferEvent::Transpose.into(),
        ];

        recorder.toggle_recording(Some(recording_name.clone()));
        for event in expected_events.iter().rev() {
            recorder.record(event.clone());
        }
        recorder.toggle_recording(Some(recording_name.clone()));

        recorder.play(&recording_name, |event| {
            // We shouldn't iterate more times than we added items!
            let expected_event = expected_events.pop();
            assert!(expected_event.is_some());

            // Should be the event we expect
            assert_eq!(*event, expected_event.unwrap());
        });

        // We should have iterated over everything we inserted
        assert_eq!(expected_events.len(), 0);
    }

    #[test]
    fn play_only_after_saved() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();
        let expected_events: Vec<EventDomain> = vec![
            BufferEvent::Indent.into(),
            BufferEvent::Outdent.into(),
            BufferEvent::DuplicateLine.into(),
            BufferEvent::Transpose.into(),
        ];

        recorder.toggle_recording(Some(recording_name.clone()));
        for event in expected_events.iter().rev() {
            recorder.record(event.clone());
        }

        recorder.play(&recording_name, |_| {
            // We shouldn't have any events to play since nothing was saved!
            assert!(false);
        });
    }

    #[test]
    fn prevent_same_playback() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();
        let expected_events: Vec<EventDomain> = vec![
            BufferEvent::Indent.into(),
            BufferEvent::Outdent.into(),
            BufferEvent::DuplicateLine.into(),
            BufferEvent::Transpose.into(),
        ];

        recorder.toggle_recording(Some(recording_name.clone()));
        for event in expected_events.iter().rev() {
            recorder.record(event.clone());
        }
        recorder.toggle_recording(Some(recording_name.clone()));

        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.play(&recording_name, |_| {
            // We shouldn't be able to play a recording while recording with the same name
            assert!(false);
        });
    }

    #[test]
    fn clear_recording() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::DuplicateLine.into());
        recorder.record(BufferEvent::Outdent.into());
        recorder.record(BufferEvent::Indent.into());
        recorder.toggle_recording(Some(recording_name.clone()));

        assert_eq!(recorder.recordings.get(&recording_name).unwrap().events.len(), 4);

        recorder.clear(&recording_name);

        assert!(recorder.recordings.get(&recording_name).is_none());
    }

    #[test]
    fn multiple_recordings() {
        let mut recorder = Recorder::new();

        let recording_a = "a".to_string();
        let recording_b = "b".to_string();

        recorder.toggle_recording(Some(recording_a.clone()));
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::DuplicateLine.into());
        recorder.toggle_recording(Some(recording_a.clone()));

        recorder.toggle_recording(Some(recording_b.clone()));
        recorder.record(BufferEvent::Outdent.into());
        recorder.record(BufferEvent::Indent.into());
        recorder.toggle_recording(Some(recording_b.clone()));

        assert_eq!(
            recorder.recordings.get(&recording_a).unwrap().events,
            vec![BufferEvent::Transpose.into(), BufferEvent::DuplicateLine.into()]
        );
        assert_eq!(
            recorder.recordings.get(&recording_b).unwrap().events,
            vec![BufferEvent::Outdent.into(), BufferEvent::Indent.into()]
        );

        recorder.clear(&recording_a);

        assert!(recorder.recordings.get(&recording_a).is_none());
        assert!(recorder.recordings.get(&recording_b).is_some());
    }

    #[test]
    fn text_playback() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Insert("Foo".to_owned()).into());
        recorder.record(BufferEvent::Insert("B".to_owned()).into());
        recorder.record(BufferEvent::Insert("A".to_owned()).into());
        recorder.record(BufferEvent::Insert("R".to_owned()).into());

        recorder.toggle_recording(Some(recording_name.clone()));
        assert_eq!(
            recorder.recordings.get(&recording_name).unwrap().events,
            vec![BufferEvent::Insert("FooBAR".to_owned()).into()]
        );
    }

    #[test]
    fn basic_undo() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        // Undo removes last item, redo only affects undo
        // A U B R => B
        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::Undo.into());
        recorder.record(BufferEvent::DuplicateLine.into());
        recorder.record(BufferEvent::Redo.into());
        recorder.toggle_recording(Some(recording_name.clone()));
        assert_eq!(
            recorder.recordings.get(&recording_name).unwrap().events,
            vec![BufferEvent::DuplicateLine.into()]
        );
    }

    #[test]
    fn basic_undo_swapped() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        // Swapping order of undo and redo from the basic test should give us a different leftover item
        // A R B U => A
        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::Redo.into());
        recorder.record(BufferEvent::DuplicateLine.into());
        recorder.record(BufferEvent::Undo.into());
        recorder.toggle_recording(Some(recording_name.clone()));
        assert_eq!(
            recorder.recordings.get(&recording_name).unwrap().events,
            vec![BufferEvent::Transpose.into()]
        );
    }

    #[test]
    fn redo_cancels_undo() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        // Redo cancels out an undo
        // A U R B => A B
        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::Undo.into());
        recorder.record(BufferEvent::Redo.into());
        recorder.record(BufferEvent::DuplicateLine.into());
        recorder.toggle_recording(Some(recording_name.clone()));
        assert_eq!(
            recorder.recordings.get(&recording_name).unwrap().events,
            vec![BufferEvent::Transpose.into(), BufferEvent::DuplicateLine.into()]
        );
    }

    #[test]
    fn undo_cancels_redo() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        // Undo should cancel a redo, preventing it from canceling another undo
        // A U R U => _
        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::Undo.into());
        recorder.record(BufferEvent::Redo.into());
        recorder.record(BufferEvent::Undo.into());
        recorder.toggle_recording(Some(recording_name.clone()));
        assert_eq!(recorder.recordings.get(&recording_name).unwrap().events, vec![]);
    }

    #[test]
    fn undo_as_first_item() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        // Undo shouldn't do anything as the first item
        // U A B R => A B
        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Undo.into());
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::DuplicateLine.into());
        recorder.record(BufferEvent::Redo.into());
        recorder.toggle_recording(Some(recording_name.clone()));
        assert_eq!(
            recorder.recordings.get(&recording_name).unwrap().events,
            vec![BufferEvent::Transpose.into(), BufferEvent::DuplicateLine.into()]
        );
    }

    #[test]
    fn redo_as_first_item() {
        let mut recorder = Recorder::new();

        let recording_name = String::new();

        // Redo shouldn't do anything as the first item
        // R A B U => A
        recorder.toggle_recording(Some(recording_name.clone()));
        recorder.record(BufferEvent::Redo.into());
        recorder.record(BufferEvent::Transpose.into());
        recorder.record(BufferEvent::DuplicateLine.into());
        recorder.record(BufferEvent::Undo.into());
        recorder.toggle_recording(Some(recording_name.clone()));
        assert_eq!(
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A data structure for manipulating sets of indices (typically used for
//! representing valid lines).

// Note: this data structure has nontrivial overlap with Subset in the rope
// crate. Maybe we don't need both.

use std::cmp::{max, min, Ordering};
use xi_rope::{RopeDelta, Transformer};

pub struct IndexSet {
    ranges: Vec<(usize, usize)>,
}

pub fn remove_n_at<T: Clone>(v: &mut Vec<T>, index: usize, n: usize) {
    match n.cmp(&1) {
        Ordering::Equal => {
            v.remove(index);
        }
        Ordering::Greater => {
            let new_len = v.len() - n;
            for i in index..new_len {
                v[i] = v[i + n].clone();
            }
            v.truncate(new_len);
        }
        Ordering::Less => (),
    }
}

impl IndexSet {
    /// Create a new, empty set.
    pub fn new() -> IndexSet {
        IndexSet { ranges: Vec::new() }
    }

    /// Clear the set.
    pub fn clear(&mut self) {
        self.ranges.clear();
    }

    /// Add the range start..end to the set.
    pub fn union_one_range(&mut self, start: usize, end: usize) {
        for i in 0..self.ranges.len() {
            let (istart, iend) = self.ranges[i];
            if start > iend {
                continue;
            } else if end < istart {
                self.ranges.insert(i, (start, end));
                return;
            } else {
                self.ranges[i].0 = min(start, istart);
                let mut j = i;
                while j + 1 < self.ranges.len() && end >= self.ranges[j + 1].0 {
                    j += 1;
                }
                self.ranges[i].1 = max(end, self.ranges[j].1);
                remove_n_at(&mut self.ranges, i + 1, j - i);
                return;
            }
        }
        self.ranges.push((start, end));
    }

    /// Deletes the given range from the set.
    pub fn delete_range(&mut self, start: usize, end: usize) {
        let mut ix = match self.ranges.binary_search_by(|r| r.1.cmp(&start)) {
            Ok(ix) => ix,
            Err(ix) => ix,
        };

        let mut del_from = None;
        let mut del_len = 0;
        while ix < self.ranges.len() {
            if self.ranges[ix].0 >= end {
                break;
            }

            if self.ranges[ix].0 < start {
                if self.ranges[ix].1 > end {
                    let range = (end, self.ranges[ix].1);
                    self.ranges.insert(ix + 1, range);
                }
                self.ranges[ix].1 = start;
            } else if self.ranges[ix].1 > end {
                self.ranges[ix].0 = end;
            } else {
                if del_from.is_none() {
                    del_from = Some(ix);
                }
                del_len += 1;
            }

            ix += 1;
        }

        if let Some(del_from) = del_from {
            remove_n_at(&mut self.ranges, del_from, del_len);
        }
    }

    /// Return an iterator that yields start..end minus the coverage in this set.
    pub fn minus_one_range(&self, start: usize, end: usize) -> MinusIter {
        let mut ranges = &self.ranges[..];
        while !ranges.is_empty() && start >= ranges[0].1 {
            ranges = &ranges[1..];
        }
        MinusIter { ranges, start, end }
    }

    /// Computes a new set based on applying a delta to the old set. Collapsed regions are removed
    /// and contiguous regions are combined.
    pub fn apply_delta(&self, delta: &RopeDelta) -> IndexSet {
        let mut ranges: Vec<(usize, usize)> = Vec::new();
        let mut transformer = Transformer::new(delta);
        for &(start, end) in &self.ranges {
            let new_range =
                (transformer.transform(start, false), transformer.transform(end, false));
            if new_range.0 == new_range.1 {
                continue; // remove collapsed regions
            }
            if !ranges.is_empty() {
                let ix = ranges.len() - 1;
                if ranges[ix].1 == new_range.0 {
                    ranges[ix] = (ranges[ix].0, new_range.1);
                    continue;
                }
            }
            ranges.push(new_range);
        }
        IndexSet { ranges }
    }

    #[cfg(test)]
    fn get_ranges(&self) -> &[(usize, usize)] {
        &self.ranges
    }
}

/// The iterator generated by `minus_one_range`.
pub struct MinusIter<'a> {
    ranges: &'a [(usize, usize)],
    start: usize,
    end: usize,
}

impl<'a> Iterator for MinusIter<'a> {
    type Item = (usize, usize);

    fn next(&mut self) -> Option<(usize, usize)> {
        while self.start < self.end {
            if self.ranges.is_empty() || self.end <= self.ranges[0].0 {
                let result = (self.start, self.end);
                self.start = self.end;
                return Some(result);
            }
            let result = (self.start, self.ranges[0].0);
            self.start = self.ranges[0].1;
            self.ranges = &self.ranges[1..];
            if result.1 > result.0 {
                return Some(result);
            }
        }
        None
    }
}

impl<'a> DoubleEndedIterator for MinusIter<'a> {
    fn next_back(&mut self) -> Option<Self::Item> {
        while self.start < self.end {
            if self.ranges.is_empty() || self.ranges[self.ranges.len() - 1].1 <= self.start {
                let result = (self.start, self.end);
                self.start = self.end;
                return Some(result);
            }
            let last_ix = self.ranges.len() - 1;
            let result = (self.ranges[last_ix].1, self.end);
            self.end = self.ranges[last_ix].0;
            self.ranges = &self.ranges[..last_ix];
            if result.1 > result.0 {
                return Some(result);
            }
        }
        None
    }
}

#[cfg(test)]
mod tests {
    use super::IndexSet;

    #[test]
    fn empty_behavior() {
        let e = IndexSet::new();
        assert_eq!(e.minus_one_range(0, 0).collect::<Vec<_>>(), vec![]);
        assert_eq!(e.minus_one_range(3, 5).collect::<Vec<_>>(), vec![(3, 5)]);
    }

    #[test]
    fn single_range_behavior() {
        let mut e = IndexSet::new();
        e.union_one_range(3, 5);
        assert_eq!(e.minus_one_range(0, 0).collect::<Vec<_>>(), vec![]);
        assert_eq!(e.minus_one_range(3, 5).collect::<Vec<_>>(), vec![]);
        assert_eq!(e.minus_one_range(0, 3).collect::<Vec<_>>(), vec![(0, 3)]);
        assert_eq!(e.minus_one_range(0, 4).collect::<Vec<_>>(), vec![(0, 3)]);
        assert_eq!(e.minus_one_range(4, 10).collect::<Vec<_>>(), vec![(5, 10)]);
        assert_eq!(e.minus_one_range(5, 10).collect::<Vec<_>>(), vec![(5, 10)]);
        assert_eq!(e.minus_one_range(0, 10).collect::<Vec<_>>(), vec![(0, 3), (5, 10)]);
    }

    #[test]
    fn two_range_minus() {
        let mut e = IndexSet::new();
        e.union_one_range(3, 5);
        e.union_one_range(7, 9);
        assert_eq!(e.minus_one_range(0, 0).collect::<Vec<_>>(), vec![]);
        assert_eq!(e.minus_one_range(3, 5).collect::<Vec<_>>(), vec![]);
        assert_eq!(e.minus_one_range(0, 3).collect::<Vec<_>>(), vec![(0, 3)]);
        assert_eq!(e.minus_one_range(0, 4).collect::<Vec<_>>(), vec![(0, 3)]);
        assert_eq!(e.minus_one_range(4, 10).collect::<Vec<_>>(), vec![(5, 7), (9, 10)]);
        assert_eq!(e.minus_one_range(5, 10).collect::<Vec<_>>(), vec![(5, 7), (9, 10)]);
        assert_eq!(e.minus_one_range(8, 10).collect::<Vec<_>>(), vec![(9, 10)]);
        assert_eq!(e.minus_one_range(0, 10).collect::<Vec<_>>(), vec![(0, 3), (5, 7), (9, 10)]);
    }

    #[test]
    fn minus_one_range_double_ended_iter() {
        let mut e = IndexSet::new();
        e.union_one_range(3, 5);
        e.union_one_range(7, 9);
        e.union_one_range(12, 15);

        let mut iter = e.minus_one_range(4, 13);
        assert_eq!(iter.next(), Some((5, 7)));
        assert_eq!(iter.next(), Some((9, 12)));
        assert_eq!(iter.next(), None);

        let mut iter = e.minus_one_range(4, 13);
        assert_eq!(iter.next_back(), Some((9, 12)));
        assert_eq!(iter.next_back(), Some((5, 7)));
        assert_eq!(iter.next_back(), None);

        let mut iter = e.minus_one_range(4, 13);
        assert_eq!(iter.next_back(), Some((9, 12)));
        assert_eq!(iter.next(), Some((5, 7)));
        assert_eq!(iter.next_back(), None);
        assert_eq!(iter.next(), None);
    }

    #[test]
    fn unions() {
        let mut e = IndexSet::new();
        e.union_one_range(3, 5);
        assert_eq!(e.get_ranges(), &[(3, 5)]);
        e.union_one_range(7, 9);
        assert_eq!(e.get_ranges(), &[(3, 5), (7, 9)]);
        e.union_one_range(1, 2);
        assert_eq!(e.get_ranges(), &[(1, 2), (3, 5), (7, 9)]);
        e.union_one_range(2, 3);
        assert_eq!(e.get_ranges(), &[(1, 5), (7, 9)]);
        e.union_one_range(4, 6);
        assert_eq!(e.get_ranges(), &[(1, 6), (7, 9)]);
        assert_eq!(e.minus_one_range(0, 10).collect::<Vec<_>>(), vec![(0, 1), (6, 7), (9, 10)]);

        e.clear();
        assert_eq!(e.get_ranges(), &[]);
        e.union_one_range(3, 4);
        assert_eq!(e.get_ranges(), &[(3, 4)]);
        e.union_one_range(5, 6);
        assert_eq!(e.get_ranges(), &[(3, 4), (5, 6)]);
        e.union_one_range(7, 8);
        assert_eq!(e.get_ranges(), &[(3, 4), (5, 6), (7, 8)]);
        e.union_one_range(9, 10);
        assert_eq!(e.get_ranges(), &[(3, 4), (5, 6), (7, 8), (9, 10)]);
        e.union_one_range(11, 12);
        assert_eq!(e.get_ranges(), &[(3, 4), (5, 6), (7, 8), (9, 10), (11, 12)]);
        e.union_one_range(2, 10);
        assert_eq!(e.get_ranges(), &[(2, 10), (11, 12)]);
    }

    #[test]
    fn delete_range() {
        let mut e = IndexSet::new();
        e.union_one_range(1, 2);
        e.union_one_range(4, 6);
        e.union_one_range(6, 7);
        e.union_one_range(8, 8);
        e.union_one_range(10, 12);
        e.union_one_range(13, 14);
        e.delete_range(5, 11);
        assert_eq!(e.get_ranges(), &[(1, 2), (4, 5), (11, 12), (13, 14)]);

        let mut e = IndexSet::new();
        e.union_one_range(1, 2);
        e.union_one_range(4, 6);
        e.delete_range(2, 4);
        assert_eq!(e.get_ranges(), &[(1, 2), (4, 6)]);

        let mut e = IndexSet::new();
        e.union_one_range(0, 10);
        e.delete_range(4, 6);
        assert_eq!(e.get_ranges(), &[(0, 4), (6, 10)]);
    }

    #[test]
    fn apply_delta() {
        use xi_rope::{Delta, Interval, Rope};

        let mut e = IndexSet::new();
        e.union_one_range(1, 3);
        e.union_one_range(5, 9);

        let d = Delta::simple_edit(Interval::new(2, 2), Rope::from("..."), 10);
        let s = e.apply_delta(&d);
        assert_eq!(s.get_ranges(), &[(1, 6), (8, 12)]);

        let d = Delta::simple_edit(Interval::new(0, 3), Rope::from(""), 10);
        let s = e.apply_delta(&d);
        assert_eq!(s.get_ranges(), &[(2, 6)]);

        let d = Delta::simple_edit(Interval::new(2, 6), Rope::from(""), 10);
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Utilities for detecting and working with indentation.

extern crate xi_rope;

use std::collections::BTreeMap;
use xi_rope::Rope;

/// An enumeration of legal indentation types.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Indentation {
    Tabs,
    Spaces(usize),
}

/// A struct representing the mixed indentation error.
#[derive(Debug)]
pub struct MixedIndentError;

impl Indentation {
    /// Parses a rope for indentation settings.
    pub fn parse(rope: &Rope) -> Result<Option<Self>, MixedIndentError> {
        let lines = rope.lines_raw(..);
        let mut tabs = false;
        let mut spaces: BTreeMap<usize, usize> = BTreeMap::new();

        for line in lines {
            match Indentation::parse_line(&line) {
                Ok(Some(Indentation::Spaces(size))) => {
                    let counter = spaces.entry(size).or_insert(0);
                    *counter += 1;
                }
                Ok(Some(Indentation::Tabs)) => tabs = true,
                Ok(None) => continue,
                Err(e) => return Err(e),
            }
        }

        match (tabs, !spaces.is_empty()) {
            (true, true) => Err(MixedIndentError),
            (true, false) => Ok(Some(Indentation::Tabs)),
            (false, true) => {
                let tab_size = extract_count(spaces);
                if tab_size > 0 {
                    Ok(Some(Indentation::Spaces(tab_size)))
                } else {
                    Ok(None)
                }
            }
            _ => Ok(None),
        }
    }

    /// Detects the indentation on a specific line.
    /// Parses whitespace until first occurrence of something else
    pub fn parse_line(line: &str) -> Result<Option<Self>, MixedIndentError> {
        let mut spaces = 0;

        for char in line.as_bytes() {
            match char {
                b' ' => spaces += 1,
                b'\t' if spaces > 0 => return Err(MixedIndentError),
                b'\t' => return Ok(Some(Indentation::Tabs)),
                _ => break,
            }
        }

        if spaces > 0 {
            Ok(Some(Indentation::Spaces(spaces)))
        } else {
            Ok(None)
        }
    }
}

/// Uses a heuristic to calculate the greatest common denominator of most used indentation depths.
///
/// As BTreeMaps are ordered by value, using take on the iterator ensures the indentation levels
/// most frequently used in the file are extracted.
fn extract_count(spaces: BTreeMap<usize, usize>) -> usize {
    let mut take_size = 4;

    if spaces.len() < take_size {
        take_size = spaces.len();
    }

    // Fold results using GCD, skipping numbers which result in gcd returning 1
    spaces.iter().take(take_size).fold(0, |a, (b, _)| {
        let d = gcd(a, *b);
        if d == 1 {
            a
        } else {
            d
        }
    })
}

/// Simple implementation to calculate greatest common divisor, based on Euclid's algorithm
fn gcd(a: usize, b: usize) -> usize {
    if a == 0 {
        b
    } else if b == 0 || a == b {
        a
    } else {
        let mut a = a;
        let mut b = b;

        while b > 0 {
            let r = a % b;
            a = b;
            b = r;
        }
        a
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn gcd_calculates_correctly() {
        assert_eq!(21, gcd(1071, 462));
        assert_eq!(6, gcd(270, 192));
    }

    #[test]
    fn line_gets_two_spaces() {
        let result = Indentation::parse_line("  ");
        let expected = Indentation::Spaces(2);

        assert_eq!(result.unwrap(), Some(expected));
    }

    #[test]
    fn line_gets_tabs() {
        let result = Indentation::parse_line("\t");
        let expected = Indentation::Tabs;

        assert_eq!(result.unwrap(), Some(expected));
    }

    #[test]
    fn line_errors_mixed_indent() {
        let result = Indentation::parse_line("  \t");
        assert!(result.is_err());
    }

    #[test]
    fn rope_gets_two_spaces() {
        let result = Indentation::parse(&Rope::from(
            r#"
        // This is a comment
          Testing
          Indented
            Even more indented
            # Comment
            # Comment
            # Comment
        "#,
        ));
        let expected = Indentation::Spaces(2);

        assert_eq!(result.unwrap(), Some(expected));
    }

    #[test]
    fn rope_gets_four_spaces() {
        let result = Indentation::parse(&Rope::from(
            r#"
        fn my_fun_func(&self,
                       another_arg: usize) -> Fun {
            /* Random comment describing program behavior */
            Fun::from(another_arg)
        }
        "#,
        ));
        let expected = Indentation::Spaces(4);

        assert_eq!(result.unwrap(), Some(expected));
    }

    #[test]
    fn rope_returns_none() {
        let result = Indentation::parse(&Rope::from(
            r#"# Readme example
 1. One space.
But the majority is still 0.
"#,
        ));

        assert_eq!(result.unwrap(), None);
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A container for the state relevant to a single event.

use std::cell::RefCell;
use std::iter;
use std::ops::Range;
use std::path::Path;
use std::time::{Duration, Instant};

use serde_json::{self, Value};

use xi_rope::{Cursor, Interval, LinesMetric, Rope, RopeDelta};
use xi_rpc::{Error as RpcError, RemoteError};
use xi_trace::trace_block;

use crate::plugins::rpc::{
    ClientPluginInfo, Hover, PluginBufferInfo, PluginNotification, PluginRequest, PluginUpdate,
};
use crate::rpc::{EditNotification, EditRequest, LineRange, Position as ClientPosition};

use crate::client::Client;
use crate::config::{BufferItems, Table};
use crate::edit_types::{EventDomain, SpecialEvent};
use crate::editor::Editor;
use crate::file::FileInfo;
use crate::line_offset::LineOffset;
use crate::plugins::Plugin;
use crate::recorder::Recorder;
use crate::selection::InsertDrift;
use crate::styles::ThemeStyleMap;
use crate::syntax::LanguageId;
use crate::tabs::{
    BufferId, PluginId, ViewId, FIND_VIEW_IDLE_MASK, RENDER_VIEW_IDLE_MASK, REWRAP_VIEW_IDLE_MASK,
};
use crate::view::View;
use crate::width_cache::WidthCache;
use crate::WeakXiCore;

// Maximum returned result from plugin get_data RPC.
pub const MAX_SIZE_LIMIT: usize = 1024 * 1024;

//TODO: tune this. a few ms can make a big difference. We may in the future
//want to make this tuneable at runtime, or to be configured by the client.
/// The render delay after an edit occurs; plugin updates received in this
/// window will be sent to the view along with the edit.
const RENDER_DELAY: Duration = Duration::from_millis(2);

/// A collection of all the state relevant for handling a particular event.
///
/// This is created dynamically for each event that arrives to the core,
/// such as a user-initiated edit or style updates from a plugin.
pub struct EventContext<'a> {
    pub(crate) view_id: ViewId,
    pub(crate) buffer_id: BufferId,
    pub(crate) editor: &'a RefCell<Editor>,
    pub(crate) info: Option<&'a FileInfo>,
    pub(crate) config: &'a BufferItems,
    pub(crate) recorder: &'a RefCell<Recorder>,
    pub(crate) language: LanguageId,
    pub(crate) view: &'a RefCell<View>,
    pub(crate) siblings: Vec<&'a RefCell<View>>,
    pub(crate) plugins: Vec<&'a Plugin>,
    pub(crate) client: &'a Client,
    pub(crate) style_map: &'a RefCell<ThemeStyleMap>,
    pub(crate) width_cache: &'a RefCell<WidthCache>,
    pub(crate) kill_ring: &'a RefCell<Rope>,
    pub(crate) weak_core: &'a WeakXiCore,
}

impl<'a> EventContext<'a> {
    /// Executes a closure with mutable references to the editor and the view,
    /// common in edit actions that modify the text.
    pub(crate) fn with_editor<R, F>(&mut self, f: F) -> R
    where
        F: FnOnce(&mut Editor, &mut View, &mut Rope, &BufferItems) -> R,
    {
        let mut editor = self.editor.borrow_mut();
        let mut view = self.view.borrow_mut();
        let mut kill_ring = self.kill_ring.borrow_mut();
        f(&mut editor, &mut view, &mut kill_ring, &self.config)
    }

    /// Executes a closure with a mutable reference to the view and a reference
    /// to the current text. This is common to most edits that just modify
    /// selection or viewport state.
    fn with_view<R, F>(&mut self, f: F) -> R
    where
        F: FnOnce(&mut View, &Rope) -> R,
    {
        let editor = self.editor.borrow();
        let mut view = self.view.borrow_mut();
        f(&mut view, editor.get_buffer())
    }

    fn with_each_plugin<F: FnMut(&&Plugin)>(&self, f: F) {
        self.plugins.iter().for_each(f)
    }

    pub(crate) fn do_edit(&mut self, cmd: EditNotification) {
        let event: EventDomain = cmd.into();

        {
            // Handle recording-- clone every non-toggle and play event into the recording buffer
            let mut recorder = self.recorder.borrow_mut();
            match (recorder.is_recording(), &event) {
                (_, EventDomain::Special(SpecialEvent::ToggleRecording(recording_name))) => {
                    recorder.toggle_recording(recording_name.clone());
                }
                // Don't save special events
                (true, EventDomain::Special(_)) => {
                    warn!("Special events cannot be recorded-- ignoring event {:?}", event)
                }
                (true, event) => recorder.record(event.clone()),
                _ => {}
            }
        }

        self.dispatch_event(event);
        self.after_edit("core");
        self.render_if_needed();
    }

    fn dispatch_event(&mut self, event: EventDomain) {
        use self::EventDomain as E;
        match event {
            E::View(cmd) => {
                self.with_view(|view, text| view.do_edit(text, cmd));
                self.editor.borrow_mut().update_edit_type();
                if self.with_view(|v, t| v.needs_wrap_in_visible_region(t)) {
                    self.rewrap();
                }
                if self.with_view(|v, _| v.find_in_progress()) {
                    self.do_incremental_find();
                }
            }
            E::Buffer(cmd) => {
                self.with_editor(|ed, view, k_ring, conf| ed.do_edit(view, k_ring, conf, cmd))
            }
            E::Special(cmd) => self.do_special(cmd),
        }
    }

    fn do_special(&mut self, cmd: SpecialEvent) {
        match cmd {
            SpecialEvent::Resize(size) => {
                self.with_view(|view, _| view.set_size(size));
                if self.config.word_wrap {
                    self.update_wrap_settings(false);
                }
            }
            SpecialEvent::DebugRewrap | SpecialEvent::DebugWrapWidth => {
                warn!("debug wrapping methods are removed, use the config system")
            }
            SpecialEvent::DebugPrintSpans => self.with_editor(|ed, view, _, _| {
                let sel = view.sel_regions().last().unwrap();
                let iv = Interval::new(sel.min(), sel.max());
                ed.get_layers().debug_print_spans(iv);
            }),
            SpecialEvent::RequestLines(LineRange { first, last }) => {
                self.do_request_lines(first as usize, last as usize)
            }
            SpecialEvent::RequestHover { request_id, position } => {
                self.do_request_hover(request_id, position)
            }
            SpecialEvent::DebugToggleComment => self.do_debug_toggle_comment(),
            SpecialEvent::Reindent => self.do_reindent(),
            SpecialEvent::ToggleRecording(_) => {}
            SpecialEvent::PlayRecording(recording_name) => {
                let recorder = self.recorder.borrow();

                let starting_revision = self.editor.borrow_mut().get_head_rev_token();

                // Don't group with the previous action
                self.editor.borrow_mut().update_edit_type();
                self.editor.borrow_mut().calculate_undo_group();

                // No matter what, our entire block must belong to the same undo group
                self.editor.borrow_mut().set_force_undo_group(true);
                recorder.play(&recording_name, |event| {
                    self.dispatch_event(event.clone());

                    let mut editor = self.editor.borrow_mut();
                    let (delta, last_text, drift) = match editor.commit_delta() {
                        Some(edit_info) => edit_info,
                        None => return,
                    };
                    self.update_views(&editor, &delta, &last_text, drift);
                });
                self.editor.borrow_mut().set_force_undo_group(false);

                // The action that follows the block must belong to a separate undo group
                self.editor.borrow_mut().update_edit_type();

                let delta = self.editor.borrow_mut().delta_rev_head(starting_revision).unwrap();
                self.update_plugins(&mut self.editor.borrow_mut(), delta, "core");
            }
            SpecialEvent::ClearRecording(recording_name) => {
                let mut recorder = self.recorder.borrow_mut();
                recorder.clear(&recording_name);
            }
        }
    }

    pub(crate) fn do_edit_sync(&mut self, cmd: EditRequest) -> Result<Value, RemoteError> {
        use self::EditRequest::*;
        let result = match cmd {
            Cut => Ok(self.with_editor(|ed, view, _, _| ed.do_cut(view))),
            Copy => Ok(self.with_editor(|ed, view, _, _| ed.do_copy(view))),
        };
        self.after_edit("core");
        self.render_if_needed();
        result
    }

    pub(crate) fn do_plugin_cmd(&mut self, plugin: PluginId, cmd: PluginNotification) {
        use self::PluginNotification::*;
        match cmd {
            AddScopes { scopes } => {
                let mut ed = self.editor.borrow_mut();
                let style_map = self.style_map.borrow();
                ed.get_layers_mut().add_scopes(plugin, scopes, &style_map);
            }
            UpdateSpans { start, len, spans, rev } => self.with_editor(|ed, view, _, _| {
                ed.update_spans(view, plugin, start, len, spans, rev)
            }),
            Edit { edit } => self.with_editor(|ed, _, _, _| ed.apply_plugin_edit(edit)),
            Alert { msg } => self.client.alert(&msg),
            AddStatusItem { key, value, alignment } => {
                let plugin_name = &self.plugins.iter().find(|p| p.id == plugin).unwrap().name;
                self.client.add_status_item(self.view_id, plugin_name, &key, &value, &alignment);
            }
            UpdateStatusItem { key, value } => {
                self.client.update_status_item(self.view_id, &key, &value)
            }
            UpdateAnnotations { start, len, spans, annotation_type, rev } => {
                self.with_editor(|ed, view, _, _| {
                    ed.update_annotations(view, plugin, start, len, spans, annotation_type, rev)
                })
            }
            RemoveStatusItem { key } => self.client.remove_status_item(self.view_id, &key),
            ShowHover { request_id, result } => self.do_show_hover(request_id, result),
        };
        self.after_edit(&plugin.to_string());
        self.render_if_needed();
    }

    pub(crate) fn do_plugin_cmd_sync(&mut self, _plugin: PluginId, cmd: PluginRequest) -> Value {
        use self::PluginRequest::*;
        match cmd {
            LineCount => json!(self.editor.borrow().plugin_n_lines()),
            GetData { start, unit, max_size, rev } => {
                json!(self.editor.borrow().plugin_get_data(start, unit, max_size, rev))
            }
            GetSelections => json!("not implemented"),
        }
    }

    /// Commits any changes to the buffer, updating views and plugins as needed.
    /// This only updates internal state; it does not update the client.
    fn after_edit(&mut self, author: &str) {
        let _t = trace_block("EventContext::after_edit", &["core"]);

        let edit_info = self.editor.borrow_mut().commit_delta();
        let (delta, last_text, drift) = match edit_info {
            Some(edit_info) => edit_info,
            None => return,
        };

        self.update_views(&self.editor.borrow(), &delta, &last_text, drift);
        self.update_plugins(&mut self.editor.borrow_mut(), delta, author);

        //if we have no plugins we always render immediately.
        if !self.plugins.is_empty() {
            let mut view = self.view.borrow_mut();
            if !view.has_pending_render() {
                let timeout = Instant::now() + RENDER_DELAY;
                let view_id: usize = self.view_id.into();
                let token = RENDER_VIEW_IDLE_MASK | view_id;
                self.client.schedule_timer(timeout, token);
                view.set_has_pending_render(true);
            }
        }
    }

    fn update_views(&self, ed: &Editor, delta: &RopeDelta, last_text: &Rope, drift: InsertDrift) {
        let mut width_cache = self.width_cache.borrow_mut();
        let iter_views = iter::once(&self.view).chain(self.siblings.iter());
        iter_views.for_each(|view| {
            view.borrow_mut().after_edit(
                ed.get_buffer(),
                last_text,
                delta,
                self.client,
                &mut width_cache,
                drift,
            )
        });
    }

    fn update_plugins(&self, ed: &mut Editor, delta: RopeDelta, author: &str) {
        let new_len = delta.new_document_len();
        let nb_lines = ed.get_buffer().measure::<LinesMetric>() + 1;
        // don't send the actual delta if it is too large, by some heuristic
        let approx_size = delta.inserts_len() + (delta.els.len() * 10);
        let delta = if approx_size > MAX_SIZE_LIMIT { None } else { Some(delta) };

        let undo_group = ed.get_active_undo_group();
        //TODO: we want to just put EditType on the wire, but don't want
        //to update the plugin lib quite yet.
        let v: Value = serde_json::to_value(&ed.get_edit_type()).unwrap();
        let edit_type_str = v.as_str().unwrap().to_string();

        let update = PluginUpdate::new(
            self.view_id,
            ed.get_head_rev_token(),
            delta,
            new_len,
            nb_lines,
            Some(undo_group),
            edit_type_str,
            author.into(),
        );

        // we always increment and decrement regardless of whether we're
        // sending plugins, to ensure that GC runs.
        ed.increment_revs_in_flight();

        self.plugins.iter().for_each(|plugin| {
            ed.increment_revs_in_flight();
            let weak_core = self.weak_core.clone();
            let id = plugin.id;
            let view_id = self.view_id;
            plugin.update(&update, move |resp| {
                weak_core.handle_plugin_update(id, view_id, resp);
            });
        });
        ed.dec_revs_in_flight();
        ed.update_edit_type();
    }

    /// Renders the view, if a render has not already been scheduled.
    pub(crate) fn render_if_needed(&mut self) {
        let needed = !self.view.borrow().has_pending_render();
        if needed {
            self.render()
        }
    }

    pub(crate) fn _finish_delayed_render(&mut self) {
        self.render();
        self.view.borrow_mut().set_has_pending_render(false);
    }

    /// Flushes any changes in the views out to the frontend.
    fn render(&mut self) {
        let _t = trace_block("EventContext::render", &["core"]);
        let ed = self.editor.borrow();
        //TODO: render other views
        self.view.borrow_mut().render_if_dirty(
            ed.get_buffer(),
            self.client,
            self.style_map,
            ed.get_layers().get_merged(),
            ed.is_pristine(),
        )
    }
}

/// Helpers related to specific commands.
///
/// Certain events and actions don't generalize well; handling these
/// requires access to particular combinations of state. We isolate such
/// special cases here.
impl<'a> EventContext<'a> {
    pub(crate) fn view_init(&mut self) {
        let wrap_width = self.config.wrap_width;
        let word_wrap = self.config.word_wrap;

        self.with_view(|view, text| view.update_wrap_settings(text, wrap_width, word_wrap));
    }

    pub(crate) fn finish_init(&mut self, config: &Table) {
        if !self.plugins.is_empty() {
            let info = self.plugin_info();

            self.plugins.iter().for_each(|plugin| {
                plugin.new_buffer(&info);
                self.plugin_started(plugin);
            });
        }

        let available_plugins = self
            .plugins
            .iter()
            .map(|plugin| ClientPluginInfo { name: plugin.name.clone(), running: true })
            .collect::<Vec<_>>();
        self.client.available_plugins(self.view_id, &available_plugins);

        self.client.config_changed(self.view_id, config);
        self.client.language_changed(self.view_id, &self.language);

        // Rewrap and request a render.
        // This is largely similar to update_wrap_settings(), the only difference
        // being that the view is expected to be already initialized.
        self.rewrap();

        if self.view.borrow().needs_more_wrap() {
            self.schedule_rewrap();
        }

        self.with_view(|view, text| view.set_dirty(text));
        self.render()
    }

    pub(crate) fn after_save(&mut self, path: &Path) {
        // notify plugins
        self.plugins.iter().for_each(|plugin| plugin.did_save(self.view_id, path));

        self.editor.borrow_mut().set_pristine();
        self.with_view(|view, text| view.set_dirty(text));
        self.render()
    }

    /// Returns `true` if this was the last view
    pub(crate) fn close_view(&self) -> bool {
        // we probably want to notify plugins _before_ we close the view
        // TODO: determine what plugins we're stopping
        self.plugins.iter().for_each(|plug| plug.close_view(self.view_id));
        self.siblings.is_empty()
    }

    pub(crate) fn config_changed(&mut self, changes: &Table) {
        if changes.contains_key("wrap_width") || changes.contains_key("word_wrap") {
            // FIXME: if switching from measurement-based widths to columnar widths,
            // we need to reset the cache, since we're using different coordinate spaces
            // for the same IDs. The long-term solution would be to include font
            // information in the width cache, and then use real width even in the column
            // case, getting the unit width for a typeface and multiplying that by
            // a string's unicode width.
            if changes.contains_key("word_wrap") {
                debug!("clearing {} items from width cache", self.width_cache.borrow().len());
                self.width_cache.replace(WidthCache::new());
            }
            self.update_wrap_settings(true);
        }

        self.client.config_changed(self.view_id, &changes);
        self.plugins.iter().for_each(|plug| plug.config_changed(self.view_id, &changes));
        self.render()
    }

    pub(crate) fn language_changed(&mut self, new_language_id: &LanguageId) {
        self.language = new_language_id.clone();
        self.client.language_changed(self.view_id, new_language_id);
        self.plugins.iter().for_each(|plug| plug.language_changed(self.view_id, new_language_id));
    }

    pub(crate) fn reload(&mut self, text: Rope) {
        self.with_editor(|ed, _, _, _| ed.reload(text));
        self.after_edit("core");
        self.render();
    }

    pub(crate) fn plugin_info(&mut self) -> PluginBufferInfo {
        let ed = self.editor.borrow();
        let nb_lines = ed.get_buffer().measure::<LinesMetric>() + 1;
        let views: Vec<ViewId> = iter::once(&self.view)
            .chain(self.siblings.iter())
            .map(|v| v.borrow().get_view_id())
            .collect();

        let changes = serde_json::to_value(self.config).unwrap();
        let path = self.info.map(|info| info.path.to_owned());
        PluginBufferInfo::new(
            self.buffer_id,
            &views,
            ed.get_head_rev_token(),
            ed.get_buffer().len(),
            nb_lines,
            path,
            self.language.clone(),
            changes.as_object().unwrap().to_owned(),
        )
    }

    pub(crate) fn plugin_started(&self, plugin: &Plugin) {
        self.client.plugin_started(self.view_id, &plugin.name)
    }

    pub(crate) fn plugin_stopped(&mut self, plugin: &Plugin) {
        self.client.plugin_stopped(self.view_id, &plugin.name, 0);
        let needs_render = self.with_editor(|ed, view, _, _| {
            if ed.get_layers_mut().remove_layer(plugin.id).is_some() {
                view.set_dirty(ed.get_buffer());
                true
            } else {
                false
            }
        });
        if needs_render {
            self.render();
        }
    }

    pub(crate) fn do_plugin_update(&mut self, update: Result<Value, RpcError>) {
        match update.map(serde_json::from_value::<u64>) {
            Ok(Ok(_)) => (),
            Ok(Err(err)) => error!("plugin response json err: {:?}", err),
            Err(err) => error!("plugin shutdown, do something {:?}", err),
        }
        self.editor.borrow_mut().dec_revs_in_flight();
    }

    /// Returns the text to be saved, appending a newline if necessary.
    pub(crate) fn text_for_save(&mut self) -> Rope {
        let editor = self.editor.borrow();
        let mut rope = editor.get_buffer().clone();
        let rope_len = rope.len();

        if rope_len < 1 || !self.config.save_with_newline {
            return rope;
        }

        let cursor = Cursor::new(&rope, rope.len());
        let has_newline_at_eof = match cursor.get_leaf() {
            Some((last_chunk, _)) => last_chunk.ends_with(&self.config.line_ending),
            // The rope can't be empty, since we would have returned earlier if it was
            None => unreachable!(),
        };

        if !has_newline_at_eof {
            let line_ending = &self.config.line_ending;
            rope.edit(rope_len.., line_ending);
            rope
        } else {
            rope
        }
    }

    /// Called after anything changes that effects word wrap, such as the size of
    /// the window or the user's wrap settings. `rewrap_immediately` should be `true`
    /// except in the resize case; during live resize we want to delay recalculation
    /// to avoid unnecessary work.
    fn update_wrap_settings(&mut self, rewrap_immediately: bool) {
        let wrap_width = self.config.wrap_width;
        let word_wrap = self.config.word_wrap;
        self.with_view(|view, text| view.update_wrap_settings(text, wrap_width, word_wrap));
        if rewrap_immediately {
            self.rewrap();
            self.with_view(|view, text| view.set_dirty(text));
        }
        if self.view.borrow().needs_more_wrap() {
            self.schedule_rewrap();
        }
    }

    /// Tells the view to rewrap a batch of lines, if needed. This guarantees that
    /// the currently visible region will be correctly wrapped; the caller should
    /// check if additional wrapping is necessary and schedule that if so.
    fn rewrap(&mut self) {
        let mut view = self.view.borrow_mut();
        let ed = self.editor.borrow();
        let mut width_cache = self.width_cache.borrow_mut();
        view.rewrap(ed.get_buffer(), &mut width_cache, self.client, ed.get_layers().get_merged());
    }

    /// Does incremental find.
    pub(crate) fn do_incremental_find(&mut self) {
        let _t = trace_block("EventContext::do_incremental_find", &["find"]);

        self.find();
        if self.view.borrow().find_in_progress() {
            let ed = self.editor.borrow();
            self.client.find_status(
                self.view_id,
                &json!(self.view.borrow().find_status(ed.get_buffer(), true)),
            );
            self.schedule_find();
        }
        self.render_if_needed();
    }

    fn schedule_find(&self) {
        let view_id: usize = self.view_id.into();
        let token = FIND_VIEW_IDLE_MASK | view_id;
        self.client.schedule_idle(token);
    }

    /// Tells the view to execute find on a batch of lines, if needed.
    fn find(&mut self) {
        let mut view = self.view.borrow_mut();
        let ed = self.editor.borrow();
        view.do_find(ed.get_buffer());
    }

    /// Does a rewrap batch, and schedules follow-up work if needed.
    pub(crate) fn do_rewrap_batch(&mut self) {
        self.rewrap();
        if self.view.borrow().needs_more_wrap() {
            self.schedule_rewrap();
        }
        self.render_if_needed();
    }

    fn schedule_rewrap(&self) {
        let view_id: usize = self.view_id.into();
        let token = REWRAP_VIEW_IDLE_MASK | view_id;
        self.client.schedule_idle(token);
    }

    fn do_request_lines(&mut self, first: usize, last: usize) {
        let mut view = self.view.borrow_mut();
        let ed = self.editor.borrow();
        view.request_lines(
            ed.get_buffer(),
            self.client,
            self.style_map,
            ed.get_layers().get_merged(),
            first,
            last,
            ed.is_pristine(),
        )
    }

    fn selected_line_ranges(&mut self) -> Vec<(usize, usize)> {
        let ed = self.editor.borrow();
        let mut prev_range: Option<Range<usize>> = None;
        let mut line_ranges = Vec::new();
        // we send selection state to syntect in the form of a vec of line ranges,
        // so we combine overlapping selections to get the minimum set of ranges.
        for region in self.view.borrow().sel_regions().iter() {
            let start = ed.get_buffer().line_of_offset(region.min());
            let end = ed.get_buffer().line_of_offset(region.max()) + 1;
            let line_range = start..end;
            let prev = prev_range.take();
            match (prev, line_range) {
                (None, range) => prev_range = Some(range),
                (Some(ref prev), ref range) if range.start <= prev.end => {
                    let combined =
                        Range { start: prev.start.min(range.start), end: prev.end.max(range.end) };
                    prev_range = Some(combined);
                }
                (Some(prev), range) => {
                    line_ranges.push((prev.start, prev.end));
                    prev_range = Some(range);
                }
            }
        }

        if let Some(prev) = prev_range {
            line_ranges.push((prev.start, prev.end));
        }

        line_ranges
    }

    fn do_reindent(&mut self) {
        let line_ranges = self.selected_line_ranges();
        // this is handled by syntect only; this is definitely not the long-term solution.
        if let Some(plug) = self.plugins.iter().find(|p| p.name == "xi-syntect-plugin") {
            plug.dispatch_command(self.view_id, "reindent", &json!(line_ranges));
        }
    }

    fn do_debug_toggle_comment(&mut self) {
        let line_ranges = self.selected_line_ranges();

        // this is handled by syntect only; this is definitely not the long-term solution.
        if let Some(plug) = self.plugins.iter().find(|p| p.name == "xi-syntect-plugin") {
            plug.dispatch_command(self.view_id, "toggle_comment", &json!(line_ranges));
        }
    }

    fn do_request_hover(&mut self, request_id: usize, position: Option<ClientPosition>) {
        if let Some(position) = self.get_resolved_position(position) {
            self.with_each_plugin(|p| p.get_hover(self.view_id, request_id, position))
        }
    }

    fn do_show_hover(&mut self, request_id: usize, hover: Result<Hover, RemoteError>) {
        match hover {
            Ok(hover) => {
                // TODO: Get Range from hover here and use it to highlight text
                self.client.show_hover(self.view_id, request_id, hover.content)
            }
            Err(err) => warn!("Hover Response from Client Error {:?}", err),
        }
    }

    /// Gives the requested position in UTF-8 offset format to be sent to plugin
    /// If position is `None`, it tries to get the current Caret Position and use
    /// that instead
    fn get_resolved_position(&mut self, position: Option<ClientPosition>) -> Option<usize> {
        position
            .map(|p| self.with_view(|view, text| view.line_col_to_offset(text, p.line, p.column)))
            .or_else(|| self.view.borrow().get_caret_offset())
    }
}

#[cfg(test)]
#[rustfmt::skip]
mod tests {
    use super::*;
    use crate::config::ConfigManager;
    use crate::core::dummy_weak_core;
    use crate::tabs::BufferId;
    use xi_rpc::test_utils::DummyPeer;

    struct ContextHarness {
        view: RefCell<View>,
        editor: RefCell<Editor>,
        client: Client,
        core_ref: WeakXiCore,
        kill_ring: RefCell<Rope>,
        style_map: RefCell<ThemeStyleMap>,
        width_cache: RefCell<WidthCache>,
        config_manager: ConfigManager,
        recorder: RefCell<Recorder>,
    }

    impl ContextHarness {
        fn new<S: AsRef<str>>(s: S) -> Self {
            // we could make this take a config, which would let us test
            // behaviour with different config settings?
            let view_id = ViewId(1);
            let buffer_id = BufferId(2);
            let mut config_manager = ConfigManager::new(None, None);
            let config = config_manager.add_buffer(buffer_id, None);
            let view = RefCell::new(View::new(view_id, buffer_id));
            let editor = RefCell::new(Editor::with_text(s));
            let client = Client::new(Box::new(DummyPeer));
            let core_ref = dummy_weak_core();
            let kill_ring = RefCell::new(Rope::from(""));
            let style_map = RefCell::new(ThemeStyleMap::new(None));
            let width_cache = RefCell::new(WidthCache::new());
            let recorder = RefCell::new(Recorder::new());
            let harness = ContextHarness { view, editor, client, core_ref, kill_ring,
                             style_map, width_cache, config_manager, recorder };
            harness.make_context().view_init();
            harness.make_context().finish_init(&config);
            harness

        }

        /// Renders the text and selections. cursors are represented with
        /// the pipe '|', and non-caret regions are represented by \[braces\].
        fn debug_render(&self) -> String {
            let b = self.editor.borrow();
            let mut text: String = b.get_buffer().into();
            let v = self.view.borrow();
            for sel in v.sel_regions().iter().rev() {
                if sel.end == sel.start {
                    text.insert(sel.end, '|');
                } else if sel.end > sel.start {
                    text.insert_str(sel.end, "|]");
                    text.insert(sel.start, '[');
                } else {
                    text.insert(sel.start, ']');
                    text.insert_str(sel.end, "[|");
                }
            }
            text
        }

        fn make_context<'a>(&'a self) -> EventContext<'a> {
            let view_id = ViewId(1);
            let buffer_id = self.view.borrow().get_buffer_id();
            let config = self.config_manager.get_buffer_config(buffer_id);
            let language = self.config_manager.get_buffer_language(buffer_id);
            EventContext {
                view_id,
                buffer_id,
                view: &self.view,
                editor: &self.editor,
                config: &config.items,
                language,
                info: None,
                siblings: Vec::new(),
                plugins: Vec::new(),
                recorder: &self.recorder,
                client: &self.client,
                kill_ring: &self.kill_ring,
                style_map: &self.style_map,
                width_cache: &self.width_cache,
                weak_core: &self.core_ref,
            }
        }
    }

    #[test]
    fn smoke_test() {
        let harness = ContextHarness::new("");
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Insert { chars: "hello".into() });
        ctx.do_edit(EditNotification::Insert { chars: " ".into() });
        ctx.do_edit(EditNotification::Insert { chars: "world".into() });
        ctx.do_edit(EditNotification::Insert { chars: "!".into() });
        assert_eq!(harness.debug_render(),"hello world!|");
        ctx.do_edit(EditNotification::MoveWordLeft);
        ctx.do_edit(EditNotification::InsertNewline);
        assert_eq!(harness.debug_render(),"hello \n|world!");
        ctx.do_edit(EditNotification::MoveWordRightAndModifySelection);
        assert_eq!(harness.debug_render(), "hello \n[world|]!");
        ctx.do_edit(EditNotification::Insert { chars: "friends".into() });
        assert_eq!(harness.debug_render(), "hello \nfriends|!");
    }

    #[test]
    fn test_gestures() {
        use crate::rpc::GestureType::*;
        let initial_text = "\
        this is a string\n\
        that has three\n\
        lines.";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();

        ctx.do_edit(EditNotification::MoveDown);
        ctx.do_edit(EditNotification::MoveDown);
        ctx.do_edit(EditNotification::MoveToEndOfParagraph);
        assert_eq!(harness.debug_render(),"\
        this is a string\n\
        that has three\n\
        lines.|" );

        ctx.do_edit(EditNotification::Gesture { line: 0, col: 0, ty: PointSelect });
        ctx.do_edit(EditNotification::MoveToEndOfParagraphAndModifySelection);
        assert_eq!(harness.debug_render(),"\
        [this is a string|]\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::MoveToEndOfParagraph);
        ctx.do_edit(EditNotification::MoveToBeginningOfParagraphAndModifySelection);
        assert_eq!(harness.debug_render(),"\
        [|this is a string]\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::Gesture { line: 0, col: 0, ty: PointSelect });
        assert_eq!(harness.debug_render(),"\
        |this is a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::Gesture { line: 0, col: 5, ty: PointSelect });
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::Gesture { line: 1, col: 5, ty: ToggleSel });
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that |has three\n\
        lines." );

        ctx.do_edit(EditNotification::MoveToRightEndOfLineAndModifySelection);
        assert_eq!(harness.debug_render(),"\
        this [is a string|]\n\
        that [has three|]\n\
        lines." );

        ctx.do_edit(EditNotification::Gesture { line: 2, col: 2, ty: MultiWordSelect });
        assert_eq!(harness.debug_render(),"\
        this [is a string|]\n\
        that [has three|]\n\
        [lines|]." );

        ctx.do_edit(EditNotification::Gesture { line: 2, col: 2, ty: ToggleSel });
        assert_eq!(harness.debug_render(),"\
        this [is a string|]\n\
        that [has three|]\n\
        lines." );

        ctx.do_edit(EditNotification::Gesture { line: 2, col: 2, ty: ToggleSel });
        assert_eq!(harness.debug_render(),"\
        this [is a string|]\n\
        that [has three|]\n\
        li|nes." );

        ctx.do_edit(EditNotification::MoveToLeftEndOfLine);
        assert_eq!(harness.debug_render(),"\
        |this is a string\n\
        |that has three\n\
        |lines." );

        ctx.do_edit(EditNotification::MoveWordRight);
        assert_eq!(harness.debug_render(),"\
        this| is a string\n\
        that| has three\n\
        lines|." );

        ctx.do_edit(EditNotification::MoveToLeftEndOfLineAndModifySelection);
        assert_eq!(harness.debug_render(),"\
        [|this] is a string\n\
        [|that] has three\n\
        [|lines]." );

        ctx.do_edit(EditNotification::CollapseSelections);
        ctx.do_edit(EditNotification::MoveToRightEndOfLine);
        assert_eq!(harness.debug_render(),"\
        this is a string|\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::Gesture { line: 2, col: 2, ty: MultiLineSelect });
        assert_eq!(harness.debug_render(),"\
        this is a string|\n\
        that has three\n\
        [lines.|]" );

        ctx.do_edit(EditNotification::SelectAll);
        assert_eq!(harness.debug_render(),"\
        [this is a string\n\
        that has three\n\
        lines.|]" );

        ctx.do_edit(EditNotification::CollapseSelections);
        ctx.do_edit(EditNotification::AddSelectionAbove);
        assert_eq!(harness.debug_render(),"\
        this is a string\n\
        that h|as three\n\
        lines.|" );

        ctx.do_edit(EditNotification::MoveRight);
        assert_eq!(harness.debug_render(),"\
        this is a string\n\
        that ha|s three\n\
        lines.|" );

        ctx.do_edit(EditNotification::MoveLeft);
        assert_eq!(harness.debug_render(),"\
        this is a string\n\
        that h|as three\n\
        lines|." );
    }

    #[test]
    fn delete_combining_enclosing_keycaps_tests() {
        use crate::rpc::GestureType::*;

        let initial_text = "1\u{E0101}\u{20E3}";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 8, ty: PointSelect });

        assert_eq!(harness.debug_render(), "1\u{E0101}\u{20E3}|");

        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // multiple COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "1\u{20E3}\u{20E3}".into() });
        assert_eq!(harness.debug_render(), "1\u{20E3}\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "1\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Isolated COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "\u{20E3}".into() });
        assert_eq!(harness.debug_render(), "\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Isolated multiple COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "\u{20E3}\u{20E3}".into() });
        assert_eq!(harness.debug_render(), "\u{20E3}\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");
    }

    #[test]
    fn delete_variation_selector_tests() {
        use crate::rpc::GestureType::*;

        let initial_text = "\u{FE0F}";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 3, ty: PointSelect });

        assert_eq!(harness.debug_render(), "\u{FE0F}|");

        // Isolated variation selector
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{E0100}".into() });
        assert_eq!(harness.debug_render(), "\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Isolated multiple variation selectors
        ctx.do_edit(EditNotification::Insert { chars: "\u{FE0F}\u{FE0F}".into() });
        assert_eq!(harness.debug_render(), "\u{FE0F}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{FE0F}\u{E0100}".into() });
        assert_eq!(harness.debug_render(), "\u{FE0F}\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{E0100}\u{FE0F}".into() });
        assert_eq!(harness.debug_render(), "\u{E0100}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{E0100}\u{E0100}".into() });
        assert_eq!(harness.debug_render(), "\u{E0100}\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Multiple variation selectors
        ctx.do_edit(EditNotification::Insert { chars: "#\u{FE0F}\u{FE0F}".into() });
        assert_eq!(harness.debug_render(), "#\u{FE0F}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "#\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "#\u{FE0F}\u{E0100}".into() });
        assert_eq!(harness.debug_render(), "#\u{FE0F}\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "#\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "#\u{E0100}\u{FE0F}".into() });
        assert_eq!(harness.debug_render(), "#\u{E0100}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "#\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "#\u{E0100}\u{E0100}".into() });
        assert_eq!(harness.debug_render(), "#\u{E0100}\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "#\u{E0100}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");
    }

    #[test]
    fn delete_emoji_zwj_sequence_tests() {
        use crate::rpc::GestureType::*;
        let initial_text = "\u{1F441}\u{200D}\u{1F5E8}";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 11, ty: PointSelect });
        assert_eq!(harness.debug_render(), "\u{1F441}\u{200D}\u{1F5E8}|");

        // U+200D is ZERO WIDTH JOINER.
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{1F441}\u{200D}\u{1F5E8}\u{FE0E}".into() });
        assert_eq!(harness.debug_render(), "\u{1F441}\u{200D}\u{1F5E8}\u{FE0E}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{1F469}\u{200D}\u{1F373}".into() });
        assert_eq!(harness.debug_render(), "\u{1F469}\u{200D}\u{1F373}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{1F487}\u{200D}\u{2640}".into() });
        assert_eq!(harness.debug_render(), "\u{1F487}\u{200D}\u{2640}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{1F487}\u{200D}\u{2640}\u{FE0F}".into() });
        assert_eq!(harness.debug_render(), "\u{1F487}\u{200D}\u{2640}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{1F468}\u{200D}\u{2764}\u{FE0F}\u{200D}\u{1F48B}\u{200D}\u{1F468}".into() });
        assert_eq!(harness.debug_render(), "\u{1F468}\u{200D}\u{2764}\u{FE0F}\u{200D}\u{1F48B}\u{200D}\u{1F468}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Emoji modifier can be appended to the first emoji.
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F469}\u{1F3FB}\u{200D}\u{1F4BC}".into() });
        assert_eq!(harness.debug_render(), "\u{1F469}\u{1F3FB}\u{200D}\u{1F4BC}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // End with ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F441}\u{200D}".into() });
        assert_eq!(harness.debug_render(), "\u{1F441}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F441}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Start with ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{200D}\u{1F5E8}".into() });
        assert_eq!(harness.debug_render(), "\u{200D}\u{1F5E8}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::Insert { chars: "\u{FE0E}\u{200D}\u{1F5E8}".into() });
        assert_eq!(harness.debug_render(), "\u{FE0E}\u{200D}\u{1F5E8}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{FE0E}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{FE0E}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Multiple ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F441}\u{200D}\u{200D}\u{1F5E8}".into() });
        assert_eq!(harness.debug_render(), "\u{1F441}\u{200D}\u{200D}\u{1F5E8}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F441}\u{200D}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F441}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F441}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Isolated ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{200D}".into() });
        assert_eq!(harness.debug_render(), "\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Isolated multiple ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{200D}\u{200D}".into() });
        assert_eq!(harness.debug_render(), "\u{200D}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");
    }

    #[test]
    fn delete_flags_tests() {
        use crate::rpc::GestureType::*;
        let initial_text = "\u{1F1FA}";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 4, ty: PointSelect });

        // Isolated regional indicator symbol
        assert_eq!(harness.debug_render(), "\u{1F1FA}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Odd numbered regional indicator symbols
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F1FA}\u{1F1F8}\u{1F1FA}".into() });
        assert_eq!(harness.debug_render(), "\u{1F1FA}\u{1F1F8}\u{1F1FA}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F1FA}\u{1F1F8}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Incomplete sequence. (no tag_term: U+E007E)
        ctx.do_edit(EditNotification::Insert { chars: "a\u{1F3F4}\u{E0067}b".into() });
        assert_eq!(harness.debug_render(), "a\u{1F3F4}\u{E0067}b|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{1F3F4}\u{E0067}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{1F3F4}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a|");

        // No tag_base
        ctx.do_edit(EditNotification::Insert { chars: "\u{E0067}\u{E007F}b".into() });
        assert_eq!(harness.debug_render(), "a\u{E0067}\u{E007F}b|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{E0067}\u{E007F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{E0067}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a|");

        // Isolated tag chars
        ctx.do_edit(EditNotification::Insert { chars: "\u{E0067}\u{E0067}b".into() });
        assert_eq!(harness.debug_render(), "a\u{E0067}\u{E0067}b|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{E0067}\u{E0067}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{E0067}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a|");

        // Isolated tab term.
        ctx.do_edit(EditNotification::Insert { chars: "\u{E007F}\u{E007F}b".into() });
        assert_eq!(harness.debug_render(), "a\u{E007F}\u{E007F}b|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{E007F}\u{E007F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{E007F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a|");

        // Immediate tag_term after tag_base
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F3F4}\u{E007F}\u{1F3F4}\u{E007F}b".into() });
        assert_eq!(harness.debug_render(), "a\u{1F3F4}\u{E007F}\u{1F3F4}\u{E007F}b|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{1F3F4}\u{E007F}\u{1F3F4}\u{E007F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a\u{1F3F4}\u{E007F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "a|");
    }

    #[test]
    fn delete_emoji_modifier_tests() {
        use crate::rpc::GestureType::*;
        let initial_text = "\u{1F466}\u{1F3FB}";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 8, ty: PointSelect });

        // U+1F3FB is EMOJI MODIFIER FITZPATRICK TYPE-1-2.
        assert_eq!(harness.debug_render(), "\u{1F466}\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Isolated emoji modifier
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F3FB}".into() });
        assert_eq!(harness.debug_render(), "\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Isolated multiple emoji modifier
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F3FB}\u{1F3FB}".into() });
        assert_eq!(harness.debug_render(), "\u{1F3FB}\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Multiple emoji modifiers
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F466}\u{1F3FB}\u{1F3FB}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F466}\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");
    }

    #[test]
    fn delete_mixed_edge_cases_tests() {
        use crate::rpc::GestureType::*;
        let initial_text = "";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 7, ty: PointSelect });

        // COMBINING ENCLOSING KEYCAP + variation selector
        ctx.do_edit(EditNotification::Insert { chars: "1\u{20E3}\u{FE0F}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "1|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Variation selector + COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "\u{2665}\u{FE0F}\u{20E3}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{2665}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // COMBINING ENCLOSING KEYCAP + ending with ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "1\u{20E3}\u{200D}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "1\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // COMBINING ENCLOSING KEYCAP + ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "1\u{20E3}\u{200D}\u{1F5E8}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "1\u{20E3}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "1\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Start with ZERO WIDTH JOINER + COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "\u{200D}\u{20E3}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // ZERO WIDTH JOINER + COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F441}\u{200D}\u{20E3}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F441}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F441}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // COMBINING ENCLOSING KEYCAP + regional indicator symbol
        ctx.do_edit(EditNotification::Insert { chars: "1\u{20E3}\u{1F1FA}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "1\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Regional indicator symbol + COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F1FA}\u{20E3}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F1FA}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // COMBINING ENCLOSING KEYCAP + emoji modifier
        ctx.do_edit(EditNotification::Insert { chars: "1\u{20E3}\u{1F3FB}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "1\u{20E3}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Emoji modifier + COMBINING ENCLOSING KEYCAP
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F466}\u{1F3FB}\u{20E3}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1f466}\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Variation selector + end with ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{2665}\u{FE0F}\u{200D}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{2665}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Variation selector + ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F469}\u{200D}\u{2764}\u{FE0F}\u{200D}\u{1F469}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Start with ZERO WIDTH JOINER + variation selector
        ctx.do_edit(EditNotification::Insert { chars: "\u{200D}\u{FE0F}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // ZERO WIDTH JOINER + variation selector
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F469}\u{200D}\u{FE0F}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F469}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Variation selector + regional indicator symbol
        ctx.do_edit(EditNotification::Insert { chars: "\u{2665}\u{FE0F}\u{1F1FA}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{2665}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Regional indicator symbol + variation selector
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F1FA}\u{FE0F}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Variation selector + emoji modifier
        ctx.do_edit(EditNotification::Insert { chars: "\u{2665}\u{FE0F}\u{1F3FB}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{2665}\u{FE0F}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Emoji modifier + variation selector
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F466}\u{1F3FB}\u{FE0F}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F466}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Start withj ZERO WIDTH JOINER + regional indicator symbol
        ctx.do_edit(EditNotification::Insert { chars: "\u{200D}\u{1F1FA}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // ZERO WIDTH JOINER + Regional indicator symbol
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F469}\u{200D}\u{1F1FA}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F469}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F469}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Regional indicator symbol + end with ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F1FA}\u{200D}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F1FA}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Regional indicator symbol + ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F1FA}\u{200D}\u{1F469}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Start with ZERO WIDTH JOINER + emoji modifier
        ctx.do_edit(EditNotification::Insert { chars: "\u{200D}\u{1F3FB}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // ZERO WIDTH JOINER + emoji modifier
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F469}\u{200D}\u{1F3FB}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F469}\u{200D}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F469}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Emoji modifier + end with ZERO WIDTH JOINER
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F466}\u{1F3FB}\u{200D}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F466}\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Regional indicator symbol + Emoji modifier
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F1FA}\u{1F3FB}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F1FA}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // Emoji modifier + regional indicator symbol
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F466}\u{1F3FB}\u{1F1FA}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F466}\u{1F3FB}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");

        // RIS + LF
        ctx.do_edit(EditNotification::Insert { chars: "\u{1F1E6}\u{000A}".into() });
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "\u{1F1E6}|");
        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(), "|");
    }

    #[test]
    fn delete_tests() {
        use crate::rpc::GestureType::*;
        let initial_text = "\
        this is a string\n\
        that has three\n\
        lines.";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 0, ty: PointSelect });

        ctx.do_edit(EditNotification::MoveRight);
        assert_eq!(harness.debug_render(),"\
        t|his is a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::DeleteBackward);
        assert_eq!(harness.debug_render(),"\
        |his is a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::DeleteForward);
        assert_eq!(harness.debug_render(),"\
        |is is a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::MoveWordRight);
        ctx.do_edit(EditNotification::DeleteWordForward);
        assert_eq!(harness.debug_render(),"\
        is| a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::DeleteWordBackward);
        assert_eq!(harness.debug_render(),"| \
        a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::MoveToRightEndOfLine);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        assert_eq!(harness.debug_render(),"\
        |\nthat has three\n\
        lines." );

        ctx.do_edit(EditNotification::DeleteToEndOfParagraph);
        ctx.do_edit(EditNotification::DeleteToEndOfParagraph);
        assert_eq!(harness.debug_render(),"\
        |\nlines." );
    }

    #[test]
    fn simple_indentation_test() {
        use crate::rpc::GestureType::*;
        let harness = ContextHarness::new("");
        let mut ctx = harness.make_context();
        // Single indent and outdent test
        ctx.do_edit(EditNotification::Insert { chars: "hello".into() });
        ctx.do_edit(EditNotification::Indent);
        assert_eq!(harness.debug_render(),"    hello|");
        ctx.do_edit(EditNotification::Outdent);
        assert_eq!(harness.debug_render(),"hello|");

        // Test when outdenting with less than 4 spaces
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 0, ty: PointSelect });
        ctx.do_edit(EditNotification::Insert { chars: "  ".into() });
        assert_eq!(harness.debug_render(),"  |hello");
        ctx.do_edit(EditNotification::Outdent);
        assert_eq!(harness.debug_render(),"|hello");

        // Non-selection one line indent and outdent test
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::Indent);
        ctx.do_edit(EditNotification::InsertNewline);
        ctx.do_edit(EditNotification::Insert { chars: "world".into() });
        assert_eq!(harness.debug_render(),"    hello\nworld|");

        ctx.do_edit(EditNotification::MoveWordLeft);
        ctx.do_edit(EditNotification::MoveToBeginningOfDocumentAndModifySelection);
        ctx.do_edit(EditNotification::Indent);
        assert_eq!(harness.debug_render(),"    [|    hello\n]world");

        ctx.do_edit(EditNotification::Outdent);
        assert_eq!(harness.debug_render(),"[|    hello\n]world");

        ctx.do_edit(EditNotification::SelectAll);
        ctx.do_edit(EditNotification::DeleteBackward);
        ctx.do_edit(EditNotification::Insert { chars: "hello".into() });
        ctx.do_edit(EditNotification::SelectAll);
        ctx.do_edit(EditNotification::InsertTab);
        assert_eq!(harness.debug_render(),"    |");
    }

    #[test]
    fn multiline_indentation_test() {
        use crate::rpc::GestureType::*;
        let initial_text = "\
        this is a string\n\
        that has three\n\
        lines.";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();

        ctx.do_edit(EditNotification::Gesture { line: 0, col: 5, ty: PointSelect });
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that has three\n\
        lines." );

        ctx.do_edit(EditNotification::Gesture { line: 1, col: 5, ty: ToggleSel });
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that |has three\n\
        lines." );

        // Simple multi line indent/outdent test
        ctx.do_edit(EditNotification::Indent);
        assert_eq!(harness.debug_render(),"    \
        this |is a string\n    \
        that |has three\n\
        lines." );

        ctx.do_edit(EditNotification::Outdent);
        ctx.do_edit(EditNotification::Outdent);
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that |has three\n\
        lines." );

        // Different position indent/outdent test
        // Shouldn't change cursor position
        ctx.do_edit(EditNotification::Gesture { line: 1, col: 5, ty: ToggleSel });
        ctx.do_edit(EditNotification::Gesture { line: 1, col: 10, ty: ToggleSel });
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that has t|hree\n\
        lines." );

        ctx.do_edit(EditNotification::Indent);
        assert_eq!(harness.debug_render(),"    \
        this |is a string\n    \
        that has t|hree\n\
        lines." );

        ctx.do_edit(EditNotification::Outdent);
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that has t|hree\n\
        lines." );

        // Multi line selection test
        ctx.do_edit(EditNotification::Gesture { line: 1, col: 10, ty: ToggleSel });
        ctx.do_edit(EditNotification::MoveToEndOfDocumentAndModifySelection);
        ctx.do_edit(EditNotification::Indent);
        assert_eq!(harness.debug_render(),"    \
        this [is a string\n    \
        that has three\n    \
        lines.|]" );

        ctx.do_edit(EditNotification::Outdent);
        assert_eq!(harness.debug_render(),"\
        this [is a string\n\
        that has three\n\
        lines.|]" );

        // Multi cursor different line indent test
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 0, ty: PointSelect });
        ctx.do_edit(EditNotification::Gesture { line: 2, col: 0, ty: ToggleSel });
        assert_eq!(harness.debug_render(),"\
        |this is a string\n\
        that has three\n\
        |lines." );

        ctx.do_edit(EditNotification::Indent);
        assert_eq!(harness.debug_render(),"    \
        |this is a string\n\
        that has three\n    \
        |lines." );

        ctx.do_edit(EditNotification::Outdent);
        assert_eq!(harness.debug_render(),"\
        |this is a string\n\
        that has three\n\
        |lines." );
    }

    #[test]
    fn number_change_tests() {
        use crate::rpc::GestureType::*;
        let harness = ContextHarness::new("");
        let mut ctx = harness.make_context();
        // Single indent and outdent test
        ctx.do_edit(EditNotification::Insert { chars: "1234".into() });
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "1235|");

        ctx.do_edit(EditNotification::Gesture { line: 0, col: 2, ty: PointSelect });
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "1236|");

        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "-42".into() });
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "-41|");

        // Cursor is on the 3
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 336 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 11, ty: PointSelect });
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this is a 335| text example");

        // Cursor is on of the 3
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a -336 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 11, ty: PointSelect });
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this is a -337| text example");

        // Cursor is on the 't' of text
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a -336 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 15, ty: PointSelect });
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this is a -336 |text example");

        // test multiple iterations
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 336 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 11, ty: PointSelect });
        ctx.do_edit(EditNotification::IncreaseNumber);
        ctx.do_edit(EditNotification::IncreaseNumber);
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "this is a 339| text example");

        // test changing number of chars
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 10 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 11, ty: PointSelect });
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this is a 9| text example");

        // test going negative
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 0 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 11, ty: PointSelect });
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this is a -1| text example");

        // test going positive
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a -1 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 12, ty: PointSelect });
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "this is a 0| text example");

        // if it begins in a region, nothing will happen
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 10 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 10, ty: PointSelect });
        ctx.do_edit(EditNotification::MoveToEndOfDocumentAndModifySelection);
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this is a [10 text example|]");

        // If a number just happens to be in a region, nothing will happen
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 10 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 5, ty: PointSelect });
        ctx.do_edit(EditNotification::MoveToEndOfDocumentAndModifySelection);
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this [is a 10 text example|]");

        // if it ends on a region, the number will be changed
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 10".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 0, ty: PointSelect });
        ctx.do_edit(EditNotification::MoveToEndOfDocumentAndModifySelection);
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "[this is a 11|]");

        // if only a part of a number is in a region, the whole number will be changed
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "this is a 1000 text example".into() });
        ctx.do_edit(EditNotification::Gesture { line: 0, col: 11, ty: PointSelect });
        ctx.do_edit(EditNotification::MoveRightAndModifySelection);
        ctx.do_edit(EditNotification::DecreaseNumber);
        assert_eq!(harness.debug_render(), "this is a 999| text example");

        // invalid numbers
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "10_000".into() });
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "10_000|");

        // decimals are kinda accounted for (i.e. 4.55 becomes 4.56 (good), but 4.99 becomes 4.100 (bad)
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "4.55".into() });
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "4.56|");

        // invalid numbers
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        ctx.do_edit(EditNotification::Insert { chars: "0xFF03".into() });
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "0xFF03|");

        // Test multiple selections
        ctx.do_edit(EditNotification::MoveToEndOfDocument);
        ctx.do_edit(EditNotification::DeleteToBeginningOfLine);
        let multi_text = "\
        example 42 number\n\
        example 90 number\n\
        Done.";
        ctx.do_edit(EditNotification::Insert { chars: multi_text.into() });
        ctx.do_edit(EditNotification::Gesture { line: 1, col: 9, ty: PointSelect });
        ctx.do_edit(EditNotification::AddSelectionAbove);
        ctx.do_edit(EditNotification::IncreaseNumber);
        assert_eq!(harness.debug_render(), "\
        example 43| number\n\
        example 91| number\n\
        Done.");
    }

    #[test]
    fn text_recording() {
        use crate::rpc::GestureType::*;
        let initial_text = "";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();

        let recording_name = String::new();

        ctx.do_edit(EditNotification::Gesture { line: 0, col: 0, ty: PointSelect });
        assert_eq!(harness.debug_render(), "|");

        ctx.do_edit(EditNotification::ToggleRecording { recording_name: Some(recording_name.clone()) });

        ctx.do_edit(EditNotification::Insert { chars: "Foo ".to_owned() });
        ctx.do_edit(EditNotification::Insert { chars: "B".to_owned() });
        ctx.do_edit(EditNotification::Insert { chars: "A".to_owned() });
        ctx.do_edit(EditNotification::Insert { chars: "R".to_owned() });
        assert_eq!(harness.debug_render(), "Foo BAR|");

        ctx.do_edit(EditNotification::ToggleRecording { recording_name: Some(recording_name.clone())});
        ctx.do_edit(EditNotification::Insert { chars: " ".to_owned() });

        ctx.do_edit(EditNotification::PlayRecording { recording_name });
        assert_eq!(harness.debug_render(), "Foo BAR Foo BAR|");
    }

    #[test]
    fn movement_recording() {
        use crate::rpc::GestureType::*;
        let initial_text = "\
        this is a string\n\
        that has about\n\
        four really nice\n\
        lines to see.";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();

        let recording_name = String::new();

        ctx.do_edit(EditNotification::Gesture { line: 0, col: 5, ty: PointSelect });
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that has about\n\
        four really nice\n\
        lines to see." );

        ctx.do_edit(EditNotification::ToggleRecording { recording_name: Some(recording_name.clone()) });

        // Swap last word of the current line and the line below
        ctx.do_edit(EditNotification::AddSelectionBelow);
        ctx.do_edit(EditNotification::MoveToRightEndOfLine);
        ctx.do_edit(EditNotification::MoveWordLeftAndModifySelection);
        ctx.do_edit(EditNotification::Transpose);
        ctx.do_edit(EditNotification::CollapseSelections);
        ctx.do_edit(EditNotification::MoveToRightEndOfLine);
        assert_eq!(harness.debug_render(),"\
        this is a about|\n\
        that has string\n\
        four really nice\n\
        lines to see." );

        ctx.do_edit(EditNotification::ToggleRecording { recording_name: Some(recording_name.clone())});

        ctx.do_edit(EditNotification::Gesture { line: 2, col: 5, ty: PointSelect });
        ctx.do_edit(EditNotification::PlayRecording { recording_name: recording_name.clone() });
        assert_eq!(harness.debug_render(),"\
        this is a about\n\
        that has string\n\
        four really see.|\n\
        lines to nice" );

        // Undo entire playback in a single command
        ctx.do_edit(EditNotification::Undo);
        assert_eq!(harness.debug_render(),"\
        this is a about\n\
        that has string\n\
        four really nice|\n\
        lines to see." );

        // Make sure we can redo in a single command as well
        ctx.do_edit(EditNotification::Redo);
        assert_eq!(harness.debug_render(),"\
        this is a about\n\
        that has string\n\
        four really see.|\n\
        lines to nice" );

        // We shouldn't be able to use cleared recordings
        ctx.do_edit(EditNotification::Undo);
        ctx.do_edit(EditNotification::Undo);
        ctx.do_edit(EditNotification::ClearRecording { recording_name: recording_name.clone() });
        ctx.do_edit(EditNotification::PlayRecording { recording_name });
        assert_eq!(harness.debug_render(),"\
        this is a string\n\
        that has about\n\
        four really nice|\n\
        lines to see." );
    }

    #[test]
    fn test_exact_position() {
        use crate::rpc::GestureType::*;
        let initial_text = "\
        this is a string\n\
        that has three\n\
        \n\
        lines.\n\
        And lines with very different length.";
        let harness = ContextHarness::new(initial_text);
        let mut ctx = harness.make_context();
        ctx.do_edit(EditNotification::Gesture { line: 1, col: 5, ty: PointSelect });
        ctx.do_edit(EditNotification::AddSelectionAbove);
        assert_eq!(harness.debug_render(),"\
        this |is a string\n\
        that |has three\n\
        \n\
        lines.\n\
        And lines with very different length.");

        ctx.do_edit(EditNotification::CollapseSelections);
        ctx.do_edit(EditNotification::Gesture { line: 1, col: 5, ty: PointSelect });
        ctx.do_edit(EditNotification::AddSelectionBelow);
        assert_eq!(harness.debug_render(),"\
        this is a string\n\
        that |has three\n\
        \n\
        lines|.\n\
        And lines with very different length.");

        ctx.do_edit(EditNotification::CollapseSelections);
        ctx.do_edit(EditNotification::Gesture { line: 4, col: 10, ty: PointSelect });
        ctx.do_edit(EditNotification::AddSelectionAbove);
        assert_eq!(harness.debug_render(),"\
        this is a string\n\
        that has t|hree\n\
        \n\
        lines.\n\
        And lines |with very different length.");
    }

    #[test]
    fn test_illegal_plugin_edit() {
        use xi_rope::DeltaBuilder;
        use crate::plugins::rpc::{PluginNotification, PluginEdit};
        use crate::plugins::PluginPid;

        let text = "text";
        let harness = ContextHarness::new(text);
        let mut ctx = harness.make_context();
        let rev_token = ctx.editor.borrow().get_head_rev_token();

        let iv = Interval::new(1, 1);
        let mut builder = DeltaBuilder::new(0); // wrong length
        builder.replace(iv, "1".into());

        let edit_one = PluginEdit {
            rev: rev_token,
            delta: builder.build(),
            priority: 55,
            after_cursor: false,
            undo_group: None,
            author: "plugin_one".into(),
        };

        ctx.do_plugin_cmd(PluginPid(1), PluginNotification::Edit { edit: edit_one });
        let new_rev_token = ctx.editor.borrow().get_head_rev_token();
        // no change should be made
        assert_eq!(rev_token, new_rev_token);
    }


    #[test]
    fn empty_transpose() {
        let harness = ContextHarness::new("");
        let mut ctx = harness.make_context();

        ctx.do_edit(EditNotification::Transpose);

        assert_eq!(harness.debug_render(), "|"); // should be noop
    }

    // This is the issue reported by #962
    #[test]
    fn eol_multicursor_transpose() {
        use crate::rpc::GestureType::*;

        let harness = ContextHarness::new("word\n");
        let mut ctx = harness.make_context();

        ctx.do_edit(EditNotification::Gesture{line: 0, col: 4, ty: PointSelect}); // end of first line
        ctx.do_edit(EditNotification::AddSelectionBelow); // add cursor below that, at eof
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Representation and calculation of movement within a lineoffset.

use std::cmp::max;

use crate::line_offset::LineOffset;
use crate::selection::{HorizPos, SelRegion, Selection};
use crate::word_boundaries::WordCursor;
use xi_rope::{Cursor, LinesMetric, Rope};

/// The specification of a movement.
#[derive(Debug, PartialEq, Clone, Copy)]
pub enum Movement {
    /// Move to the left by one grapheme cluster.
    Left,
    /// Move to the right by one grapheme cluster.
    Right,
    /// Move to the left by one word.
    LeftWord,
    /// Move to the right by one word.
    RightWord,
    /// Move to left end of visible line.
    LeftOfLine,
    /// Move to right end of visible line.
    RightOfLine,
    /// Move up one visible line.
    Up,
    /// Move down one visible line.
    Down,
    /// Move up one viewport height.
    UpPage,
    /// Move down one viewport height.
    DownPage,
    /// Move up to the next line that can preserve the cursor position.
    UpExactPosition,
    /// Move down to the next line that can preserve the cursor position.
    DownExactPosition,
    /// Move to the start of the text line.
    StartOfParagraph,
    /// Move to the end of the text line.
    EndOfParagraph,
    /// Move to the end of the text line, or next line if already at end.
    EndOfParagraphKill,
    /// Move to the start of the document.
    StartOfDocument,
    /// Move to the end of the document
    EndOfDocument,
}

/// Compute movement based on vertical motion by the given number of lines.
///
/// Note: in non-exceptional cases, this function preserves the `horiz`
/// field of the selection region.
fn vertical_motion(
    r: SelRegion,
    lo: &dyn LineOffset,
    text: &Rope,
    line_delta: isize,
    modify: bool,
) -> (usize, Option<HorizPos>) {
    let (col, line) = selection_position(r, lo, text, line_delta < 0, modify);
    let n_lines = lo.line_of_offset(text, text.len());

    // This code is quite careful to avoid integer overflow.
    // TODO: write tests to verify
    if line_delta < 0 && (-line_delta as usize) > line {
        return (0, Some(col));
    }
    let line = if line_delta < 0 {
        line - (-line_delta as usize)
    } else {
        line.saturating_add(line_delta as usize)
    };
    if line > n_lines {
        return (text.len(), Some(col));
    }
    let new_offset = lo.line_col_to_offset(text, line, col);
    (new_offset, Some(col))
}

/// Compute movement based on vertical motion by the given number of lines skipping
/// any line that is shorter than the current cursor position.
fn vertical_motion_exact_pos(
    r: SelRegion,
    lo: &dyn LineOffset,
    text: &Rope,
    move_up: bool,
    modify: bool,
) -> (usize, Option<HorizPos>) {
    let (col, init_line) = selection_position(r, lo, text, move_up, modify);
    let n_lines = lo.line_of_offset(text, text.len());

    let mut line_length =
        lo.offset_of_line(text, init_line.saturating_add(1)) - lo.offset_of_line(text, init_line);
    if move_up && init_line == 0 {
        return (lo.line_col_to_offset(text, init_line, col), Some(col));
    }
    let mut line = if move_up { init_line - 1 } else { init_line.saturating_add(1) };

    // If the active columns is longer than the current line, use the current line length.
    let col = if line_length < col { line_length - 1 } else { col };

    loop {
        line_length = lo.offset_of_line(text, line + 1) - lo.offset_of_line(text, line);

        // If the line is longer than the current cursor position, break.
        // We use > instead of >= because line_length includes newline.
        if line_length > col {
            break;
        }

        // If you are trying to add a selection past the end of the file or before the first line, return original selection
        if line >= n_lines || (line == 0 && move_up) {
            line = init_line;
            break;
        }

        line = if move_up { line - 1 } else { line.saturating_add(1) };
    }

    (lo.line_col_to_offset(text, line, col), Some(col))
}

/// Based on the current selection position this will return the cursor position, the current line, and the
/// total number of lines of the file.
fn selection_position(
    r: SelRegion,
    lo: &dyn LineOffset,
    text: &Rope,
    move_up: bool,
    modify: bool,
) -> (HorizPos, usize) {
    // The active point of the selection
    let active = if modify {
        r.end
    } else if move_up {
        r.min()
    } else {
        r.max()
    };
    let col = if let Some(col) = r.horiz { col } else { lo.offset_to_line_col(text, active).1 };
    let line = lo.line_of_offset(text, active);

    (col, line)
}

/// When paging through a file, the number of lines from the previous page
/// that will also be visible in the next.
const SCROLL_OVERLAP: isize = 2;

/// Computes the actual desired amount of scrolling (generally slightly
/// less than the height of the viewport, to allow overlap).
fn scroll_height(height: usize) -> isize {
    max(height as isize - SCROLL_OVERLAP, 1)
}

/// Compute the result of movement on one selection region.
///
/// # Arguments
///
/// * `height` - viewport height
pub fn region_movement(
    m: Movement,
    r: SelRegion,
    lo: &dyn LineOffset,
    height: usize,
    text: &Rope,
    modify: bool,
) -> SelRegion {
    let (offset, horiz) = match m {
        Movement::Left => {
            if r.is_caret() || modify {
                if let Some(offset) = text.prev_grapheme_offset(r.end) {
                    (offset, None)
                } else {
                    (0, r.horiz)
                }
            } else {
                (r.min(), None)
            }
        }
        Movement::Right => {
            if r.is_caret() || modify {
                if let Some(offset) = text.next_grapheme_offset(r.end) {
                    (offset, None)
                } else {
                    (r.end, r.horiz)
                }
            } else {
                (r.max(), None)
            }
        }
        Movement::LeftWord => {
            let mut word_cursor = WordCursor::new(text, r.end);
            let offset = word_cursor.prev_boundary().unwrap_or(0);
            (offset, None)
        }
        Movement::RightWord => {
            let mut word_cursor = WordCursor::new(text, r.end);
            let offset = word_cursor.next_boundary().unwrap_or_else(|| text.len());
            (offset, None)
        }
        Movement::LeftOfLine => {
            let line = lo.line_of_offset(text, r.end);
            let offset = lo.offset_of_line(text, line);
            (offset, None)
        }
        Movement::RightOfLine => {
            let line = lo.line_of_offset(text, r.end);
            let mut offset = text.len();

            // calculate end of line
            let next_line_offset = lo.offset_of_line(text, line + 1);
            if line < lo.line_of_offset(text, offset) {
                if let Some(prev) = text.prev_grapheme_offset(next_line_offset) {
                    offset = prev;
                }
            }
            (offset, None)
        }
        Movement::Up => vertical_motion(r, lo, text, -1, modify),
        Movement::Down => vertical_motion(r, lo, text, 1, modify),
        Movement::UpExactPosition => vertical_motion_exact_pos(r, lo, text, true, modify),
        Movement::DownExactPosition => vertical_motion_exact_pos(r, lo, text, false, modify),
        Movement::StartOfParagraph => {
            // Note: TextEdit would start at modify ? r.end : r.min()
            let mut cursor = Cursor::new(&text, r.end);
            let offset = cursor.prev::<LinesMetric>().unwrap_or(0);
            (offset, None)
        }
        Movement::EndOfParagraph => {
            // Note: TextEdit would start at modify ? r.end : r.max()
            let mut offset = r.end;
            let mut cursor = Cursor::new(&text, offset);
            if let Some(next_para_offset) = cursor.next::<LinesMetric>() {
                if cursor.is_boundary::<LinesMetric>() {
                    if let Some(eol) = text.prev_grapheme_offset(next_para_offset) {
                        offset = eol;
                    }
                } else if cursor.pos() == text.len() {
                    offset = text.len();
                }
                (offset, None)
            } else {
                //in this case we are already on a last line so just moving to EOL
                (text.len(), None)
            }
        }
        Movement::EndOfParagraphKill => {
            // Note: TextEdit would start at modify ? r.end : r.max()
            let mut offset = r.end;
            let mut cursor = Cursor::new(&text, offset);
            if let Some(next_para_offset) = cursor.next::<LinesMetric>() {
                offset = next_para_offset;
                if cursor.is_boundary::<LinesMetric>() {
                    if let Some(eol) = text.prev_grapheme_offset(next_para_offset) {
                        if eol != r.end {
                            offset = eol;
                        }
                    }
                }
            }
            (offset, None)
        }
        Movement::UpPage => vertical_motion(r, lo, text, -scroll_height(height), modify),
        Movement::DownPage => vertical_motion(r, lo, text, scroll_height(height), modify),
        Movement::StartOfDocument => (0, None),
        Movement::EndOfDocument => (text.len(), None),
    };
    SelRegion::new(if modify { r.start } else { offset }, offset).with_horiz(horiz)
}

/// Compute a new selection by applying a movement to an existing selection.
///
/// In a multi-region selection, this function applies the movement to each
/// region in the selection, and returns the union of the results.
///
/// If `modify` is `true`, the selections are modified, otherwise the results
/// of individual region movements become carets.
///
/// # Arguments
///
/// * `height` - viewport height
pub fn selection_movement(
    m: Movement,
    s: &Selection,
    lo: &dyn LineOffset,
    height: usize,
    text: &Rope,
    modify: bool,
) -> Selection {
    let mut result = Selection::new();
    for &r in s.iter() {
        let new_region = region_movement(m, r, lo, height, text, modify);
        result.add_region(new_region);
    }
    result
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Monitoring files and directories.
//!
//! This module contains `FileWatcher` and related types, responsible for
//! monitoring changes to files and directories. Under the hood it is a
//! thin wrapper around some concrete type provided by the
//! [`notify`](https://docs.rs/notify) crate; the implementation is
//! platform dependent, and may be using kqueue, fsevent, or another
//! low-level monitoring system.
//!
//! Our wrapper provides a few useful features:
//!
//! - All `watch` calls are associated with a `WatchToken`; this
//! allows for the same path to be watched multiple times,
//! presumably by multiple interested parties. events are delivered
//! once-per token.
//!
//! - There is the option (via `FileWatcher::watch_filtered`) to include
//! a predicate along with a path, to filter paths before delivery.
//!
//! - We are integrated with the xi_rpc runloop; events are queued as
//! they arrive, and an idle task is scheduled.

use crossbeam_channel::unbounded;
use notify::{event::*, watcher, RecommendedWatcher, RecursiveMode, Watcher};
use std::collections::VecDeque;
use std::fmt;
use std::mem;
use std::path::{Path, PathBuf};
use std::sync::{Arc, Mutex};
use std::thread;
use std::time::Duration;

use xi_rpc::RpcPeer;

/// Delay for aggregating related file system events.
pub const DEBOUNCE_WAIT_MILLIS: u64 = 50;

/// Wrapper around a `notify::Watcher`. It runs the inner watcher
/// in a separate thread, and communicates with it via a [crossbeam channel].
/// [crossbeam channel]: https://docs.rs/crossbeam-channel
pub struct FileWatcher {
    inner: RecommendedWatcher,
    state: Arc<Mutex<WatcherState>>,
}

#[derive(Debug, Default)]
struct WatcherState {
    events: EventQueue,
    watchees: Vec<Watchee>,
}

/// Tracks a registered 'that-which-is-watched'.
#[doc(hidden)]
struct Watchee {
    path: PathBuf,
    recursive: bool,
    token: WatchToken,
    filter: Option<Box<PathFilter>>,
}

/// Token provided to `FileWatcher`, to associate events with
/// interested parties.
///
/// Note: `WatchToken`s are assumed to correspond with an
/// 'area of interest'; that is, they are used to route delivery
/// of events.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct WatchToken(pub usize);

/// A trait for types which can be notified of new events.
/// New events are accessible through the `FileWatcher` instance.
pub trait Notify: Send {
    fn notify(&self);
}

pub type EventQueue = VecDeque<(WatchToken, Event)>;

pub type PathFilter = dyn Fn(&Path) -> bool + Send + 'static;

impl FileWatcher {
    pub fn new<T: Notify + 'static>(peer: T) -> Self {
        let (tx_event, rx_event) = unbounded();

        let state = Arc::new(Mutex::new(WatcherState::default()));
        let state_clone = state.clone();

        let inner = watcher(tx_event, Duration::from_millis(100)).expect("watcher should spawn");

        thread::spawn(move || {
            while let Ok(Ok(event)) = rx_event.recv() {
                let mut state = state_clone.lock().unwrap();
                let WatcherState { ref mut events, ref mut watchees } = *state;

                watchees
                    .iter()
                    .filter(|w| w.wants_event(&event))
                    .map(|w| w.token)
                    .for_each(|t| events.push_back((t, event.clone())));

                peer.notify();
            }
        });

        FileWatcher { inner, state }
    }

    /// Begin watching `path`. As `Event`s (documented in the
    /// [notify](https://docs.rs/notify) crate) arrive, they are stored
    /// with the associated `token` and a task is added to the runloop's
    /// idle queue.
    ///
    /// Delivery of events then requires that the runloop's handler
    /// correctly forward the `handle_idle` call to the interested party.
    pub fn watch(&mut self, path: &Path, recursive: bool, token: WatchToken) {
        self.watch_impl(path, recursive, token, None);
    }

    /// Like `watch`, but taking a predicate function that filters delivery
    /// of events based on their path.
    pub fn watch_filtered<F>(&mut self, path: &Path, recursive: bool, token: WatchToken, filter: F)
    where
        F: Fn(&Path) -> bool + Send + 'static,
    {
        let filter = Box::new(filter) as Box<PathFilter>;
        self.watch_impl(path, recursive, token, Some(filter));
    }

    fn watch_impl(
        &mut self,
        path: &Path,
        recursive: bool,
        token: WatchToken,
        filter: Option<Box<PathFilter>>,
    ) {
        let path = match path.canonicalize() {
            Ok(ref p) => p.to_owned(),
            Err(e) => {
                warn!("error watching {:?}: {:?}", path, e);
                return;
            }
        };

        let mut state = self.state.lock().unwrap();

        let w = Watchee { path, recursive, token, filter };
        let mode = mode_from_bool(w.recursive);

        if !state.watchees.iter().any(|w2| w.path == w2.path) {
            if let Err(e) = self.inner.watch(&w.path, mode) {
                warn!("watching error {:?}", e);
            }
        }

        state.watchees.push(w);
    }

    /// Removes the provided token/path pair from the watch list.
    /// Does not stop watching this path, if it is associated with
    /// other tokens.
    pub fn unwatch(&mut self, path: &Path, token: WatchToken) {
        let mut state = self.state.lock().unwrap();

        let idx = state.watchees.iter().position(|w| w.token == token && w.path == path);

        if let Some(idx) = idx {
            let removed = state.watchees.remove(idx);
            if !state.watchees.iter().any(|w| w.path == removed.path) {
                if let Err(e) = self.inner.unwatch(&removed.path) {
                    warn!("unwatching error {:?}", e);
                }
            }
            //TODO: Ideally we would be tracking what paths we're watching with
            // some prefix-tree-like structure, which would let us keep track
            // of when some child path might need to be reregistered. How this
            // works and when registration would be required is dependent on
            // the underlying notification mechanism, however. There's an
            // in-progress rewrite of the Notify crate which use under the
            // hood, and a component of that rewrite is adding this
            // functionality; so until that lands we're using a fairly coarse
            // heuristic to determine if we need to re-watch subpaths.

            // if this was recursive, check if any child paths need to be
            // manually re-added
            if removed.recursive {
                // do this in two steps because we've borrowed mutably up top
                let to_add = state
                    .watchees
                    .iter()
                    .filter(|w| w.path.starts_with(&removed.path))
                    .map(|w| (w.path.to_owned(), mode_from_bool(w.recursive)))
                    .collect::<Vec<_>>();

                for (path, mode) in to_add {
                    if let Err(e) = self.inner.watch(&path, mode) {
                        warn!("watching error {:?}", e);
                    }
                }
            }
        }
    }

    /// Takes ownership of this `Watcher`'s current event queue.
    pub fn take_events(&mut self) -> VecDeque<(WatchToken, Event)> {
        let mut state = self.state.lock().unwrap();
        let WatcherState { ref mut events, .. } = *state;
        mem::replace(events, VecDeque::new())
    }
}

impl Watchee {
    fn wants_event(&self, event: &Event) -> bool {
        match &event.kind {
            EventKind::Create(CreateKind::Any)
            | EventKind::Remove(RemoveKind::Any)
            | EventKind::Modify(ModifyKind::Any)
            | EventKind::Modify(ModifyKind::Metadata(MetadataKind::Any)) => {
                if event.paths.len() == 1 {
                    self.applies_to_path(&event.paths[0])
                } else {
                    info!(
                        "Rejecting event {:?} with incorrect paths. Expected 1 found {}.",
                        event,
                        event.paths.len()
                    );
                    false
                }
            }
            EventKind::Modify(ModifyKind::Name(RenameMode::Both)) => {
                if event.paths.len() == 2 {
                    //There will be two paths. First is "from" and other is "to".
                    self.applies_to_path(&event.paths[0]) || self.applies_to_path(&event.paths[1])
                } else {
                    info!(
                        "Rejecting event {:?} with incorrect paths. Expected 2 found {}.",
                        event,
                        event.paths.len()
                    );
                    false
                }
            }
            _ => false,
        }
    }

    fn applies_to_path(&self, path: &Path) -> bool {
        let general_case = if path.starts_with(&self.path) {
            (self.recursive || self.path == path) || path.parent() == Some(&self.path)
        } else {
            false
        };

        if let Some(ref filter) = self.filter {
            general_case && filter(path)
        } else {
            general_case
        }
    }
}

impl Notify for RpcPeer {
    fn notify(&self) {
        self.schedule_idle(crate::tabs::WATCH_IDLE_TOKEN);
    }
}

impl fmt::Debug for Watchee {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(
            f,
            "Watchee path: {:?}, r {}, t {} f {}",
            self.path,
            self.recursive,
            self.token.0,
            self.filter.is_some()
        )
    }
}

fn mode_from_bool(is_recursive: bool) -> RecursiveMode {
    if is_recursive {
        RecursiveMode::Recursive
    } else {
        RecursiveMode::NonRecursive
    }
}

#[cfg(test)]
extern crate tempdir;

#[cfg(test)]
mod tests {
    use super::*;
    use crossbeam_channel::unbounded;
    use notify::EventKind;
    use std::ffi::OsStr;
    use std::fs;
    use std::io::Write;
    use std::thread;
    use std::time::{Duration, Instant};

    impl PartialEq<usize> for WatchToken {
        fn eq(&self, other: &usize) -> bool {
            self.0 == *other
        }
    }

    impl From<usize> for WatchToken {
        fn from(err: usize) -> WatchToken {
            WatchToken(err)
        }
    }

    impl Notify for crossbeam_channel::Sender<bool> {
        fn notify(&self) {
            self.send(true).expect("send shouldn't fail")
        }
    }

    // Sleep for `duration` in milliseconds
    pub fn sleep(millis: u64) {
        thread::sleep(Duration::from_millis(millis));
    }

    // Sleep for `duration` in milliseconds if running on OS X
    pub fn sleep_if_macos(millis: u64) {
        if cfg!(target_os = "macos") {
            sleep(millis)
        }
    }

    pub fn recv_all<T>(rx: &crossbeam_channel::Receiver<T>, duration: Duration) -> Vec<T> {
        let start = Instant::now();
        let mut events = Vec::new();

        while start.elapsed() < duration {
            match rx.recv_timeout(Duration::from_millis(50)) {
                Ok(event) => events.push(event),
                Err(crossbeam_channel::RecvTimeoutError::Timeout) => (),
                Err(e) => panic!("unexpected channel err: {:?}", e),
            }
        }
        events
    }

    // from https://github.com/passcod/notify/blob/master/tests/utils/mod.rs
    pub trait TestHelpers {
        /// Return path relative to the TempDir. Directory separator must
        /// be a forward slash, and will be converted to the platform's
        /// native separator.
        fn mkpath(&self, p: &str) -> PathBuf;
        /// Create file or directory. Directories must contain the phrase
        /// "dir" otherwise they will be interpreted as files.
        fn create(&self, p: &str);
        /// Create all files and directories in the `paths` list.
        /// Directories must contain the phrase "dir" otherwise they
        /// will be interpreted as files.
        fn create_all(&self, paths: Vec<&str>);
        /// Rename file or directory.
        fn rename(&self, a: &str, b: &str);
        ///// Toggle "other" rights on linux and os x and "readonly" on windows
        //fn chmod(&self, p: &str);
        /// Write some data to a file
        fn write(&self, p: &str);
        /// Remove file or directory
        fn remove(&self, p: &str);
    }

    impl TestHelpers for tempdir::TempDir {
        fn mkpath(&self, p: &str) -> PathBuf {
            let mut path =
                self.path().canonicalize().expect("failed to canonalize path").to_owned();
            for part in p.split('/').collect::<Vec<_>>() {
                if part != "." {
                    path.push(part);
                }
            }
            path
        }

        fn create(&self, p: &str) {
            let path = self.mkpath(p);
            if path.components().last().unwrap().as_os_str().to_str().unwrap().contains("dir") {
                fs::create_dir_all(path).expect("failed to create directory");
            } else {
                let parent = path.parent().expect("failed to get parent directory").to_owned();
                if !parent.exists() {
                    fs::create_dir_all(parent).expect("failed to create parent directory");
                }
                fs::File::create(path).expect("failed to create file");
            }
        }

        fn create_all(&self, paths: Vec<&str>) {
            for p in paths {
                self.create(p);
            }
        }

        fn rename(&self, a: &str, b: &str) {
            let path_a = self.mkpath(a);
            let path_b = self.mkpath(b);
            fs::rename(&path_a, &path_b).expect("failed to rename file or directory");
        }

        fn write(&self, p: &str) {
            let path = self.mkpath(p);

            let mut file =
                fs::OpenOptions::new().write(true).open(path).expect("failed to open file");

            file.write(b"some data").expect("failed to write to file");
            file.sync_all().expect("failed to sync file");
        }

        fn remove(&self, p: &str) {
            let path = self.mkpath(p);
            if path.is_dir() {
                fs::remove_dir(path).expect("failed to remove directory");
            } else {
                fs::remove_file(path).expect("failed to remove file");
            }
        }
    }

    #[test]
    fn test_applies_to_path() {
        let mut w = Watchee {
            path: PathBuf::from("/hi/there/"),
            recursive: false,
            token: WatchToken(1),
            filter: None,
        };
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/friend.txt")));
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/")));
        assert!(!w.applies_to_path(&PathBuf::from("/hi/there/dear/friend.txt")));
        assert!(!w.applies_to_path(&PathBuf::from("/oh/hi/there/")));

        w.recursive = true;
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/dear/friend.txt")));
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/friend.txt")));
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/")));

        w.filter = Some(Box::new(|p| p.extension().and_then(OsStr::to_str) == Some("txt")));
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/dear/friend.txt")));
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/friend.txt")));
        assert!(!w.applies_to_path(&PathBuf::from("/hi/there/")));
        assert!(!w.applies_to_path(&PathBuf::from("/hi/there/friend.exe")));
        assert!(w.applies_to_path(&PathBuf::from("/hi/there/my/old/sweet/pal.txt")));
    }

    //https://github.com/passcod/notify/issues/131
    #[test]
    #[cfg(unix)]
    fn test_crash_repro() {
        let (tx, _rx) = unbounded();
        let path = PathBuf::from("/bin/cat");
        let mut w = watcher(tx, Duration::from_secs(1)).unwrap();
        w.watch(&path, RecursiveMode::NonRecursive).unwrap();
        sleep(20);
        w.watch(&path, RecursiveMode::NonRecursive).unwrap();
        w.unwatch(&path).unwrap();
    }

    #[test]
    fn recurse_with_contained() {
        let (tx, rx) = unbounded();
        let tmp = tempdir::TempDir::new("xi-test-recurse-contained").unwrap();
        let mut w = FileWatcher::new(tx);
        tmp.create("adir/dir2/file");
        sleep_if_macos(35_000);
        w.watch(&tmp.mkpath("adir"), true, 1.into());
        sleep(10);
        w.watch(&tmp.mkpath("adir/dir2/file"), false, 2.into());
        sleep(10);
        w.unwatch(&tmp.mkpath("adir"), 1.into());
        sleep(10);
        tmp.write("adir/dir2/file");
        let _ = recv_all(&rx, Duration::from_millis(1000));
        let events = w.take_events();
        assert_eq!(
            events,
            vec![
                (
                    2.into(),
                    Event::new(EventKind::Modify(ModifyKind::Any))
                        .add_path(tmp.mkpath("adir/dir2/file"))
                        .set_flag(Flag::Notice)
                ),
                (
                    2.into(),
                    Event::new(EventKind::Modify(ModifyKind::Any))
                        .add_path(tmp.mkpath("adir/dir2/file"))
                ),
            ]
        );
    }

    #[test]
    fn two_watchers_one_file() {
        let (tx, rx) = unbounded();
        let tmp = tempdir::TempDir::new("xi-test-two-watchers").unwrap();
        tmp.create("my_file");
        sleep_if_macos(30_100);
        let mut w = FileWatcher::new(tx);
        w.watch(&tmp.mkpath("my_file"), false, 1.into());
        sleep_if_macos(10);
        w.watch(&tmp.mkpath("my_file"), false, 2.into());
        sleep_if_macos(10);
        tmp.write("my_file");

        let _ = recv_all(&rx, Duration::from_millis(1000));
        let events = w.take_events();
        assert_eq!(
            events,
            vec![
                (
                    1.into(),
                    Event::new(EventKind::Modify(ModifyKind::Any))
                        .add_path(tmp.mkpath("my_file"))
                        .set_flag(Flag::Notice)
                ),
                (
                    2.into(),
                    Event::new(EventKind::Modify(ModifyKind::Any))
                        .add_path(tmp.mkpath("my_file"))
                        .set_flag(Flag::Notice)
                ),
                (
                    1.into(),
                    Event::new(EventKind::Modify(ModifyKind::Any)).add_path(tmp.mkpath("my_file"))
                ),
                (
                    2.into(),
                    Event::new(EventKind::Modify(ModifyKind::Any)).add_path(tmp.mkpath("my_file"))
                ),
            ]
        );

        assert_eq!(w.state.lock().unwrap().watchees.len(), 2);
        w.unwatch(&tmp.mkpath("my_file"), 1.into());
        assert_eq!(w.state.lock().unwrap().watchees.len(), 1);
        sleep_if_macos(1000);
        let path = tmp.mkpath("my_file");
        tmp.remove("my_file");
        sleep_if_macos(1000);
        let _ = recv_all(&rx, Duration::from_millis(1000));
        let events = w.take_events();
        assert!(events.contains(&(
            2.into(),
            Event::new(EventKind::Remove(RemoveKind::Any))
                .add_path(path.clone())
                .set_flag(Flag::Notice)
        )));
        assert!(!events.contains(&(
            1.into(),
            Event::new(EventKind::Remove(RemoveKind::Any)).add_path(path).set_flag(Flag::Notice)
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::cell::RefCell;
use std::cmp::{max, min};
use std::iter;
use std::ops::Range;

use serde_json::Value;

use crate::annotations::{AnnotationStore, Annotations, ToAnnotation};
use crate::client::{Client, Update, UpdateOp};
use crate::edit_types::ViewEvent;
use crate::find::{Find, FindStatus};
use crate::line_cache_shadow::{self, LineCacheShadow, RenderPlan, RenderTactic};
use crate::line_offset::LineOffset;
use crate::linewrap::{InvalLines, Lines, VisualLine, WrapWidth};
use crate::movement::{region_movement, selection_movement, Movement};
use crate::plugins::PluginId;
use crate::rpc::{FindQuery, GestureType, MouseAction, SelectionGranularity, SelectionModifier};
use crate::selection::{Affinity, InsertDrift, SelRegion, Selection};
use crate::styles::{Style, ThemeStyleMap};
use crate::tabs::{BufferId, Counter, ViewId};
use crate::width_cache::WidthCache;
use crate::word_boundaries::WordCursor;
use xi_rope::spans::Spans;
use xi_rope::{Cursor, Interval, LinesMetric, Rope, RopeDelta};
use xi_trace::trace_block;

type StyleMap = RefCell<ThemeStyleMap>;

/// A flag used to indicate when legacy actions should modify selections
const FLAG_SELECT: u64 = 2;

/// Size of batches as number of bytes used during incremental find.
const FIND_BATCH_SIZE: usize = 500000;

/// A view to a buffer. It is the buffer plus additional information
/// like line breaks and selection state.
pub struct View {
    view_id: ViewId,
    buffer_id: BufferId,

    /// Tracks whether this view has been scheduled to render.
    /// We attempt to reduce duplicate renders by setting a small timeout
    /// after an edit is applied, to allow batching with any plugin updates.
    pending_render: bool,
    size: Size,
    /// The selection state for this view. Invariant: non-empty.
    selection: Selection,

    drag_state: Option<DragState>,

    /// vertical scroll position
    first_line: usize,
    /// height of visible portion
    height: usize,
    lines: Lines,

    /// Front end's line cache state for this view. See the `LineCacheShadow`
    /// description for the invariant.
    lc_shadow: LineCacheShadow,

    /// New offset to be scrolled into position after an edit.
    scroll_to: Option<usize>,

    /// The state for finding text for this view.
    /// Each instance represents a separate search query.
    find: Vec<Find>,

    /// Tracks the IDs for additional search queries in find.
    find_id_counter: Counter,

    /// Tracks whether there has been changes in find results or find parameters.
    /// This is used to determined whether FindStatus should be sent to the frontend.
    find_changed: FindStatusChange,

    /// Tracks the progress of incremental find.
    find_progress: FindProgress,

    /// Tracks whether find highlights should be rendered.
    /// Highlights are only rendered when search dialog is open.
    highlight_find: bool,

    /// The state for replacing matches for this view.
    replace: Option<Replace>,

    /// Tracks whether the replacement string or replace parameters changed.
    replace_changed: bool,

    /// Annotations provided by plugins.
    annotations: AnnotationStore,
}

/// Indicates what changed in the find state.
#[derive(PartialEq, Debug)]
enum FindStatusChange {
    /// None of the find parameters or number of matches changed.
    None,

    /// Find parameters and number of matches changed.
    All,

    /// Only number of matches changed
    Matches,
}

/// Indicates what changed in the find state.
#[derive(PartialEq, Debug, Clone)]
enum FindProgress {
    /// Incremental find is done/not running.
    Ready,

    /// The find process just started.
    Started,

    /// Incremental find is in progress. Keeps tracked of already searched range.
    InProgress(Range<usize>),
}

/// Contains replacement string and replace options.
#[derive(Debug, Default, PartialEq, Serialize, Deserialize, Clone)]
pub struct Replace {
    /// Replacement string.
    pub chars: String,
    pub preserve_case: bool,
}

/// A size, in pixel units (not display pixels).
#[derive(Debug, Default, PartialEq, Serialize, Deserialize, Clone)]
pub struct Size {
    pub width: f64,
    pub height: f64,
}

/// State required to resolve a drag gesture into a selection.
struct DragState {
    /// All the selection regions other than the one being dragged.
    base_sel: Selection,

    /// Start of the region selected when drag was started (region is
    /// assumed to be forward).
    min: usize,

    /// End of the region selected when drag was started.
    max: usize,

    granularity: SelectionGranularity,
}

impl View {
    pub fn new(view_id: ViewId, buffer_id: BufferId) -> View {
        View {
            view_id,
            buffer_id,
            pending_render: false,
            selection: SelRegion::caret(0).into(),
            scroll_to: Some(0),
            size: Size::default(),
            drag_state: None,
            first_line: 0,
            height: 10,
            lines: Lines::default(),
            lc_shadow: LineCacheShadow::default(),
            find: Vec::new(),
            find_id_counter: Counter::default(),
            find_changed: FindStatusChange::None,
            find_progress: FindProgress::Ready,
            highlight_find: false,
            replace: None,
            replace_changed: false,
            annotations: AnnotationStore::new(),
        }
    }

    pub(crate) fn get_buffer_id(&self) -> BufferId {
        self.buffer_id
    }

    pub(crate) fn get_view_id(&self) -> ViewId {
        self.view_id
    }

    pub(crate) fn get_lines(&self) -> &Lines {
        &self.lines
    }

    pub(crate) fn get_replace(&self) -> Option<Replace> {
        self.replace.clone()
    }

    pub(crate) fn set_has_pending_render(&mut self, pending: bool) {
        self.pending_render = pending
    }

    pub(crate) fn has_pending_render(&self) -> bool {
        self.pending_render
    }

    pub(crate) fn update_wrap_settings(&mut self, text: &Rope, wrap_cols: usize, word_wrap: bool) {
        let wrap_width = match (word_wrap, wrap_cols) {
            (true, _) => WrapWidth::Width(self.size.width),
            (false, 0) => WrapWidth::None,
            (false, cols) => WrapWidth::Bytes(cols),
        };
        self.lines.set_wrap_width(text, wrap_width);
    }

    pub(crate) fn needs_more_wrap(&self) -> bool {
        !self.lines.is_converged()
    }

    pub(crate) fn needs_wrap_in_visible_region(&self, text: &Rope) -> bool {
        if self.lines.is_converged() {
            false
        } else {
            let visible_region = self.interval_of_visible_region(text);
            self.lines.interval_needs_wrap(visible_region)
        }
    }

    pub(crate) fn find_in_progress(&self) -> bool {
        match self.find_progress {
            FindProgress::InProgress(_) => true,
            FindProgress::Started => true,
            _ => false,
        }
    }

    pub(crate) fn do_edit(&mut self, text: &Rope, cmd: ViewEvent) {
        use self::ViewEvent::*;
        match cmd {
            Move(movement) => self.do_move(text, movement, false),
            ModifySelection(movement) => self.do_move(text, movement, true),
            SelectAll => self.select_all(text),
            Scroll(range) => self.set_scroll(range.first, range.last),
            AddSelectionAbove => self.add_selection_by_movement(text, Movement::UpExactPosition),
            AddSelectionBelow => self.add_selection_by_movement(text, Movement::DownExactPosition),
            Gesture { line, col, ty } => self.do_gesture(text, line, col, ty),
            GotoLine { line } => self.goto_line(text, line),
            Find { chars, case_sensitive, regex, whole_words } => {
                let id = self.find.first().map(|q| q.id());
                let query_changes = FindQuery { id, chars, case_sensitive, regex, whole_words };
                self.set_find(text, [query_changes].to_vec())
            }
            MultiFind { queries } => self.set_find(text, queries),
            FindNext { wrap_around, allow_same, modify_selection } => {
                self.do_find_next(text, false, wrap_around, allow_same, &modify_selection)
            }
            FindPrevious { wrap_around, allow_same, modify_selection } => {
                self.do_find_next(text, true, wrap_around, allow_same, &modify_selection)
            }
            FindAll => self.do_find_all(text),
            Click(MouseAction { line, column, flags, click_count }) => {
                // Deprecated (kept for client compatibility):
                // should be removed in favor of do_gesture
                warn!("Usage of click is deprecated; use do_gesture");
                if (flags & FLAG_SELECT) != 0 {
                    self.do_gesture(
                        text,
                        line,
                        column,
                        GestureType::SelectExtend { granularity: SelectionGranularity::Point },
                    )
                } else if click_count == Some(2) {
                    self.do_gesture(text, line, column, GestureType::WordSelect)
                } else if click_count == Some(3) {
                    self.do_gesture(text, line, column, GestureType::LineSelect)
                } else {
                    self.do_gesture(text, line, column, GestureType::PointSelect)
                }
            }
            Drag(MouseAction { line, column, .. }) => {
                warn!("Usage of drag is deprecated; use gesture instead");
                self.do_gesture(text, line, column, GestureType::Drag)
            }
            CollapseSelections => self.collapse_selections(text),
            HighlightFind { visible } => {
                self.highlight_find = visible;
                self.find_changed = FindStatusChange::All;
                self.set_dirty(text);
            }
            SelectionForFind { case_sensitive } => self.do_selection_for_find(text, case_sensitive),
            Replace { chars, preserve_case } => self.do_set_replace(chars, preserve_case),
            SelectionForReplace => self.do_selection_for_replace(text),
            SelectionIntoLines => self.do_split_selection_into_lines(text),
        }
    }

    fn do_gesture(&mut self, text: &Rope, line: u64, col: u64, ty: GestureType) {
        let line = line as usize;
        let col = col as usize;
        let offset = self.line_col_to_offset(text, line, col);
        match ty {
            GestureType::Select { granularity, multi } => {
                self.select(text, offset, granularity, multi)
            }
            GestureType::SelectExtend { granularity } => {
                self.extend_selection(text, offset, granularity)
            }
            GestureType::Drag => self.do_drag(text, offset, Affinity::default()),

            _ => {
                warn!("Deprecated gesture type sent to do_gesture method");
            }
        }
    }

    fn goto_line(&mut self, text: &Rope, line: u64) {
        let offset = self.line_col_to_offset(text, line as usize, 0);
        self.set_selection(text, SelRegion::caret(offset));
    }

    pub fn set_size(&mut self, size: Size) {
        self.size = size;
    }

    pub fn set_scroll(&mut self, first: i64, last: i64) {
        let first = max(first, 0) as usize;
        let last = max(last, 0) as usize;
        self.first_line = first;
        self.height = last - first;
    }

    pub fn scroll_height(&self) -> usize {
        self.height
    }

    fn scroll_to_cursor(&mut self, text: &Rope) {
        let end = self.sel_regions().last().unwrap().end;
        let line = self.line_of_offset(text, end);
        if line < self.first_line {
            self.first_line = line;
        } else if self.first_line + self.height <= line {
            self.first_line = line - (self.height - 1);
        }
        // We somewhat arbitrarily choose the last region for setting the old-style
        // selection state, and for scrolling it into view if needed. This choice can
        // likely be improved.
        self.scroll_to = Some(end);
    }

    /// Removes any selection present at the given offset.
    /// Returns true if a selection was removed, false otherwise.
    pub fn deselect_at_offset(&mut self, text: &Rope, offset: usize) -> bool {
        if !self.selection.regions_in_range(offset, offset).is_empty() {
            let mut sel = self.selection.clone();
            sel.delete_range(offset, offset, true);
            if !sel.is_empty() {
                self.drag_state = None;
                self.set_selection_raw(text, sel);
                return true;
            }
        }
        false
    }

    /// Move the selection by the given movement. Return value is the offset of
    /// a point that should be scrolled into view.
    ///
    /// If `modify` is `true`, the selections are modified, otherwise the results
    /// of individual region movements become carets.
    pub fn do_move(&mut self, text: &Rope, movement: Movement, modify: bool) {
        self.drag_state = None;
        let new_sel =
            selection_movement(movement, &self.selection, self, self.scroll_height(), text, modify);
        self.set_selection(text, new_sel);
    }

    /// Set the selection to a new value.
    pub fn set_selection<S: Into<Selection>>(&mut self, text: &Rope, sel: S) {
        self.set_selection_raw(text, sel.into());
        self.scroll_to_cursor(text);
    }

    /// Sets the selection to a new value, without invalidating.
    fn set_selection_for_edit(&mut self, text: &Rope, sel: Selection) {
        self.selection = sel;
        self.scroll_to_cursor(text);
    }

    /// Sets the selection to a new value, invalidating the line cache as needed.
    /// This function does not perform any scrolling.
    fn set_selection_raw(&mut self, text: &Rope, sel: Selection) {
        self.invalidate_selection(text);
        self.selection = sel;
        self.invalidate_selection(text);
    }

    /// Invalidate the current selection. Note that we could be even more
    /// fine-grained in the case of multiple cursors, but we also want this
    /// method to be fast even when the selection is large.
    fn invalidate_selection(&mut self, text: &Rope) {
        // TODO: refine for upstream (caret appears on prev line)
        let first_line = self.line_of_offset(text, self.selection.first().unwrap().min());
        let last_line = self.line_of_offset(text, self.selection.last().unwrap().max()) + 1;
        let all_caret = self.selection.iter().all(|region| region.is_caret());
        let invalid = if all_caret {
            line_cache_shadow::CURSOR_VALID
        } else {
            line_cache_shadow::CURSOR_VALID | line_cache_shadow::STYLES_VALID
        };
        self.lc_shadow.partial_invalidate(first_line, last_line, invalid);
    }

    fn add_selection_by_movement(&mut self, text: &Rope, movement: Movement) {
        let mut sel = Selection::new();
        for &region in self.sel_regions() {
            sel.add_region(region);
            let new_region =
                region_movement(movement, region, self, self.scroll_height(), &text, false);
            sel.add_region(new_region);
        }
        self.set_selection(text, sel);
    }

    // TODO: insert from keyboard or input method shouldn't break undo group,
    /// Invalidates the styles of the given range (start and end are offsets within
    /// the text).
    pub fn invalidate_styles(&mut self, text: &Rope, start: usize, end: usize) {
        let first_line = self.line_of_offset(text, start);
        let (mut last_line, last_col) = self.offset_to_line_col(text, end);
        last_line += if last_col > 0 { 1 } else { 0 };
        self.lc_shadow.partial_invalidate(first_line, last_line, line_cache_shadow::STYLES_VALID);
    }

    pub fn update_annotations(
        &mut self,
        plugin: PluginId,
        interval: Interval,
        annotations: Annotations,
    ) {
        self.annotations.update(plugin, interval, annotations)
    }

    /// Select entire buffer.
    ///
    /// Note: unlike movement based selection, this does not scroll.
    pub fn select_all(&mut self, text: &Rope) {
        let selection = SelRegion::new(0, text.len()).into();
        self.set_selection_raw(text, selection);
    }

    /// Finds the unit of text containing the given offset.
    fn unit(&self, text: &Rope, offset: usize, granularity: SelectionGranularity) -> Interval {
        match granularity {
            SelectionGranularity::Point => Interval::new(offset, offset),
            SelectionGranularity::Word => {
                let mut word_cursor = WordCursor::new(text, offset);
                let (start, end) = word_cursor.select_word();
                Interval::new(start, end)
            }
            SelectionGranularity::Line => {
                let (line, _) = self.offset_to_line_col(text, offset);
                let (start, end) = self.lines.logical_line_range(text, line);
                Interval::new(start, end)
            }
        }
    }

    /// Selects text with a certain granularity and supports multi_selection
    fn select(
        &mut self,
        text: &Rope,
        offset: usize,
        granularity: SelectionGranularity,
        multi: bool,
    ) {
        // If multi-select is enabled, toggle existing regions
        if multi
            && granularity == SelectionGranularity::Point
            && self.deselect_at_offset(text, offset)
        {
            return;
        }

        let region = self.unit(text, offset, granularity).into();

        let base_sel = match multi {
            true => self.selection.clone(),
            false => Selection::new(),
        };
        let mut selection = base_sel.clone();
        selection.add_region(region);
        self.set_selection(text, selection);

        self.drag_state =
            Some(DragState { base_sel, min: region.start, max: region.end, granularity });
    }

    /// Extends an existing selection (eg. when the user performs SHIFT + click).
    pub fn extend_selection(
        &mut self,
        text: &Rope,
        offset: usize,
        granularity: SelectionGranularity,
    ) {
        if self.sel_regions().is_empty() {
            return;
        }

        let (base_sel, last) = {
            let mut base = Selection::new();
            let (last, rest) = self.sel_regions().split_last().unwrap();
            for &region in rest {
                base.add_region(region);
            }
            (base, *last)
        };

        let mut sel = base_sel.clone();
        self.drag_state =
            Some(DragState { base_sel, min: last.start, max: last.start, granularity });

        let start = (last.start, last.start);
        let new_region = self.range_region(text, start, offset, granularity);

        // TODO: small nit, merged region should be backward if end < start.
        // This could be done by explicitly overriding, or by tweaking the
        // merge logic.
        sel.add_region(new_region);
        self.set_selection(text, sel);
    }

    /// Splits current selections into lines.
    fn do_split_selection_into_lines(&mut self, text: &Rope) {
        let mut selection = Selection::new();

        for region in self.selection.iter() {
            if region.is_caret() {
                selection.add_region(SelRegion::caret(region.max()));
            } else {
                let mut cursor = Cursor::new(&text, region.min());

                while cursor.pos() < region.max() {
                    let sel_start = cursor.pos();
                    let end_of_line = match cursor.next::<LinesMetric>() {
                        Some(end) if end >= region.max() => max(0, region.max() - 1),
                        Some(end) => max(0, end - 1),
                        None if cursor.pos() == text.len() => cursor.pos(),
                        _ => break,
                    };

                    selection.add_region(SelRegion::new(sel_start, end_of_line));
                }
            }
        }

        self.set_selection_raw(text, selection);
    }

    /// Does a drag gesture, setting the selection from a combination of the drag
    /// state and new offset.
    fn do_drag(&mut self, text: &Rope, offset: usize, affinity: Affinity) {
        let new_sel = self.drag_state.as_ref().map(|drag_state| {
            let mut sel = drag_state.base_sel.clone();
            let start = (drag_state.min, drag_state.max);
            let new_region = self.range_region(text, start, offset, drag_state.granularity);
            sel.add_region(new_region.with_horiz(None).with_affinity(affinity));
            sel
        });

        if let Some(sel) = new_sel {
            self.set_selection(text, sel);
        }
    }

    /// Creates a `SelRegion` for range select or drag operations.
    pub fn range_region(
        &self,
        text: &Rope,
        start: (usize, usize),
        offset: usize,
        granularity: SelectionGranularity,
    ) -> SelRegion {
        let (min_start, max_start) = start;
        let end = self.unit(text, offset, granularity);
        let (min_end, max_end) = (end.start, end.end);
        if offset >= min_start {
            SelRegion::new(min_start, max_end)
        } else {
            SelRegion::new(max_start, min_end)
        }
    }

    /// Returns the regions of the current selection.
    pub fn sel_regions(&self) -> &[SelRegion] {
        &self.selection
    }

    /// Collapse all selections in this view into a single caret
    pub fn collapse_selections(&mut self, text: &Rope) {
        let mut sel = self.selection.clone();
        sel.collapse();
        self.set_selection(text, sel);
    }

    /// Determines whether the offset is in any selection (counting carets and
    /// selection edges).
    pub fn is_point_in_selection(&self, offset: usize) -> bool {
        !self.selection.regions_in_range(offset, offset).is_empty()
    }

    // Encode a single line with its styles and cursors in JSON.
    // If "text" is not specified, don't add "text" to the output.
    // If "style_spans" are not specified, don't add "styles" to the output.
    fn encode_line(
        &self,
        client: &Client,
        styles: &StyleMap,
        line: VisualLine,
        text: Option<&Rope>,
        style_spans: Option<&Spans<Style>>,
        last_pos: usize,
    ) -> Value {
        let start_pos = line.interval.start;
        let pos = line.interval.end;
        let mut cursors = Vec::new();
        let mut selections = Vec::new();
        for region in self.selection.regions_in_range(start_pos, pos) {
            // cursor
            let c = region.end;

            if (c > start_pos && c < pos)
                || (!region.is_upstream() && c == start_pos)
                || (region.is_upstream() && c == pos)
                || (c == pos && c == last_pos)
            {
                cursors.push(c - start_pos);
            }

            // selection with interior
            let sel_start_ix = clamp(region.min(), start_pos, pos) - start_pos;
            let sel_end_ix = clamp(region.max(), start_pos, pos) - start_pos;
            if sel_end_ix > sel_start_ix {
                selections.push((sel_start_ix, sel_end_ix));
            }
        }

        let mut hls = Vec::new();

        if self.highlight_find {
            for find in &self.find {
                let mut cur_hls = Vec::new();
                for region in find.occurrences().regions_in_range(start_pos, pos) {
                    let sel_start_ix = clamp(region.min(), start_pos, pos) - start_pos;
                    let sel_end_ix = clamp(region.max(), start_pos, pos) - start_pos;
                    if sel_end_ix > sel_start_ix {
                        cur_hls.push((sel_start_ix, sel_end_ix));
                    }
                }
                hls.push(cur_hls);
            }
        }

        let mut result = json!({});

        if let Some(text) = text {
            result["text"] = json!(text.slice_to_cow(start_pos..pos));
        }
        if let Some(style_spans) = style_spans {
            result["styles"] = json!(self.encode_styles(
                client,
                styles,
                start_pos,
                pos,
                &selections,
                &hls,
                style_spans
            ));
        }
        if !cursors.is_empty() {
            result["cursor"] = json!(cursors);
        }
        if let Some(line_num) = line.line_num {
            result["ln"] = json!(line_num);
        }
        result
    }

    pub fn encode_styles(
        &self,
        client: &Client,
        styles: &StyleMap,
        start: usize,
        end: usize,
        sel: &[(usize, usize)],
        hls: &Vec<Vec<(usize, usize)>>,
        style_spans: &Spans<Style>,
    ) -> Vec<isize> {
        let mut encoded_styles = Vec::new();
        assert!(start <= end, "{} {}", start, end);
        let style_spans = style_spans.subseq(Interval::new(start, end));

        let mut ix = 0;
        // we add the special find highlights (1 to N) and selection (0) styles first.
        // We add selection after find because we want it to be preferred if the
        // same span exists in both sets (as when there is an active selection)
        for (index, cur_find_hls) in hls.iter().enumerate() {
            for &(sel_start, sel_end) in cur_find_hls {
                encoded_styles.push((sel_start as isize) - ix);
                encoded_styles.push(sel_end as isize - sel_start as isize);
                encoded_styles.push(index as isize + 1);
                ix = sel_end as isize;
            }
        }
        for &(sel_start, sel_end) in sel {
            encoded_styles.push((sel_start as isize) - ix);
            encoded_styles.push(sel_end as isize - sel_start as isize);
            encoded_styles.push(0);
            ix = sel_end as isize;
        }
        for (iv, style) in style_spans.iter() {
            let style_id = self.get_or_def_style_id(client, styles, &style);
            encoded_styles.push((iv.start() as isize) - ix);
            encoded_styles.push(iv.end() as isize - iv.start() as isize);
            encoded_styles.push(style_id as isize);
            ix = iv.end() as isize;
        }
        encoded_styles
    }

    fn get_or_def_style_id(&self, client: &Client, style_map: &StyleMap, style: &Style) -> usize {
        let mut style_map = style_map.borrow_mut();
        if let Some(ix) = style_map.lookup(style) {
            return ix;
        }
        let ix = style_map.add(style);
        let style = style_map.merge_with_default(style);
        client.def_style(&style.to_json(ix));
        ix
    }

    fn send_update_for_plan(
        &mut self,
        text: &Rope,
        client: &Client,
        styles: &StyleMap,
        style_spans: &Spans<Style>,
        plan: &RenderPlan,
        pristine: bool,
    ) {
        // every time current visible range changes, annotations are sent to frontend
        let start_off = self.offset_of_line(text, self.first_line);
        let end_off = self.offset_of_line(text, self.first_line + self.height + 2);
        let visible_range = Interval::new(start_off, end_off);
        let selection_annotations =
            self.selection.get_annotations(visible_range, &self, text).to_json();
        let find_annotations =
            self.find.iter().map(|ref f| f.get_annotations(visible_range, &self, text).to_json());
        let plugin_annotations =
            self.annotations.iter_range(&self, text, visible_range).map(|a| a.to_json());

        let annotations = iter::once(selection_annotations)
            .chain(find_annotations)
            .chain(plugin_annotations)
            .collect::<Vec<_>>();

        if !self.lc_shadow.needs_render(plan) {
            let total_lines = self.line_of_offset(text, text.len()) + 1;
            let update =
                Update { ops: vec![UpdateOp::copy(total_lines, 1)], pristine, annotations };
            client.update_view(self.view_id, &update);
            return;
        }

        // send updated find status only if there have been changes
        if self.find_changed != FindStatusChange::None {
            let matches_only = self.find_changed == FindStatusChange::Matches;
            client.find_status(self.view_id, &json!(self.find_status(text, matches_only)));
            self.find_changed = FindStatusChange::None;
        }

        // send updated replace status if changed
        if self.replace_changed {
            if let Some(replace) = self.get_replace() {
                client.replace_status(self.view_id, &json!(replace))
            }
        }

        let mut b = line_cache_shadow::Builder::new();
        let mut ops = Vec::new();
        let mut line_num = 0; // tracks old line cache

        for seg in self.lc_shadow.iter_with_plan(plan) {
            match seg.tactic {
                RenderTactic::Discard => {
                    ops.push(UpdateOp::invalidate(seg.n));
                    b.add_span(seg.n, 0, 0);
                }
                RenderTactic::Preserve | RenderTactic::Render => {
                    // Depending on the state of TEXT_VALID, STYLES_VALID and
                    // CURSOR_VALID, perform one of the following actions:
                    //
                    //   - All the three are valid => send the "copy" op
                    //     (+leading "skip" to catch up with "ln" to update);
                    //
                    //   - Text and styles are valid, cursors are not => same,
                    //     but send an "update" op instead of "copy" to move
                    //     the cursors;
                    //
                    //   - Text or styles are invalid:
                    //     => send "invalidate" if RenderTactic is "Preserve";
                    //     => send "skip"+"insert" (recreate the lines) if
                    //        RenderTactic is "Render".
                    if (seg.validity & line_cache_shadow::TEXT_VALID) != 0
                        && (seg.validity & line_cache_shadow::STYLES_VALID) != 0
                    {
                        let n_skip = seg.their_line_num - line_num;
                        if n_skip > 0 {
                            ops.push(UpdateOp::skip(n_skip));
                        }
                        let line_offset = self.offset_of_line(text, seg.our_line_num);
                        let logical_line = text.line_of_offset(line_offset);
                        if (seg.validity & line_cache_shadow::CURSOR_VALID) != 0 {
                            // ALL_VALID; copy lines as-is
                            ops.push(UpdateOp::copy(seg.n, logical_line + 1));
                        } else {
                            // !CURSOR_VALID; update cursors
                            let start_line = seg.our_line_num;

                            let encoded_lines = self
                                .lines
                                .iter_lines(text, start_line)
                                .take(seg.n)
                                .map(|l| {
                                    self.encode_line(
                                        client,
                                        styles,
                                        l,
                                        /* text = */ None,
                                        /* style_spans = */ None,
                                        text.len(),
                                    )
                                })
                                .collect::<Vec<_>>();

                            let logical_line_opt =
                                if logical_line == 0 { None } else { Some(logical_line + 1) };
                            ops.push(UpdateOp::update(encoded_lines, logical_line_opt));
                        }
                        b.add_span(seg.n, seg.our_line_num, seg.validity);
                        line_num = seg.their_line_num + seg.n;
                    } else {
                        if seg.tactic == RenderTactic::Preserve {
                            ops.push(UpdateOp::invalidate(seg.n));
                            b.add_span(seg.n, 0, 0);
                        } else if seg.tactic == RenderTactic::Render {
                            let start_line = seg.our_line_num;
                            let encoded_lines = self
                                .lines
                                .iter_lines(text, start_line)
                                .take(seg.n)
                                .map(|l| {
                                    self.encode_line(
                                        client,
                                        styles,
                                        l,
                                        Some(text),
                                        Some(style_spans),
                                        text.len(),
                                    )
                                })
                                .collect::<Vec<_>>();
                            debug_assert_eq!(encoded_lines.len(), seg.n);
                            ops.push(UpdateOp::insert(encoded_lines));
                            b.add_span(seg.n, seg.our_line_num, line_cache_shadow::ALL_VALID);
                        }
                    }
                }
            }
        }

        self.lc_shadow = b.build();
        for find in &mut self.find {
            find.set_hls_dirty(false)
        }

        let update = Update { ops, pristine, annotations };
        client.update_view(self.view_id, &update);
    }

    /// Determines the current number of find results and search parameters to send them to
    /// the frontend.
    pub fn find_status(&self, text: &Rope, matches_only: bool) -> Vec<FindStatus> {
        self.find
            .iter()
            .map(|find| find.find_status(&self, text, matches_only))
            .collect::<Vec<FindStatus>>()
    }

    /// Update front-end with any changes to view since the last time sent.
    /// The `pristine` argument indicates whether or not the buffer has
    /// unsaved changes.
    pub fn render_if_dirty(
        &mut self,
        text: &Rope,
        client: &Client,
        styles: &StyleMap,
        style_spans: &Spans<Style>,
        pristine: bool,
    ) {
        let height = self.line_of_offset(text, text.len()) + 1;
        let plan = RenderPlan::create(height, self.first_line, self.height);
        self.send_update_for_plan(text, client, styles, style_spans, &plan, pristine);
        if let Some(new_scroll_pos) = self.scroll_to.take() {
            let (line, col) = self.offset_to_line_col(text, new_scroll_pos);
            client.scroll_to(self.view_id, line, col);
        }
    }

    // Send the requested lines even if they're outside the current scroll region.
    pub fn request_lines(
        &mut self,
        text: &Rope,
        client: &Client,
        styles: &StyleMap,
        style_spans: &Spans<Style>,
        first_line: usize,
        last_line: usize,
        pristine: bool,
    ) {
        let height = self.line_of_offset(text, text.len()) + 1;
        let mut plan = RenderPlan::create(height, self.first_line, self.height);
        plan.request_lines(first_line, last_line);
        self.send_update_for_plan(text, client, styles, style_spans, &plan, pristine);
    }

    /// Invalidates front-end's entire line cache, forcing a full render at the next
    /// update cycle. This should be a last resort, updates should generally cause
    /// finer grain invalidation.
    pub fn set_dirty(&mut self, text: &Rope) {
        let height = self.line_of_offset(text, text.len()) + 1;
        let mut b = line_cache_shadow::Builder::new();
        b.add_span(height, 0, 0);
        b.set_dirty(true);
        self.lc_shadow = b.build();
    }

    /// Returns the byte range of the currently visible lines.
    fn interval_of_visible_region(&self, text: &Rope) -> Interval {
        let start = self.offset_of_line(text, self.first_line);
        let end = self.offset_of_line(text, self.first_line + self.height + 1);
        Interval::new(start, end)
    }

    /// Generate line breaks, based on current settings. Currently batch-mode,
    /// and currently in a debugging state.
    pub(crate) fn rewrap(
        &mut self,
        text: &Rope,
        width_cache: &mut WidthCache,
        client: &Client,
        spans: &Spans<Style>,
    ) {
        let _t = trace_block("View::rewrap", &["core"]);
        let visible = self.first_line..self.first_line + self.height;
        let inval = self.lines.rewrap_chunk(text, width_cache, client, spans, visible);
        if let Some(InvalLines { start_line, inval_count, new_count }) = inval {
            self.lc_shadow.edit(start_line, start_line + inval_count, new_count);
        }
    }

    /// Updates the view after the text has been modified by the given `delta`.
    /// This method is responsible for updating the cursors, and also for
    /// recomputing line wraps.
    pub fn after_edit(
        &mut self,
        text: &Rope,
        last_text: &Rope,
        delta: &RopeDelta,
        client: &Client,
        width_cache: &mut WidthCache,
        drift: InsertDrift,
    ) {
        let visible = self.first_line..self.first_line + self.height;
        match self.lines.after_edit(text, last_text, delta, width_cache, client, visible) {
            Some(InvalLines { start_line, inval_count, new_count }) => {
                self.lc_shadow.edit(start_line, start_line + inval_count, new_count);
            }
            None => self.set_dirty(text),
        }

        // Any edit cancels a drag. This is good behavior for edits initiated through
        // the front-end, but perhaps not for async edits.
        self.drag_state = None;

        // all annotations that come after the edit need to be invalidated
        let (iv, _) = delta.summary();
        self.annotations.invalidate(iv);

        // update only find highlights affected by change
        for find in &mut self.find {
            find.update_highlights(text, delta);
            self.find_changed = FindStatusChange::All;
        }

        // Note: for committing plugin edits, we probably want to know the priority
        // of the delta so we can set the cursor before or after the edit, as needed.
        let new_sel = self.selection.apply_delta(delta, true, drift);
        self.set_selection_for_edit(text, new_sel);
    }

    fn do_selection_for_find(&mut self, text: &Rope, case_sensitive: bool) {
        // set last selection or word under current cursor as search query
        let search_query = match self.selection.last() {
            Some(region) => {
                if !region.is_caret() {
                    text.slice_to_cow(region)
                } else {
                    let (start, end) = {
                        let mut word_cursor = WordCursor::new(text, region.max());
                        word_cursor.select_word()
                    };
                    text.slice_to_cow(start..end)
                }
            }
            _ => return,
        };

        self.set_dirty(text);

        // set selection as search query for first find if no additional search queries are used
        // otherwise add new find with selection as search query
        if self.find.len() != 1 {
            self.add_find();
        }

        self.find.last_mut().unwrap().set_find(&search_query, case_sensitive, false, true);
        self.find_progress = FindProgress::Started;
    }

    fn add_find(&mut self) {
        let id = self.find_id_counter.next();
        self.find.push(Find::new(id));
    }

    fn set_find(&mut self, text: &Rope, queries: Vec<FindQuery>) {
        // checks if at least query has been changed, otherwise we don't need to rerun find
        let mut find_changed = queries.len() != self.find.len();

        // remove deleted queries
        self.find.retain(|f| queries.iter().any(|q| q.id == Some(f.id())));

        for query in &queries {
            let pos = match query.id {
                Some(id) => {
                    // update existing query
                    match self.find.iter().position(|f| f.id() == id) {
                        Some(p) => p,
                        None => return,
                    }
                }
                None => {
                    // add new query
                    self.add_find();
                    self.find.len() - 1
                }
            };

            if self.find[pos].set_find(
                &query.chars.clone(),
                query.case_sensitive,
                query.regex,
                query.whole_words,
            ) {
                find_changed = true;
            }
        }

        if find_changed {
            self.set_dirty(text);
            self.find_progress = FindProgress::Started;
        }
    }

    pub fn do_find(&mut self, text: &Rope) {
        let search_range = match &self.find_progress.clone() {
            FindProgress::Started => {
                // start incremental find on visible region
                let start = self.offset_of_line(text, self.first_line);
                let end = min(text.len(), start + FIND_BATCH_SIZE);
                self.find_changed = FindStatusChange::Matches;
                self.find_progress = FindProgress::InProgress(Range { start, end });
                Some((start, end))
            }
            FindProgress::InProgress(searched_range) => {
                if searched_range.start == 0 && searched_range.end >= text.len() {
                    // the entire text has been searched
                    // end find by executing multi-line regex queries on entire text
                    // stop incremental find
                    self.find_progress = FindProgress::Ready;
                    self.find_changed = FindStatusChange::All;
                    Some((0, text.len()))
                } else {
                    self.find_changed = FindStatusChange::Matches;
                    // expand find to un-searched regions
                    let start_off = self.offset_of_line(text, self.first_line);

                    // If there is unsearched text before the visible region, we want to include it in this search operation
                    let search_preceding_range = start_off.saturating_sub(searched_range.start)
                        < searched_range.end.saturating_sub(start_off)
                        && searched_range.start > 0;

                    if search_preceding_range || searched_range.end >= text.len() {
                        let start = searched_range.start.saturating_sub(FIND_BATCH_SIZE);
                        self.find_progress =
                            FindProgress::InProgress(Range { start, end: searched_range.end });
                        Some((start, searched_range.start))
                    } else if searched_range.end < text.len() {
                        let end = min(text.len(), searched_range.end + FIND_BATCH_SIZE);
                        self.find_progress =
                            FindProgress::InProgress(Range { start: searched_range.start, end });
                        Some((searched_range.end, end))
                    } else {
                        self.find_changed = FindStatusChange::All;
                        None
                    }
                }
            }
            _ => {
                self.find_changed = FindStatusChange::None;
                None
            }
        };

        if let Some((search_range_start, search_range_end)) = search_range {
            for query in &mut self.find {
                if !query.is_multiline_regex() {
                    query.update_find(text, search_range_start, search_range_end, true);
                } else {
                    // only execute multi-line regex queries if we are searching the entire text (last step)
                    if search_range_start == 0 && search_range_end == text.len() {
                        query.update_find(text, search_range_start, search_range_end, true);
                    }
                }
            }
        }
    }

    /// Selects the next find match.
    pub fn do_find_next(
        &mut self,
        text: &Rope,
        reverse: bool,
        wrap: bool,
        allow_same: bool,
        modify_selection: &SelectionModifier,
    ) {
        self.select_next_occurrence(text, reverse, false, allow_same, modify_selection);
        if self.scroll_to.is_none() && wrap {
            self.select_next_occurrence(text, reverse, true, allow_same, modify_selection);
        }
    }

    /// Selects all find matches.
    pub fn do_find_all(&mut self, text: &Rope) {
        let mut selection = Selection::new();
        for find in &self.find {
            for &occurrence in find.occurrences().iter() {
                selection.add_region(occurrence);
            }
        }

        if !selection.is_empty() {
            // todo: invalidate so that nothing selected accidentally replaced
            self.set_selection(text, selection);
        }
    }

    /// Select the next occurrence relative to the last cursor. `reverse` determines whether the
    /// next occurrence before (`true`) or after (`false`) the last cursor is selected. `wrapped`
    /// indicates a search for the next occurrence past the end of the file.
    pub fn select_next_occurrence(
        &mut self,
        text: &Rope,
        reverse: bool,
        wrapped: bool,
        _allow_same: bool,
        modify_selection: &SelectionModifier,
    ) {
        let (cur_start, cur_end) = match self.selection.last() {
            Some(sel) => (sel.min(), sel.max()),
            _ => (0, 0),
        };

        // multiple queries; select closest occurrence
        let closest_occurrence = self
            .find
            .iter()
            .flat_map(|x| x.next_occurrence(text, reverse, wrapped, &self.selection))
            .min_by_key(|x| match reverse {
                true if x.end > cur_end => 2 * text.len() - x.end,
                true => cur_end - x.end,
                false if x.start < cur_start => x.start + text.len(),
                false => x.start - cur_start,
            });

        if let Some(occ) = closest_occurrence {
            match modify_selection {
                SelectionModifier::Set => self.set_selection(text, occ),
                SelectionModifier::Add => {
                    let mut selection = self.selection.clone();
                    selection.add_region(occ);
                    self.set_selection(text, selection);
                }
                SelectionModifier::AddRemovingCurrent => {
                    let mut selection = self.selection.clone();

                    if let Some(last_selection) = self.selection.last() {
                        if !last_selection.is_caret() {
                            selection.delete_range(
                                last_selection.min(),
                                last_selection.max(),
                                false,
                            );
                        }
                    }

                    selection.add_region(occ);
                    self.set_selection(text, selection);
                }
                _ => {}
            }
        }
    }

    fn do_set_replace(&mut self, chars: String, preserve_case: bool) {
        self.replace = Some(Replace { chars, preserve_case });
        self.replace_changed = true;
    }

    fn do_selection_for_replace(&mut self, text: &Rope) {
        // set last selection or word under current cursor as replacement string
        let replacement = match self.selection.last() {
            Some(region) => {
                if !region.is_caret() {
                    text.slice_to_cow(region)
                } else {
                    let (start, end) = {
                        let mut word_cursor = WordCursor::new(text, region.max());
                        word_cursor.select_word()
                    };
                    text.slice_to_cow(start..end)
                }
            }
            _ => return,
        };

        self.set_dirty(text);
        self.do_set_replace(replacement.into_owned(), false);
    }

    pub fn get_caret_offset(&self) -> Option<usize> {
        match self.selection.len() {
            1 if self.selection[0].is_caret() => {
                let offset = self.selection[0].start;
                Some(offset)
            }
            _ => None,
        }
    }
}

impl View {
    /// Exposed for benchmarking
    #[doc(hidden)]
    pub fn debug_force_rewrap_cols(&mut self, text: &Rope, cols: usize) {
        use xi_rpc::test_utils::DummyPeer;

        let spans: Spans<Style> = Spans::default();
        let mut width_cache = WidthCache::new();
        let client = Client::new(Box::new(DummyPeer));
        self.update_wrap_settings(text, cols, false);
        self.rewrap(text, &mut width_cache, &client, &spans);
    }
}

impl LineOffset for View {
    fn offset_of_line(&self, text: &Rope, line: usize) -> usize {
        self.lines.offset_of_visual_line(text, line)
    }

    fn line_of_offset(&self, text: &Rope, offset: usize) -> usize {
        self.lines.visual_line_of_offset(text, offset)
    }
}

// utility function to clamp a value within the given range
fn clamp(x: usize, min: usize, max: usize) -> usize {
    if x < min {
        min
    } else if x < max {
        x
    } else {
        max
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::rpc::FindQuery;

    #[test]
    fn incremental_find_update() {
        let mut view = View::new(1.into(), BufferId::new(2));
        let mut s = String::new();
        for _ in 0..(FIND_BATCH_SIZE - 2) {
            s += "x";
        }
        s += "aaaaaa";
        for _ in 0..(FIND_BATCH_SIZE) {
            s += "x";
        }
        s += "aaaaaa";
        assert_eq!(view.find_in_progress(), false);

        let text = Rope::from(&s);
        view.do_edit(
            &text,
            ViewEvent::Find {
                chars: "aaaaaa".to_string(),
                case_sensitive: false,
                regex: false,
                whole_words: false,
            },
        );
        view.do_find(&text);
        assert_eq!(view.find_in_progress(), true);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 1);
        assert_eq!(
            view.sel_regions().first(),
            Some(&SelRegion::new(FIND_BATCH_SIZE - 2, FIND_BATCH_SIZE + 6 - 2))
        );
        view.do_find(&text);
        assert_eq!(view.find_in_progress(), true);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 2);
    }

    #[test]
    fn incremental_find_codepoint_boundary() {
        let mut view = View::new(1.into(), BufferId::new(2));
        let mut s = String::new();
        for _ in 0..(FIND_BATCH_SIZE + 2) {
            s += "£€äßß";
        }

        assert_eq!(view.find_in_progress(), false);

        let text = Rope::from(&s);
        view.do_edit(
            &text,
            ViewEvent::Find {
                chars: "a".to_string(),
                case_sensitive: false,
                regex: false,
                whole_words: false,
            },
        );
        view.do_find(&text);
        assert_eq!(view.find_in_progress(), true);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 1); // cursor
    }

    #[test]
    fn selection_for_find() {
        let mut view = View::new(1.into(), BufferId::new(2));
        let text = Rope::from("hello hello world\n");
        view.set_selection(&text, SelRegion::new(6, 11));
        view.do_edit(&text, ViewEvent::SelectionForFind { case_sensitive: false });
        view.do_find(&text);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 2);
    }

    #[test]
    fn find_next() {
        let mut view = View::new(1.into(), BufferId::new(2));
        let text = Rope::from("hello hello world\n");
        view.do_edit(
            &text,
            ViewEvent::Find {
                chars: "foo".to_string(),
                case_sensitive: false,
                regex: false,
                whole_words: false,
            },
        );
        view.do_find(&text);
        view.do_find_next(&text, false, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().len(), 1);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(0, 0))); // caret

        view.do_edit(
            &text,
            ViewEvent::Find {
                chars: "hello".to_string(),
                case_sensitive: false,
                regex: false,
                whole_words: false,
            },
        );
        view.do_find(&text);
        assert_eq!(view.sel_regions().len(), 1);
        view.do_find_next(&text, false, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(0, 5)));
        view.do_find_next(&text, false, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(6, 11)));
        view.do_find_next(&text, false, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(0, 5)));
        view.do_find_next(&text, true, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(6, 11)));

        view.do_find_next(&text, true, true, false, &SelectionModifier::Add);
        assert_eq!(view.sel_regions().len(), 2);
        view.do_find_next(&text, true, true, false, &SelectionModifier::AddRemovingCurrent);
        assert_eq!(view.sel_regions().len(), 1);
        view.do_find_next(&text, true, true, false, &SelectionModifier::None);
        assert_eq!(view.sel_regions().len(), 1);
    }

    #[test]
    fn find_all() {
        let mut view = View::new(1.into(), BufferId::new(2));
        let text = Rope::from("hello hello world\n hello!");
        view.do_edit(
            &text,
            ViewEvent::Find {
                chars: "foo".to_string(),
                case_sensitive: false,
                regex: false,
                whole_words: false,
            },
        );
        view.do_find(&text);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 1); // caret

        view.do_edit(
            &text,
            ViewEvent::Find {
                chars: "hello".to_string(),
                case_sensitive: false,
                regex: false,
                whole_words: false,
            },
        );
        view.do_find(&text);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 3);

        view.do_edit(
            &text,
            ViewEvent::Find {
                chars: "foo".to_string(),
                case_sensitive: false,
                regex: false,
                whole_words: false,
            },
        );
        view.do_find(&text);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 3);
    }

    #[test]
    fn multi_queries_find_next() {
        let mut view = View::new(1.into(), BufferId::new(2));
        let text = Rope::from("hello hello world\n hello!");
        let query1 = FindQuery {
            id: None,
            chars: "hello".to_string(),
            case_sensitive: false,
            regex: false,
            whole_words: false,
        };
        let query2 = FindQuery {
            id: None,
            chars: "o world".to_string(),
            case_sensitive: false,
            regex: false,
            whole_words: false,
        };
        view.do_edit(&text, ViewEvent::MultiFind { queries: vec![query1, query2] });
        view.do_find(&text);
        view.do_find_next(&text, false, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(0, 5)));
        view.do_find_next(&text, false, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(6, 11)));
        view.do_find_next(&text, false, true, false, &SelectionModifier::Set);
        assert_eq!(view.sel_regions().first(), Some(&SelRegion::new(10, 17)));
    }

    #[test]
    fn multi_queries_find_all() {
        let mut view = View::new(1.into(), BufferId::new(2));
        let text = Rope::from("hello hello world\n hello!");
        let query1 = FindQuery {
            id: None,
            chars: "hello".to_string(),
            case_sensitive: false,
            regex: false,
            whole_words: false,
        };
        let query2 = FindQuery {
            id: None,
            chars: "world".to_string(),
            case_sensitive: false,
            regex: false,
            whole_words: false,
        };
        view.do_edit(&text, ViewEvent::MultiFind { queries: vec![query1, query2] });
        view.do_find(&text);
        view.do_find_all(&text);
        assert_eq!(view.sel_regions().len(), 4);
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Calc start of a backspace delete interval
use xi_rope::{Cursor, Rope};

use crate::config::BufferItems;
use crate::line_offset::{LineOffset, LogicalLines};
use crate::selection::SelRegion;
use xi_unicode::*;

#[allow(clippy::cognitive_complexity)]
pub fn offset_for_delete_backwards(region: &SelRegion, text: &Rope, config: &BufferItems) -> usize {
    if !region.is_caret() {
        region.min()
    } else {
        // backspace deletes max(1, tab_size) contiguous spaces
        let (_, c) = LogicalLines.offset_to_line_col(&text, region.start);

        let tab_off = c % config.tab_size;
        let tab_size = config.tab_size;
        let tab_size = if tab_off == 0 { tab_size } else { tab_off };
        let tab_start = region.start.saturating_sub(tab_size);
        let preceded_by_spaces =
            region.start > 0 && (tab_start..region.start).all(|i| text.byte_at(i) == b' ');
        if preceded_by_spaces && config.translate_tabs_to_spaces && config.use_tab_stops {
            tab_start
        } else {
            #[derive(PartialEq)]
            enum State {
                Start,
                Lf,
                BeforeKeycap,
                BeforeVsAndKeycap,
                BeforeEmojiModifier,
                BeforeVSAndEmojiModifier,
                BeforeVS,
                BeforeEmoji,
                BeforeZwj,
                BeforeVSAndZWJ,
                OddNumberedRIS,
                EvenNumberedRIS,
                InTagSequence,
                Finished,
            };
            let mut state = State::Start;
            let mut tmp_offset = region.end;

            let mut delete_code_point_count = 0;
            let mut last_seen_vs_code_point_count = 0;

            while state != State::Finished && tmp_offset > 0 {
                let mut cursor = Cursor::new(&text, tmp_offset);
                let code_point = cursor.prev_codepoint().unwrap_or('0');

                tmp_offset = text.prev_codepoint_offset(tmp_offset).unwrap_or(0);

                match state {
                    State::Start => {
                        delete_code_point_count = 1;
                        if code_point == '\n' {
                            state = State::Lf;
                        } else if is_variation_selector(code_point) {
                            state = State::BeforeVS;
                        } else if code_point.is_regional_indicator_symbol() {
                            state = State::OddNumberedRIS;
                        } else if code_point.is_emoji_modifier() {
                            state = State::BeforeEmojiModifier;
                        } else if code_point.is_emoji_combining_enclosing_keycap() {
                            state = State::BeforeKeycap;
                        } else if code_point.is_emoji() {
                            state = State::BeforeEmoji;
                        } else if code_point.is_emoji_cancel_tag() {
                            state = State::InTagSequence;
                        } else {
                            state = State::Finished;
                        }
                    }
                    State::Lf => {
                        if code_point == '\r' {
                            delete_code_point_count += 1;
                        }
                        state = State::Finished;
                    }
                    State::OddNumberedRIS => {
                        if code_point.is_regional_indicator_symbol() {
                            delete_code_point_count += 1;
                            state = State::EvenNumberedRIS
                        } else {
                            state = State::Finished
                        }
                    }
                    State::EvenNumberedRIS => {
                        if code_point.is_regional_indicator_symbol() {
                            delete_code_point_count -= 1;
                            state = State::OddNumberedRIS;
                        } else {
                            state = State::Finished;
                        }
                    }
                    State::BeforeKeycap => {
                        if is_variation_selector(code_point) {
                            last_seen_vs_code_point_count = 1;
                            state = State::BeforeVsAndKeycap;
                        } else {
                            if is_keycap_base(code_point) {
                                delete_code_point_count += 1;
                            }
                            state = State::Finished;
                        }
                    }
                    State::BeforeVsAndKeycap => {
                        if is_keycap_base(code_point) {
                            delete_code_point_count += last_seen_vs_code_point_count + 1;
                        }
                        state = State::Finished;
                    }
                    State::BeforeEmojiModifier => {
                        if is_variation_selector(code_point) {
                            last_seen_vs_code_point_count = 1;
                            state = State::BeforeVSAndEmojiModifier;
                        } else {
                            if code_point.is_emoji_modifier_base() {
                                delete_code_point_count += 1;
                            }
                            state = State::Finished;
                        }
                    }
                    State::BeforeVSAndEmojiModifier => {
                        if code_point.is_emoji_modifier_base() {
                            delete_code_point_count += last_seen_vs_code_point_count + 1;
                        }
                        state = State::Finished;
                    }
                    State::BeforeVS => {
                        if code_point.is_emoji() {
                            delete_code_point_count += 1;
                            state = State::BeforeEmoji;
                        } else {
                            if !is_variation_selector(code_point) {
                                //TODO: UCharacter.getCombiningClass(codePoint) == 0
                                delete_code_point_count += 1;
                            }
                            state = State::Finished;
                        }
                    }
                    State::BeforeEmoji => {
                        if code_point.is_zwj() {
                            state = State::BeforeZwj;
                        } else {
                            state = State::Finished;
                        }
                    }
                    State::BeforeZwj => {
                        if code_point.is_emoji() {
                            delete_code_point_count += 2;
                            state = if code_point.is_emoji_modifier() {
                                State::BeforeEmojiModifier
                            } else {
                                State::BeforeEmoji
                            };
                        } else if is_variation_selector(code_point) {
                            last_seen_vs_code_point_count = 1;
                            state = State::BeforeVSAndZWJ;
                        } else {
                            state = State::Finished;
                        }
                    }
                    State::BeforeVSAndZWJ => {
                        if code_point.is_emoji() {
                            delete_code_point_count += last_seen_vs_code_point_count + 2;
                            last_seen_vs_code_point_count = 0;
                            state = State::BeforeEmoji;
                        } else {
                            state = State::Finished;
                        }
                    }
                    State::InTagSequence => {
                        if code_point.is_tag_spec_char() {
                            delete_code_point_count += 1;
                        } else if code_point.is_emoji() {
                            delete_code_point_count += 1;
                            state = State::Finished;
                        } else {
                            delete_code_point_count = 1;
                            state = State::Finished;
                        }
                    }
                    State::Finished => {
                        break;
                    }
                }
            }

            let mut start = region.end;
            while delete_code_point_count > 0 {
                start = text.prev_codepoint_offset(start).unwrap_or(0);
                delete_code_point_count -= 1;
            }
// Copyright 2020 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Functions for editing ropes.

use std::borrow::Cow;
use std::collections::BTreeSet;

use xi_rope::{Cursor, DeltaBuilder, Interval, LinesMetric, Rope, RopeDelta};

use crate::backspace::offset_for_delete_backwards;
use crate::config::BufferItems;
use crate::line_offset::{LineOffset, LogicalLines};
use crate::linewrap::Lines;
use crate::movement::{region_movement, Movement};
use crate::selection::{SelRegion, Selection};
use crate::word_boundaries::WordCursor;

#[derive(Debug, Copy, Clone)]
pub enum IndentDirection {
    In,
    Out,
}

/// Replaces the selection with the text `T`.
pub fn insert<T: Into<Rope>>(base: &Rope, regions: &[SelRegion], text: T) -> RopeDelta {
    let rope = text.into();
    let mut builder = DeltaBuilder::new(base.len());
    for region in regions {
        let iv = Interval::new(region.min(), region.max());
        builder.replace(iv, rope.clone());
    }

    builder.build()
}

/// Leaves the current selection untouched, but surrounds it with two insertions.
pub fn surround<BT, AT>(
    base: &Rope,
    regions: &[SelRegion],
    before_text: BT,
    after_text: AT,
) -> RopeDelta
where
    BT: Into<Rope>,
    AT: Into<Rope>,
{
    let mut builder = DeltaBuilder::new(base.len());
    let before_rope = before_text.into();
    let after_rope = after_text.into();
    for region in regions {
        let before_iv = Interval::new(region.min(), region.min());
        builder.replace(before_iv, before_rope.clone());
        let after_iv = Interval::new(region.max(), region.max());
        builder.replace(after_iv, after_rope.clone());
    }

    builder.build()
}

pub fn duplicate_line(base: &Rope, regions: &[SelRegion], config: &BufferItems) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());
    // get affected lines or regions
    let mut to_duplicate = BTreeSet::new();

    for region in regions {
        let (first_line, _) = LogicalLines.offset_to_line_col(base, region.min());
        let line_start = LogicalLines.offset_of_line(base, first_line);

        let mut cursor = match region.is_caret() {
            true => Cursor::new(base, line_start),
            false => {
                // duplicate all lines together that are part of the same selections
                let (last_line, _) = LogicalLines.offset_to_line_col(base, region.max());
                let line_end = LogicalLines.offset_of_line(base, last_line);
                Cursor::new(base, line_end)
            }
        };

        if let Some(line_end) = cursor.next::<LinesMetric>() {
            to_duplicate.insert((line_start, line_end));
        }
    }

    for (start, end) in to_duplicate {
        // insert duplicates
        let iv = Interval::new(start, start);
        builder.replace(iv, base.slice(start..end));

        // last line does not have new line character so it needs to be manually added
        if end == base.len() {
            builder.replace(iv, Rope::from(&config.line_ending))
        }
    }

    builder.build()
}

/// Used when the user presses the backspace key. If no delta is returned, then nothing changes.
pub fn delete_backward(base: &Rope, regions: &[SelRegion], config: &BufferItems) -> RopeDelta {
    // TODO: this function is workable but probably overall code complexity
    // could be improved by implementing a "backspace" movement instead.
    let mut builder = DeltaBuilder::new(base.len());
    for region in regions {
        let start = offset_for_delete_backwards(&region, base, &config);
        let iv = Interval::new(start, region.max());
        if !iv.is_empty() {
            builder.delete(iv);
        }
    }

    builder.build()
}

/// Common logic for a number of delete methods. For each region in the
/// selection, if the selection is a caret, delete the region between
/// the caret and the movement applied to the caret, otherwise delete
/// the region.
///
/// If `save` is set, the tuple will contain a rope with the deleted text.
///
/// # Arguments
///
/// * `height` - viewport height
pub(crate) fn delete_by_movement(
    base: &Rope,
    regions: &[SelRegion],
    lines: &Lines,
    movement: Movement,
    height: usize,
    save: bool,
) -> (RopeDelta, Option<Rope>) {
    // We compute deletions as a selection because the merge logic
    // is convenient. Another possibility would be to make the delta
    // builder able to handle overlapping deletions (with union semantics).
    let mut deletions = Selection::new();
    for &r in regions {
        if r.is_caret() {
            let new_region = region_movement(movement, r, lines, height, base, true);
            deletions.add_region(new_region);
        } else {
            deletions.add_region(r);
        }
    }

    let kill_ring = if save {
        let saved = extract_sel_regions(base, &deletions).unwrap_or_default();
        Some(Rope::from(saved))
    } else {
        None
    };

    (delete_sel_regions(base, &deletions), kill_ring)
}

/// Deletes the given regions.
pub(crate) fn delete_sel_regions(base: &Rope, sel_regions: &[SelRegion]) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());
    for region in sel_regions {
        let iv = Interval::new(region.min(), region.max());
        if !iv.is_empty() {
            builder.delete(iv);
        }
    }

    builder.build()
}

/// Extracts non-caret selection regions into a string,
/// joining multiple regions with newlines.
pub(crate) fn extract_sel_regions<'a>(
    base: &'a Rope,
    sel_regions: &[SelRegion],
) -> Option<Cow<'a, str>> {
    let mut saved = None;
    for region in sel_regions {
        if !region.is_caret() {
            let val = base.slice_to_cow(region);
            match saved {
                None => saved = Some(val),
                Some(ref mut s) => {
                    s.to_mut().push('\n');
                    s.to_mut().push_str(&val);
                }
            }
        }
    }
    saved
}

pub fn insert_newline(base: &Rope, regions: &[SelRegion], config: &BufferItems) -> RopeDelta {
    insert(base, regions, &config.line_ending)
}

pub fn insert_tab(base: &Rope, regions: &[SelRegion], config: &BufferItems) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());
    let const_tab_text = get_tab_text(config, None);

    for region in regions {
        let line_range = LogicalLines.get_line_range(base, region);

        if line_range.len() > 1 {
            for line in line_range {
                let offset = LogicalLines.line_col_to_offset(base, line, 0);
                let iv = Interval::new(offset, offset);
                builder.replace(iv, Rope::from(const_tab_text));
            }
        } else {
            let (_, col) = LogicalLines.offset_to_line_col(base, region.start);
            let mut tab_size = config.tab_size;
            tab_size = tab_size - (col % tab_size);
            let tab_text = get_tab_text(config, Some(tab_size));

            let iv = Interval::new(region.min(), region.max());
            builder.replace(iv, Rope::from(tab_text));
        }
    }

    builder.build()
}

/// Indents or outdents lines based on selection and user's tab settings.
/// Uses a BTreeSet to holds the collection of lines to modify.
/// Preserves cursor position and current selection as much as possible.
/// Tries to have behavior consistent with other editors like Atom,
/// Sublime and VSCode, with non-caret selections not being modified.
pub fn modify_indent(
    base: &Rope,
    regions: &[SelRegion],
    config: &BufferItems,
    direction: IndentDirection,
) -> RopeDelta {
    let mut lines = BTreeSet::new();
    let tab_text = get_tab_text(config, None);
    for region in regions {
        let line_range = LogicalLines.get_line_range(base, region);
        for line in line_range {
            lines.insert(line);
        }
    }
    match direction {
        IndentDirection::In => indent(base, lines, tab_text),
        IndentDirection::Out => outdent(base, lines, tab_text),
    }
}

fn indent(base: &Rope, lines: BTreeSet<usize>, tab_text: &str) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());
    for line in lines {
        let offset = LogicalLines.line_col_to_offset(base, line, 0);
        let interval = Interval::new(offset, offset);
        builder.replace(interval, Rope::from(tab_text));
    }
    builder.build()
}

fn outdent(base: &Rope, lines: BTreeSet<usize>, tab_text: &str) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());
    for line in lines {
        let offset = LogicalLines.line_col_to_offset(base, line, 0);
        let tab_offset = LogicalLines.line_col_to_offset(base, line, tab_text.len());
        let interval = Interval::new(offset, tab_offset);
        let leading_slice = base.slice_to_cow(interval.start()..interval.end());
        if leading_slice == tab_text {
            builder.delete(interval);
        } else if let Some(first_char_col) = leading_slice.find(|c: char| !c.is_whitespace()) {
            let first_char_offset = LogicalLines.line_col_to_offset(base, line, first_char_col);
            let interval = Interval::new(offset, first_char_offset);
            builder.delete(interval);
        }
    }
    builder.build()
}

pub fn transpose(base: &Rope, regions: &[SelRegion]) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());
    let mut last = 0;
    let mut optional_previous_selection: Option<(Interval, Rope)> =
        last_selection_region(regions).map(|&region| sel_region_to_interval_and_rope(base, region));

    for &region in regions {
        if region.is_caret() {
            let mut middle = region.end;
            let mut start = base.prev_grapheme_offset(middle).unwrap_or(0);
            let mut end = base.next_grapheme_offset(middle).unwrap_or(middle);

            // Note: this matches Emac's behavior. It swaps last
            // two characters of line if at end of line.
            if start >= last {
                let end_line_offset =
                    LogicalLines.offset_of_line(base, LogicalLines.line_of_offset(base, end));
                // include end != base.len() because if the editor is entirely empty, we dont' want to pull from empty space
                if (end == middle || end == end_line_offset) && end != base.len() {
                    middle = start;
                    start = base.prev_grapheme_offset(middle).unwrap_or(0);
                    end = middle.wrapping_add(1);
                }

                let interval = Interval::new(start, end);
                let before = base.slice_to_cow(start..middle);
                let after = base.slice_to_cow(middle..end);
                let swapped: String = [after, before].concat();
                builder.replace(interval, Rope::from(swapped));
                last = end;
            }
        } else if let Some(previous_selection) = optional_previous_selection {
            let current_interval = sel_region_to_interval_and_rope(base, region);
            builder.replace(current_interval.0, previous_selection.1);
            optional_previous_selection = Some(current_interval);
        }
    }

    builder.build()
}

pub fn transform_text<F: Fn(&str) -> String>(
    base: &Rope,
    regions: &[SelRegion],
    transform_function: F,
) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());

    for region in regions {
        let selected_text = base.slice_to_cow(region);
        let interval = Interval::new(region.min(), region.max());
        builder.replace(interval, Rope::from(transform_function(&selected_text)));
    }

    builder.build()
}

/// Changes the number(s) under the cursor(s) with the `transform_function`.
/// If there is a number next to or on the beginning of the region, then
/// this number will be replaced with the result of `transform_function` and
/// the cursor will be placed at the end of the number.
/// Some Examples with a increment `transform_function`:
///
/// "|1234" -> "1235|"
/// "12|34" -> "1235|"
/// "-|12" -> "-11|"
/// "another number is 123|]" -> "another number is 124"
///
/// This function also works fine with multiple regions.
pub fn change_number<F: Fn(i128) -> Option<i128>>(
    base: &Rope,
    regions: &[SelRegion],
    transform_function: F,
) -> RopeDelta {
    let mut builder = DeltaBuilder::new(base.len());
    for region in regions {
        let mut cursor = WordCursor::new(base, region.end);
        let (mut start, end) = cursor.select_word();

        // if the word begins with '-', then it is a negative number
        if start > 0 && base.byte_at(start - 1) == (b'-') {
            start -= 1;
        }

        let word = base.slice_to_cow(start..end);
        if let Some(number) = word.parse::<i128>().ok().and_then(&transform_function) {
            let interval = Interval::new(start, end);
            builder.replace(interval, Rope::from(number.to_string()));
        }
    }

    builder.build()
}

// capitalization behaviour is similar to behaviour in XCode
pub fn capitalize_text(base: &Rope, regions: &[SelRegion]) -> (RopeDelta, Selection) {
    let mut builder = DeltaBuilder::new(base.len());
    let mut final_selection = Selection::new();

    for &region in regions {
        final_selection.add_region(SelRegion::new(region.max(), region.max()));
        let mut word_cursor = WordCursor::new(base, region.min());

        loop {
            // capitalize each word in the current selection
            let (start, end) = word_cursor.select_word();

            if start < end {
                let interval = Interval::new(start, end);
                let word = base.slice_to_cow(start..end);

                // first letter is uppercase, remaining letters are lowercase
                let (first_char, rest) = word.split_at(1);
                let capitalized_text = [first_char.to_uppercase(), rest.to_lowercase()].concat();
                builder.replace(interval, Rope::from(capitalized_text));
            }

            if word_cursor.next_boundary().is_none() || end > region.max() {
                break;
            }
        }
    }

    (builder.build(), final_selection)
}

fn sel_region_to_interval_and_rope(base: &Rope, region: SelRegion) -> (Interval, Rope) {
    let as_interval = Interval::new(region.min(), region.max());
    let interval_rope = base.subseq(as_interval);
    (as_interval, interval_rope)
}

fn last_selection_region(regions: &[SelRegion]) -> Option<&SelRegion> {
    for region in regions.iter().rev() {
        if !region.is_caret() {
            return Some(region);
        }
    }
    None
}

fn get_tab_text(config: &BufferItems, tab_size: Option<usize>) -> &'static str {
    let tab_size = tab_size.unwrap_or(config.tab_size);
    let tab_text = if config.translate_tabs_to_spaces { n_spaces(tab_size) } else { "\t" };

    tab_text
}

fn n_spaces(n: usize) -> &'static str {
    let spaces = "                                ";
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! The main container for core state.
//!
//! All events from the frontend or from plugins are handled here first.
//!
//! This file is called 'tabs' for historical reasons, and should probably
//! be renamed.

use std::cell::{Cell, RefCell};
use std::collections::{BTreeMap, HashSet};
use std::fmt;
use std::fs::File;
use std::io;
use std::mem;
use std::path::{Path, PathBuf};

use serde::de::{self, Deserialize, Deserializer, Unexpected};
use serde::ser::{Serialize, Serializer};
use serde_json::Value;

use xi_rope::Rope;
use xi_rpc::{self, ReadError, RemoteError, RpcCtx, RpcPeer};
use xi_trace::{self, trace_block};

use crate::client::Client;
use crate::config::{self, ConfigDomain, ConfigDomainExternal, ConfigManager, Table};
use crate::editor::Editor;
use crate::event_context::EventContext;
use crate::file::FileManager;
use crate::line_ending::LineEnding;
use crate::plugin_rpc::{PluginNotification, PluginRequest};
use crate::plugins::rpc::ClientPluginInfo;
use crate::plugins::{start_plugin_process, Plugin, PluginCatalog, PluginPid};
use crate::recorder::Recorder;
use crate::rpc::{
    CoreNotification, CoreRequest, EditNotification, EditRequest,
    PluginNotification as CorePluginNotification,
};
use crate::styles::{ThemeStyleMap, DEFAULT_THEME};
use crate::syntax::LanguageId;
use crate::view::View;
use crate::whitespace::Indentation;
use crate::width_cache::WidthCache;
use crate::WeakXiCore;

#[cfg(feature = "notify")]
use crate::watcher::{FileWatcher, WatchToken};
#[cfg(feature = "notify")]
use notify::Event;
#[cfg(feature = "notify")]
use std::ffi::OsStr;

/// ViewIds are the primary means of routing messages between
/// xi-core and a client view.
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct ViewId(pub(crate) usize);

/// BufferIds uniquely identify open buffers.
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize, Hash)]
pub struct BufferId(pub(crate) usize);

pub type PluginId = crate::plugins::PluginPid;

// old-style names; will be deprecated
pub type BufferIdentifier = BufferId;

/// Totally arbitrary; we reserve this space for `ViewId`s
pub(crate) const RENDER_VIEW_IDLE_MASK: usize = 1 << 25;
pub(crate) const REWRAP_VIEW_IDLE_MASK: usize = 1 << 26;
pub(crate) const FIND_VIEW_IDLE_MASK: usize = 1 << 27;

const NEW_VIEW_IDLE_TOKEN: usize = 1001;

/// xi_rpc idle Token for watcher related idle scheduling.
pub(crate) const WATCH_IDLE_TOKEN: usize = 1002;

#[cfg(feature = "notify")]
const CONFIG_EVENT_TOKEN: WatchToken = WatchToken(1);

/// Token for file-change events in open files
#[cfg(feature = "notify")]
pub const OPEN_FILE_EVENT_TOKEN: WatchToken = WatchToken(2);

#[cfg(feature = "notify")]
const THEME_FILE_EVENT_TOKEN: WatchToken = WatchToken(3);

#[cfg(feature = "notify")]
const PLUGIN_EVENT_TOKEN: WatchToken = WatchToken(4);

#[allow(dead_code)]
pub struct CoreState {
    editors: BTreeMap<BufferId, RefCell<Editor>>,
    views: BTreeMap<ViewId, RefCell<View>>,
    file_manager: FileManager,
    /// A local pasteboard.
    kill_ring: RefCell<Rope>,
    /// Theme and style state.
    style_map: RefCell<ThemeStyleMap>,
    width_cache: RefCell<WidthCache>,
    /// User and platform specific settings
    config_manager: ConfigManager,
    /// Recorded editor actions
    recorder: RefCell<Recorder>,
    /// A weak reference to the main state container, stashed so that
    /// it can be passed to plugins.
    self_ref: Option<WeakXiCore>,
    /// Views which need to have setup finished.
    pending_views: Vec<(ViewId, Table)>,
    peer: Client,
    id_counter: Counter,
    plugins: PluginCatalog,
    // for the time being we auto-start all plugins we find on launch.
    running_plugins: Vec<Plugin>,
}

/// Initial setup and bookkeeping
impl CoreState {
    pub(crate) fn new(
        peer: &RpcPeer,
        config_dir: Option<PathBuf>,
        extras_dir: Option<PathBuf>,
    ) -> Self {
        #[cfg(feature = "notify")]
        let mut watcher = FileWatcher::new(peer.clone());

        if let Some(p) = config_dir.as_ref() {
            if !p.exists() {
                if let Err(e) = config::init_config_dir(p) {
                    //TODO: report this error?
                    error!("error initing file based configs: {:?}", e);
                }
            }

            #[cfg(feature = "notify")]
            watcher.watch_filtered(p, true, CONFIG_EVENT_TOKEN, |p| {
                p.extension().and_then(OsStr::to_str).unwrap_or("") == "xiconfig"
            });
        }

        let config_manager = ConfigManager::new(config_dir, extras_dir);

        let themes_dir = config_manager.get_themes_dir();
        if let Some(p) = themes_dir.as_ref() {
            #[cfg(feature = "notify")]
            watcher.watch_filtered(p, true, THEME_FILE_EVENT_TOKEN, |p| {
                p.extension().and_then(OsStr::to_str).unwrap_or("") == "tmTheme"
            });
        }

        let plugins_dir = config_manager.get_plugins_dir();
        if let Some(p) = plugins_dir.as_ref() {
            #[cfg(feature = "notify")]
            watcher.watch_filtered(p, true, PLUGIN_EVENT_TOKEN, |p| p.is_dir() || !p.exists());
        }

        CoreState {
            views: BTreeMap::new(),
            editors: BTreeMap::new(),
            #[cfg(feature = "notify")]
            file_manager: FileManager::new(watcher),
            #[cfg(not(feature = "notify"))]
            file_manager: FileManager::new(),
            kill_ring: RefCell::new(Rope::from("")),
            style_map: RefCell::new(ThemeStyleMap::new(themes_dir)),
            width_cache: RefCell::new(WidthCache::new()),
            config_manager,
            recorder: RefCell::new(Recorder::new()),
            self_ref: None,
            pending_views: Vec::new(),
            peer: Client::new(peer.clone()),
            id_counter: Counter::default(),
            plugins: PluginCatalog::default(),
            running_plugins: Vec::new(),
        }
    }

    fn next_view_id(&self) -> ViewId {
        ViewId(self.id_counter.next())
    }

    fn next_buffer_id(&self) -> BufferId {
        BufferId(self.id_counter.next())
    }

    fn next_plugin_id(&self) -> PluginId {
        PluginPid(self.id_counter.next())
    }

    pub(crate) fn finish_setup(&mut self, self_ref: WeakXiCore) {
        self.self_ref = Some(self_ref);

        if let Some(path) = self.config_manager.base_config_file_path() {
            self.load_file_based_config(&path);
        }

        // Load the custom theme files.
        self.style_map.borrow_mut().load_theme_dir();

        // instead of having to do this here, config should just own
        // the plugin catalog and reload automatically
        let plugin_paths = self.config_manager.get_plugin_paths();
        self.plugins.reload_from_paths(&plugin_paths);
        let languages = self.plugins.make_languages_map();
        let languages_ids = languages.iter().map(|l| l.name.clone()).collect::<Vec<_>>();
        self.peer.available_languages(languages_ids);
        self.config_manager.set_languages(languages);
        let theme_names = self.style_map.borrow().get_theme_names();
        self.peer.available_themes(theme_names);

        // FIXME: temporary: we just launch every plugin we find at startup
        for manifest in self.plugins.iter() {
            start_plugin_process(
                manifest.clone(),
                self.next_plugin_id(),
                self.self_ref.as_ref().unwrap().clone(),
            );
        }
    }

    /// Attempt to load a config file.
    fn load_file_based_config(&mut self, path: &Path) {
        let _t = trace_block("CoreState::load_config_file", &["core"]);
        if let Some(domain) = self.config_manager.domain_for_path(path) {
            match config::try_load_from_file(&path) {
                Ok(table) => self.set_config(domain, table),
                Err(e) => self.peer.alert(e.to_string()),
            }
        } else {
            self.peer.alert(format!("Unexpected config file {:?}", path));
        }
    }

    /// Sets (overwriting) the config for a given domain.
    fn set_config(&mut self, domain: ConfigDomain, table: Table) {
        match self.config_manager.set_user_config(domain, table) {
            Err(e) => self.peer.alert(format!("{}", &e)),
            Ok(changes) => self.handle_config_changes(changes),
        }
    }

    /// Notify editors/views/plugins of config changes.
    fn handle_config_changes(&self, changes: Vec<(BufferId, Table)>) {
        for (id, table) in changes {
            let view_id = self
                .views
                .values()
                .find(|v| v.borrow().get_buffer_id() == id)
                .map(|v| v.borrow().get_view_id())
                .unwrap();

            self.make_context(view_id).unwrap().config_changed(&table)
        }
    }
}

/// Handling client events
impl CoreState {
    /// Creates an `EventContext` for the provided `ViewId`. This context
    /// holds references to the `Editor` and `View` backing this `ViewId`,
    /// as well as to sibling views, plugins, and other state necessary
    /// for handling most events.
    pub(crate) fn make_context(&self, view_id: ViewId) -> Option<EventContext> {
        self.views.get(&view_id).map(|view| {
            let buffer_id = view.borrow().get_buffer_id();

            let editor = &self.editors[&buffer_id];
            let info = self.file_manager.get_info(buffer_id);
            let plugins = self.running_plugins.iter().collect::<Vec<_>>();
            let config = self.config_manager.get_buffer_config(buffer_id);
            let language = self.config_manager.get_buffer_language(buffer_id);

            EventContext {
                view_id,
                buffer_id,
                view,
                editor,
                config: &config.items,
                recorder: &self.recorder,
                language,
                info,
                siblings: Vec::new(),
                plugins,
                client: &self.peer,
                style_map: &self.style_map,
                width_cache: &self.width_cache,
                kill_ring: &self.kill_ring,
                weak_core: self.self_ref.as_ref().unwrap(),
            }
        })
    }

    /// Produces an iterator over all event contexts, with each view appearing
    /// exactly once.
    fn iter_groups<'a>(&'a self) -> Iter<'a, Box<dyn Iterator<Item = &ViewId> + 'a>> {
        Iter { views: Box::new(self.views.keys()), seen: HashSet::new(), inner: self }
    }

    pub(crate) fn client_notification(&mut self, cmd: CoreNotification) {
        use self::CoreNotification::*;
        use self::CorePluginNotification as PN;
        match cmd {
            Edit(crate::rpc::EditCommand { view_id, cmd }) => self.do_edit(view_id, cmd),
            Save { view_id, file_path } => self.do_save(view_id, file_path),
            CloseView { view_id } => self.do_close_view(view_id),
            ModifyUserConfig { domain, changes } => self.do_modify_user_config(domain, changes),
            SetTheme { theme_name } => self.do_set_theme(&theme_name),
            SaveTrace { destination, frontend_samples } => {
                self.save_trace(&destination, frontend_samples)
            }
            Plugin(cmd) => match cmd {
                PN::Start { view_id, plugin_name } => self.do_start_plugin(view_id, &plugin_name),
                PN::Stop { view_id, plugin_name } => self.do_stop_plugin(view_id, &plugin_name),
                PN::PluginRpc { view_id, receiver, rpc } => {
                    self.do_plugin_rpc(view_id, &receiver, &rpc.method, &rpc.params)
                }
            },
            TracingConfig { enabled } => self.toggle_tracing(enabled),
            // handled at the top level
            ClientStarted { .. } => (),
            SetLanguage { view_id, language_id } => self.do_set_language(view_id, language_id),
        }
    }

    pub(crate) fn client_request(&mut self, cmd: CoreRequest) -> Result<Value, RemoteError> {
        use self::CoreRequest::*;
        match cmd {
            //TODO: make file_path be an Option<PathBuf>
            //TODO: make this a notification
            NewView { file_path } => self.do_new_view(file_path.map(PathBuf::from)),
            Edit(crate::rpc::EditCommand { view_id, cmd }) => self.do_edit_sync(view_id, cmd),
            //TODO: why is this a request?? make a notification?
            GetConfig { view_id } => self.do_get_config(view_id).map(|c| json!(c)),
            DebugGetContents { view_id } => self.do_get_contents(view_id).map(|c| json!(c)),
        }
    }

    fn do_edit(&mut self, view_id: ViewId, cmd: EditNotification) {
        if let Some(mut edit_ctx) = self.make_context(view_id) {
            edit_ctx.do_edit(cmd);
        }
    }

    fn do_edit_sync(&mut self, view_id: ViewId, cmd: EditRequest) -> Result<Value, RemoteError> {
        if let Some(mut edit_ctx) = self.make_context(view_id) {
            edit_ctx.do_edit_sync(cmd)
        } else {
            // TODO: some custom error tpye that can Into<RemoteError>
            Err(RemoteError::custom(404, format!("missing view {:?}", view_id), None))
        }
    }

    fn do_new_view(&mut self, path: Option<PathBuf>) -> Result<Value, RemoteError> {
        let view_id = self.next_view_id();
        let buffer_id = self.next_buffer_id();

        let rope = match path.as_ref() {
            Some(p) => self.file_manager.open(p, buffer_id)?,
            None => Rope::from(""),
        };

        let editor = RefCell::new(Editor::with_text(rope));
        let view = RefCell::new(View::new(view_id, buffer_id));

        self.editors.insert(buffer_id, editor);
        self.views.insert(view_id, view);

        let config = self.config_manager.add_buffer(buffer_id, path.as_deref());

        // NOTE: because this is a synchronous call, we have to initialize the
        // view and return the view_id before we can send any events to this
        // view. We call view_init(), mark the view as pending and schedule the
        // idle handler so that we can finish setting up this view on the next
        // runloop pass, in finalize_new_views.

        let mut edit_ctx = self.make_context(view_id).unwrap();
        edit_ctx.view_init();

        self.pending_views.push((view_id, config));
        self.peer.schedule_idle(NEW_VIEW_IDLE_TOKEN);

        Ok(json!(view_id))
    }

    fn do_save<P>(&mut self, view_id: ViewId, path: P)
    where
        P: AsRef<Path>,
    {
        let _t = trace_block("CoreState::do_save", &["core"]);
        let path = path.as_ref();
        let buffer_id = self.views.get(&view_id).map(|v| v.borrow().get_buffer_id());
        let buffer_id = match buffer_id {
            Some(id) => id,
            None => return,
        };

        let mut save_ctx = self.make_context(view_id).unwrap();
        let fin_text = save_ctx.text_for_save();

        if let Err(e) = self.file_manager.save(path, &fin_text, buffer_id) {
            let error_message = e.to_string();
            error!("File error: {:?}", error_message);
            self.peer.alert(error_message);
            return;
        }

        let changes = self.config_manager.update_buffer_path(buffer_id, path);
        let language = self.config_manager.get_buffer_language(buffer_id);

        self.make_context(view_id).unwrap().after_save(path);
        self.make_context(view_id).unwrap().language_changed(&language);

        // update the config _after_ sending save related events
        if let Some(changes) = changes {
            self.make_context(view_id).unwrap().config_changed(&changes);
        }
    }

    fn do_close_view(&mut self, view_id: ViewId) {
        let close_buffer = self.make_context(view_id).map(|ctx| ctx.close_view()).unwrap_or(true);

        let buffer_id = self.views.remove(&view_id).map(|v| v.borrow().get_buffer_id());

        if let Some(buffer_id) = buffer_id {
            if close_buffer {
                self.editors.remove(&buffer_id);
                self.file_manager.close(buffer_id);
                self.config_manager.remove_buffer(buffer_id);
            }
        }
    }

    fn do_set_theme(&self, theme_name: &str) {
        //Set only if requested theme is different from the
        //current one.
        if theme_name != self.style_map.borrow().get_theme_name() {
            if let Err(e) = self.style_map.borrow_mut().set_theme(&theme_name) {
                error!("error setting theme: {:?}, {:?}", theme_name, e);
                return;
            }
        }
        self.notify_client_and_update_views();
    }

    fn notify_client_and_update_views(&self) {
        {
            let style_map = self.style_map.borrow();
            self.peer.theme_changed(style_map.get_theme_name(), style_map.get_theme_settings());
        }

        self.iter_groups().for_each(|mut edit_ctx| {
            edit_ctx.with_editor(|ed, view, _, _| {
                ed.theme_changed(&self.style_map.borrow());
                view.set_dirty(ed.get_buffer());
            });
            edit_ctx.render_if_needed();
        });
    }

    /// Updates the config for a given domain.
    fn do_modify_user_config(&mut self, domain: ConfigDomainExternal, changes: Table) {
        // the client sends ViewId but we need BufferId so we do a dance
        let domain: ConfigDomain = match domain {
            ConfigDomainExternal::General => ConfigDomain::General,
            ConfigDomainExternal::Syntax(id) => ConfigDomain::Language(id),
            ConfigDomainExternal::Language(id) => ConfigDomain::Language(id),
            ConfigDomainExternal::UserOverride(view_id) => match self.views.get(&view_id) {
                Some(v) => ConfigDomain::UserOverride(v.borrow().get_buffer_id()),
                None => return,
            },
        };
        let new_config = self.config_manager.table_for_update(domain.clone(), changes);
        self.set_config(domain, new_config);
    }

    fn do_get_config(&self, view_id: ViewId) -> Result<Table, RemoteError> {
        let _t = trace_block("CoreState::get_config", &["core"]);
        self.views
            .get(&view_id)
            .map(|v| v.borrow().get_buffer_id())
            .map(|id| self.config_manager.get_buffer_config(id).to_table())
            .ok_or(RemoteError::custom(404, format!("missing {}", view_id), None))
    }

    fn do_get_contents(&self, view_id: ViewId) -> Result<Rope, RemoteError> {
        self.make_context(view_id)
            .map(|ctx| ctx.editor.borrow().get_buffer().to_owned())
            .ok_or_else(|| RemoteError::custom(404, format!("No view for id {}", view_id), None))
    }

    fn do_set_language(&mut self, view_id: ViewId, language_id: LanguageId) {
        if let Some(view) = self.views.get(&view_id) {
            let buffer_id = view.borrow().get_buffer_id();
            let changes = self.config_manager.override_language(buffer_id, language_id.clone());

            let mut context = self.make_context(view_id).unwrap();
            context.language_changed(&language_id);
            if let Some(changes) = changes {
                context.config_changed(&changes);
            }
        }
    }

    fn do_start_plugin(&mut self, _view_id: ViewId, plugin: &str) {
        if self.running_plugins.iter().any(|p| p.name == plugin) {
            info!("plugin {} already running", plugin);
            return;
        }

        if let Some(manifest) = self.plugins.get_named(plugin) {
            //TODO: lots of races possible here, we need to keep track of
            //pending launches.
            start_plugin_process(
                manifest,
                self.next_plugin_id(),
                self.self_ref.as_ref().unwrap().clone(),
            );
        } else {
            warn!("no plugin found with name '{}'", plugin);
        }
    }

    fn do_stop_plugin(&mut self, _view_id: ViewId, plugin: &str) {
        if let Some(p) = self
            .running_plugins
            .iter()
            .position(|p| p.name == plugin)
            .map(|ix| self.running_plugins.remove(ix))
        {
            //TODO: verify shutdown; kill if necessary
            p.shutdown();
            self.after_stop_plugin(&p);
        }
    }

    fn do_plugin_rpc(&self, view_id: ViewId, receiver: &str, method: &str, params: &Value) {
        self.running_plugins
            .iter()
            .filter(|p| p.name == receiver)
            .for_each(|p| p.dispatch_command(view_id, method, params))
    }

    fn after_stop_plugin(&mut self, plugin: &Plugin) {
        self.iter_groups().for_each(|mut cx| cx.plugin_stopped(plugin));
    }
}

/// Idle, tracing, and file event handling
impl CoreState {
    pub(crate) fn handle_idle(&mut self, token: usize) {
        match token {
            NEW_VIEW_IDLE_TOKEN => self.finalize_new_views(),
            WATCH_IDLE_TOKEN => self.handle_fs_events(),
            other if (other & RENDER_VIEW_IDLE_MASK) != 0 => {
                self.handle_render_timer(other ^ RENDER_VIEW_IDLE_MASK)
            }
            other if (other & REWRAP_VIEW_IDLE_MASK) != 0 => {
                self.handle_rewrap_callback(other ^ REWRAP_VIEW_IDLE_MASK)
            }
            other if (other & FIND_VIEW_IDLE_MASK) != 0 => {
                self.handle_find_callback(other ^ FIND_VIEW_IDLE_MASK)
            }
            other => panic!("unexpected idle token {}", other),
        };
    }

    fn finalize_new_views(&mut self) {
        let to_start = mem::replace(&mut self.pending_views, Vec::new());

        to_start.iter().for_each(|(id, config)| {
            let modified = self.detect_whitespace(*id, config);
            let config = modified.as_ref().unwrap_or(config);
            let mut edit_ctx = self.make_context(*id).unwrap();
            edit_ctx.finish_init(&config);
        });
    }

    // Detects whitespace settings from the file and merges them with the config
    fn detect_whitespace(&mut self, id: ViewId, config: &Table) -> Option<Table> {
        let buffer_id = self.views.get(&id).map(|v| v.borrow().get_buffer_id())?;
        let editor = self
            .editors
            .get(&buffer_id)
            .expect("existing buffer_id must have corresponding editor");

        if editor.borrow().get_buffer().is_empty() {
            return None;
        }

        let autodetect_whitespace =
            self.config_manager.get_buffer_config(buffer_id).items.autodetect_whitespace;
        if !autodetect_whitespace {
            return None;
        }

        let mut changes = Table::new();
        let indentation = Indentation::parse(editor.borrow().get_buffer());
        match indentation {
            Ok(Some(Indentation::Tabs)) => {
                changes.insert("translate_tabs_to_spaces".into(), false.into());
            }
            Ok(Some(Indentation::Spaces(n))) => {
                changes.insert("translate_tabs_to_spaces".into(), true.into());
                changes.insert("tab_size".into(), n.into());
            }
            Err(_) => info!("detected mixed indentation"),
            Ok(None) => info!("file contains no indentation"),
        }

        let line_ending = LineEnding::parse(editor.borrow().get_buffer());
        match line_ending {
            Ok(Some(LineEnding::CrLf)) => {
                changes.insert("line_ending".into(), "\r\n".into());
            }
            Ok(Some(LineEnding::Lf)) => {
                changes.insert("line_ending".into(), "\n".into());
            }
            Err(_) => info!("detected mixed line endings"),
            Ok(None) => info!("file contains no supported line endings"),
        }

        let config_delta =
            self.config_manager.table_for_update(ConfigDomain::SysOverride(buffer_id), changes);
        match self
            .config_manager
            .set_user_config(ConfigDomain::SysOverride(buffer_id), config_delta)
        {
            Ok(ref mut items) if !items.is_empty() => {
                assert!(
                    items.len() == 1,
                    "whitespace overrides can only update a single buffer's config\n{:?}",
                    items
                );
                let table = items.remove(0).1;
                let mut config = config.clone();
                config.extend(table);
                Some(config)
            }
            Ok(_) => {
                warn!("set_user_config failed to update config, no tables were returned");
                None
            }
            Err(err) => {
                warn!("detect_whitespace failed to update config: {:?}", err);
                None
            }
        }
    }

    fn handle_render_timer(&mut self, token: usize) {
        let id: ViewId = token.into();
        if let Some(mut ctx) = self.make_context(id) {
            ctx._finish_delayed_render();
        }
    }

    /// Callback for doing word wrap on a view
    fn handle_rewrap_callback(&mut self, token: usize) {
        let id: ViewId = token.into();
        if let Some(mut ctx) = self.make_context(id) {
            ctx.do_rewrap_batch();
        }
    }

    /// Callback for doing incremental find in a view
    fn handle_find_callback(&mut self, token: usize) {
        let id: ViewId = token.into();
        if let Some(mut ctx) = self.make_context(id) {
            ctx.do_incremental_find();
        }
    }

    #[cfg(feature = "notify")]
    fn handle_fs_events(&mut self) {
        let _t = trace_block("CoreState::handle_fs_events", &["core"]);
        let mut events = self.file_manager.watcher().take_events();

        for (token, event) in events.drain(..) {
            match token {
                OPEN_FILE_EVENT_TOKEN => self.handle_open_file_fs_event(event),
                CONFIG_EVENT_TOKEN => self.handle_config_fs_event(event),
                THEME_FILE_EVENT_TOKEN => self.handle_themes_fs_event(event),
                PLUGIN_EVENT_TOKEN => self.handle_plugin_fs_event(event),
                _ => warn!("unexpected fs event token {:?}", token),
            }
        }
    }

    #[cfg(not(feature = "notify"))]
    fn handle_fs_events(&mut self) {}

    /// Handles a file system event related to a currently open file
    #[cfg(feature = "notify")]
    fn handle_open_file_fs_event(&mut self, event: Event) {
        use notify::event::*;
        let path = match event.kind {
            EventKind::Create(CreateKind::Any)
            | EventKind::Modify(ModifyKind::Metadata(MetadataKind::Any))
            | EventKind::Modify(ModifyKind::Any) => &event.paths[0],
            other => {
                debug!("Ignoring event in open file {:?}", other);
                return;
            }
        };

        let buffer_id = match self.file_manager.get_editor(path) {
            Some(id) => id,
            None => return,
        };

        let has_changes = self.file_manager.check_file(path, buffer_id);
        let is_pristine = self.editors.get(&buffer_id).map(|ed| ed.borrow().is_pristine()).unwrap();
        //TODO: currently we only use the file's modification time when
        // determining if a file has been changed by another process.
        // A more robust solution would also hash the file's contents.

        if has_changes && is_pristine {
            if let Ok(text) = self.file_manager.open(path, buffer_id) {
                // this is ugly; we don't map buffer_id -> view_id anywhere
                // but we know we must have a view.
                let view_id = self
                    .views
                    .values()
                    .find(|v| v.borrow().get_buffer_id() == buffer_id)
                    .map(|v| v.borrow().get_view_id())
                    .unwrap();
                self.make_context(view_id).unwrap().reload(text);
            }
        }
    }

    /// Handles a config related file system event.
    #[cfg(feature = "notify")]
    fn handle_config_fs_event(&mut self, event: Event) {
        use notify::event::*;
        match event.kind {
            EventKind::Create(CreateKind::Any)
            | EventKind::Modify(ModifyKind::Any)
            | EventKind::Modify(ModifyKind::Metadata(MetadataKind::Any)) => {
                self.load_file_based_config(&event.paths[0])
            }
            EventKind::Remove(RemoveKind::Any) if !event.paths[0].exists() => {
                self.remove_config_at_path(&event.paths[0])
            }
            EventKind::Modify(ModifyKind::Name(RenameMode::Both)) => {
                self.remove_config_at_path(&event.paths[0]);
                self.load_file_based_config(&event.paths[1]);
            }
            _ => (),
        }
    }

    fn remove_config_at_path(&mut self, path: &Path) {
        if let Some(domain) = self.config_manager.domain_for_path(path) {
            self.set_config(domain, Table::default());
        }
    }

    /// Handles changes in plugin files.
    #[cfg(feature = "notify")]
    fn handle_plugin_fs_event(&mut self, event: Event) {
        use notify::event::*;
        match event.kind {
            EventKind::Create(CreateKind::Any) | EventKind::Modify(ModifyKind::Any) => {
                self.plugins.load_from_paths(&[event.paths[0].clone()]);
                if let Some(plugin) = self.plugins.get_from_path(&event.paths[0]) {
                    self.do_start_plugin(ViewId(0), &plugin.name);
                }
            }
            // the way FSEvents on macOS work, we want to verify that this path
            // has actually be removed before we do anything.
            EventKind::Remove(RemoveKind::Any) if !event.paths[0].exists() => {
                if let Some(plugin) = self.plugins.get_from_path(&event.paths[0]) {
                    self.do_stop_plugin(ViewId(0), &plugin.name);
                    self.plugins.remove_named(&plugin.name);
                }
            }
            EventKind::Modify(ModifyKind::Name(RenameMode::Both)) => {
                let old = &event.paths[0];
                let new = &event.paths[1];
                if let Some(old_plugin) = self.plugins.get_from_path(old) {
                    self.do_stop_plugin(ViewId(0), &old_plugin.name);
                    self.plugins.remove_named(&old_plugin.name);
                }

                self.plugins.load_from_paths(&[new.clone()]);
                if let Some(new_plugin) = self.plugins.get_from_path(new) {
                    self.do_start_plugin(ViewId(0), &new_plugin.name);
                }
            }
            EventKind::Modify(ModifyKind::Metadata(MetadataKind::Any))
            | EventKind::Remove(RemoveKind::Any) => {
                if let Some(plugin) = self.plugins.get_from_path(&event.paths[0]) {
                    self.do_stop_plugin(ViewId(0), &plugin.name);
                    self.do_start_plugin(ViewId(0), &plugin.name);
                }
            }
            _ => (),
        }

        self.views.keys().for_each(|view_id| {
            let available_plugins = self
                .plugins
                .iter()
                .map(|plugin| ClientPluginInfo { name: plugin.name.clone(), running: true })
                .collect::<Vec<_>>();
            self.peer.available_plugins(*view_id, &available_plugins);
        });
    }

    /// Handles changes in theme files.
    #[cfg(feature = "notify")]
    fn handle_themes_fs_event(&mut self, event: Event) {
        use notify::event::*;
        match event.kind {
            EventKind::Create(CreateKind::Any) | EventKind::Modify(ModifyKind::Any) => {
                self.load_theme_file(&event.paths[0])
            }
            // the way FSEvents on macOS work, we want to verify that this path
            // has actually be removed before we do anything.
            EventKind::Remove(RemoveKind::Any) if !event.paths[0].exists() => {
                self.remove_theme(&event.paths[0]);
            }
            EventKind::Modify(ModifyKind::Name(RenameMode::Both)) => {
                let old = &event.paths[0];
                let new = &event.paths[1];
                self.remove_theme(old);
                self.load_theme_file(new);
            }
            EventKind::Modify(ModifyKind::Metadata(MetadataKind::Any))
            | EventKind::Remove(RemoveKind::Any) => {
                self.style_map.borrow_mut().sync_dir(event.paths[0].parent())
            }
            _ => (),
        }
        let theme_names = self.style_map.borrow().get_theme_names();
        self.peer.available_themes(theme_names);
    }

    /// Load a single theme file. Updates if already present.
    fn load_theme_file(&mut self, path: &Path) {
        let _t = trace_block("CoreState::load_theme_file", &["core"]);

        let result = self.style_map.borrow_mut().load_theme_info_from_path(path);
        match result {
            Ok(theme_name) => {
                if theme_name == self.style_map.borrow().get_theme_name() {
                    if self.style_map.borrow_mut().set_theme(&theme_name).is_ok() {
                        self.notify_client_and_update_views();
                    }
                }
            }
            Err(e) => error!("Error loading theme file: {:?}, {:?}", path, e),
        }
    }

    fn remove_theme(&mut self, path: &Path) {
        let result = self.style_map.borrow_mut().remove_theme(path);

        // Set default theme if the removed theme was the
        // current one.
        if let Some(theme_name) = result {
            if theme_name == self.style_map.borrow().get_theme_name() {
                self.do_set_theme(DEFAULT_THEME);
            }
        }
    }

    fn toggle_tracing(&self, enabled: bool) {
        self.running_plugins.iter().for_each(|plugin| plugin.toggle_tracing(enabled))
    }

    fn save_trace<P>(&self, path: P, frontend_samples: Value)
    where
        P: AsRef<Path>,
    {
        use xi_trace::chrome_trace_dump;
        let mut all_traces = xi_trace::samples_cloned_unsorted();
        if let Ok(mut traces) = chrome_trace_dump::decode(frontend_samples) {
            all_traces.append(&mut traces);
        }

        for plugin in &self.running_plugins {
            match plugin.collect_trace() {
                Ok(json) => {
                    let mut trace = chrome_trace_dump::decode(json).unwrap();
                    all_traces.append(&mut trace);
                }
                Err(e) => error!("trace error {:?}", e),
            }
        }

        all_traces.sort_unstable();

        let mut trace_file = match File::create(path.as_ref()) {
            Ok(f) => f,
            Err(e) => {
                error!("error saving trace {:?}", e);
                return;
            }
        };

        if let Err(e) = chrome_trace_dump::serialize(&all_traces, &mut trace_file) {
            error!("error saving trace {:?}", e);
        }
    }
}

/// plugin event handling
impl CoreState {
    /// Called from a plugin's thread after trying to start the plugin.
    pub(crate) fn plugin_connect(&mut self, plugin: Result<Plugin, io::Error>) {
        match plugin {
            Ok(plugin) => {
                let init_info =
                    self.iter_groups().map(|mut ctx| ctx.plugin_info()).collect::<Vec<_>>();
                plugin.initialize(init_info);
                self.running_plugins.push(plugin);
            }
            Err(e) => error!("failed to start plugin {:?}", e),
        }
    }

    pub(crate) fn plugin_exit(&mut self, id: PluginId, error: Result<(), ReadError>) {
        warn!("plugin {:?} exited with result {:?}", id, error);
        let running_idx = self.running_plugins.iter().position(|p| p.id == id);
        if let Some(idx) = running_idx {
            let plugin = self.running_plugins.remove(idx);
            self.after_stop_plugin(&plugin);
        }
    }

    /// Handles the response to a sync update sent to a plugin.
    pub(crate) fn plugin_update(
        &mut self,
        _plugin_id: PluginId,
        view_id: ViewId,
        response: Result<Value, xi_rpc::Error>,
    ) {
        if let Some(mut edit_ctx) = self.make_context(view_id) {
            edit_ctx.do_plugin_update(response);
        }
    }

    pub(crate) fn plugin_notification(
        &mut self,
        _ctx: &RpcCtx,
        view_id: ViewId,
        plugin_id: PluginId,
        cmd: PluginNotification,
    ) {
        if let Some(mut edit_ctx) = self.make_context(view_id) {
            edit_ctx.do_plugin_cmd(plugin_id, cmd)
        }
    }

    pub(crate) fn plugin_request(
        &mut self,
        _ctx: &RpcCtx,
        view_id: ViewId,
        plugin_id: PluginId,
        cmd: PluginRequest,
    ) -> Result<Value, RemoteError> {
        if let Some(mut edit_ctx) = self.make_context(view_id) {
            Ok(edit_ctx.do_plugin_cmd_sync(plugin_id, cmd))
        } else {
            Err(RemoteError::custom(404, "missing view", None))
        }
    }
}

/// test helpers
impl CoreState {
    pub fn _test_open_editors(&self) -> Vec<BufferId> {
        self.editors.keys().cloned().collect()
    }

    pub fn _test_open_views(&self) -> Vec<ViewId> {
        self.views.keys().cloned().collect()
    }
}

pub mod test_helpers {
    use super::{BufferId, ViewId};

    pub fn new_view_id(id: usize) -> ViewId {
        ViewId(id)
    }

    pub fn new_buffer_id(id: usize) -> BufferId {
        BufferId(id)
    }
}

/// A multi-view aware iterator over `EventContext`s. A view which appears
/// as a sibling will not appear again as a main view.
pub struct Iter<'a, I> {
    views: I,
    seen: HashSet<ViewId>,
    inner: &'a CoreState,
}

impl<'a, I> Iterator for Iter<'a, I>
where
    I: Iterator<Item = &'a ViewId>,
{
    type Item = EventContext<'a>;

    fn next(&mut self) -> Option<Self::Item> {
        let &mut Iter { ref mut views, ref mut seen, ref inner } = self;
        loop {
            let next_view = match views.next() {
                None => return None,
                Some(v) if seen.contains(v) => continue,
                Some(v) => v,
            };
            let context = inner.make_context(*next_view).unwrap();
            context.siblings.iter().for_each(|sibl| {
                let _ = seen.insert(sibl.borrow().get_view_id());
            });
            return Some(context);
        }
    }
}

#[derive(Debug, Default)]
pub(crate) struct Counter(Cell<usize>);

impl Counter {
    pub(crate) fn next(&self) -> usize {
        let n = self.0.get();
        self.0.set(n + 1);
        n + 1
    }
}

// these two only exist so that we can use ViewIds as idle tokens
impl From<usize> for ViewId {
    fn from(src: usize) -> ViewId {
        ViewId(src)
    }
}

impl From<ViewId> for usize {
    fn from(src: ViewId) -> usize {
        src.0
    }
}

impl fmt::Display for ViewId {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "view-id-{}", self.0)
    }
}

impl Serialize for ViewId {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&self.to_string())
    }
}

impl<'de> Deserialize<'de> for ViewId {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        let ord = s.trim_start_matches("view-id-");
        match usize::from_str_radix(ord, 10) {
            Ok(id) => Ok(ViewId(id)),
            Err(_) => Err(de::Error::invalid_value(Unexpected::Str(&s), &"view id")),
        }
    }
}

impl fmt::Display for BufferId {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "buffer-id-{}", self.0)
    }
}

impl BufferId {
    pub fn new(val: usize) -> Self {
        BufferId(val)
    }
}

#[cfg(test)]
mod tests {
    use serde::Deserialize;

    use super::ViewId;

    #[test]
    fn test_deserialize_view_id() {
        let de = json!("view-id-1");
        assert_eq!(ViewId::deserialize(&de).unwrap(), ViewId(1));

        let de = json!("not-a-view-id");
        assert!(ViewId::deserialize(&de).unwrap_err().is_data());
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Cache and utilities for doing width measurement.

use std::borrow::Cow;
use std::collections::{BTreeMap, HashMap};

use crate::client::Client;

/// A token which can be used to retrieve an actual width value when the
/// batch request is submitted.
///
/// Internally, it is implemented as an index into the `widths` array.
pub type Token = usize;

/// A measured width, in px units.
type Width = f64;

type StyleId = usize;

pub struct WidthCache {
    /// maps cache key to index within widths
    m: HashMap<WidthCacheKey<'static>, Token>,
    widths: Vec<Width>,
}

#[derive(Eq, PartialEq, Hash)]
struct WidthCacheKey<'a> {
    id: StyleId,
    s: Cow<'a, str>,
}

/// A batched request, so that a number of strings can be measured in a
/// a single RPC.
pub struct WidthBatchReq<'a> {
    cache: &'a mut WidthCache,
    pending_tok: Token,
    req: Vec<WidthReq>,
    req_toks: Vec<Vec<Token>>,
    // maps style id to index into req/req_toks
    req_ids: BTreeMap<StyleId, Token>,
}

/// A request for measuring the widths of strings all of the same style
/// (a request from core to front-end).
#[derive(Serialize, Deserialize)]
pub struct WidthReq {
    pub id: StyleId,
    pub strings: Vec<String>,
}

/// The response for a batch of [`WidthReq`]s.
pub type WidthResponse = Vec<Vec<Width>>;

/// A trait for types that provide width measurement. In the general case this
/// will be provided by the frontend, but alternative implementations might
/// be provided for faster measurement of 'fixed-width' fonts, or for testing.
pub trait WidthMeasure {
    fn measure_width(&self, request: &[WidthReq]) -> Result<WidthResponse, xi_rpc::Error>;
}

impl WidthMeasure for Client {
    fn measure_width(&self, request: &[WidthReq]) -> Result<WidthResponse, xi_rpc::Error> {
        Client::measure_width(self, request)
    }
}

/// A measure in which each codepoint has width of 1.
pub struct CodepointMono;

impl WidthMeasure for CodepointMono {
    /// In which each codepoint has width == 1.
    fn measure_width(&self, request: &[WidthReq]) -> Result<WidthResponse, xi_rpc::Error> {
        Ok(request
            .iter()
            .map(|r| r.strings.iter().map(|s| s.chars().count() as f64).collect())
            .collect())
    }
}

impl WidthCache {
    pub fn new() -> WidthCache {
        WidthCache { m: HashMap::new(), widths: Vec::new() }
    }

    /// Returns the number of items currently in the cache.
    pub(crate) fn len(&self) -> usize {
        self.m.len()
    }

    /// Resolve a previously obtained token into a width value.
    pub fn resolve(&self, tok: Token) -> Width {
        self.widths[tok]
    }

    /// Create a new batch of requests.
    pub fn batch_req(self: &mut WidthCache) -> WidthBatchReq {
        let pending_tok = self.widths.len();
        WidthBatchReq {
            cache: self,
            pending_tok,
            req: Vec::new(),
            req_toks: Vec::new(),
            req_ids: BTreeMap::new(),
        }
    }
}

impl<'a> WidthBatchReq<'a> {
    /// Request measurement of one string/style pair within the batch.
    pub fn request(&mut self, id: StyleId, s: &str) -> Token {
        let key = WidthCacheKey { id, s: Cow::Borrowed(s) };
        if let Some(tok) = self.cache.m.get(&key) {
            return *tok;
        }
        // cache miss, add the request
        let key = WidthCacheKey { id, s: Cow::Owned(s.to_owned()) };
        let req = &mut self.req;
        let req_toks = &mut self.req_toks;
        let id_off = *self.req_ids.entry(id).or_insert_with(|| {
            let id_off = req.len();
            req.push(WidthReq { id, strings: Vec::new() });
            req_toks.push(Vec::new());
            id_off
        });
        // To avoid this second clone, we could potentially do a tricky thing where
        // we extract the strings from the WidthReq. Probably not worth it though.
        req[id_off].strings.push(s.to_owned());
        let tok = self.pending_tok;
        self.cache.m.insert(key, tok);
        self.pending_tok += 1;
        req_toks[id_off].push(tok);
        tok
    }

    /// Resolves pending measurements to concrete widths using the provided [`WidthMeasure`].
    /// On success, the tokens given by `request` will resolve in the cache.
    pub fn resolve_pending<T: WidthMeasure + ?Sized>(
        &mut self,
        handler: &T,
    ) -> Result<(), xi_rpc::Error> {
        // The 0.0 values should all get replaced with actual widths, assuming the
        // shape of the response from the front-end matches that of the request.
        if self.pending_tok > self.cache.widths.len() {
            self.cache.widths.resize(self.pending_tok, 0.0);
            let widths = handler.measure_width(&self.req)?;
            for (w, t) in widths.iter().zip(self.req_toks.iter()) {
                for (width, tok) in w.iter().zip(t.iter()) {
                    self.cache.widths[*tok] = *width;
                }
            }
        }
        Ok(())
// Copyright 2020 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#![allow(clippy::range_plus_one)]

use std::ops::Range;

use xi_rope::Rope;

use crate::linewrap::Lines;
use crate::selection::SelRegion;

/// A trait from which lines and columns in a document can be calculated
/// into offsets inside a rope an vice versa.
pub trait LineOffset {
    // use own breaks if present, or text if not (no line wrapping)

    /// Returns the byte offset corresponding to the given line.
    fn offset_of_line(&self, text: &Rope, line: usize) -> usize {
        text.offset_of_line(line)
    }

    /// Returns the visible line number containing the given offset.
    fn line_of_offset(&self, text: &Rope, offset: usize) -> usize {
        text.line_of_offset(offset)
    }

    // How should we count "column"? Valid choices include:
    // * Unicode codepoints
    // * grapheme clusters
    // * Unicode width (so CJK counts as 2)
    // * Actual measurement in text layout
    // * Code units in some encoding
    //
    // Of course, all these are identical for ASCII. For now we use UTF-8 code units
    // for simplicity.

    fn offset_to_line_col(&self, text: &Rope, offset: usize) -> (usize, usize) {
        let line = self.line_of_offset(text, offset);
        (line, offset - self.offset_of_line(text, line))
    }

    fn line_col_to_offset(&self, text: &Rope, line: usize, col: usize) -> usize {
        let mut offset = self.offset_of_line(text, line).saturating_add(col);
        if offset >= text.len() {
            offset = text.len();
            if self.line_of_offset(text, offset) <= line {
                return offset;
            }
        } else {
            // Snap to grapheme cluster boundary
            offset = text.prev_grapheme_offset(offset + 1).unwrap();
        }

        // clamp to end of line
        let next_line_offset = self.offset_of_line(text, line + 1);
        if offset >= next_line_offset {
            if let Some(prev) = text.prev_grapheme_offset(next_line_offset) {
                offset = prev;
            }
        }
        offset
    }

    /// Get the line range of a selected region.
    fn get_line_range(&self, text: &Rope, region: &SelRegion) -> Range<usize> {
        let (first_line, _) = self.offset_to_line_col(text, region.min());
        let (mut last_line, last_col) = self.offset_to_line_col(text, region.max());
        if last_col == 0 && last_line > first_line {
            last_line -= 1;
        }

        first_line..(last_line + 1)
    }
}

/// A struct from which the default definitions for `offset_of_line`
/// and `line_of_offset` can be accessed, and think in logical lines.
pub struct LogicalLines;

impl LineOffset for LogicalLines {}

impl LineOffset for xi_rope::breaks::Breaks {
    fn offset_of_line(&self, _text: &Rope, line: usize) -> usize {
        self.count_base_units::<xi_rope::breaks::BreaksMetric>(line)
    }

    fn line_of_offset(&self, text: &Rope, offset: usize) -> usize {
        let offset = offset.min(text.len());
        self.count::<xi_rope::breaks::BreaksMetric>(offset)
    }
}

impl LineOffset for Lines {
    fn offset_of_line(&self, text: &Rope, line: usize) -> usize {
        self.offset_of_visual_line(text, line)
    }

    fn line_of_offset(&self, text: &Rope, offset: usize) -> usize {
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::borrow::{Borrow, Cow};
use std::cmp::min;
use std::collections::BTreeSet;

use serde_json::Value;

use xi_rope::diff::{Diff, LineHashDiff};
use xi_rope::engine::{Engine, RevId, RevToken};
use xi_rope::rope::count_newlines;
use xi_rope::spans::SpansBuilder;
use xi_rope::{DeltaBuilder, Interval, LinesMetric, Rope, RopeDelta, Transformer};
use xi_trace::{trace_block, trace_payload};

use crate::annotations::{AnnotationType, Annotations};
use crate::config::BufferItems;
use crate::edit_ops::{self, IndentDirection};
use crate::edit_types::BufferEvent;
use crate::event_context::MAX_SIZE_LIMIT;
use crate::layers::Layers;
use crate::line_offset::{LineOffset, LogicalLines};
use crate::movement::Movement;
use crate::plugins::rpc::{DataSpan, GetDataResponse, PluginEdit, ScopeSpan, TextUnit};
use crate::plugins::PluginId;
use crate::rpc::SelectionModifier;
use crate::selection::{InsertDrift, SelRegion, Selection};
use crate::styles::ThemeStyleMap;
use crate::view::{Replace, View};

#[cfg(not(feature = "ledger"))]
pub struct SyncStore;
#[cfg(feature = "ledger")]
use fuchsia::sync::SyncStore;

// TODO This could go much higher without issue but while developing it is
// better to keep it low to expose bugs in the GC during casual testing.
const MAX_UNDOS: usize = 20;

pub struct Editor {
    /// The contents of the buffer.
    text: Rope,
    /// The CRDT engine, which tracks edit history and manages concurrent edits.
    engine: Engine,

    /// The most recent revision.
    last_rev_id: RevId,
    /// The revision of the last save.
    pristine_rev_id: RevId,
    undo_group_id: usize,
    /// Undo groups that may still be toggled
    live_undos: Vec<usize>,
    /// The index of the current undo; subsequent undos are currently 'undone'
    /// (but may be redone)
    cur_undo: usize,
    /// undo groups that are undone
    undos: BTreeSet<usize>,
    /// undo groups that are no longer live and should be gc'ed
    gc_undos: BTreeSet<usize>,
    force_undo_group: bool,

    this_edit_type: EditType,
    last_edit_type: EditType,

    revs_in_flight: usize,

    /// Used only on Fuchsia for syncing
    #[allow(dead_code)]
    sync_store: Option<SyncStore>,
    #[allow(dead_code)]
    last_synced_rev: RevId,

    layers: Layers,
}

impl Editor {
    /// Creates a new `Editor` with a new empty buffer.
    pub fn new() -> Editor {
        Self::with_text("")
    }

    /// Creates a new `Editor`, loading text into a new buffer.
    pub fn with_text<T: Into<Rope>>(text: T) -> Editor {
        let engine = Engine::new(text.into());
        let buffer = engine.get_head().clone();
        let last_rev_id = engine.get_head_rev_id();

        Editor {
            text: buffer,
            engine,
            last_rev_id,
            pristine_rev_id: last_rev_id,
            undo_group_id: 1,
            // GC only works on undone edits or prefixes of the visible edits,
            // but initial file loading can create an edit with undo group 0,
            // so we want to collect that as part of the prefix.
            live_undos: vec![0],
            cur_undo: 1,
            undos: BTreeSet::new(),
            gc_undos: BTreeSet::new(),
            force_undo_group: false,
            last_edit_type: EditType::Other,
            this_edit_type: EditType::Other,
            layers: Layers::default(),
            revs_in_flight: 0,
            sync_store: None,
            last_synced_rev: last_rev_id,
        }
    }

    pub(crate) fn get_buffer(&self) -> &Rope {
        &self.text
    }

    pub(crate) fn get_layers(&self) -> &Layers {
        &self.layers
    }

    pub(crate) fn get_layers_mut(&mut self) -> &mut Layers {
        &mut self.layers
    }

    pub(crate) fn get_head_rev_token(&self) -> u64 {
        self.engine.get_head_rev_id().token()
    }

    pub(crate) fn get_edit_type(&self) -> EditType {
        self.this_edit_type
    }

    pub(crate) fn get_active_undo_group(&self) -> usize {
        *self.live_undos.last().unwrap_or(&0)
    }

    pub(crate) fn update_edit_type(&mut self) {
        self.last_edit_type = self.this_edit_type;
        self.this_edit_type = EditType::Other
    }

    pub(crate) fn set_pristine(&mut self) {
        self.pristine_rev_id = self.engine.get_head_rev_id();
    }

    pub(crate) fn is_pristine(&self) -> bool {
        self.engine.is_equivalent_revision(self.pristine_rev_id, self.engine.get_head_rev_id())
    }

    /// Set whether or not edits are forced into the same undo group rather than being split by
    /// their EditType.
    ///
    /// This is used for things such as recording playback, where you don't want the
    /// individual events to be undoable, but instead the entire playback should be.
    pub(crate) fn set_force_undo_group(&mut self, force_undo_group: bool) {
        trace_payload("Editor::set_force_undo_group", &["core"], force_undo_group.to_string());
        self.force_undo_group = force_undo_group;
    }

    /// Sets this Editor's contents to `text`, preserving undo state and cursor
    /// position when possible.
    pub fn reload(&mut self, text: Rope) {
        let delta = LineHashDiff::compute_delta(self.get_buffer(), &text);
        self.add_delta(delta);
        self.set_pristine();
    }

    // each outstanding plugin edit represents a rev_in_flight.
    pub fn increment_revs_in_flight(&mut self) {
        self.revs_in_flight += 1;
    }

    // GC of CRDT engine is deferred until all plugins have acknowledged the new rev,
    // so when the ack comes back, potentially trigger GC.
    pub fn dec_revs_in_flight(&mut self) {
        self.revs_in_flight -= 1;
        self.gc_undos();
    }

    /// Applies a delta to the text, and updates undo state.
    ///
    /// Records the delta into the CRDT engine so that it can be undone. Also
    /// contains the logic for merging edits into the same undo group. At call
    /// time, self.this_edit_type should be set appropriately.
    ///
    /// This method can be called multiple times, accumulating deltas that will
    /// be committed at once with `commit_delta`. Note that it does not update
    /// the views. Thus, view-associated state such as the selection and line
    /// breaks are to be considered invalid after this method, until the
    /// `commit_delta` call.
    fn add_delta(&mut self, delta: RopeDelta) {
        let head_rev_id = self.engine.get_head_rev_id();
        let undo_group = self.calculate_undo_group();
        self.last_edit_type = self.this_edit_type;
        let priority = 0x10000;
        self.engine.edit_rev(priority, undo_group, head_rev_id.token(), delta);
        self.text = self.engine.get_head().clone();
    }

    pub(crate) fn calculate_undo_group(&mut self) -> usize {
        let has_undos = !self.live_undos.is_empty();
        let force_undo_group = self.force_undo_group;
        let is_unbroken_group = !self.this_edit_type.breaks_undo_group(self.last_edit_type);

        if has_undos && (force_undo_group || is_unbroken_group) {
            *self.live_undos.last().unwrap()
        } else {
            let undo_group = self.undo_group_id;
            self.gc_undos.extend(&self.live_undos[self.cur_undo..]);
            self.live_undos.truncate(self.cur_undo);
            self.live_undos.push(undo_group);
            if self.live_undos.len() <= MAX_UNDOS {
                self.cur_undo += 1;
            } else {
                self.gc_undos.insert(self.live_undos.remove(0));
            }
            self.undo_group_id += 1;
            undo_group
        }
    }

    /// generates a delta from a plugin's response and applies it to the buffer.
    pub fn apply_plugin_edit(&mut self, edit: PluginEdit) {
        let _t = trace_block("Editor::apply_plugin_edit", &["core"]);
        //TODO: get priority working, so that plugin edits don't necessarily move cursor
        let PluginEdit { rev, delta, priority, undo_group, .. } = edit;
        let priority = priority as usize;
        let undo_group = undo_group.unwrap_or_else(|| self.calculate_undo_group());
        match self.engine.try_edit_rev(priority, undo_group, rev, delta) {
            Err(e) => error!("Error applying plugin edit: {}", e),
            Ok(_) => self.text = self.engine.get_head().clone(),
        };
    }

    /// Commits the current delta. If the buffer has changed, returns
    /// a 3-tuple containing the delta representing the changes, the previous
    /// buffer, and an `InsertDrift` enum describing the correct selection update
    /// behaviour.
    pub(crate) fn commit_delta(&mut self) -> Option<(RopeDelta, Rope, InsertDrift)> {
        let _t = trace_block("Editor::commit_delta", &["core"]);

        if self.engine.get_head_rev_id() == self.last_rev_id {
            return None;
        }

        let last_token = self.last_rev_id.token();
        let delta = self.engine.try_delta_rev_head(last_token).expect("last_rev not found");
        // TODO (performance): it's probably quicker to stash last_text
        // rather than resynthesize it.
        let last_text = self.engine.get_rev(last_token).expect("last_rev not found");

        // Transpose can rotate characters inside of a selection; this is why it's an Inside edit.
        // Surround adds characters on either side of a selection, that's why it's an Outside edit.
        let drift = match self.this_edit_type {
            EditType::Transpose => InsertDrift::Inside,
            EditType::Surround => InsertDrift::Outside,
            _ => InsertDrift::Default,
        };
        self.layers.update_all(&delta);

        self.last_rev_id = self.engine.get_head_rev_id();
        self.sync_state_changed();
        Some((delta, last_text, drift))
    }

    /// Attempts to find the delta from head for the given `RevToken`. Returns
    /// `None` if the revision is not found, so this result should be checked if
    /// the revision is coming from a plugin.
    pub(crate) fn delta_rev_head(&self, target_rev_id: RevToken) -> Option<RopeDelta> {
        self.engine.try_delta_rev_head(target_rev_id).ok()
    }

    #[cfg(not(target_os = "fuchsia"))]
    fn gc_undos(&mut self) {
        if self.revs_in_flight == 0 && !self.gc_undos.is_empty() {
            self.engine.gc(&self.gc_undos);
            self.undos = &self.undos - &self.gc_undos;
            self.gc_undos.clear();
        }
    }

    #[cfg(target_os = "fuchsia")]
    fn gc_undos(&mut self) {
        // Never run GC on Fuchsia so that peers don't invalidate our
        // last_rev_id and so that merge will work.
    }

    pub fn merge_new_state(&mut self, new_engine: Engine) {
        self.engine.merge(&new_engine);
        self.text = self.engine.get_head().clone();
        // TODO: better undo semantics. This only implements separate undo
        // histories for low concurrency.
        self.undo_group_id = self.engine.max_undo_group_id() + 1;
        self.last_synced_rev = self.engine.get_head_rev_id();
        self.commit_delta();
        //self.render();
        //FIXME: render after fuchsia sync
    }

    /// See `Engine::set_session_id`. Only useful for Fuchsia sync.
    pub fn set_session_id(&mut self, session: (u64, u32)) {
        self.engine.set_session_id(session);
    }

    #[cfg(feature = "ledger")]
    pub fn set_sync_store(&mut self, sync_store: SyncStore) {
        self.sync_store = Some(sync_store);
    }

    #[cfg(not(feature = "ledger"))]
    pub fn sync_state_changed(&mut self) {}

    #[cfg(feature = "ledger")]
    pub fn sync_state_changed(&mut self) {
        if let Some(sync_store) = self.sync_store.as_mut() {
            // we don't want to sync right after recieving a new merge
            if self.last_synced_rev != self.engine.get_head_rev_id() {
                self.last_synced_rev = self.engine.get_head_rev_id();
                sync_store.state_changed();
            }
        }
    }

    #[cfg(feature = "ledger")]
    pub fn transaction_ready(&mut self) {
        if let Some(sync_store) = self.sync_store.as_mut() {
            sync_store.commit_transaction(&self.engine);
        }
    }

    fn do_insert(&mut self, view: &View, config: &BufferItems, chars: &str) {
        let pair_search = config.surrounding_pairs.iter().find(|pair| pair.0 == chars);
        let caret_exists = view.sel_regions().iter().any(|region| region.is_caret());
        if let (Some(pair), false) = (pair_search, caret_exists) {
            self.this_edit_type = EditType::Surround;
            self.add_delta(edit_ops::surround(
                &self.text,
                view.sel_regions(),
                pair.0.to_string(),
                pair.1.to_string(),
            ));
        } else {
            self.this_edit_type = EditType::InsertChars;
            self.add_delta(edit_ops::insert(&self.text, view.sel_regions(), chars));
        }
    }

    fn do_paste(&mut self, view: &View, chars: &str) {
        if view.sel_regions().len() == 1 || view.sel_regions().len() != count_lines(chars) {
            self.add_delta(edit_ops::insert(&self.text, view.sel_regions(), chars));
        } else {
            let mut builder = DeltaBuilder::new(self.text.len());
            for (sel, line) in view.sel_regions().iter().zip(chars.lines()) {
                let iv = Interval::new(sel.min(), sel.max());
                builder.replace(iv, line.into());
            }
            self.add_delta(builder.build());
        }
    }

    pub(crate) fn do_cut(&mut self, view: &mut View) -> Value {
        let result = self.do_copy(view);
        let delta = edit_ops::delete_sel_regions(&self.text, &view.sel_regions());
        if !delta.is_identity() {
            self.this_edit_type = EditType::Delete;
            self.add_delta(delta);
        }
        result
    }

    pub(crate) fn do_copy(&self, view: &View) -> Value {
        if let Some(val) = edit_ops::extract_sel_regions(&self.text, view.sel_regions()) {
            Value::String(val.into_owned())
        } else {
            Value::Null
        }
    }

    fn do_undo(&mut self) {
        if self.cur_undo > 1 {
            self.cur_undo -= 1;
            assert!(self.undos.insert(self.live_undos[self.cur_undo]));
            self.this_edit_type = EditType::Undo;
            self.update_undos();
        }
    }

    fn do_redo(&mut self) {
        if self.cur_undo < self.live_undos.len() {
            assert!(self.undos.remove(&self.live_undos[self.cur_undo]));
            self.cur_undo += 1;
            self.this_edit_type = EditType::Redo;
            self.update_undos();
        }
    }

    fn update_undos(&mut self) {
        self.engine.undo(self.undos.clone());
        self.text = self.engine.get_head().clone();
    }

    fn do_replace(&mut self, view: &mut View, replace_all: bool) {
        if let Some(Replace { chars, .. }) = view.get_replace() {
            // todo: implement preserve case
            // store old selection because in case nothing is found the selection will be preserved
            let mut old_selection = Selection::new();
            for &region in view.sel_regions() {
                old_selection.add_region(region);
            }
            view.collapse_selections(&self.text);

            if replace_all {
                view.do_find_all(&self.text);
            } else {
                view.do_find_next(&self.text, false, true, true, &SelectionModifier::Set);
            }

            match last_selection_region(view.sel_regions()) {
                Some(_) => self.add_delta(edit_ops::insert(&self.text, view.sel_regions(), chars)),
                None => return,
            };
        }
    }

    fn do_delete_by_movement(
        &mut self,
        view: &View,
        movement: Movement,
        save: bool,
        kill_ring: &mut Rope,
    ) {
        let (delta, rope) = edit_ops::delete_by_movement(
            &self.text,
            view.sel_regions(),
            view.get_lines(),
            movement,
            view.scroll_height(),
            save,
        );
        if let Some(rope) = rope {
            *kill_ring = rope;
        }
        if !delta.is_identity() {
            self.this_edit_type = EditType::Delete;
            self.add_delta(delta);
        }
    }

    fn do_delete_backward(&mut self, view: &View, config: &BufferItems) {
        let delta = edit_ops::delete_backward(&self.text, view.sel_regions(), config);
        if !delta.is_identity() {
            self.this_edit_type = EditType::Delete;
            self.add_delta(delta);
        }
    }

    fn do_transpose(&mut self, view: &View) {
        let delta = edit_ops::transpose(&self.text, view.sel_regions());
        if !delta.is_identity() {
            self.this_edit_type = EditType::Transpose;
            self.add_delta(delta);
        }
    }

    fn do_transform_text<F: Fn(&str) -> String>(&mut self, view: &View, transform_function: F) {
        let delta = edit_ops::transform_text(&self.text, view.sel_regions(), transform_function);
        if !delta.is_identity() {
            self.this_edit_type = EditType::Other;
            self.add_delta(delta);
        }
    }

    fn do_capitalize_text(&mut self, view: &mut View) {
        let (delta, final_selection) = edit_ops::capitalize_text(&self.text, view.sel_regions());
        if !delta.is_identity() {
            self.this_edit_type = EditType::Other;
            self.add_delta(delta);
        }

        // at the end of the transformation carets are located at the end of the words that were
        // transformed last in the selections
        view.collapse_selections(&self.text);
        view.set_selection(&self.text, final_selection);
    }

    fn do_modify_indent(&mut self, view: &View, config: &BufferItems, direction: IndentDirection) {
        let delta = edit_ops::modify_indent(&self.text, view.sel_regions(), config, direction);
        self.add_delta(delta);
        self.this_edit_type = match direction {
            IndentDirection::In => EditType::InsertChars,
            IndentDirection::Out => EditType::Delete,
        }
    }

    fn do_insert_newline(&mut self, view: &View, config: &BufferItems) {
        let delta = edit_ops::insert_newline(&self.text, view.sel_regions(), config);
        self.add_delta(delta);
        self.this_edit_type = EditType::InsertNewline;
    }

    fn do_insert_tab(&mut self, view: &View, config: &BufferItems) {
        let regions = view.sel_regions();
        let delta = edit_ops::insert_tab(&self.text, regions, config);

        // if we indent multiple regions or multiple lines,
        // we treat this as an indentation adjustment; otherwise it is
        // just inserting text.
        let condition = regions
            .first()
            .map(|x| LogicalLines.get_line_range(&self.text, x).len() > 1)
            .unwrap_or(false);

        self.add_delta(delta);
        self.this_edit_type =
            if regions.len() > 1 || condition { EditType::Indent } else { EditType::InsertChars };
    }

    fn do_yank(&mut self, view: &View, kill_ring: &Rope) {
        // TODO: if there are multiple cursors and the number of newlines
        // is one less than the number of cursors, split and distribute one
        // line per cursor.
        let delta = edit_ops::insert(&self.text, view.sel_regions(), kill_ring.clone());
        self.add_delta(delta);
    }

    fn do_duplicate_line(&mut self, view: &View, config: &BufferItems) {
        let delta = edit_ops::duplicate_line(&self.text, view.sel_regions(), config);
        self.add_delta(delta);
        self.this_edit_type = EditType::Other;
    }

    fn do_change_number<F: Fn(i128) -> Option<i128>>(
        &mut self,
        view: &View,
        transform_function: F,
    ) {
        let delta = edit_ops::change_number(&self.text, view.sel_regions(), transform_function);
        if !delta.is_identity() {
            self.this_edit_type = EditType::Other;
            self.add_delta(delta);
        }
    }

    pub(crate) fn do_edit(
        &mut self,
        view: &mut View,
        kill_ring: &mut Rope,
        config: &BufferItems,
        cmd: BufferEvent,
    ) {
        use self::BufferEvent::*;
        match cmd {
            Delete { movement, kill } => {
                self.do_delete_by_movement(view, movement, kill, kill_ring)
            }
            Backspace => self.do_delete_backward(view, config),
            Transpose => self.do_transpose(view),
            Undo => self.do_undo(),
            Redo => self.do_redo(),
            Uppercase => self.do_transform_text(view, |s| s.to_uppercase()),
            Lowercase => self.do_transform_text(view, |s| s.to_lowercase()),
            Capitalize => self.do_capitalize_text(view),
            Indent => self.do_modify_indent(view, config, IndentDirection::In),
            Outdent => self.do_modify_indent(view, config, IndentDirection::Out),
            InsertNewline => self.do_insert_newline(view, config),
            InsertTab => self.do_insert_tab(view, config),
            Insert(chars) => self.do_insert(view, config, &chars),
            Paste(chars) => self.do_paste(view, &chars),
            Yank => self.do_yank(view, kill_ring),
            ReplaceNext => self.do_replace(view, false),
            ReplaceAll => self.do_replace(view, true),
            DuplicateLine => self.do_duplicate_line(view, config),
            IncreaseNumber => self.do_change_number(view, |s| s.checked_add(1)),
            DecreaseNumber => self.do_change_number(view, |s| s.checked_sub(1)),
        }
    }

    pub fn theme_changed(&mut self, style_map: &ThemeStyleMap) {
        self.layers.theme_changed(style_map);
    }

    pub fn plugin_n_lines(&self) -> usize {
        self.text.measure::<LinesMetric>() + 1
    }

    pub fn update_spans(
        &mut self,
        view: &mut View,
        plugin: PluginId,
        start: usize,
        len: usize,
        spans: Vec<ScopeSpan>,
        rev: RevToken,
    ) {
        let _t = trace_block("Editor::update_spans", &["core"]);
        // TODO: more protection against invalid input
        let mut start = start;
        let mut end_offset = start + len;
        let mut sb = SpansBuilder::new(len);
        for span in spans {
            sb.add_span(Interval::new(span.start, span.end), span.scope_id);
        }
        let mut spans = sb.build();
        if rev != self.engine.get_head_rev_id().token() {
            if let Ok(delta) = self.engine.try_delta_rev_head(rev) {
                let mut transformer = Transformer::new(&delta);
                let new_start = transformer.transform(start, false);
                if !transformer.interval_untouched(Interval::new(start, end_offset)) {
                    spans = spans.transform(start, end_offset, &mut transformer);
                }
                start = new_start;
                end_offset = transformer.transform(end_offset, true);
            } else {
                error!("Revision {} not found", rev);
            }
        }
        let iv = Interval::new(start, end_offset);
        self.layers.update_layer(plugin, iv, spans);
        view.invalidate_styles(&self.text, start, end_offset);
    }

    pub fn update_annotations(
        &mut self,
        view: &mut View,
        plugin: PluginId,
        start: usize,
        len: usize,
        annotation_spans: Vec<DataSpan>,
        annotation_type: AnnotationType,
        rev: RevToken,
    ) {
        let _t = trace_block("Editor::update_annotations", &["core"]);

        let mut start = start;
        let mut end_offset = start + len;
        let mut sb = SpansBuilder::new(len);
        for span in annotation_spans {
            sb.add_span(Interval::new(span.start, span.end), span.data);
        }
        let mut spans = sb.build();
        if rev != self.engine.get_head_rev_id().token() {
            if let Ok(delta) = self.engine.try_delta_rev_head(rev) {
                let mut transformer = Transformer::new(&delta);
                let new_start = transformer.transform(start, false);
                if !transformer.interval_untouched(Interval::new(start, end_offset)) {
                    spans = spans.transform(start, end_offset, &mut transformer);
                }
                start = new_start;
                end_offset = transformer.transform(end_offset, true);
            } else {
                error!("Revision {} not found", rev);
            }
        }
        let iv = Interval::new(start, end_offset);
        view.update_annotations(plugin, iv, Annotations { items: spans, annotation_type });
    }

    pub(crate) fn get_rev(&self, rev: RevToken) -> Option<Cow<Rope>> {
        let text_cow = if rev == self.engine.get_head_rev_id().token() {
            Cow::Borrowed(&self.text)
        } else {
            match self.engine.get_rev(rev) {
                None => return None,
                Some(text) => Cow::Owned(text),
            }
        };

        Some(text_cow)
    }

    pub fn plugin_get_data(
        &self,
        start: usize,
        unit: TextUnit,
        max_size: usize,
        rev: RevToken,
    ) -> Option<GetDataResponse> {
        let _t = trace_block("Editor::plugin_get_data", &["core"]);
        let text_cow = self.get_rev(rev)?;
        let text = &text_cow;
        // convert our offset into a valid byte offset
        let offset = unit.resolve_offset(text.borrow(), start)?;

        let max_size = min(max_size, MAX_SIZE_LIMIT);
        let mut end_off = offset.saturating_add(max_size);
        if end_off >= text.len() {
            end_off = text.len();
        } else {
            // Snap end to codepoint boundary.
            end_off = text.prev_codepoint_offset(end_off + 1).unwrap();
        }

        let chunk = text.slice_to_cow(offset..end_off).into_owned();
        let first_line = text.line_of_offset(offset);
        let first_line_offset = offset - text.offset_of_line(first_line);

        Some(GetDataResponse { chunk, offset, first_line, first_line_offset })
    }
}

#[derive(PartialEq, Eq, Clone, Copy, Debug, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum EditType {
    /// A catchall for edits that don't fit elsewhere, and which should
    /// always have their own undo groups; used for things like cut/copy/paste.
    Other,
    /// An insert from the keyboard/IME (not a paste or a yank).
    #[serde(rename = "insert")]
    InsertChars,
    #[serde(rename = "newline")]
    InsertNewline,
    /// An indentation adjustment.
    Indent,
    Delete,
    Undo,
    Redo,
    Transpose,
    Surround,
}

impl EditType {
    /// Checks whether a new undo group should be created between two edits.
    fn breaks_undo_group(self, previous: EditType) -> bool {
        self == EditType::Other || self == EditType::Transpose || self != previous
    }
}

fn last_selection_region(regions: &[SelRegion]) -> Option<&SelRegion> {
    for region in regions.iter().rev() {
        if !region.is_caret() {
            return Some(region);
        }
    }
    None
}

/// Counts the number of lines in the string, not including any trailing newline.
fn count_lines(s: &str) -> usize {
    let mut newlines = count_newlines(s);
    if s.as_bytes().last() == Some(&0xa) {
        newlines -= 1;
    }
    1 + newlines
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn plugin_edit() {
        let base_text = "hello";
        let mut editor = Editor::with_text(base_text);
        let mut builder = DeltaBuilder::new(base_text.len());
        builder.replace(0..0, "s".into());
        let delta = builder.build();
        let rev = editor.get_head_rev_token();

        let edit_one = PluginEdit {
            rev,
            delta,
            priority: 55,
            after_cursor: false,
            undo_group: None,
            author: "plugin_one".into(),
        };

        editor.apply_plugin_edit(edit_one.clone());
        editor.apply_plugin_edit(edit_one);

// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Requests and notifications from the core to front-ends.

use std::time::Instant;

use serde_json::{self, Value};
use xi_rpc::{self, RpcPeer};

use crate::config::Table;
use crate::plugins::rpc::ClientPluginInfo;
use crate::plugins::Command;
use crate::styles::ThemeSettings;
use crate::syntax::LanguageId;
use crate::tabs::ViewId;
use crate::width_cache::{WidthReq, WidthResponse};

/// An interface to the frontend.
pub struct Client(RpcPeer);

impl Client {
    pub fn new(peer: RpcPeer) -> Self {
        Client(peer)
    }

    pub fn update_view(&self, view_id: ViewId, update: &Update) {
        self.0.send_rpc_notification(
            "update",
            &json!({
                "view_id": view_id,
                "update": update,
            }),
        );
    }

    pub fn scroll_to(&self, view_id: ViewId, line: usize, col: usize) {
        self.0.send_rpc_notification(
            "scroll_to",
            &json!({
                "view_id": view_id,
                "line": line,
                "col": col,
            }),
        );
    }

    pub fn config_changed(&self, view_id: ViewId, changes: &Table) {
        self.0.send_rpc_notification(
            "config_changed",
            &json!({
                "view_id": view_id,
                "changes": changes,
            }),
        );
    }

    pub fn available_themes(&self, theme_names: Vec<String>) {
        self.0.send_rpc_notification("available_themes", &json!({ "themes": theme_names }))
    }

    pub fn available_languages(&self, languages: Vec<LanguageId>) {
        self.0.send_rpc_notification("available_languages", &json!({ "languages": languages }))
    }

    pub fn theme_changed(&self, name: &str, theme: &ThemeSettings) {
        self.0.send_rpc_notification(
            "theme_changed",
            &json!({
                "name": name,
                "theme": theme,
            }),
        );
    }

    pub fn language_changed(&self, view_id: ViewId, new_lang: &LanguageId) {
        self.0.send_rpc_notification(
            "language_changed",
            &json!({
                "view_id": view_id,
                "language_id": new_lang,
            }),
        );
    }

    /// Notify the client that a plugin has started.
    pub fn plugin_started(&self, view_id: ViewId, plugin: &str) {
        self.0.send_rpc_notification(
            "plugin_started",
            &json!({
                "view_id": view_id,
                "plugin": plugin,
            }),
        );
    }

    /// Notify the client that a plugin has stopped.
    ///
    /// `code` is not currently used; in the future may be used to
    /// pass an exit code.
    pub fn plugin_stopped(&self, view_id: ViewId, plugin: &str, code: i32) {
        self.0.send_rpc_notification(
            "plugin_stopped",
            &json!({
                "view_id": view_id,
                "plugin": plugin,
                "code": code,
            }),
        );
    }

    /// Notify the client of the available plugins.
    pub fn available_plugins(&self, view_id: ViewId, plugins: &[ClientPluginInfo]) {
        self.0.send_rpc_notification(
            "available_plugins",
            &json!({
                "view_id": view_id,
                "plugins": plugins }),
        );
    }

    pub fn update_cmds(&self, view_id: ViewId, plugin: &str, cmds: &[Command]) {
        self.0.send_rpc_notification(
            "update_cmds",
            &json!({
                "view_id": view_id,
                "plugin": plugin,
                "cmds": cmds,
            }),
        );
    }

    pub fn def_style(&self, style: &Value) {
        self.0.send_rpc_notification("def_style", &style)
    }

    pub fn find_status(&self, view_id: ViewId, queries: &Value) {
        self.0.send_rpc_notification(
            "find_status",
            &json!({
                "view_id": view_id,
                "queries": queries,
            }),
        );
    }

    pub fn replace_status(&self, view_id: ViewId, replace: &Value) {
        self.0.send_rpc_notification(
            "replace_status",
            &json!({
                "view_id": view_id,
                "status": replace,
            }),
        );
    }

    /// Ask front-end to measure widths of strings.
    pub fn measure_width(&self, reqs: &[WidthReq]) -> Result<WidthResponse, xi_rpc::Error> {
        let req_json = serde_json::to_value(reqs).expect("failed to serialize width req");
        let resp = self.0.send_rpc_request("measure_width", &req_json)?;
        Ok(serde_json::from_value(resp).expect("failed to deserialize width response"))
    }

    pub fn alert<S: AsRef<str>>(&self, msg: S) {
        self.0.send_rpc_notification("alert", &json!({ "msg": msg.as_ref() }));
    }

    pub fn add_status_item(
        &self,
        view_id: ViewId,
        source: &str,
        key: &str,
        value: &str,
        alignment: &str,
    ) {
        self.0.send_rpc_notification(
            "add_status_item",
            &json!({
                "view_id": view_id,
                "source": source,
                "key": key,
                "value": value,
                "alignment": alignment
            }),
        );
    }

    pub fn update_status_item(&self, view_id: ViewId, key: &str, value: &str) {
        self.0.send_rpc_notification(
            "update_status_item",
            &json!({
                "view_id": view_id,
                "key": key,
                "value": value,
            }),
        );
    }

    pub fn remove_status_item(&self, view_id: ViewId, key: &str) {
        self.0.send_rpc_notification(
            "remove_status_item",
            &json!({
                "view_id": view_id,
                "key": key,
            }),
        );
    }

    pub fn show_hover(&self, view_id: ViewId, request_id: usize, result: String) {
        self.0.send_rpc_notification(
            "show_hover",
            &json!({
                "view_id": view_id,
                "request_id": request_id,
                "result": result,
            }),
        )
    }

    pub fn schedule_idle(&self, token: usize) {
        self.0.schedule_idle(token)
    }

    pub fn schedule_timer(&self, timeout: Instant, token: usize) {
        self.0.schedule_timer(timeout, token);
    }
}

#[derive(Debug, Serialize)]
pub struct Update {
    pub(crate) ops: Vec<UpdateOp>,
    pub(crate) pristine: bool,
    pub(crate) annotations: Vec<Value>,
}

#[derive(Debug, Serialize)]
pub(crate) struct UpdateOp {
    op: OpType,
    n: usize,
    #[serde(skip_serializing_if = "Option::is_none")]
    lines: Option<Vec<Value>>,
    #[serde(rename = "ln")]
    #[serde(skip_serializing_if = "Option::is_none")]
    first_line_number: Option<usize>,
}

impl UpdateOp {
    pub(crate) fn invalidate(n: usize) -> Self {
        UpdateOp { op: OpType::Invalidate, n, lines: None, first_line_number: None }
    }

    pub(crate) fn skip(n: usize) -> Self {
        UpdateOp { op: OpType::Skip, n, lines: None, first_line_number: None }
    }

    pub(crate) fn copy(n: usize, line: usize) -> Self {
        UpdateOp { op: OpType::Copy, n, lines: None, first_line_number: Some(line) }
    }

    pub(crate) fn insert(lines: Vec<Value>) -> Self {
        UpdateOp { op: OpType::Insert, n: lines.len(), lines: Some(lines), first_line_number: None }
    }

    pub(crate) fn update(lines: Vec<Value>, line_opt: Option<usize>) -> Self {
        UpdateOp {
            op: OpType::Update,
            n: lines.len(),
            lines: Some(lines),
            first_line_number: line_opt,
        }
    }
}

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "lowercase")]
enum OpType {
    #[serde(rename = "ins")]
    Insert,
    Skip,
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Segmentation of word boundaries. Note: this current implementation
//! is intended to work for code. Future work is to make it Unicode aware.

use xi_rope::{Cursor, Rope, RopeInfo};

pub struct WordCursor<'a> {
    inner: Cursor<'a, RopeInfo>,
}

impl<'a> WordCursor<'a> {
    pub fn new(text: &'a Rope, pos: usize) -> WordCursor<'a> {
        let inner = Cursor::new(text, pos);
        WordCursor { inner }
    }

    /// Get previous boundary, and set the cursor at the boundary found.
    pub fn prev_boundary(&mut self) -> Option<usize> {
        if let Some(ch) = self.inner.prev_codepoint() {
            let mut prop = get_word_property(ch);
            let mut candidate = self.inner.pos();
            while let Some(prev) = self.inner.prev_codepoint() {
                let prop_prev = get_word_property(prev);
                if classify_boundary(prop_prev, prop).is_start() {
                    break;
                }
                prop = prop_prev;
                candidate = self.inner.pos();
            }
            self.inner.set(candidate);
            return Some(candidate);
        }
        None
    }

    /// Get next boundary, and set the cursor at the boundary found.
    pub fn next_boundary(&mut self) -> Option<usize> {
        if let Some(ch) = self.inner.next_codepoint() {
            let mut prop = get_word_property(ch);
            let mut candidate = self.inner.pos();
            while let Some(next) = self.inner.next_codepoint() {
                let prop_next = get_word_property(next);
                if classify_boundary(prop, prop_next).is_end() {
                    break;
                }
                prop = prop_next;
                candidate = self.inner.pos();
            }
            self.inner.set(candidate);
            return Some(candidate);
        }
        None
    }

    /// Return the selection for the word containing the current cursor. The
    /// cursor is moved to the end of that selection.
    pub fn select_word(&mut self) -> (usize, usize) {
        let initial = self.inner.pos();
        let init_prop_after = self.inner.next_codepoint().map(get_word_property);
        self.inner.set(initial);
        let init_prop_before = self.inner.prev_codepoint().map(get_word_property);
        let mut start = initial;
        let init_boundary = if let (Some(pb), Some(pa)) = (init_prop_before, init_prop_after) {
            classify_boundary_initial(pb, pa)
        } else {
            WordBoundary::Both
        };
        let mut prop_after = init_prop_after;
        let mut prop_before = init_prop_before;
        if prop_after.is_none() {
            start = self.inner.pos();
            prop_after = prop_before;
            prop_before = self.inner.prev_codepoint().map(get_word_property);
        }
        while let (Some(pb), Some(pa)) = (prop_before, prop_after) {
            if start == initial {
                if init_boundary.is_start() {
                    break;
                }
            } else if !init_boundary.is_boundary() {
                if classify_boundary(pb, pa).is_boundary() {
                    break;
                }
            } else if classify_boundary(pb, pa).is_start() {
                break;
            }
            start = self.inner.pos();
            prop_after = prop_before;
            prop_before = self.inner.prev_codepoint().map(get_word_property);
        }
        self.inner.set(initial);
        let mut end = initial;
        prop_after = init_prop_after;
        prop_before = init_prop_before;
        if prop_before.is_none() {
            prop_before = self.inner.next_codepoint().map(get_word_property);
            end = self.inner.pos();
            prop_after = self.inner.next_codepoint().map(get_word_property);
        }
        while let (Some(pb), Some(pa)) = (prop_before, prop_after) {
            if end == initial {
                if init_boundary.is_end() {
                    break;
                }
            } else if !init_boundary.is_boundary() {
                if classify_boundary(pb, pa).is_boundary() {
                    break;
                }
            } else if classify_boundary(pb, pa).is_end() {
                break;
            }
            end = self.inner.pos();
            prop_before = prop_after;
            prop_after = self.inner.next_codepoint().map(get_word_property);
        }
        self.inner.set(end);
        (start, end)
    }
}

#[derive(PartialEq, Eq)]
enum WordBoundary {
    Interior,
    Start, // a boundary indicating the end of a word
    End,   // a boundary indicating the start of a word
    Both,
}

impl WordBoundary {
    fn is_start(&self) -> bool {
        *self == WordBoundary::Start || *self == WordBoundary::Both
    }

    fn is_end(&self) -> bool {
        *self == WordBoundary::End || *self == WordBoundary::Both
    }

    fn is_boundary(&self) -> bool {
        *self != WordBoundary::Interior
    }
}

fn classify_boundary(prev: WordProperty, next: WordProperty) -> WordBoundary {
    use self::WordBoundary::*;
    use self::WordProperty::*;
    match (prev, next) {
        (Lf, _) => Both,
        (_, Lf) => Both,
        (Space, Other) => Start,
        (Space, Punctuation) => Start,
        (Punctuation, Other) => Start,
        (Other, Space) => End,
        (Punctuation, Space) => End,
        (Other, Punctuation) => End,
        _ => Interior,
    }
}

fn classify_boundary_initial(prev: WordProperty, next: WordProperty) -> WordBoundary {
    use self::WordBoundary::*;
    use self::WordProperty::*;
    match (prev, next) {
        (Lf, Other) => Start,
        (Other, Lf) => End,
        (Lf, Space) => Interior,
        (Lf, Punctuation) => Interior,
        (Space, Lf) => Interior,
        (Punctuation, Lf) => Interior,
        (Space, Punctuation) => Interior,
        (Punctuation, Space) => Interior,
        _ => classify_boundary(prev, next),
    }
}

#[derive(Copy, Clone)]
enum WordProperty {
    Lf,
    Space,
    Punctuation,
    Other, // includes letters and all of non-ascii unicode
}

fn get_word_property(codepoint: char) -> WordProperty {
    if codepoint <= ' ' {
        // TODO: deal with \r
        if codepoint == '\n' {
            return WordProperty::Lf;
        }
        return WordProperty::Space;
    } else if codepoint <= '\u{3f}' {
        // Hardcoded: !"#$%&'()*+,-./:;<=>?
        if (0xfc00fffe00000000u64 >> (codepoint as u32)) & 1 != 0 {
            return WordProperty::Punctuation;
        }
    } else if codepoint <= '\u{7f}' {
        // Hardcoded: @[\]^`{|}~
        if (0x7800000178000001u64 >> ((codepoint as u32) & 0x3f)) & 1 != 0 {
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! The main RPC protocol, for communication between `xi-core` and the client.
//!
//! We rely on [Serde] for serialization and deserialization between
//! the JSON-RPC protocol and the types here.
//!
//! [Serde]: https://serde.rs

use std::path::PathBuf;

use serde::de::{self, Deserialize, Deserializer};
use serde::ser::{self, Serialize, Serializer};
use serde_json::{self, Value};

use crate::config::{ConfigDomainExternal, Table};
use crate::plugins::PlaceholderRpc;
use crate::syntax::LanguageId;
use crate::tabs::ViewId;
use crate::view::Size;

// =============================================================================
//  Command types
// =============================================================================

#[derive(Serialize, Deserialize, Debug, PartialEq)]
#[doc(hidden)]
pub struct EmptyStruct {}

/// The notifications which make up the base of the protocol.
///
/// # Note
///
/// For serialization, all identifiers are converted to "snake_case".
///
/// # Examples
///
/// The `close_view` command:
///
/// ```
/// # extern crate xi_core_lib as xi_core;
/// extern crate serde_json;
/// use crate::xi_core::rpc::CoreNotification;
///
/// let json = r#"{
///     "method": "close_view",
///     "params": { "view_id": "view-id-1" }
///     }"#;
///
/// let cmd: CoreNotification = serde_json::from_str(&json).unwrap();
/// match cmd {
///     CoreNotification::CloseView { .. } => (), // expected
///     other => panic!("Unexpected variant"),
/// }
/// ```
///
/// The `client_started` command:
///
/// ```
/// # extern crate xi_core_lib as xi_core;
/// extern crate serde_json;
/// use crate::xi_core::rpc::CoreNotification;
///
/// let json = r#"{
///     "method": "client_started",
///     "params": {}
///     }"#;
///
/// let cmd: CoreNotification = serde_json::from_str(&json).unwrap();
/// match cmd {
///     CoreNotification::ClientStarted { .. }  => (), // expected
///     other => panic!("Unexpected variant"),
/// }
/// ```
#[derive(Serialize, Deserialize, Debug, PartialEq)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
pub enum CoreNotification {
    /// The 'edit' namespace, for view-specific editor actions.
    ///
    /// The params object has internal `method` and `params` members,
    /// which are parsed into the appropriate `EditNotification`.
    ///
    /// # Note:
    ///
    /// All edit commands (notifications and requests) include in their
    /// inner params object a `view_id` field. On the xi-core side, we
    /// pull out this value during parsing, and use it for routing.
    ///
    /// For more on the edit commands, see [`EditNotification`] and
    /// [`EditRequest`].
    ///
    /// [`EditNotification`]: enum.EditNotification.html
    /// [`EditRequest`]: enum.EditRequest.html
    ///
    /// # Examples
    ///
    /// ```
    /// # extern crate xi_core_lib as xi_core;
    /// #[macro_use]
    /// extern crate serde_json;
    /// use crate::xi_core::rpc::*;
    /// # fn main() {
    /// let edit = EditCommand {
    ///     view_id: 1.into(),
    ///     cmd: EditNotification::Insert { chars: "hello!".into() },
    /// };
    /// let rpc = CoreNotification::Edit(edit);
    /// let expected = json!({
    ///     "method": "edit",
    ///     "params": {
    ///         "method": "insert",
    ///         "view_id": "view-id-1",
    ///         "params": {
    ///             "chars": "hello!",
    ///         }
    ///     }
    /// });
    /// assert_eq!(serde_json::to_value(&rpc).unwrap(), expected);
    /// # }
    /// ```
    Edit(EditCommand<EditNotification>),
    /// The 'plugin' namespace, for interacting with plugins.
    ///
    /// As with edit commands, the params object has is a nested RPC,
    /// with the name of the command included as the `command` field.
    ///
    /// (this should be changed to more accurately reflect the behaviour
    /// of the edit commands).
    ///
    /// For the available commands, see [`PluginNotification`].
    ///
    /// [`PluginNotification`]: enum.PluginNotification.html
    ///
    /// # Examples
    ///
    /// ```
    /// # extern crate xi_core_lib as xi_core;
    /// #[macro_use]
    /// extern crate serde_json;
    /// use crate::xi_core::rpc::*;
    /// # fn main() {
    /// let rpc = CoreNotification::Plugin(
    ///     PluginNotification::Start {
    ///         view_id: 1.into(),
    ///         plugin_name: "syntect".into(),
    ///     });
    ///
    /// let expected = json!({
    ///     "method": "plugin",
    ///     "params": {
    ///         "command": "start",
    ///         "view_id": "view-id-1",
    ///         "plugin_name": "syntect",
    ///     }
    /// });
    /// assert_eq!(serde_json::to_value(&rpc).unwrap(), expected);
    /// # }
    /// ```
    Plugin(PluginNotification),
    /// Tells `xi-core` to close the specified view.
    CloseView { view_id: ViewId },
    /// Tells `xi-core` to save the contents of the specified view's
    /// buffer to the specified path.
    Save { view_id: ViewId, file_path: String },
    /// Tells `xi-core` to set the theme.
    SetTheme { theme_name: String },
    /// Notifies `xi-core` that the client has started.
    ClientStarted {
        #[serde(default)]
        config_dir: Option<PathBuf>,
        /// Path to additional plugins, included by the client.
        #[serde(default)]
        client_extras_dir: Option<PathBuf>,
    },
    /// Updates the user's config for the given domain. Where keys in
    /// `changes` are `null`, those keys are cleared in the user config
    /// for that domain; otherwise the config is updated with the new
    /// value.
    ///
    /// Note: If the client is using file-based config, the only valid
    /// domain argument is `ConfigDomain::UserOverride(_)`, which
    /// represents non-persistent view-specific settings, such as when
    /// a user manually changes whitespace settings for a given view.
    ModifyUserConfig { domain: ConfigDomainExternal, changes: Table },
    /// Control whether the tracing infrastructure is enabled.
    /// This propagates to all peers that should respond by toggling its own
    /// infrastructure on/off.
    TracingConfig { enabled: bool },
    /// Save trace data to the given path.  The core will first send
    /// CoreRequest::CollectTrace to all peers to collect the samples.
    SaveTrace { destination: PathBuf, frontend_samples: Value },
    /// Tells `xi-core` to set the language id for the view.
    SetLanguage { view_id: ViewId, language_id: LanguageId },
}

/// The requests which make up the base of the protocol.
///
/// All requests expect a response.
///
/// # Examples
///
/// The `new_view` command:
///
/// ```
/// # extern crate xi_core_lib as xi_core;
/// extern crate serde_json;
/// use crate::xi_core::rpc::CoreRequest;
///
/// let json = r#"{
///     "method": "new_view",
///     "params": { "file_path": "~/my_very_fun_file.rs" }
///     }"#;
///
/// let cmd: CoreRequest = serde_json::from_str(&json).unwrap();
/// match cmd {
///     CoreRequest::NewView { .. } => (), // expected
///     other => panic!("Unexpected variant {:?}", other),
/// }
/// ```
#[derive(Serialize, Deserialize, Debug, PartialEq)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
pub enum CoreRequest {
    /// The 'edit' namespace, for view-specific requests.
    Edit(EditCommand<EditRequest>),
    /// Tells `xi-core` to create a new view. If the `file_path`
    /// argument is present, `xi-core` should attempt to open the file
    /// at that location.
    ///
    /// Returns the view identifier that should be used to interact
    /// with the newly created view.
    NewView { file_path: Option<String> },
    /// Returns the current collated config object for the given view.
    GetConfig { view_id: ViewId },
    /// Returns the contents of the buffer for a given `ViewId`.
    /// In the future this might also be used to return structured data (such
    /// as for printing).
    DebugGetContents { view_id: ViewId },
}

/// A helper type, which extracts the `view_id` field from edit
/// requests and notifications.
///
/// Edit requests and notifications have 'method', 'params', and
/// 'view_id' param members. We use this wrapper, which has custom
/// `Deserialize` and `Serialize` implementations, to pull out the
/// `view_id` field.
///
/// # Examples
///
/// ```
/// # extern crate xi_core_lib as xi_core;
/// extern crate serde_json;
/// use crate::xi_core::rpc::*;
///
/// let json = r#"{
///     "view_id": "view-id-1",
///     "method": "scroll",
///     "params": [0, 6]
///     }"#;
///
/// let cmd: EditCommand<EditNotification> = serde_json::from_str(&json).unwrap();
/// match cmd.cmd {
///     EditNotification::Scroll( .. ) => (), // expected
///     other => panic!("Unexpected variant {:?}", other),
/// }
/// ```
#[derive(Debug, Clone, PartialEq)]
pub struct EditCommand<T> {
    pub view_id: ViewId,
    pub cmd: T,
}

/// The smallest unit of text that a gesture can select
#[derive(Serialize, Deserialize, PartialEq, Eq, Debug, Copy, Clone)]
#[serde(rename_all = "snake_case")]
pub enum SelectionGranularity {
    /// Selects any point or character range
    Point,
    /// Selects one word at a time
    Word,
    /// Selects one line at a time
    Line,
}

/// An enum representing touch and mouse gestures applied to the text.
#[derive(Serialize, Deserialize, PartialEq, Eq, Debug, Copy, Clone)]
#[serde(rename_all = "snake_case")]
pub enum GestureType {
    Select { granularity: SelectionGranularity, multi: bool },
    SelectExtend { granularity: SelectionGranularity },
    Drag,

    // Deprecated
    PointSelect,
    ToggleSel,
    RangeSelect,
    LineSelect,
    WordSelect,
    MultiLineSelect,
    MultiWordSelect,
}

/// An inclusive range.
///
/// # Note:
///
/// Several core protocol commands use a params array to pass arguments
/// which are named, internally. this type use custom Serialize /
/// Deserialize impls to accommodate this.
#[derive(PartialEq, Eq, Debug, Clone)]
pub struct LineRange {
    pub first: i64,
    pub last: i64,
}

/// A mouse event. See the note for [`LineRange`].
///
/// [`LineRange`]: enum.LineRange.html
#[derive(PartialEq, Eq, Debug, Clone)]
pub struct MouseAction {
    pub line: u64,
    pub column: u64,
    pub flags: u64,
    pub click_count: Option<u64>,
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
pub struct Position {
    pub line: usize,
    pub column: usize,
}

/// Represents how the current selection is modified (used by find
/// operations).
#[derive(Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
#[serde(rename_all = "snake_case")]
pub enum SelectionModifier {
    None,
    Set,
    Add,
    AddRemovingCurrent,
}

impl Default for SelectionModifier {
    fn default() -> SelectionModifier {
        SelectionModifier::Set
    }
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug, Clone)]
#[serde(rename_all = "snake_case")]
pub struct FindQuery {
    pub id: Option<usize>,
    pub chars: String,
    pub case_sensitive: bool,
    #[serde(default)]
    pub regex: bool,
    #[serde(default)]
    pub whole_words: bool,
}

/// The edit-related notifications.
///
/// Alongside the [`EditRequest`] members, these commands constitute
/// the API for interacting with a particular window and document.
#[derive(Serialize, Deserialize, Debug, PartialEq)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
pub enum EditNotification {
    Insert {
        chars: String,
    },
    Paste {
        chars: String,
    },
    DeleteForward,
    DeleteBackward,
    DeleteWordForward,
    DeleteWordBackward,
    DeleteToEndOfParagraph,
    DeleteToBeginningOfLine,
    InsertNewline,
    InsertTab,
    MoveUp,
    MoveUpAndModifySelection,
    MoveDown,
    MoveDownAndModifySelection,
    MoveLeft,
    // synoynm for `MoveLeft`
    MoveBackward,
    MoveLeftAndModifySelection,
    MoveRight,
    // synoynm for `MoveRight`
    MoveForward,
    MoveRightAndModifySelection,
    MoveWordLeft,
    MoveWordLeftAndModifySelection,
    MoveWordRight,
    MoveWordRightAndModifySelection,
    MoveToBeginningOfParagraph,
    MoveToBeginningOfParagraphAndModifySelection,
    MoveToEndOfParagraph,
    MoveToEndOfParagraphAndModifySelection,
    MoveToLeftEndOfLine,
    MoveToLeftEndOfLineAndModifySelection,
    MoveToRightEndOfLine,
    MoveToRightEndOfLineAndModifySelection,
    MoveToBeginningOfDocument,
    MoveToBeginningOfDocumentAndModifySelection,
    MoveToEndOfDocument,
    MoveToEndOfDocumentAndModifySelection,
    ScrollPageUp,
    PageUpAndModifySelection,
    ScrollPageDown,
    PageDownAndModifySelection,
    SelectAll,
    AddSelectionAbove,
    AddSelectionBelow,
    Scroll(LineRange),
    Resize(Size),
    GotoLine {
        line: u64,
    },
    RequestLines(LineRange),
    Yank,
    Transpose,
    Click(MouseAction),
    Drag(MouseAction),
    Gesture {
        line: u64,
        col: u64,
        ty: GestureType,
    },
    Undo,
    Redo,
    Find {
        chars: String,
        case_sensitive: bool,
        #[serde(default)]
        regex: bool,
        #[serde(default)]
        whole_words: bool,
    },
    MultiFind {
        queries: Vec<FindQuery>,
    },
    FindNext {
        #[serde(default)]
        wrap_around: bool,
        #[serde(default)]
        allow_same: bool,
        #[serde(default)]
        modify_selection: SelectionModifier,
    },
    FindPrevious {
        #[serde(default)]
        wrap_around: bool,
        #[serde(default)]
        allow_same: bool,
        #[serde(default)]
        modify_selection: SelectionModifier,
    },
    FindAll,
    DebugRewrap,
    DebugWrapWidth,
    /// Prints the style spans present in the active selection.
    DebugPrintSpans,
    DebugToggleComment,
    Uppercase,
    Lowercase,
    Capitalize,
    Reindent,
    Indent,
    Outdent,
    /// Indicates whether find highlights should be rendered
    HighlightFind {
        visible: bool,
    },
    SelectionForFind {
        #[serde(default)]
        case_sensitive: bool,
    },
    Replace {
        chars: String,
        #[serde(default)]
        preserve_case: bool,
    },
    ReplaceNext,
    ReplaceAll,
    SelectionForReplace,
    RequestHover {
        request_id: usize,
        position: Option<Position>,
    },
    SelectionIntoLines,
    DuplicateLine,
    IncreaseNumber,
    DecreaseNumber,
    ToggleRecording {
        recording_name: Option<String>,
    },
    PlayRecording {
        recording_name: String,
    },
    ClearRecording {
        recording_name: String,
    },
    CollapseSelections,
}

/// The edit related requests.
#[derive(Serialize, Deserialize, Debug, PartialEq)]
#[serde(rename_all = "snake_case")]
#[serde(tag = "method", content = "params")]
pub enum EditRequest {
    /// Cuts the active selection, returning their contents,
    /// or `Null` if the selection was empty.
    Cut,
    /// Copies the active selection, returning their contents or
    /// or `Null` if the selection was empty.
    Copy,
}

/// The plugin related notifications.
#[derive(Serialize, Deserialize, Debug, PartialEq)]
#[serde(tag = "command")]
#[serde(rename_all = "snake_case")]
pub enum PluginNotification {
    Start { view_id: ViewId, plugin_name: String },
    Stop { view_id: ViewId, plugin_name: String },
    PluginRpc { view_id: ViewId, receiver: String, rpc: PlaceholderRpc },
}

// Serialize / Deserialize

impl<T: Serialize> Serialize for EditCommand<T> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let mut v = serde_json::to_value(&self.cmd).map_err(ser::Error::custom)?;
        v["view_id"] = json!(self.view_id);
        v.serialize(serializer)
    }
}

impl<'de, T: Deserialize<'de>> Deserialize<'de> for EditCommand<T> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        struct InnerId {
            view_id: ViewId,
        }

        let mut v = Value::deserialize(deserializer)?;
        let helper = InnerId::deserialize(&v).map_err(de::Error::custom)?;
        let InnerId { view_id } = helper;

        // if params are empty, remove them
        let remove_params = match v.get("params") {
            Some(&Value::Object(ref obj)) => obj.is_empty() && T::deserialize(v.clone()).is_err(),
            Some(&Value::Array(ref arr)) => arr.is_empty() && T::deserialize(v.clone()).is_err(),
            Some(_) => {
                return Err(de::Error::custom(
                    "'params' field, if present, must be object or array.",
                ));
            }
            None => false,
        };

        if remove_params {
            v.as_object_mut().map(|v| v.remove("params"));
        }

        let cmd = T::deserialize(v).map_err(de::Error::custom)?;
        Ok(EditCommand { view_id, cmd })
    }
}

impl Serialize for MouseAction {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        #[derive(Serialize)]
        struct Helper(u64, u64, u64, Option<u64>);

        let as_tup = Helper(self.line, self.column, self.flags, self.click_count);
        as_tup.serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for MouseAction {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let v: Vec<u64> = Vec::deserialize(deserializer)?;
        let click_count = if v.len() == 4 { Some(v[3]) } else { None };
        Ok(MouseAction { line: v[0], column: v[1], flags: v[2], click_count })
    }
}

impl Serialize for LineRange {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let as_tup = (self.first, self.last);
        as_tup.serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for LineRange {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        #[derive(Deserialize)]
        struct TwoTuple(i64, i64);

        let tup = TwoTuple::deserialize(deserializer)?;
        Ok(LineRange { first: tup.0, last: tup.1 })
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::tabs::ViewId;

    #[test]
    fn test_serialize_edit_command() {
        // Ensure that an EditCommand can be serialized and then correctly deserialized.
        let message: String = "hello world".into();
        let edit = EditCommand {
            view_id: ViewId(1),
            cmd: EditNotification::Insert { chars: message.clone() },
        };
        let json = serde_json::to_string(&edit).unwrap();
        let cmd: EditCommand<EditNotification> = serde_json::from_str(&json).unwrap();
        assert_eq!(cmd.view_id, edit.view_id);
        if let EditNotification::Insert { chars } = cmd.cmd {
            assert_eq!(chars, message);
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Module for searching text.

use std::cmp::{max, min};
use std::iter;

use crate::annotations::{AnnotationRange, AnnotationSlice, AnnotationType, ToAnnotation};
use crate::line_offset::LineOffset;
use crate::selection::{InsertDrift, SelRegion, Selection};
use crate::view::View;
use crate::word_boundaries::WordCursor;
use regex::{Regex, RegexBuilder};
use xi_rope::delta::DeltaRegion;
use xi_rope::find::{find, is_multiline_regex, CaseMatching};
use xi_rope::{Cursor, Interval, LinesMetric, Metric, Rope, RopeDelta};

const REGEX_SIZE_LIMIT: usize = 1000000;

/// Information about search queries and number of matches for find
#[derive(Serialize, Deserialize, Debug)]
pub struct FindStatus {
    /// Identifier for the current search query.
    id: usize,

    /// The current search query.
    chars: Option<String>,

    /// Whether the active search is case matching.
    case_sensitive: Option<bool>,

    /// Whether the search query is considered as regular expression.
    is_regex: Option<bool>,

    /// Query only matches whole words.
    whole_words: Option<bool>,

    /// Total number of matches.
    matches: usize,

    /// Line numbers which have find results.
    lines: Vec<usize>,
}

/// Contains logic to search text
pub struct Find {
    /// Uniquely identifies this search query.
    id: usize,

    /// The occurrences, which determine the highlights, have been updated.
    hls_dirty: bool,

    /// The currently active search string.
    search_string: Option<String>,

    /// The case matching setting for the currently active search.
    case_matching: CaseMatching,

    /// The search query should be considered as regular expression.
    regex: Option<Regex>,

    /// Query matches only whole words.
    whole_words: bool,

    /// The set of all known find occurrences (highlights).
    occurrences: Selection,
}

impl Find {
    pub fn new(id: usize) -> Find {
        Find {
            id,
            hls_dirty: true,
            search_string: None,
            case_matching: CaseMatching::CaseInsensitive,
            regex: None,
            whole_words: false,
            occurrences: Selection::new(),
        }
    }

    pub fn id(&self) -> usize {
        self.id
    }

    pub fn occurrences(&self) -> &Selection {
        &self.occurrences
    }

    pub fn hls_dirty(&self) -> bool {
        self.hls_dirty
    }

    pub fn find_status(&self, view: &View, text: &Rope, matches_only: bool) -> FindStatus {
        if matches_only {
            FindStatus {
                id: self.id,
                chars: None,
                case_sensitive: None,
                is_regex: None,
                whole_words: None,
                matches: self.occurrences.len(),
                lines: Vec::new(),
            }
        } else {
            FindStatus {
                id: self.id,
                chars: self.search_string.clone(),
                case_sensitive: Some(self.case_matching == CaseMatching::Exact),
                is_regex: Some(self.regex.is_some()),
                whole_words: Some(self.whole_words),
                matches: self.occurrences.len(),
                lines: self
                    .occurrences
                    .iter()
                    .map(|o| view.offset_to_line_col(text, o.min()).0 + 1)
                    .collect(),
            }
        }
    }

    pub fn set_hls_dirty(&mut self, is_dirty: bool) {
        self.hls_dirty = is_dirty
    }

    pub fn update_highlights(&mut self, text: &Rope, delta: &RopeDelta) {
        // update search highlights for changed regions
        if self.search_string.is_some() {
            // invalidate occurrences around deletion positions
            for DeltaRegion { old_offset, len, .. } in delta.iter_deletions() {
                self.occurrences.delete_range(old_offset, old_offset + len, false);
            }

            self.occurrences = self.occurrences.apply_delta(delta, false, InsertDrift::Default);

            // invalidate occurrences around insert positions
            for DeltaRegion { new_offset, len, .. } in delta.iter_inserts() {
                // also invalidate previous occurrence since it might expand after insertion
                // eg. for regex .* every insertion after match will be part of match
                self.occurrences.delete_range(
                    new_offset.saturating_sub(1),
                    new_offset + len,
                    false,
                );
            }

            // update find for the whole delta and everything after
            let (iv, new_len) = delta.summary();

            // get last valid occurrence that was unaffected by the delta
            let start = match self.occurrences.regions_in_range(0, iv.start()).last() {
                Some(reg) => reg.end,
                None => 0,
            };

            // invalidate all search results from the point of the last valid search result until ...
            let is_multiline = LinesMetric::next(self.search_string.as_ref().unwrap(), 0).is_some();

            if is_multiline || self.is_multiline_regex() {
                // ... the end of the file
                self.occurrences.delete_range(iv.start(), text.len(), false);
                self.update_find(text, start, text.len(), false);
            } else {
                // ... the end of the line including line break
                let mut cursor = Cursor::new(&text, iv.end() + new_len);

                let end_of_line = match cursor.next::<LinesMetric>() {
                    Some(end) => end,
                    None if cursor.pos() == text.len() => cursor.pos(),
                    _ => return,
                };

                self.occurrences.delete_range(iv.start(), end_of_line, false);
                self.update_find(text, start, end_of_line, false);
            }
        }
    }

    /// Returns `true` if the search query is a multi-line regex.
    pub(crate) fn is_multiline_regex(&self) -> bool {
        self.regex.is_some() && is_multiline_regex(self.search_string.as_ref().unwrap())
    }

    /// Unsets the search and removes all highlights from the view.
    pub fn unset(&mut self) {
        self.search_string = None;
        self.occurrences = Selection::new();
        self.hls_dirty = true;
    }

    /// Sets find parameters and search query. Returns `true` if parameters have been updated.
    /// Returns `false` to indicate that parameters haven't change.
    pub(crate) fn set_find(
        &mut self,
        search_string: &str,
        case_sensitive: bool,
        is_regex: bool,
        whole_words: bool,
    ) -> bool {
        if search_string.is_empty() {
            self.unset();
        }

        let case_matching =
            if case_sensitive { CaseMatching::Exact } else { CaseMatching::CaseInsensitive };

        if let Some(ref s) = self.search_string {
            if s == search_string
                && case_matching == self.case_matching
                && self.regex.is_some() == is_regex
                && self.whole_words == whole_words
            {
                // search parameters did not change
                return false;
            }
        }

        self.unset();

        self.search_string = Some(search_string.to_string());
        self.case_matching = case_matching;
        self.whole_words = whole_words;

        // create regex from untrusted input
        self.regex = match is_regex {
            false => None,
            true => RegexBuilder::new(search_string)
                .size_limit(REGEX_SIZE_LIMIT)
                .case_insensitive(case_matching == CaseMatching::CaseInsensitive)
                .build()
                .ok(),
        };

        true
    }

    /// Execute the search on the provided text in the range provided by `start` and `end`.
    pub fn update_find(&mut self, text: &Rope, start: usize, end: usize, include_slop: bool) {
        if self.search_string.is_none() {
            return;
        }

        // extend the search by twice the string length (twice, because case matching may increase
        // the length of an occurrence)
        let slop = if include_slop { self.search_string.as_ref().unwrap().len() * 2 } else { 0 };

        let search_string = self.search_string.as_ref().unwrap();

        // expand region to be able to find occurrences around the region's edges
        let expanded_start = max(start, slop) - slop;
        let expanded_end = min(end + slop, text.len());
        let from = text.at_or_prev_codepoint_boundary(expanded_start).unwrap_or(0);
        let to = text.at_or_next_codepoint_boundary(expanded_end).unwrap_or(text.len());
        let mut to_cursor = Cursor::new(&text, to);
        let _ = to_cursor.next_leaf();

        let sub_text = text.subseq(Interval::new(0, to_cursor.pos()));
        let mut find_cursor = Cursor::new(&sub_text, from);

        let mut raw_lines = text.lines_raw(from..to);

        while let Some(start) = find(
            &mut find_cursor,
            &mut raw_lines,
            self.case_matching,
            &search_string,
            self.regex.as_ref(),
        ) {
            let end = find_cursor.pos();

            if self.whole_words && !self.is_matching_whole_words(text, start, end) {
                raw_lines = text.lines_raw(find_cursor.pos()..to);
                continue;
            }

            let region = SelRegion::new(start, end);
            let (_, e) = self.occurrences.add_range_distinct(region);
            // in case of ambiguous search results (e.g. search "aba" in "ababa"),
            // the search result closer to the beginning of the file wins
            if e != end {
                // Skip the search result and keep the occurrence that is closer to
                // the beginning of the file. Re-align the cursor to the kept
                // occurrence
                find_cursor.set(e);
                raw_lines = text.lines_raw(find_cursor.pos()..to);
                continue;
            }

            // in case current cursor matches search result (for example query a* matches)
            // all cursor positions, then cursor needs to be increased so that search
            // continues at next position. Otherwise, search will result in overflow since
            // search will always repeat at current cursor position.
            if start == end {
                // determine whether end of text is reached and stop search or increase
                // cursor manually
                if end + 1 >= text.len() {
                    break;
                } else {
                    find_cursor.set(end + 1);
                }
            }

            // update line iterator so that line starts at current cursor position
            raw_lines = text.lines_raw(find_cursor.pos()..to);
        }

        self.hls_dirty = true;
    }

    /// Return the occurrence closest to the provided selection `sel`. If searched is reversed then
    /// the occurrence closest to the start of the selection is returned. `wrapped` indicates that
    /// if the end of the text is reached the search continues from the start.
    pub fn next_occurrence(
        &self,
        text: &Rope,
        reverse: bool,
        wrapped: bool,
        sel: &Selection,
    ) -> Option<SelRegion> {
        if self.occurrences.len() == 0 {
            return None;
        }

        let (sel_start, sel_end) = match sel.last() {
            Some(last) if last.is_caret() =>
            // if last selection is caret then allow the current position to be part of the occurrence
            {
                (last.min(), last.max())
            }
            Some(last) if !last.is_caret() =>
            // if the last selection is not a caret then continue searching after the caret
            {
                (last.min(), last.max() + 1)
            }
            _ => (0, 0),
        };

        if reverse {
            let next_occurrence = match sel_start.checked_sub(1) {
                Some(search_end) => self.occurrences.regions_in_range(0, search_end).last(),
                None => None,
            };

            if next_occurrence.is_none() && !wrapped {
                // get previous unselected occurrence
                return self
                    .occurrences
                    .regions_in_range(0, text.len())
                    .iter()
                    .cloned()
                    .filter(|o| sel.regions_in_range(o.min(), o.max()).is_empty())
                    .collect::<Vec<SelRegion>>()
                    .last()
                    .cloned();
            }

            next_occurrence.cloned()
        } else {
            let next_occurrence = self.occurrences.regions_in_range(sel_end, text.len()).first();

            if next_occurrence.is_none() && !wrapped {
                // get next unselected occurrence
                return self
                    .occurrences
                    .regions_in_range(0, text.len())
                    .iter()
                    .cloned()
                    .filter(|o| sel.regions_in_range(o.min(), o.max()).is_empty())
                    .collect::<Vec<SelRegion>>()
                    .first()
                    .cloned();
            }

            next_occurrence.cloned()
        }
    }

    /// Checks if the start and end of a match is matching whole words.
    fn is_matching_whole_words(&self, text: &Rope, start: usize, end: usize) -> bool {
        let mut word_end_cursor = WordCursor::new(text, end - 1);
        let mut word_start_cursor = WordCursor::new(text, start + 1);

        if let Some(start_boundary) = word_start_cursor.prev_boundary() {
            if start_boundary != start {
                return false;
            }
        }

        if let Some(end_boundary) = word_end_cursor.next_boundary() {
            if end_boundary != end {
                return false;
            }
        }

        true
    }
}

/// Implementing the `ToAnnotation` trait allows to convert finds to annotations.
impl ToAnnotation for Find {
    fn get_annotations(&self, interval: Interval, view: &View, text: &Rope) -> AnnotationSlice {
        let regions = self.occurrences.regions_in_range(interval.start(), interval.end());
        let ranges = regions
            .iter()
            .map(|region| {
                let (start_line, start_col) = view.offset_to_line_col(text, region.min());
                let (end_line, end_col) = view.offset_to_line_col(text, region.max());

                AnnotationRange { start_line, start_col, end_line, end_col }
            })
            .collect::<Vec<AnnotationRange>>();

        let payload = iter::repeat(json!({"id": self.id})).take(ranges.len()).collect::<Vec<_>>();

        AnnotationSlice::new(AnnotationType::Find, ranges, Some(payload))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use xi_rope::DeltaBuilder;

    #[test]
    fn find() {
        let base_text = Rope::from("hello world");
        let mut find = Find::new(1);
        find.set_find("world", false, false, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 1);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(6, 11)));
    }

    #[test]
    fn find_whole_words() {
        let base_text = Rope::from("hello world\n many worlds");
        let mut find = Find::new(1);
        find.set_find("world", false, false, true);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 1);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(6, 11)));
    }

    #[test]
    fn find_case_sensitive() {
        let base_text = Rope::from("hello world\n HELLO WORLD");
        let mut find = Find::new(1);
        find.set_find("world", true, false, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 1);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(6, 11)));
    }

    #[test]
    fn find_multiline() {
        let base_text = Rope::from("hello world\n HELLO WORLD");
        let mut find = Find::new(1);
        find.set_find("hello world\n HELLO", true, false, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 1);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(0, 18)));
    }

    #[test]
    fn find_regex() {
        let base_text = Rope::from("hello world\n HELLO WORLD");
        let mut find = Find::new(1);
        find.set_find("hello \\w+", false, true, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 2);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(0, 11)));

        find.set_find("h.llo", true, true, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 1);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(0, 5)));

        find.set_find(".*", false, true, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 3);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(0, 11)));
    }

    #[test]
    fn find_regex_multiline() {
        let base_text = Rope::from("hello world\n HELLO WORLD");
        let mut find = Find::new(1);
        find.set_find("(.*\n.*)+", true, true, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 1);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(0, 12)));
    }

    #[test]
    fn find_multiline_regex() {
        let mut find = Find::new(1);
        find.set_find("a", true, true, false);
        assert_eq!(find.is_multiline_regex(), false);
        find.set_find(".*", true, true, false);
        assert_eq!(find.is_multiline_regex(), false);
        find.set_find("\\n", true, true, false);
        assert_eq!(find.is_multiline_regex(), true);
    }

    #[test]
    fn find_slop() {
        let base_text = Rope::from("aaa bbb aaa bbb aaa x");
        let mut find = Find::new(1);
        find.set_find("aaa", true, true, false);
        find.update_find(&base_text, 2, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 2);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(8, 11)));

        find.update_find(&base_text, 3, base_text.len(), true);
        assert_eq!(find.occurrences().len(), 3);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(0, 3)));
    }

    #[test]
    fn find_next_occurrence() {
        let base_text = Rope::from("aaa bbb aaa bbb aaa x");
        let mut find = Find::new(1);
        find.set_find("aaa", true, true, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 3);
        assert_eq!(
            find.next_occurrence(&base_text, false, false, &Selection::new()),
            Some(SelRegion::new(0, 3))
        );

        let mut prev_selection = Selection::new();
        prev_selection.add_region(SelRegion::new(0, 3));
        assert_eq!(
            find.next_occurrence(&base_text, false, false, &prev_selection),
            Some(SelRegion::new(8, 11))
        );

        let mut prev_selection = Selection::new();
        prev_selection.add_region(SelRegion::new(19, 19));
        assert_eq!(
            find.next_occurrence(&base_text, false, true, &prev_selection),
            Some(SelRegion::new(16, 19))
        );

        let mut prev_selection = Selection::new();
        prev_selection.add_region(SelRegion::new(20, 20));
        assert_eq!(
            find.next_occurrence(&base_text, false, false, &prev_selection),
            Some(SelRegion::new(0, 3))
        );
    }

    #[test]
    fn find_previous_occurrence() {
        let base_text = Rope::from("aaa bbb aaa bbb aaa x");
        let mut find = Find::new(1);
        find.set_find("aaa", true, true, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 3);
        assert_eq!(
            find.next_occurrence(&base_text, true, false, &Selection::new()),
            Some(SelRegion::new(16, 19))
        );

        let mut prev_selection = Selection::new();
        prev_selection.add_region(SelRegion::new(20, 20));
        assert_eq!(find.next_occurrence(&base_text, true, true, &Selection::new()), None);
    }

    #[test]
    fn unset_find() {
        let base_text = Rope::from("aaa bbb aaa bbb aaa x");
        let mut find = Find::new(1);
        find.set_find("aaa", true, true, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        assert_eq!(find.occurrences().len(), 3);
        find.unset();
        assert_eq!(find.occurrences().len(), 0);
    }

    #[test]
    fn update_find_edit() {
        let base_text = Rope::from("a b a c");
        let mut find = Find::new(1);
        find.set_find("a", false, false, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        let mut builder = DeltaBuilder::new(base_text.len());
        builder.replace(0..0, "a ".into());

        assert_eq!(find.occurrences().len(), 2);
        assert_eq!(find.occurrences().first(), Some(&SelRegion::new(0, 1)));
        assert_eq!(find.occurrences().last(), Some(&SelRegion::new(4, 5)));
    }

    #[test]
    fn update_find_multiline_edit() {
        let base_text = Rope::from("x\n a\n b\n a\n c");
        let mut find = Find::new(1);
        find.set_find("a", false, false, false);
        find.update_find(&base_text, 0, base_text.len(), false);
        let mut builder = DeltaBuilder::new(base_text.len());
        builder.replace(2..2, " a\n b\n a\n".into());

// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Compute line wrapping breaks for text.

use std::cmp::Ordering;
use std::ops::Range;

use xi_rope::breaks::{BreakBuilder, Breaks, BreaksInfo, BreaksMetric};
use xi_rope::spans::Spans;
use xi_rope::{Cursor, Interval, LinesMetric, Rope, RopeDelta, RopeInfo};
use xi_trace::trace_block;
use xi_unicode::LineBreakLeafIter;

use crate::client::Client;
use crate::styles::{Style, N_RESERVED_STYLES};
use crate::width_cache::{CodepointMono, Token, WidthCache, WidthMeasure};

/// The visual width of the buffer for the purpose of word wrapping.
#[derive(Clone, Copy, Debug, PartialEq)]
pub(crate) enum WrapWidth {
    /// No wrapping in effect.
    None,

    /// Width in bytes (utf-8 code units).
    ///
    /// Only works well for ASCII, will probably not be maintained long-term.
    Bytes(usize),

    /// Width in px units, requiring measurement by the front-end.
    Width(f64),
}

impl Default for WrapWidth {
    fn default() -> Self {
        WrapWidth::None
    }
}

impl WrapWidth {
    fn differs_in_kind(self, other: WrapWidth) -> bool {
        use self::WrapWidth::*;
        match (self, other) {
            (None, None) | (Bytes(_), Bytes(_)) | (Width(_), Width(_)) => false,
            _else => true,
        }
    }
}

/// A range to be rewrapped.
type Task = Interval;

/// Tracks state related to visual lines.
#[derive(Default)]
pub(crate) struct Lines {
    breaks: Breaks,
    wrap: WrapWidth,
    /// Aka the 'frontier'; ranges of lines that still need to be wrapped.
    work: Vec<Task>,
}

pub(crate) struct VisualLine {
    pub(crate) interval: Interval,
    /// The logical line number for this line. Only present when this is the
    /// first visual line in a logical line.
    pub(crate) line_num: Option<usize>,
}

impl VisualLine {
    fn new<I: Into<Interval>, L: Into<Option<usize>>>(iv: I, line: L) -> Self {
        VisualLine { interval: iv.into(), line_num: line.into() }
    }
}

/// Describes what has changed after a batch of word wrapping; this is used
/// for minimal invalidation.
pub(crate) struct InvalLines {
    pub(crate) start_line: usize,
    pub(crate) inval_count: usize,
    pub(crate) new_count: usize,
}

/// Detailed information about changes to linebreaks, used to generate
/// invalidation information. The logic behind invalidation is different
/// depending on whether we're updating breaks after an edit, or continuing
/// a bulk rewrapping task. This is shared between the two cases, and contains
/// the information relevant to both of them.
struct WrapSummary {
    start_line: usize,
    /// Total number of invalidated lines; this is meaningless in the after_edit case.
    inval_count: usize,
    /// The total number of new (hard + soft) breaks in the wrapped region.
    new_count: usize,
    /// The number of new soft breaks.
    new_soft: usize,
}

impl Lines {
    pub(crate) fn set_wrap_width(&mut self, text: &Rope, wrap: WrapWidth) {
        self.work.clear();
        self.add_task(0..text.len());
        if self.breaks.is_empty() || self.wrap.differs_in_kind(wrap) {
            // we keep breaks while resizing, for more efficient invalidation
            self.breaks = Breaks::new_no_break(text.len());
        }
        self.wrap = wrap;
    }

    fn add_task<T: Into<Interval>>(&mut self, iv: T) {
        let iv = iv.into();
        if iv.is_empty() {
            return;
        }

        // keep everything that doesn't intersect. merge things that do.
        let split_idx = match self.work.iter().position(|&t| !t.intersect(iv).is_empty()) {
            Some(idx) => idx,
            None => {
                self.work.push(iv);
                return;
            }
        };

        let to_update = self.work.split_off(split_idx);
        let mut new_task = Some(iv);

        for t in &to_update {
            match new_task.take() {
                Some(new) if !t.intersect(new).is_empty() => new_task = Some(t.union(new)),
                Some(new) => {
                    self.work.push(new);
                    self.work.push(*t);
                }
                None => self.work.push(*t),
            }
        }
        if let Some(end) = new_task.take() {
            self.work.push(end);
        }
    }

    pub(crate) fn is_converged(&self) -> bool {
        self.wrap == WrapWidth::None || self.work.is_empty()
    }

    /// Returns `true` if this interval is part of an incomplete task.
    pub(crate) fn interval_needs_wrap(&self, iv: Interval) -> bool {
        self.work.iter().any(|t| !t.intersect(iv).is_empty())
    }

    pub(crate) fn visual_line_of_offset(&self, text: &Rope, offset: usize) -> usize {
        let mut line = text.line_of_offset(offset);
        if self.wrap != WrapWidth::None {
            line += self.breaks.count::<BreaksMetric>(offset)
        }
        line
    }

    /// Returns the byte offset corresponding to the line `line`.
    pub(crate) fn offset_of_visual_line(&self, text: &Rope, line: usize) -> usize {
        match self.wrap {
            WrapWidth::None => {
                // sanitize input
                let line = line.min(text.measure::<LinesMetric>() + 1);
                text.offset_of_line(line)
            }
            _ => {
                let mut cursor = MergedBreaks::new(text, &self.breaks);
                cursor.offset_of_line(line)
            }
        }
    }

    /// Returns an iterator over [`VisualLine`]s, starting at (and including)
    /// `start_line`.
    pub(crate) fn iter_lines<'a>(
        &'a self,
        text: &'a Rope,
        start_line: usize,
    ) -> impl Iterator<Item = VisualLine> + 'a {
        let mut cursor = MergedBreaks::new(text, &self.breaks);
        let offset = cursor.offset_of_line(start_line);
        let logical_line = text.line_of_offset(offset) + 1;
        cursor.set_offset(offset);
        VisualLines { offset, cursor, len: text.len(), logical_line, eof: false }
    }

    /// Returns the next task, prioritizing the currently visible region.
    /// Does not modify the task list; this is done after the task runs.
    fn get_next_task(&self, visible_offset: usize) -> Option<Task> {
        // the first task t where t.end > visible_offset is the only task
        // that might contain the visible region.
        self.work
            .iter()
            .find(|t| t.end > visible_offset)
            .map(|t| Task::new(t.start.max(visible_offset), t.end))
            .or(self.work.last().cloned())
    }

    fn update_tasks_after_wrap<T: Into<Interval>>(&mut self, wrapped_iv: T) {
        if self.work.is_empty() {
            return;
        }
        let wrapped_iv = wrapped_iv.into();

        let mut work = Vec::new();
        for task in &self.work {
            if task.is_before(wrapped_iv.start) || task.is_after(wrapped_iv.end) {
                work.push(*task);
                continue;
            }
            if wrapped_iv.start > task.start {
                work.push(task.prefix(wrapped_iv));
            }
            if wrapped_iv.end < task.end {
                work.push(task.suffix(wrapped_iv));
            }
        }
        self.work = work;
    }

    /// Adjust offsets for any tasks after an edit.
    fn patchup_tasks<T: Into<Interval>>(&mut self, iv: T, new_len: usize) {
        let iv = iv.into();
        let mut new_work = Vec::new();

        for task in &self.work {
            if task.is_before(iv.start) {
                new_work.push(*task);
            } else if task.contains(iv.start) {
                let head = task.prefix(iv);
                let tail_end = iv.start.max((task.end + new_len).saturating_sub(iv.size()));
                let tail = Interval::new(iv.start, tail_end);
                new_work.push(head);
                new_work.push(tail);
            } else {
                // take task - our edit interval, then translate it (- old_size, + new_size)
                let tail = task.suffix(iv).translate(new_len).translate_neg(iv.size());
                new_work.push(tail);
            }
        }
        new_work.retain(|iv| !iv.is_empty());
        self.work.clear();
        for task in new_work {
            if let Some(prev) = self.work.last_mut() {
                if prev.end >= task.start {
                    *prev = prev.union(task);
                    continue;
                }
            }
            self.work.push(task);
        }
    }

    /// Do a chunk of wrap work, if any exists.
    pub(crate) fn rewrap_chunk(
        &mut self,
        text: &Rope,
        width_cache: &mut WidthCache,
        client: &Client,
        _spans: &Spans<Style>,
        visible_lines: Range<usize>,
    ) -> Option<InvalLines> {
        if self.is_converged() {
            None
        } else {
            let summary = self.do_wrap_task(text, width_cache, client, visible_lines, None);
            let WrapSummary { start_line, inval_count, new_count, .. } = summary;
            Some(InvalLines { start_line, inval_count, new_count })
        }
    }

    /// Updates breaks after an edit. Returns `InvalLines`, for minimal invalidation,
    /// when possible.
    pub(crate) fn after_edit(
        &mut self,
        text: &Rope,
        old_text: &Rope,
        delta: &RopeDelta,
        width_cache: &mut WidthCache,
        client: &Client,
        visible_lines: Range<usize>,
    ) -> Option<InvalLines> {
        let (iv, newlen) = delta.summary();

        let logical_start_line = text.line_of_offset(iv.start);
        let old_logical_end_line = old_text.line_of_offset(iv.end) + 1;
        let new_logical_end_line = text.line_of_offset(iv.start + newlen) + 1;
        let old_logical_end_offset = old_text.offset_of_line(old_logical_end_line);
        let old_hard_count = old_logical_end_line - logical_start_line;
        let new_hard_count = new_logical_end_line - logical_start_line;

        //TODO: we should be able to avoid wrapping the whole para in most cases,
        // but the logic is trickier.
        let prev_break = text.offset_of_line(logical_start_line);
        let next_hard_break = text.offset_of_line(new_logical_end_line);

        // count the soft breaks in the region we will rewrap, before we update them.
        let inval_soft = self.breaks.count::<BreaksMetric>(old_logical_end_offset)
            - self.breaks.count::<BreaksMetric>(prev_break);

        // update soft breaks, adding empty spans in the edited region
        let mut builder = BreakBuilder::new();
        builder.add_no_break(newlen);
        self.breaks.edit(iv, builder.build());
        self.patchup_tasks(iv, newlen);

        if self.wrap == WrapWidth::None {
            return Some(InvalLines {
                start_line: logical_start_line,
                inval_count: old_hard_count,
                new_count: new_hard_count,
            });
        }

        let new_task = prev_break..next_hard_break;
        self.add_task(new_task);

        // possible if the whole buffer is deleted, e.g
        if !self.work.is_empty() {
            let summary = self.do_wrap_task(text, width_cache, client, visible_lines, None);
            let WrapSummary { start_line, new_soft, .. } = summary;
            // if we haven't converged after this update we can't do minimal invalidation
            // because we don't have complete knowledge of the new breaks state.
            if self.is_converged() {
                let inval_count = old_hard_count + inval_soft;
                let new_count = new_hard_count + new_soft;
                Some(InvalLines { start_line, new_count, inval_count })
            } else {
                None
            }
        } else {
            None
        }
    }

    fn do_wrap_task(
        &mut self,
        text: &Rope,
        width_cache: &mut WidthCache,
        client: &Client,
        visible_lines: Range<usize>,
        max_lines: Option<usize>,
    ) -> WrapSummary {
        use self::WrapWidth::*;
        let _t = trace_block("Lines::do_wrap_task", &["core"]);
        // 'line' is a poor unit here; could do some fancy Duration thing?
        const MAX_LINES_PER_BATCH: usize = 500;

        let mut cursor = MergedBreaks::new(text, &self.breaks);
        let visible_off = cursor.offset_of_line(visible_lines.start);
        let logical_off = text.offset_of_line(text.line_of_offset(visible_off));

        // task.start is a hard break; task.end is a boundary or EOF.
        let task = self.get_next_task(logical_off).unwrap();
        cursor.set_offset(task.start);
        debug_assert_eq!(cursor.offset, task.start, "task_start must be valid offset");

        let mut ctx = match self.wrap {
            Bytes(b) => RewrapCtx::new(text, &CodepointMono, b as f64, width_cache, task.start),
            Width(w) => RewrapCtx::new(text, client, w, width_cache, task.start),
            None => unreachable!(),
        };

        let start_line = cursor.cur_line;
        let max_lines = max_lines.unwrap_or(MAX_LINES_PER_BATCH);
        // always wrap at least a screen worth of lines (unless we converge earlier)
        let batch_size = max_lines.max(visible_lines.end - visible_lines.start);

        let mut builder = BreakBuilder::new();
        let mut lines_wrapped = 0;
        let mut pos = task.start;
        let mut old_next_maybe = cursor.next();

        loop {
            if let Some(new_next) = ctx.wrap_one_line(pos) {
                while let Some(old_next) = old_next_maybe {
                    if old_next >= new_next {
                        break; // just advance old cursor and continue
                    }
                    old_next_maybe = cursor.next();
                }

                let is_hard = cursor.offset == new_next && cursor.is_hard_break();
                if is_hard {
                    builder.add_no_break(new_next - pos);
                } else {
                    builder.add_break(new_next - pos);
                }
                lines_wrapped += 1;
                pos = new_next;
                if pos == task.end || (lines_wrapped > batch_size && is_hard) {
                    break;
                }
            } else {
                // EOF
                builder.add_no_break(text.len() - pos);
                break;
            }
        }

        let breaks = builder.build();
        let end = task.start + breaks.len();

        // this is correct *only* when an edit has not occured.
        let inval_soft =
            self.breaks.count::<BreaksMetric>(end) - self.breaks.count::<BreaksMetric>(task.start);

        let hard_count = 1 + text.line_of_offset(end) - text.line_of_offset(task.start);

        let inval_count = inval_soft + hard_count;
        let new_soft = breaks.measure::<BreaksMetric>();
        let new_count = new_soft + hard_count;

        let iv = Interval::new(task.start, end);
        self.breaks.edit(iv, breaks);
        self.update_tasks_after_wrap(iv);

        WrapSummary { start_line, inval_count, new_count, new_soft }
    }

    pub fn logical_line_range(&self, text: &Rope, line: usize) -> (usize, usize) {
        let mut cursor = MergedBreaks::new(text, &self.breaks);
        let offset = cursor.offset_of_line(line);
        let logical_line = text.line_of_offset(offset);
        let start_logical_line_offset = text.offset_of_line(logical_line);
        let end_logical_line_offset = text.offset_of_line(logical_line + 1);
        (start_logical_line_offset, end_logical_line_offset)
    }

    #[cfg(test)]
    fn for_testing(text: &Rope, wrap: WrapWidth) -> Lines {
        let mut lines = Lines::default();
        lines.set_wrap_width(text, wrap);
        lines
    }

    #[cfg(test)]
    fn rewrap_all(&mut self, text: &Rope, client: &Client, width_cache: &mut WidthCache) {
        if !self.is_converged() {
            self.do_wrap_task(text, width_cache, client, 0..10, Some(usize::max_value()));
        }
    }
}

/// A potential opportunity to insert a break. In this representation, the widths
/// have been requested (in a batch request) but are not necessarily known until
/// the request is issued.
struct PotentialBreak {
    /// The offset within the text of the end of the word.
    pos: usize,
    /// A token referencing the width of the word, to be resolved in the width cache.
    tok: Token,
    /// Whether the break is a hard break or a soft break.
    hard: bool,
}

/// State for a rewrap in progress
struct RewrapCtx<'a> {
    text: &'a Rope,
    lb_cursor: LineBreakCursor<'a>,
    lb_cursor_pos: usize,
    width_cache: &'a mut WidthCache,
    client: &'a dyn WidthMeasure,
    pot_breaks: Vec<PotentialBreak>,
    /// Index within `pot_breaks`
    pot_break_ix: usize,
    max_width: f64,
}

// This constant should be tuned so that the RPC takes about 1ms. Less than that,
// RPC overhead becomes significant. More than that, interactivity suffers.
const MAX_POT_BREAKS: usize = 10_000;

impl<'a> RewrapCtx<'a> {
    fn new(
        text: &'a Rope,
        //_style_spans: &Spans<Style>,  client: &'a T,
        client: &'a dyn WidthMeasure,
        max_width: f64,
        width_cache: &'a mut WidthCache,
        start: usize,
    ) -> RewrapCtx<'a> {
        let lb_cursor_pos = start;
        let lb_cursor = LineBreakCursor::new(text, start);
        RewrapCtx {
            text,
            lb_cursor,
            lb_cursor_pos,
            width_cache,
            client,
            pot_breaks: Vec::new(),
            pot_break_ix: 0,
            max_width,
        }
    }

    fn refill_pot_breaks(&mut self) {
        let mut req = self.width_cache.batch_req();

        self.pot_breaks.clear();
        self.pot_break_ix = 0;
        let mut pos = self.lb_cursor_pos;
        while pos < self.text.len() && self.pot_breaks.len() < MAX_POT_BREAKS {
            let (next, hard) = self.lb_cursor.next();
            let word = self.text.slice_to_cow(pos..next);
            let tok = req.request(N_RESERVED_STYLES, &word);
            pos = next;
            self.pot_breaks.push(PotentialBreak { pos, tok, hard });
        }
        req.resolve_pending(self.client).unwrap();
        self.lb_cursor_pos = pos;
    }

    /// Compute the next break, assuming `start` is a valid break.
    ///
    /// Invariant: `start` corresponds to the start of the word referenced by `pot_break_ix`.
    fn wrap_one_line(&mut self, start: usize) -> Option<usize> {
        let mut line_width = 0.0;
        let mut pos = start;
        while pos < self.text.len() {
            if self.pot_break_ix >= self.pot_breaks.len() {
                self.refill_pot_breaks();
            }
            let pot_break = &self.pot_breaks[self.pot_break_ix];
            let width = self.width_cache.resolve(pot_break.tok);
            if !pot_break.hard {
                if line_width == 0.0 && width >= self.max_width {
                    // we don't care about soft breaks at EOF
                    if pot_break.pos == self.text.len() {
                        return None;
                    }
                    self.pot_break_ix += 1;
                    return Some(pot_break.pos);
                }
                line_width += width;
                if line_width > self.max_width {
                    return Some(pos);
                }
                self.pot_break_ix += 1;
                pos = pot_break.pos;
            } else if line_width != 0. && width + line_width > self.max_width {
                // if this is a hard break but we would have broken at the previous
                // pos otherwise, we still break at the previous pos.
                return Some(pos);
            } else {
                self.pot_break_ix += 1;
                return Some(pot_break.pos);
            }
        }
        None
    }
}

struct LineBreakCursor<'a> {
    inner: Cursor<'a, RopeInfo>,
    lb_iter: LineBreakLeafIter,
    last_byte: u8,
}

impl<'a> LineBreakCursor<'a> {
    fn new(text: &'a Rope, pos: usize) -> LineBreakCursor<'a> {
        let inner = Cursor::new(text, pos);
        let lb_iter = match inner.get_leaf() {
            Some((s, offset)) => LineBreakLeafIter::new(s.as_str(), offset),
            _ => LineBreakLeafIter::default(),
        };
        LineBreakCursor { inner, lb_iter, last_byte: 0 }
    }

    // position and whether break is hard; up to caller to stop calling after EOT
    fn next(&mut self) -> (usize, bool) {
        let mut leaf = self.inner.get_leaf();
        loop {
            match leaf {
                Some((s, offset)) => {
                    let (next, hard) = self.lb_iter.next(s.as_str());
                    if next < s.len() {
                        return (self.inner.pos() - offset + next, hard);
                    }
                    if !s.is_empty() {
                        self.last_byte = s.as_bytes()[s.len() - 1];
                    }
                    leaf = self.inner.next_leaf();
                }
                // A little hacky but only reports last break as hard if final newline
                None => return (self.inner.pos(), self.last_byte == b'\n'),
            }
        }
    }
}

struct VisualLines<'a> {
    cursor: MergedBreaks<'a>,
    offset: usize,
    /// The current logical line number.
    logical_line: usize,
    len: usize,
    eof: bool,
}

impl<'a> Iterator for VisualLines<'a> {
    type Item = VisualLine;

    fn next(&mut self) -> Option<VisualLine> {
        let line_num = if self.cursor.is_hard_break() { Some(self.logical_line) } else { None };
        let next_end_bound = match self.cursor.next() {
            Some(b) => b,
            None if self.eof => return None,
            _else => {
                self.eof = true;
                self.len
            }
        };
        let result = VisualLine::new(self.offset..next_end_bound, line_num);
        if self.cursor.is_hard_break() {
            self.logical_line += 1;
        }
        self.offset = next_end_bound;
        Some(result)
    }
}

/// A cursor over both hard and soft breaks. Hard breaks are retrieved from
/// the rope; the soft breaks are stored independently; this interleaves them.
///
/// # Invariants:
///
/// `self.offset` is always a valid break in one of the cursors, unless
/// at 0 or EOF.
///
/// `self.offset == self.text.pos().min(self.soft.pos())`.
struct MergedBreaks<'a> {
    text: Cursor<'a, RopeInfo>,
    soft: Cursor<'a, BreaksInfo>,
    offset: usize,
    /// Starting from zero, how many calls to `next` to get to `self.offset`?
    cur_line: usize,
    total_lines: usize,
    /// Total length, in base units
    len: usize,
}

impl<'a> Iterator for MergedBreaks<'a> {
    type Item = usize;

    fn next(&mut self) -> Option<usize> {
        if self.text.pos() == self.offset && !self.at_eof() {
            // don't iterate past EOF, or we can't get the leaf and check for \n
            self.text.next::<LinesMetric>();
        }
        if self.soft.pos() == self.offset {
            self.soft.next::<BreaksMetric>();
        }
        let prev_off = self.offset;
        self.offset = self.text.pos().min(self.soft.pos());

        let eof_without_newline = self.offset > 0 && self.at_eof() && self.eof_without_newline();
        if self.offset == prev_off || eof_without_newline {
            None
        } else {
            self.cur_line += 1;
            Some(self.offset)
        }
    }
}

// arrived at this by just trying out a bunch of values ¯\_(ツ)_/¯
/// how far away a line can be before we switch to a binary search
const MAX_LINEAR_DIST: usize = 20;

impl<'a> MergedBreaks<'a> {
    fn new(text: &'a Rope, breaks: &'a Breaks) -> Self {
        debug_assert_eq!(text.len(), breaks.len());
        let text = Cursor::new(text, 0);
        let soft = Cursor::new(breaks, 0);
        let total_lines =
            text.root().measure::<LinesMetric>() + soft.root().measure::<BreaksMetric>() + 1;
        let len = text.total_len();
        MergedBreaks { text, soft, offset: 0, cur_line: 0, total_lines, len }
    }

    /// Sets the `self.offset` to the first valid break immediately at or preceding `offset`,
    /// and restores invariants.
    fn set_offset(&mut self, offset: usize) {
        self.text.set(offset);
        self.soft.set(offset);
        if offset > 0 {
            if self.text.at_or_prev::<LinesMetric>().is_none() {
                self.text.set(0);
            }
            if self.soft.at_or_prev::<BreaksMetric>().is_none() {
                self.soft.set(0);
            }
        }

        // self.offset should be at the first valid break immediately preceding `offset`, or 0.
        // the position of the non-break cursor should be > than that of the break cursor, or EOF.
        match self.text.pos().cmp(&self.soft.pos()) {
            Ordering::Less => {
                self.text.next::<LinesMetric>();
            }
            Ordering::Greater => {
                self.soft.next::<BreaksMetric>();
            }
            Ordering::Equal => assert!(self.text.pos() == 0),
        }

        self.offset = self.text.pos().min(self.soft.pos());
        self.cur_line = merged_line_of_offset(self.text.root(), self.soft.root(), self.offset);
    }

    fn offset_of_line(&mut self, line: usize) -> usize {
        match line {
            0 => 0,
            l if l >= self.total_lines => self.text.total_len(),
            l if l == self.cur_line => self.offset,
            l if l > self.cur_line && l - self.cur_line < MAX_LINEAR_DIST => {
                self.offset_of_line_linear(l)
            }
            other => self.offset_of_line_bsearch(other),
        }
    }

    fn offset_of_line_linear(&mut self, line: usize) -> usize {
        assert!(line > self.cur_line);
        let dist = line - self.cur_line;
        self.nth(dist - 1).unwrap_or(self.len)
    }

    fn offset_of_line_bsearch(&mut self, line: usize) -> usize {
        let mut range = 0..self.len;
        loop {
            let pivot = range.start + (range.end - range.start) / 2;
            self.set_offset(pivot);

            match self.cur_line {
                l if l == line => break self.offset,
                l if l > line => range = range.start..pivot,
                l if line - l > MAX_LINEAR_DIST => range = pivot..range.end,
                _else => break self.offset_of_line_linear(line),
            }
        }
    }

    fn is_hard_break(&self) -> bool {
        self.offset == self.text.pos()
    }

    fn at_eof(&self) -> bool {
        self.offset == self.len
    }

    fn eof_without_newline(&mut self) -> bool {
        debug_assert!(self.at_eof());
        self.text.set(self.len);
        self.text.get_leaf().map(|(l, _)| l.as_bytes().last() != Some(&b'\n')).unwrap()
    }
}

fn merged_line_of_offset(text: &Rope, soft: &Breaks, offset: usize) -> usize {
    text.count::<LinesMetric>(offset) + soft.count::<BreaksMetric>(offset)
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::borrow::Cow;
    use std::iter;
    use xi_rpc::test_utils::DummyPeer;

    fn make_lines(text: &Rope, width: f64) -> Lines {
        let client = Client::new(Box::new(DummyPeer));
        let mut width_cache = WidthCache::new();
        let wrap = WrapWidth::Bytes(width as usize);
        let mut lines = Lines::for_testing(text, wrap);
        lines.rewrap_all(text, &client, &mut width_cache);
        lines
    }

    fn render_breaks<'a>(text: &'a Rope, lines: &Lines) -> Vec<Cow<'a, str>> {
        let result = lines.iter_lines(text, 0).map(|l| text.slice_to_cow(l.interval)).collect();
        result
    }

    fn debug_breaks<'a>(text: &'a Rope, width: f64) -> Vec<Cow<'a, str>> {
        let lines = make_lines(text, width);
        render_breaks(text, &lines)
    }

    #[test]
    fn column_breaks_basic() {
        let text: Rope = "every wordthing should getits own".into();
        let result = debug_breaks(&text, 8.0);
        assert_eq!(result, vec!["every ", "wordthing ", "should ", "getits ", "own",]);
    }

    #[test]
    fn column_breaks_trailing_newline() {
        let text: Rope = "every wordthing should getits ow\n".into();
        let result = debug_breaks(&text, 8.0);
        assert_eq!(result, vec!["every ", "wordthing ", "should ", "getits ", "ow\n", "",]);
    }

    #[test]
    fn soft_before_hard() {
        let text: Rope = "create abreak between THESE TWO\nwords andbreakcorrectlyhere\nplz".into();
        let result = debug_breaks(&text, 4.0);
        assert_eq!(
            result,
            vec![
                "create ",
                "abreak ",
                "between ",
                "THESE ",
                "TWO\n",
                "words ",
                "andbreakcorrectlyhere\n",
                "plz",
            ]
        );
    }

    #[test]
    fn column_breaks_hard_soft() {
        let text: Rope = "so\nevery wordthing should getits own".into();
        let result = debug_breaks(&text, 4.0);
        assert_eq!(result, vec!["so\n", "every ", "wordthing ", "should ", "getits ", "own",]);
    }

    #[test]
    fn empty_file() {
        let text: Rope = "".into();
        let result = debug_breaks(&text, 4.0);
        assert_eq!(result, vec![""]);
    }

    #[test]
    fn dont_break_til_i_tell_you() {
        let text: Rope = "thisis_longerthan_our_break_width".into();
        let result = debug_breaks(&text, 12.0);
        assert_eq!(result, vec!["thisis_longerthan_our_break_width"]);
    }

    #[test]
    fn break_now_though() {
        let text: Rope = "thisis_longerthan_our_break_width hi".into();
        let result = debug_breaks(&text, 12.0);
        assert_eq!(result, vec!["thisis_longerthan_our_break_width ", "hi"]);
    }

    #[test]
    fn newlines() {
        let text: Rope = "\n\n".into();
        let result = debug_breaks(&text, 4.0);
        assert_eq!(result, vec!["\n", "\n", ""]);
    }

    #[test]
    fn newline_eof() {
        let text: Rope = "hello\n".into();
        let result = debug_breaks(&text, 4.0);
        assert_eq!(result, vec!["hello\n", ""]);
    }

    #[test]
    fn no_newline_eof() {
        let text: Rope = "hello".into();
        let result = debug_breaks(&text, 4.0);
        assert_eq!(result, vec!["hello"]);
    }

    #[test]
    fn merged_offset() {
        let text: Rope = "a quite\nshort text".into();
        let mut builder = BreakBuilder::new();
        builder.add_break(2);
        builder.add_no_break(text.len() - 2);
        let breaks = builder.build();
        assert_eq!(merged_line_of_offset(&text, &breaks, 0), 0);
        assert_eq!(merged_line_of_offset(&text, &breaks, 1), 0);
        assert_eq!(merged_line_of_offset(&text, &breaks, 2), 1);
        assert_eq!(merged_line_of_offset(&text, &breaks, 5), 1);
        assert_eq!(merged_line_of_offset(&text, &breaks, 5), 1);
        assert_eq!(merged_line_of_offset(&text, &breaks, 9), 2);
        assert_eq!(merged_line_of_offset(&text, &breaks, text.len()), 2);

        let text: Rope = "a quite\nshort tex\n".into();
        // trailing newline increases total count
        assert_eq!(merged_line_of_offset(&text, &breaks, text.len()), 3);
    }

    #[test]
    fn bsearch_equivalence() {
        let text: Rope =
            iter::repeat("this is a line with some text in it, which is not unusual\n")
                .take(1000)
                .collect::<String>()
                .into();
        let lines = make_lines(&text, 30.);

        let mut linear = MergedBreaks::new(&text, &lines.breaks);
        let mut binary = MergedBreaks::new(&text, &lines.breaks);

        // skip zero because these two impls don't handle edge cases
        for i in 1..1000 {
            linear.set_offset(0);
            binary.set_offset(0);
            assert_eq!(
                linear.offset_of_line_linear(i),
                binary.offset_of_line_bsearch(i),
                "line {}",
                i
            );
        }
    }

    #[test]
    fn merge_cursor_no_breaks() {
        let text: Rope = "aaaa\nbb bb cc\ncc dddd eeee ff\nff gggg".into();
        // first with no breaks
        let breaks = Breaks::new_no_break(text.len());
        let mut cursor = MergedBreaks::new(&text, &breaks);
        assert_eq!(cursor.offset, 0);
        assert_eq!(cursor.cur_line, 0);
        assert_eq!(cursor.len, text.len());
        assert_eq!(cursor.total_lines, 4);
        assert!(cursor.is_hard_break());

        assert_eq!(cursor.next(), Some(5));
        assert_eq!(cursor.cur_line, 1);
        assert_eq!(cursor.offset, 5);
        assert_eq!(cursor.text.pos(), 5);
        assert_eq!(cursor.soft.pos(), text.len());
        assert!(cursor.is_hard_break());

        assert_eq!(cursor.next(), Some(14));
        assert_eq!(cursor.cur_line, 2);
        assert_eq!(cursor.offset, 14);
        assert_eq!(cursor.text.pos(), 14);
        assert_eq!(cursor.soft.pos(), text.len());
        assert!(cursor.is_hard_break());

        assert_eq!(cursor.next(), Some(30));
        assert_eq!(cursor.next(), None);
    }

    #[test]
    fn merge_cursor_breaks() {
        let text: Rope = "aaaa\nbb bb cc\ncc dddd eeee ff\nff gggg".into();

        let mut builder = BreakBuilder::new();
        builder.add_break(8);
        builder.add_break(3);
        builder.add_no_break(text.len() - (8 + 3));
        let breaks = builder.build();

        let mut cursor = MergedBreaks::new(&text, &breaks);
        assert_eq!(cursor.offset, 0);
        assert_eq!(cursor.cur_line, 0);
        assert_eq!(cursor.len, text.len());
        assert_eq!(cursor.total_lines, 6);

        assert_eq!(cursor.next(), Some(5));
        assert_eq!(cursor.cur_line, 1);
        assert_eq!(cursor.offset, 5);
        assert_eq!(cursor.text.pos(), 5);
        assert_eq!(cursor.soft.pos(), 8);
        assert!(cursor.is_hard_break());

        assert_eq!(cursor.next(), Some(8));
        assert_eq!(cursor.cur_line, 2);
        assert_eq!(cursor.offset, 8);
        assert_eq!(cursor.text.pos(), 14);
        assert_eq!(cursor.soft.pos(), 8);
        assert!(!cursor.is_hard_break());

        assert_eq!(cursor.next(), Some(11));
        assert_eq!(cursor.cur_line, 3);
        assert_eq!(cursor.offset, 11);
        assert_eq!(cursor.text.pos(), 14);
        assert_eq!(cursor.soft.pos(), 11);
        assert!(!cursor.is_hard_break());

        assert_eq!(cursor.next(), Some(14));
        assert_eq!(cursor.cur_line, 4);
        assert_eq!(cursor.offset, 14);
        assert_eq!(cursor.text.pos(), 14);
        assert_eq!(cursor.soft.pos(), text.len());
        assert!(cursor.is_hard_break());
    }

    #[test]
    fn set_offset() {
        let text: Rope = "aaaa\nbb bb cc\ncc dddd eeee ff\nff gggg".into();
        let lines = make_lines(&text, 2.);
        let mut merged = MergedBreaks::new(&text, &lines.breaks);
        assert_eq!(merged.total_lines, 10);

        let check_props = |m: &MergedBreaks, line, off, softpos, hardpos| {
            assert_eq!(m.cur_line, line);
            assert_eq!(m.offset, off);
            assert_eq!(m.soft.pos(), softpos);
            assert_eq!(m.text.pos(), hardpos);
        };
        merged.next();
        check_props(&merged, 1, 5, 8, 5);
        merged.set_offset(0);
        check_props(&merged, 0, 0, 0, 0);
        merged.set_offset(5);
        check_props(&merged, 1, 5, 8, 5);
        merged.set_offset(0);
        merged.set_offset(6);
        check_props(&merged, 1, 5, 8, 5);
        merged.set_offset(9);
        check_props(&merged, 2, 8, 8, 14);
        merged.set_offset(text.len());
        check_props(&merged, 9, 33, 33, 37);
        merged.set_offset(text.len() - 1);
        check_props(&merged, 9, 33, 33, 37);

        // but a trailing newline adds a line at EOF
        let text: Rope = "aaaa\nbb bb cc\ncc dddd eeee ff\nff ggg\n".into();
        let lines = make_lines(&text, 2.);
        let mut merged = MergedBreaks::new(&text, &lines.breaks);
        assert_eq!(merged.total_lines, 11);
        merged.set_offset(text.len());
        check_props(&merged, 10, 37, 37, 37);
        merged.set_offset(text.len() - 1);
        check_props(&merged, 9, 33, 33, 37);
    }

    #[test]
    fn test_break_at_linear_transition() {
        // do we handle the break at MAX_LINEAR_DIST correctly?
        let text = "a b c d e f g h i j k l m n o p q r s t u v w x ".into();
        let lines = make_lines(&text, 1.);

        for offset in 0..text.len() {
            let line = lines.visual_line_of_offset(&text, offset);
            let line_offset = lines.offset_of_visual_line(&text, line);
            assert!(line_offset <= offset, "{} <= {} L{} O{}", line_offset, offset, line, offset);
        }
    }

    #[test]
    fn expected_soft_breaks() {
        let text = "a b c d ".into();
        let mut text_cursor = Cursor::new(&text, text.len());
        assert!(!text_cursor.is_boundary::<LinesMetric>());

        let Lines { breaks, .. } = make_lines(&text, 1.);
        let mut cursor = Cursor::new(&breaks, 0);

        cursor.set(2);
        assert!(cursor.is_boundary::<BreaksMetric>());
        cursor.set(4);
        assert!(cursor.is_boundary::<BreaksMetric>());
        cursor.set(6);
        assert!(cursor.is_boundary::<BreaksMetric>());
        cursor.set(8);
        assert!(!cursor.is_boundary::<BreaksMetric>());

        cursor.set(0);
        let breaks = cursor.iter::<BreaksMetric>().collect::<Vec<_>>();
        assert_eq!(breaks, vec![2, 4, 6]);
    }

    #[test]
    fn expected_soft_with_hard() {
        let text: Rope = "aa\nbb cc\ncc dd ee ff\ngggg".into();
        let Lines { breaks, .. } = make_lines(&text, 2.);
        let mut cursor = Cursor::new(&breaks, 0);
        let breaks = cursor.iter::<BreaksMetric>().collect::<Vec<_>>();
        assert_eq!(breaks, vec![6, 12, 15, 18]);
    }

    #[test]
    fn offset_to_line() {
        let text = "a b c d ".into();
        let lines = make_lines(&text, 1.);
        let cursor = MergedBreaks::new(&text, &lines.breaks);
        assert_eq!(cursor.total_lines, 4);

        assert_eq!(lines.visual_line_of_offset(&text, 0), 0);
        assert_eq!(lines.visual_line_of_offset(&text, 1), 0);
        assert_eq!(lines.visual_line_of_offset(&text, 2), 1);
        assert_eq!(lines.visual_line_of_offset(&text, 3), 1);
        assert_eq!(lines.visual_line_of_offset(&text, 4), 2);
        assert_eq!(lines.visual_line_of_offset(&text, 5), 2);
        assert_eq!(lines.visual_line_of_offset(&text, 6), 3);
        assert_eq!(lines.visual_line_of_offset(&text, 7), 3);

        assert_eq!(lines.offset_of_visual_line(&text, 0), 0);
        assert_eq!(lines.offset_of_visual_line(&text, 1), 2);
        assert_eq!(lines.offset_of_visual_line(&text, 2), 4);
        assert_eq!(lines.offset_of_visual_line(&text, 3), 6);
        assert_eq!(lines.offset_of_visual_line(&text, 10), 8);

        for offset in 0..text.len() {
            let line = lines.visual_line_of_offset(&text, offset);
            let line_offset = lines.offset_of_visual_line(&text, line);
            assert!(line_offset <= offset, "{} <= {} L{} O{}", line_offset, offset, line, offset);
        }
    }

    #[test]
    fn iter_lines() {
        let text: Rope = "aaaa\nbb bb cc\ncc dddd eeee ff\nff gggg".into();
        let lines = make_lines(&text, 2.);
        let r: Vec<_> =
            lines.iter_lines(&text, 0).take(2).map(|l| text.slice_to_cow(l.interval)).collect();
        assert_eq!(r, vec!["aaaa\n", "bb "]);

        let r: Vec<_> =
            lines.iter_lines(&text, 1).take(2).map(|l| text.slice_to_cow(l.interval)).collect();
        assert_eq!(r, vec!["bb ", "bb "]);

        let r: Vec<_> =
            lines.iter_lines(&text, 3).take(3).map(|l| text.slice_to_cow(l.interval)).collect();
        assert_eq!(r, vec!["cc\n", "cc ", "dddd "]);
    }

    #[test]
    fn line_numbers() {
        let text: Rope = "aaaa\nbb bb cc\ncc dddd eeee ff\nff gggg".into();
        let lines = make_lines(&text, 2.);
        let nums: Vec<_> = lines.iter_lines(&text, 0).map(|l| l.line_num).collect();
        assert_eq!(
            nums,
            vec![Some(1), Some(2), None, None, Some(3), None, None, None, Some(4), None]
        );
    }

    fn make_ranges(ivs: &[Interval]) -> Vec<Range<usize>> {
        ivs.iter().map(|iv| iv.start..iv.end).collect()
    }

    #[test]
    fn update_frontier() {
        let mut lines = Lines::default();
        lines.add_task(0..1000);
        lines.update_tasks_after_wrap(0..10);
        lines.update_tasks_after_wrap(50..100);
        assert_eq!(make_ranges(&lines.work), vec![10..50, 100..1000]);
        lines.update_tasks_after_wrap(200..1000);
        assert_eq!(make_ranges(&lines.work), vec![10..50, 100..200]);
        lines.add_task(300..400);
        assert_eq!(make_ranges(&lines.work), vec![10..50, 100..200, 300..400]);
        lines.add_task(250..350);
        assert_eq!(make_ranges(&lines.work), vec![10..50, 100..200, 250..400]);
        lines.add_task(60..450);
        assert_eq!(make_ranges(&lines.work), vec![10..50, 60..450]);
    }

    #[test]
    fn patchup_frontier() {
        let mut lines = Lines::default();
        lines.add_task(0..100);
        assert_eq!(make_ranges(&lines.work), vec![0..100]);
        lines.patchup_tasks(20..30, 20);
        assert_eq!(make_ranges(&lines.work), vec![0..110]);

        // delete everything?
        lines.patchup_tasks(0..200, 0);
        assert_eq!(make_ranges(&lines.work), vec![]);

        lines.add_task(0..110);
        lines.patchup_tasks(0..30, 0);
        assert_eq!(make_ranges(&lines.work), vec![0..80]);
        lines.update_tasks_after_wrap(20..30);
        assert_eq!(make_ranges(&lines.work), vec![0..20, 30..80]);
        lines.patchup_tasks(10..40, 0);
        assert_eq!(make_ranges(&lines.work), vec![0..50]);
        lines.update_tasks_after_wrap(20..30);
        assert_eq!(make_ranges(&lines.work), vec![0..20, 30..50]);
        lines.patchup_tasks(10..10, 10);
        assert_eq!(make_ranges(&lines.work), vec![0..30, 40..60]);
    }

    /// https://github.com/xi-editor/xi-editor/issues/1112
    #[test]
    fn patchup_for_edit_before_task() {
        let mut lines = Lines::default();
        lines.add_task(0..100);
        lines.update_tasks_after_wrap(0..30);
        assert_eq!(make_ranges(&lines.work), vec![30..100]);
        lines.patchup_tasks(5..90, 80);
        assert_eq!(make_ranges(&lines.work), vec![85..95]);
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#![feature(test)]

extern crate test;
extern crate xi_core_lib as xi_core;
extern crate xi_rope;

use crate::xi_core::line_offset::LineOffset;
use crate::xi_core::tabs::BufferId;
use crate::xi_core::view::View;
use test::Bencher;
use xi_rope::Rope;

fn build_short_lines(n: usize) -> String {
    let line =
        "See it, the beautiful ball Poised in the toyshop window, Rounder than sun or moon.\n";
    let mut s = String::new();
    for _ in 0..n {
        s += line;
    }
    s
}

#[bench]
fn line_of_offset_no_breaks(b: &mut Bencher) {
    let text = Rope::from(build_short_lines(10_000));
    let view = View::new(1.into(), BufferId::new(2));

    let total_bytes = text.len();
    b.iter(|| {
        for i in 0..total_bytes {
            let _line = view.line_of_offset(&text, i);
        }
    })
}

#[bench]
fn line_of_offset_col_breaks(b: &mut Bencher) {
    let text = Rope::from(build_short_lines(10_000));
    let mut view = View::new(1.into(), BufferId::new(2));
    view.debug_force_rewrap_cols(&text, 20);

    let total_bytes = text.len();
    b.iter(|| {
        for i in 0..total_bytes {
            let _line = view.line_of_offset(&text, i);
        }
    })
}

#[bench]
fn offset_of_line_no_breaks(b: &mut Bencher) {
    let text = Rope::from(build_short_lines(10_000));
    let view = View::new(1.into(), BufferId::new(2));

    b.iter(|| {
        for i in 0..10_000 {
            let _line = view.offset_of_line(&text, i);
        }
    })
}

#[bench]
fn offset_of_line_col_breaks(b: &mut Bencher) {
    let text = Rope::from(build_short_lines(10_000));
    let mut view = View::new(1.into(), BufferId::new(2));
    view.debug_force_rewrap_cols(&text, 20);

    b.iter(|| {
        for i in 0..10_000 {
            let _line = view.offset_of_line(&text, i);
        }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#[macro_use]
extern crate serde_json;

extern crate xi_core_lib;
extern crate xi_rpc;

use std::io;

use xi_core_lib::test_helpers;
use xi_core_lib::XiCore;
use xi_rpc::test_utils::{make_reader, test_channel};
use xi_rpc::{ReadError, RpcLoop};

#[test]
/// Tests that the handler responds to a standard startup sequence as expected.
fn test_startup() {
    let mut state = XiCore::new();
    let (tx, mut rx) = test_channel();
    let mut rpc_looper = RpcLoop::new(tx);
    let json = make_reader(
        r#"{"method":"client_started","params":{}}
{"method":"set_theme","params":{"theme_name":"InspiredGitHub"}}"#,
    );
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());
    rx.expect_rpc("available_languages");
    rx.expect_rpc("available_themes");
    rx.expect_rpc("theme_changed");

    let json = make_reader(r#"{"id":0,"method":"new_view","params":{}}"#);
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());
    assert_eq!(rx.expect_response(), Ok(json!("view-id-1")));
    rx.expect_rpc("available_plugins");
    rx.expect_rpc("config_changed");
    rx.expect_rpc("language_changed");
    rx.expect_rpc("update");
    rx.expect_rpc("scroll_to");
    rx.expect_nothing();
}

#[test]
/// Tests that the handler creates and destroys views and buffers
fn test_state() {
    let mut state = XiCore::new();

    let write = io::sink();
    let json = make_reader(
        r#"{"method":"client_started","params":{}}
{"id":0,"method":"new_view","params":{"file_path":"../Cargo.toml"}}
{"method":"set_theme","params":{"theme_name":"InspiredGitHub"}}"#,
    );
    let mut rpc_looper = RpcLoop::new(write);
    rpc_looper.mainloop(|| json, &mut state).unwrap();

    {
        let state = state.inner();
        assert_eq!(state._test_open_editors(), vec![test_helpers::new_buffer_id(2)]);
        assert_eq!(state._test_open_views(), vec![test_helpers::new_view_id(1)]);
    }

    let json = make_reader(r#"{"method":"close_view","params":{"view_id":"view-id-1"}}"#);
    rpc_looper.mainloop(|| json, &mut state).unwrap();
    {
        let state = state.inner();
        assert_eq!(state._test_open_views(), Vec::new());
        assert_eq!(state._test_open_editors(), Vec::new());
    }

    let json = make_reader(
        r#"{"id":1,"method":"new_view","params":{}}
{"id":2,"method":"new_view","params":{}}
{"id":3,"method":"new_view","params":{}}"#,
    );

    rpc_looper.mainloop(|| json, &mut state).unwrap();
    {
        let state = state.inner();
        assert_eq!(state._test_open_editors().len(), 3);
    }
}

/// Test whether xi-core invalidates cache lines upon a cursor motion.
#[test]
fn test_invalidate() {
    let mut state = XiCore::new();
    let (tx, mut rx) = test_channel();
    let mut rpc_looper = RpcLoop::new(tx);
    let json = make_reader(
        r#"{"method":"client_started","params":{}}
{"id":0,"method":"new_view","params":{}}
"#,
    );
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());

    let mut edit_cmds = String::new();

    for i in 1..20 {
        // add lines "line 1", "line 2",...
        edit_cmds.push_str(r#"{"method":"edit","params":{"view_id":"view-id-1","method":"insert","params":{"chars":"line "#);
        edit_cmds.push_str(&i.to_string());
        edit_cmds.push_str(
            r#""}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"insert_newline","params":[]}}
"#,
        );
    }

    let json = make_reader(edit_cmds);
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());

    // jump to line 1, then jump to line 18
    const MOVEMENTS: &str = r#"{"method":"edit","params":{"view_id":"view-id-1","method":"goto_line","params":{"line":1}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"goto_line","params":{"line":18}}}"#;

    let json = make_reader(MOVEMENTS);
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());

    let mut last_ops = Vec::new();

    while let Some(Ok(resp)) = rx.next_timeout(std::time::Duration::from_millis(1000)) {
        if !resp.is_response() && resp.get_method().unwrap() == "update" {
            let ops = resp.0.as_object().unwrap()["params"].as_object().unwrap()["update"]
                .as_object()
                .unwrap()["ops"]
                .as_array()
                .unwrap();
            last_ops = ops.clone();

            // Verify that the "invalidate" ops can only go first or last.
            if ops.len() > 2 {
                debug_assert!(
                    ops.iter()
                        // step over leading "invalidate" and "skip"
                        .skip_while(|op| op["op"].as_str().unwrap() == "invalidate"
                            || op["op"].as_str().unwrap() == "skip")
                        // current op (ins/copy/update) adds lines;
                        // wait for another invalidate/skip
                        .skip_while(|op| op["op"].as_str().unwrap() != "invalidate")
                        // step over trailing "invalidate" and "skip"
                        .skip_while(|op| op["op"].as_str().unwrap() == "invalidate"
                            || op["op"].as_str().unwrap() == "skip")
                        .next()
                        .is_none(),
                    "bad update: ".to_string()
                        + &ops
                            .iter()
                            .map(|op| format!(
                                "{} {}",
                                op["op"].as_str().unwrap(),
                                op["n"].as_u64().unwrap()
                            ))
                            .collect::<Vec<_>>()
                            .join(", ")
                );
            }
        }
    }

    // Dump the last vector of ops.
    // Verify that there is an "update" op in case of a cursor motion.
    assert_eq!(
        last_ops
            .iter()
            .map(|op| {
                let op_in = op.as_object().unwrap();
                (op_in["op"].as_str().unwrap(), op_in["n"].as_u64().unwrap())
            })
            .collect::<Vec<_>>(),
        [("copy", 1), ("update", 1), ("copy", 5), ("copy", 11), ("update", 2)]
    );
}

#[test]
/// Tests that the runloop exits with the correct error when receiving
/// malformed json.
fn test_malformed_json() {
    let mut state = XiCore::new();
    let write = io::sink();
    let mut rpc_looper = RpcLoop::new(write);
    // malformed json: method should be in quotes.
    let read = make_reader(
        r#"{"method":"client_started","params":{}}
{"id":0,method:"new_view","params":{}}"#,
    );
    match rpc_looper.mainloop(|| read, &mut state).err().expect("malformed json exits with error") {
        ReadError::Json(_) => (), // expected
        err => panic!("Unexpected error: {:?}", err),
    }
    // read should have ended after first item
    {
        let state = state.inner();
        assert_eq!(state._test_open_editors().len(), 0);
    }
}

#[test]
/// Sends all of the cursor movement-related commands, and verifies that
/// they are handled.
///
///
/// Note: this is a test of message parsing, not of editor behaviour.
fn test_movement_cmds() {
    let mut state = XiCore::new();
    let write = io::sink();
    let mut rpc_looper = RpcLoop::new(write);
    // init a new view
    let json = make_reader(
        r#"{"method":"client_started","params":{}}
{"method":"set_theme","params":{"theme_name":"InspiredGitHub"}}
{"id":0,"method":"new_view","params":{}}"#,
    );
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());

    let json = make_reader(MOVEMENT_RPCS);
    rpc_looper.mainloop(|| json, &mut state).unwrap();
}

#[test]
/// Sends all the commands which modify the buffer, and verifies that they
/// are handled.
fn test_text_commands() {
    let mut state = XiCore::new();
    let write = io::sink();
    let mut rpc_looper = RpcLoop::new(write);
    // init a new view
    let json = make_reader(
        r#"{"method":"client_started","params":{}}
{"method":"set_theme","params":{"theme_name":"InspiredGitHub"}}
{"id":0,"method":"new_view","params":{}}"#,
    );
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());

    let json = make_reader(TEXT_EDIT_RPCS);
    rpc_looper.mainloop(|| json, &mut state).unwrap();
}

#[test]
fn test_other_edit_commands() {
    let mut state = XiCore::new();
    let write = io::sink();
    let mut rpc_looper = RpcLoop::new(write);
    // init a new view
    let json = make_reader(
        r#"{"method":"client_started","params":{}}
{"method":"set_theme","params":{"theme_name":"InspiredGitHub"}}
{"id":0,"method":"new_view","params":{}}"#,
    );
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());

    let json = make_reader(OTHER_EDIT_RPCS);
    rpc_looper.mainloop(|| json, &mut state).unwrap();
}

#[test]
fn test_settings_commands() {
    let mut state = XiCore::new();
    let (tx, mut rx) = test_channel();
    let mut rpc_looper = RpcLoop::new(tx);
    // init a new view
    let json = make_reader(
        r#"{"method":"client_started","params":{}}
{"method":"set_theme","params":{"theme_name":"InspiredGitHub"}}
{"id":0,"method":"new_view","params":{}}"#,
    );
    assert!(rpc_looper.mainloop(|| json, &mut state).is_ok());
    rx.expect_rpc("available_languages");
    rx.expect_rpc("available_themes");
    rx.expect_rpc("theme_changed");
    rx.expect_response().unwrap();
    rx.expect_rpc("available_plugins");
    rx.expect_rpc("config_changed");
    rx.expect_rpc("language_changed");
    rx.expect_rpc("update");
    rx.expect_rpc("scroll_to");

    let json = make_reader(r#"{"method":"get_config","id":1,"params":{"view_id":"view-id-1"}}"#);
    rpc_looper.mainloop(|| json, &mut state).unwrap();
    let resp = rx.expect_response().unwrap();
    assert_eq!(resp["tab_size"], json!(4));

    let json = make_reader(
        r#"{"method":"modify_user_config","params":{"domain":{"user_override":"view-id-1"},"changes":{"font_face": "Comic Sans"}}}
{"method":"modify_user_config","params":{"domain":{"syntax":"rust"},"changes":{"font_size":42}}}
{"method":"modify_user_config","params":{"domain":"general","changes":{"tab_size":13,"font_face":"Papyrus"}}}"#,
    );
    rpc_looper.mainloop(|| json, &mut state).unwrap();
    // discard config_changed
    rx.expect_rpc("config_changed");
    rx.expect_rpc("update");
    rx.expect_rpc("config_changed");
    rx.expect_rpc("update");

    let json = make_reader(r#"{"method":"get_config","id":2,"params":{"view_id":"view-id-1"}}"#);
    rpc_looper.mainloop(|| json, &mut state).unwrap();
    let resp = rx.expect_response().unwrap();
    assert_eq!(resp["tab_size"], json!(13));
    assert_eq!(resp["font_face"], json!("Comic Sans"));

    // null value should clear entry from this config
    let json = make_reader(
        r#"{"method":"modify_user_config","params":{"domain":{"user_override":"view-id-1"},"changes":{"font_face": null}}}"#,
    );
    rpc_looper.mainloop(|| json, &mut state).unwrap();
    let resp = rx.expect_rpc("config_changed");
    assert_eq!(resp.0["params"]["changes"]["font_face"], json!("Papyrus"));
}

//TODO: test saving rpc
//TODO: test plugin rpc

const MOVEMENT_RPCS: &str = r#"{"method":"edit","params":{"view_id":"view-id-1","method":"move_up","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_down","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_up_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_down_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_left","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_backward","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_right","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_forward","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_left_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_right_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_word_left","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_word_right","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_word_left_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_word_right_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_beginning_of_paragraph","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_end_of_paragraph","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_left_end_of_line","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_left_end_of_line_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_right_end_of_line","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_right_end_of_line_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_beginning_of_document","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_beginning_of_document_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_end_of_document","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"move_to_end_of_document_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"scroll_page_up","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"scroll_page_down","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"page_up_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"page_down_and_modify_selection","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"select_all","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"add_selection_above","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"add_selection_below","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"collapse_selections","params":[]}}"#;

const TEXT_EDIT_RPCS: &str = r#"{"method":"edit","params":{"view_id":"view-id-1","method":"insert","params":{"chars":"a"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"delete_backward","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"delete_forward","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"delete_word_forward","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"delete_word_backward","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"delete_to_end_of_paragraph","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"insert_newline","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"insert_tab","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"yank","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"undo","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"redo","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"transpose","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"uppercase","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"lowercase","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"indent","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"outdent","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"duplicate_line","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"replace_next","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"replace_all","params":[]}}
{"id":2,"method":"edit","params":{"view_id":"view-id-1","method":"cut","params":[]}}"#;

const OTHER_EDIT_RPCS: &str = r#"{"method":"edit","params":{"view_id":"view-id-1","method":"scroll","params":[0,1]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"goto_line","params":{"line":1}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"request_lines","params":[0,1]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"drag","params":[17,15,0]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"gesture","params":{"line": 1, "col": 2, "ty": "toggle_sel"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"gesture","params":{"line": 1, "col": 2, "ty": "point_select"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"gesture","params":{"line": 1, "col": 2, "ty": "range_select"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"gesture","params":{"line": 1, "col": 2, "ty": "line_select"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"gesture","params":{"line": 1, "col": 2, "ty": "word_select"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"gesture","params":{"line": 1, "col": 2, "ty": "multi_line_select"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"gesture","params":{"line": 1, "col": 2, "ty": "multi_word_select"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"find","params":{"case_sensitive":false,"chars":"m"}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"multi_find","params":{"queries": [{"case_sensitive":false,"chars":"m"}]}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"find_next","params":{"wrap_around":true}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"find_previous","params":{"wrap_around":true}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"find_all","params":[]}}
{"method":"edit","params":{"view_id":"view-id-1","method":"highlight_find","params":{"visible":true}}}
{"method":"edit","params":{"view_id":"view-id-1","method":"selection_for_find","params":{"case_sensitive":true}}}
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Utility functions meant for converting types from LSP to Core format
//! and vice-versa

use crate::lsp_types::*;
use crate::types::LanguageResponseError;
use xi_plugin_lib::{Cache, Error as PluginLibError, Hover as CoreHover, Range as CoreRange, View};

pub(crate) fn marked_string_to_string(marked_string: &MarkedString) -> String {
    match *marked_string {
        MarkedString::String(ref text) => text.to_owned(),
        MarkedString::LanguageString(ref d) => format!("```{}\n{}\n```", d.language, d.value),
    }
}

pub(crate) fn markdown_from_hover_contents(
    hover_contents: HoverContents,
) -> Result<String, LanguageResponseError> {
    let res = match hover_contents {
        HoverContents::Scalar(content) => marked_string_to_string(&content),
        HoverContents::Array(content) => {
            let res: Vec<String> = content.iter().map(|c| marked_string_to_string(c)).collect();
            res.join("\n")
        }
        HoverContents::Markup(content) => content.value,
    };
    if res.is_empty() {
        Err(LanguageResponseError::FallbackResponse)
    } else {
        Ok(res)
    }
}

/// Counts the number of utf-16 code units in the given string.
pub(crate) fn count_utf16(s: &str) -> usize {
    let mut utf16_count = 0;
    for &b in s.as_bytes() {
        if (b as i8) >= -0x40 {
            utf16_count += 1;
        }
        if b >= 0xf0 {
            utf16_count += 1;
        }
    }
    utf16_count
}

/// Get LSP Style Utf-16 based position given the xi-core style utf-8 offset
pub(crate) fn get_position_of_offset<C: Cache>(
    view: &mut View<C>,
    offset: usize,
) -> Result<Position, PluginLibError> {
    let line_num = view.line_of_offset(offset)?;
    let line_offset = view.offset_of_line(line_num)?;

    let char_offset = count_utf16(&(view.get_line(line_num)?[0..(offset - line_offset)]));

    Ok(Position { line: line_num as u64, character: char_offset as u64 })
}

pub(crate) fn offset_of_position<C: Cache>(
    view: &mut View<C>,
    position: Position,
) -> Result<usize, PluginLibError> {
    let line_offset = view.offset_of_line(position.line as usize);

    let mut cur_len_utf16 = 0;
    let mut cur_len_utf8 = 0;

    for u in view.get_line(position.line as usize)?.chars() {
        if cur_len_utf16 >= (position.character as usize) {
            break;
        }
        cur_len_utf16 += u.len_utf16();
        cur_len_utf8 += u.len_utf8();
    }

    Ok(cur_len_utf8 + line_offset?)
}

pub(crate) fn core_range_from_range<C: Cache>(
    view: &mut View<C>,
    range: Range,
) -> Result<CoreRange, PluginLibError> {
    Ok(CoreRange {
        start: offset_of_position(view, range.start)?,
        end: offset_of_position(view, range.end)?,
    })
}

pub(crate) fn core_hover_from_hover<C: Cache>(
    view: &mut View<C>,
    hover: Hover,
) -> Result<CoreHover, LanguageResponseError> {
    Ok(CoreHover {
        content: markdown_from_hover_contents(hover.contents)?,
        range: match hover.range {
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Utility methods to parse the input from the Language Server

use crate::types::{LspHeader, ParseError};
use std::io::BufRead;

const HEADER_CONTENT_LENGTH: &str = "content-length";
const HEADER_CONTENT_TYPE: &str = "content-type";

/// parse header from the incoming input string
fn parse_header(s: &str) -> Result<LspHeader, ParseError> {
    let split: Vec<String> = s.splitn(2, ": ").map(|s| s.trim().to_lowercase()).collect();
    if split.len() != 2 {
        return Err(ParseError::Unknown("Malformed".to_string()));
    };
    match split[0].as_ref() {
        HEADER_CONTENT_TYPE => Ok(LspHeader::ContentType),
        HEADER_CONTENT_LENGTH => {
            Ok(LspHeader::ContentLength(usize::from_str_radix(&split[1], 10)?))
        }
        _ => Err(ParseError::Unknown("Unknown parse error occurred".to_string())),
    }
}

/// Blocking call to read a message from the provided BufRead
pub fn read_message<T: BufRead>(reader: &mut T) -> Result<String, ParseError> {
    let mut buffer = String::new();
    let mut content_length: Option<usize> = None;

    loop {
        buffer.clear();
        let _result = reader.read_line(&mut buffer);

        match &buffer {
            s if s.trim().is_empty() => break,
            s => {
                match parse_header(s)? {
                    LspHeader::ContentLength(len) => content_length = Some(len),
                    LspHeader::ContentType => (),
                };
            }
        };
    }

    let content_length =
        content_length.ok_or_else(|| format!("missing content-length header: {}", buffer))?;

    let mut body_buffer = vec![0; content_length];
    reader.read_exact(&mut body_buffer)?;

    let body = String::from_utf8(body_buffer)?;
    Ok(body)
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#[macro_use]
extern crate serde_derive;
extern crate serde_json;

#[macro_use]
extern crate log;
extern crate chrono;
extern crate fern;

extern crate jsonrpc_lite;
extern crate languageserver_types as lsp_types;
extern crate serde;

extern crate url;
extern crate xi_core_lib as xi_core;
extern crate xi_plugin_lib;
extern crate xi_rope;
extern crate xi_rpc;

use xi_plugin_lib::mainloop;
use xi_plugin_lib::Plugin;

pub mod conversion_utils;
pub mod language_server_client;
pub mod lsp_plugin;
pub mod parse_helper;
mod result_queue;
pub mod types;
mod utils;
pub use crate::lsp_plugin::LspPlugin;
pub use crate::types::Config;

// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
extern crate xi_lsp_lib;
#[macro_use]
extern crate serde_json;

extern crate chrono;
extern crate fern;
extern crate log;

use xi_lsp_lib::{start_mainloop, Config, LspPlugin};

fn init_logger() -> Result<(), fern::InitError> {
    let level_filter = match std::env::var("XI_LOG") {
        Ok(level) => match level.to_lowercase().as_ref() {
            "trace" => log::LevelFilter::Trace,
            "debug" => log::LevelFilter::Debug,
            _ => log::LevelFilter::Info,
        },
        // Default to info
        Err(_) => log::LevelFilter::Info,
    };

    fern::Dispatch::new()
        .format(|out, message, record| {
            out.finish(format_args!(
                "{}[{}][{}] {}",
                chrono::Local::now().format("[%Y-%m-%d][%H:%M:%S]"),
                record.target(),
                record.level(),
                message
            ))
        })
        .level(level_filter)
        .chain(std::io::stderr())
        .chain(fern::log_file("xi-lsp-plugin.log")?)
        .apply()
        .map_err(|e| e.into())
}

fn main() {
    // The specified language server must be in PATH. XCode does not use
    // the PATH variable of your shell. See the answers below to modify PATH to
    // have language servers in PATH while running from XCode.
    // https://stackoverflow.com/a/17394454 and https://stackoverflow.com/a/43043687
    let config = json!({
        "language_config": {
            // Install instructions here: https://github.com/rust-lang-nursery/rls
            "rust" : {
                "language_name": "Rust",
                "start_command": "rls",
                "start_arguments": [],
                "extensions": ["rs"],
                "supports_single_file": false,
                "workspace_identifier": "Cargo.toml"
            },
            // Install with: npm install -g vscode-json-languageserver
            "json": {
                "language_name": "Json",
                "start_command": "vscode-json-languageserver",
                "start_arguments": ["--stdio"],
                "extensions": ["json", "jsonc"],
                "supports_single_file": true,
            },
            // Install with: npm install -g javascript-typescript-langserver
            "typescript": {
                "language_name": "Typescript",
                "start_command": "javascript-typescript-stdio",
                "start_arguments": [],
                "extensions": ["ts", "js", "jsx", "tsx"],
                "supports_single_file": true,
                "workspace_identifier": "package.json"
            }
        }
    });

    init_logger().expect("Failed to start logger for LSP Plugin");
    let config: Config = serde_json::from_value(config).unwrap();
    let mut plugin = LspPlugin::new(config);
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Implementation of Language Server Plugin

use std::collections::HashMap;
use std::path::Path;
use std::sync::{Arc, Mutex};

use url::Url;
use xi_plugin_lib::{ChunkCache, CoreProxy, Plugin, View};
use xi_rope::rope::RopeDelta;

use crate::conversion_utils::*;
use crate::language_server_client::LanguageServerClient;
use crate::lsp_types::*;
use crate::result_queue::ResultQueue;
use crate::types::{Config, LanguageResponseError, LspResponse};
use crate::utils::*;
use crate::xi_core::{ConfigTable, ViewId};

pub struct ViewInfo {
    version: u64,
    ls_identifier: String,
}

/// Represents the state of the Language Server Plugin
pub struct LspPlugin {
    pub config: Config,
    view_info: HashMap<ViewId, ViewInfo>,
    core: Option<CoreProxy>,
    result_queue: ResultQueue,
    language_server_clients: HashMap<String, Arc<Mutex<LanguageServerClient>>>,
}

impl LspPlugin {
    pub fn new(config: Config) -> Self {
        LspPlugin {
            config,
            core: None,
            result_queue: ResultQueue::new(),
            view_info: HashMap::new(),
            language_server_clients: HashMap::new(),
        }
    }
}

impl Plugin for LspPlugin {
    type Cache = ChunkCache;

    fn initialize(&mut self, core: CoreProxy) {
        self.core = Some(core)
    }

    fn update(
        &mut self,
        view: &mut View<Self::Cache>,
        delta: Option<&RopeDelta>,
        _edit_type: String,
        _author: String,
    ) {
        let view_info = self.view_info.get_mut(&view.get_id());
        if let Some(view_info) = view_info {
            // This won't fail since we definitely have a client for the given
            // client identifier
            let ls_client = &self.language_server_clients[&view_info.ls_identifier];
            let mut ls_client = ls_client.lock().unwrap();

            let sync_kind = ls_client.get_sync_kind();
            view_info.version += 1;
            if let Some(changes) = get_change_for_sync_kind(sync_kind, view, delta) {
                ls_client.send_did_change(view.get_id(), changes, view_info.version);
            }
        }
    }

    fn did_save(&mut self, view: &mut View<Self::Cache>, _old: Option<&Path>) {
        trace!("saved view {}", view.get_id());

        let document_text = view.get_document().unwrap();
        self.with_language_server_for_view(view, |ls_client| {
            ls_client.send_did_save(view.get_id(), &document_text);
        });
    }

    fn did_close(&mut self, view: &View<Self::Cache>) {
        trace!("close view {}", view.get_id());

        self.with_language_server_for_view(view, |ls_client| {
            ls_client.send_did_close(view.get_id());
        });
    }

    fn new_view(&mut self, view: &mut View<Self::Cache>) {
        trace!("new view {}", view.get_id());

        let document_text = view.get_document().unwrap();
        let path = view.get_path();
        let view_id = view.get_id();

        // TODO: Use Language Idenitifier assigned by core when the
        // implementation is settled
        if let Some(language_id) = self.get_language_for_view(view) {
            let path = path.unwrap();

            let workspace_root_uri = {
                let config = &self.config.language_config.get_mut(&language_id).unwrap();

                config.workspace_identifier.clone().and_then(|identifier| {
                    let path = view.get_path().unwrap();
                    let q = get_workspace_root_uri(&identifier, path);
                    q.ok()
                })
            };

            let result = self.get_lsclient_from_workspace_root(&language_id, &workspace_root_uri);

            if let Some((identifier, ls_client)) = result {
                self.view_info
                    .insert(view.get_id(), ViewInfo { version: 0, ls_identifier: identifier });
                let mut ls_client = ls_client.lock().unwrap();

                let document_uri = Url::from_file_path(path).unwrap();

                if !ls_client.is_initialized {
                    ls_client.send_initialize(workspace_root_uri, move |ls_client, result| {
                        if let Ok(result) = result {
                            let init_result: InitializeResult =
                                serde_json::from_value(result).unwrap();

                            debug!("Init Result: {:?}", init_result);

                            ls_client.server_capabilities = Some(init_result.capabilities);
                            ls_client.is_initialized = true;
                            ls_client.send_did_open(view_id, document_uri, document_text);
                        }
                    });
                } else {
                    ls_client.send_did_open(view_id, document_uri, document_text);
                }
            }
        }
    }

    fn config_changed(&mut self, _view: &mut View<Self::Cache>, _changes: &ConfigTable) {}

    fn get_hover(&mut self, view: &mut View<Self::Cache>, request_id: usize, position: usize) {
        let view_id = view.get_id();
        let position_ls = get_position_of_offset(view, position);

        self.with_language_server_for_view(view, |ls_client| match position_ls {
            Ok(position) => ls_client.request_hover(view_id, position, move |ls_client, result| {
                let res = result
                    .map_err(|e| LanguageResponseError::LanguageServerError(format!("{:?}", e)))
                    .and_then(|h| {
                        let hover: Option<Hover> = serde_json::from_value(h).unwrap();
                        hover.ok_or(LanguageResponseError::NullResponse)
                    });

                ls_client.result_queue.push_result(request_id, LspResponse::Hover(res));
                ls_client.core.schedule_idle(view_id);
            }),
            Err(err) => {
                ls_client.result_queue.push_result(request_id, LspResponse::Hover(Err(err.into())));
                ls_client.core.schedule_idle(view_id);
            }
        });
    }

    fn idle(&mut self, view: &mut View<Self::Cache>) {
        let result = self.result_queue.pop_result();
        if let Some((request_id, reponse)) = result {
            match reponse {
                LspResponse::Hover(res) => {
                    let res =
                        res.and_then(|h| core_hover_from_hover(view, h)).map_err(|e| e.into());
                    self.with_language_server_for_view(view, |ls_client| {
                        ls_client.core.display_hover(view.get_id(), request_id, &res)
                    });
                }
            }
        }
    }
}

/// Util Methods
impl LspPlugin {
    /// Get the Language Server Client given the Workspace root
    /// This method checks if a language server is running at the specified root
    /// and returns it else it tries to spawn a new language server and returns a
    /// Arc reference to it
    fn get_lsclient_from_workspace_root(
        &mut self,
        language_id: &str,
        workspace_root: &Option<Url>,
    ) -> Option<(String, Arc<Mutex<LanguageServerClient>>)> {
        workspace_root
            .clone()
            .map(|r| r.into_string())
            .or_else(|| {
                let config = &self.config.language_config[language_id];
                if config.supports_single_file {
                    // A generic client is the one that supports single files i.e.
                    // Non-Workspace projects as well
                    Some(String::from("generic"))
                } else {
                    None
                }
            })
            .and_then(|language_server_identifier| {
                let contains =
                    self.language_server_clients.contains_key(&language_server_identifier);

                if contains {
                    let client = self.language_server_clients[&language_server_identifier].clone();

                    Some((language_server_identifier, client))
                } else {
                    let config = &self.config.language_config[language_id];
                    let client = start_new_server(
                        config.start_command.clone(),
                        config.start_arguments.clone(),
                        config.extensions.clone(),
                        language_id,
                        // Unwrap is safe
                        self.core.clone().unwrap(),
                        self.result_queue.clone(),
                    );

                    match client {
                        Ok(client) => {
                            let client_clone = client.clone();
                            self.language_server_clients
                                .insert(language_server_identifier.clone(), client);

                            Some((language_server_identifier, client_clone))
                        }
                        Err(err) => {
                            error!(
                                "Error occured while starting server for Language: {}: {:?}",
                                language_id, err
                            );
                            None
                        }
                    }
                }
            })
    }

    /// Tries to get language for the View using the extension of the document.
    /// Only searches for the languages supported by the Language Plugin as
    /// defined in the config
    fn get_language_for_view(&mut self, view: &View<ChunkCache>) -> Option<String> {
        view.get_path()
            .and_then(|path| path.extension())
            .and_then(|extension| extension.to_str())
            .and_then(|extension_str| {
                for (lang, config) in &self.config.language_config {
                    if config.extensions.iter().any(|x| x == extension_str) {
                        return Some(lang.clone());
                    }
                }
                None
            })
    }

    fn with_language_server_for_view<F, R>(&mut self, view: &View<ChunkCache>, f: F) -> Option<R>
    where
        F: FnOnce(&mut LanguageServerClient) -> R,
    {
        let view_info = self.view_info.get_mut(&view.get_id())?;

        let ls_client_arc = &self.language_server_clients[&view_info.ls_identifier];
        let mut ls_client = ls_client_arc.lock().unwrap();
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Implementation for Language Server Client

use std::collections::{HashMap, HashSet};
use std::io::Write;
use std::process;

use jsonrpc_lite::{Error, Id, JsonRpc, Params};
use serde_json::{to_value, Value};
use url::Url;
use xi_plugin_lib::CoreProxy;

use crate::lsp_types::*;
use crate::result_queue::ResultQueue;
use crate::types::Callback;
use crate::xi_core::ViewId;

/// A type to abstract communication with the language server
pub struct LanguageServerClient {
    writer: Box<dyn Write + Send>,
    pending: HashMap<u64, Callback>,
    next_id: u64,
    language_id: String,
    pub result_queue: ResultQueue,
    pub status_items: HashSet<String>,
    pub core: CoreProxy,
    pub is_initialized: bool,
    pub opened_documents: HashMap<ViewId, Url>,
    pub server_capabilities: Option<ServerCapabilities>,
    pub file_extensions: Vec<String>,
}

/// Prepare Language Server Protocol style JSON String from
/// a serde_json object `Value`
fn prepare_lsp_json(msg: &Value) -> Result<String, serde_json::error::Error> {
    let request = serde_json::to_string(&msg)?;
    Ok(format!("Content-Length: {}\r\n\r\n{}", request.len(), request))
}

/// Get numeric id from the request id.
fn number_from_id(id: &Id) -> u64 {
    match *id {
        Id::Num(n) => n as u64,
        Id::Str(ref s) => u64::from_str_radix(s, 10).expect("failed to convert string id to u64"),
        _ => panic!("unexpected value for id: None"),
    }
}

impl LanguageServerClient {
    pub fn new(
        writer: Box<dyn Write + Send>,
        core: CoreProxy,
        result_queue: ResultQueue,
        language_id: String,
        file_extensions: Vec<String>,
    ) -> Self {
        LanguageServerClient {
            writer,
            pending: HashMap::new(),
            next_id: 1,
            is_initialized: false,
            core,
            result_queue,
            status_items: HashSet::new(),
            language_id,
            server_capabilities: None,
            opened_documents: HashMap::new(),
            file_extensions,
        }
    }

    pub fn write(&mut self, msg: &str) {
        self.writer.write_all(msg.as_bytes()).expect("error writing to stdin");

        self.writer.flush().expect("error flushing child stdin");
    }

    pub fn handle_message(&mut self, message: &str) {
        match JsonRpc::parse(message) {
            Ok(JsonRpc::Request(obj)) => trace!("client received unexpected request: {:?}", obj),
            Ok(value @ JsonRpc::Notification(_)) => {
                self.handle_notification(value.get_method().unwrap(), value.get_params().unwrap())
            }
            Ok(value @ JsonRpc::Success(_)) => {
                let id = number_from_id(&value.get_id().unwrap());
                let result = value.get_result().unwrap();
                self.handle_response(id, Ok(result.clone()));
            }
            Ok(value @ JsonRpc::Error(_)) => {
                let id = number_from_id(&value.get_id().unwrap());
                let error = value.get_error().unwrap();
                self.handle_response(id, Err(error.clone()));
            }
            Err(err) => error!("Error in parsing incoming string: {}", err),
        }
    }

    pub fn handle_response(&mut self, id: u64, result: Result<Value, Error>) {
        let callback = self
            .pending
            .remove(&id)
            .unwrap_or_else(|| panic!("id {} missing from request table", id));
        callback.call(self, result);
    }

    pub fn handle_notification(&mut self, method: &str, params: Params) {
        trace!("Notification Received =>\n Method: {}, params: {:?}", method, params);
        match method {
            "window/showMessage" => {}
            "window/logMessage" => {}
            "textDocument/publishDiagnostics" => {}
            "telemetry/event" => {}
            _ => self.handle_misc_notification(method, params),
        }
    }

    pub fn handle_misc_notification(&mut self, method: &str, params: Params) {
        match self.language_id.to_lowercase().as_ref() {
            "rust" => self.handle_rust_misc_notification(method, params),
            _ => warn!("Unknown notification: {}", method),
        }
    }

    fn remove_status_item(&mut self, id: &str) {
        self.status_items.remove(id);
        for view_id in self.opened_documents.keys() {
            self.core.remove_status_item(*view_id, id);
        }
    }

    fn add_status_item(&mut self, id: &str, value: &str, alignment: &str) {
        self.status_items.insert(id.to_string());
        for view_id in self.opened_documents.keys() {
            self.core.add_status_item(*view_id, id, value, alignment);
        }
    }

    fn update_status_item(&mut self, id: &str, value: &str) {
        for view_id in self.opened_documents.keys() {
            self.core.update_status_item(*view_id, id, value);
        }
    }

    pub fn send_request(&mut self, method: &str, params: Params, completion: Callback) {
        let request = JsonRpc::request_with_params(Id::Num(self.next_id as i64), method, params);

        self.pending.insert(self.next_id, completion);
        self.next_id += 1;

        self.send_rpc(&to_value(&request).unwrap());
    }

    fn send_rpc(&mut self, value: &Value) {
        let rpc = match prepare_lsp_json(value) {
            Ok(r) => r,
            Err(err) => panic!("Encoding Error {:?}", err),
        };

        trace!("Sending RPC: {:?}", rpc);
        self.write(rpc.as_ref());
    }

    pub fn send_notification(&mut self, method: &str, params: Params) {
        let notification = JsonRpc::notification_with_params(method, params);
        let res = to_value(&notification).unwrap();
        self.send_rpc(&res);
    }
}

/// Methods to abstract sending notifications and requests to the language server
impl LanguageServerClient {
    /// Send the Initialize Request given the Root URI of the
    /// Workspace. It is None for non-workspace projects.
    pub fn send_initialize<CB>(&mut self, root_uri: Option<Url>, on_init: CB)
    where
        CB: 'static + Send + FnOnce(&mut LanguageServerClient, Result<Value, Error>),
    {
        let client_capabilities = ClientCapabilities::default();

        let init_params = InitializeParams {
            process_id: Some(u64::from(process::id())),
            root_uri,
            root_path: None,
            initialization_options: None,
            capabilities: client_capabilities,
            trace: Some(TraceOption::Verbose),
            workspace_folders: None,
        };

        let params = Params::from(serde_json::to_value(init_params).unwrap());
        self.send_request("initialize", params, Box::new(on_init));
    }

    /// Send textDocument/didOpen Notification to the Language Server
    pub fn send_did_open(&mut self, view_id: ViewId, document_uri: Url, document_text: String) {
        self.opened_documents.insert(view_id, document_uri.clone());

        let text_document_did_open_params = DidOpenTextDocumentParams {
            text_document: TextDocumentItem {
                language_id: self.language_id.clone(),
                uri: document_uri,
                version: 0,
                text: document_text,
            },
        };

        let params = Params::from(serde_json::to_value(text_document_did_open_params).unwrap());
        self.send_notification("textDocument/didOpen", params);
    }

    /// Send textDocument/didClose Notification to the Language Server
    pub fn send_did_close(&mut self, view_id: ViewId) {
        let uri = self.opened_documents[&view_id].clone();
        let text_document_did_close_params =
            DidCloseTextDocumentParams { text_document: TextDocumentIdentifier { uri } };

        let params = Params::from(serde_json::to_value(text_document_did_close_params).unwrap());
        self.send_notification("textDocument/didClose", params);

        self.opened_documents.remove(&view_id);
    }

    /// Send textDocument/didChange Notification to the Language Server
    pub fn send_did_change(
        &mut self,
        view_id: ViewId,
        changes: Vec<TextDocumentContentChangeEvent>,
        version: u64,
    ) {
        let text_document_did_change_params = DidChangeTextDocumentParams {
            text_document: VersionedTextDocumentIdentifier {
                uri: self.opened_documents[&view_id].clone(),
                version: Some(version),
            },
            content_changes: changes,
        };

        let params = Params::from(serde_json::to_value(text_document_did_change_params).unwrap());
        self.send_notification("textDocument/didChange", params);
    }

    /// Send textDocument/didSave notification to the Language Server
    pub fn send_did_save(&mut self, view_id: ViewId, _document_text: &str) {
        // Add support for sending document text as well. Currently missing in LSP types
        // and is optional in LSP Specification
        let text_document_did_save_params = DidSaveTextDocumentParams {
            text_document: TextDocumentIdentifier { uri: self.opened_documents[&view_id].clone() },
        };
        let params = Params::from(serde_json::to_value(text_document_did_save_params).unwrap());
        self.send_notification("textDocument/didSave", params);
    }

    pub fn request_hover<CB>(&mut self, view_id: ViewId, position: Position, on_result: CB)
    where
        CB: 'static + Send + FnOnce(&mut LanguageServerClient, Result<Value, Error>),
    {
        let text_document_position_params = TextDocumentPositionParams {
            text_document: TextDocumentIdentifier { uri: self.opened_documents[&view_id].clone() },
            position,
        };

        let params = Params::from(serde_json::to_value(text_document_position_params).unwrap());
        self.send_request("textDocument/hover", params, Box::new(on_result))
    }
}

/// Helper methods to query the capabilities of the Language Server before making
/// a request. For example: we can check if the Language Server supports sending
/// incremental edits before proceeding to send one.
impl LanguageServerClient {
    /// Method to get the sync kind Supported by the Server
    pub fn get_sync_kind(&mut self) -> TextDocumentSyncKind {
        match self.server_capabilities.as_ref().and_then(|c| c.text_document_sync.as_ref()) {
            Some(&TextDocumentSyncCapability::Kind(kind)) => kind,
            _ => TextDocumentSyncKind::Full,
        }
    }
}

/// Language Specific Notification handling implementations
impl LanguageServerClient {
    pub fn handle_rust_misc_notification(&mut self, method: &str, params: Params) {
        match method {
            "window/progress" => {
                match params {
                    Params::Map(m) => {
                        let done = m.get("done").unwrap_or(&Value::Bool(false));
                        if let Value::Bool(done) = done {
                            let id: String =
                                serde_json::from_value(m.get("id").unwrap().clone()).unwrap();
                            if *done {
                                self.remove_status_item(&id);
                            } else {
                                let mut value = String::new();
                                if let Some(Value::String(s)) = &m.get("title") {
                                    value.push_str(&format!("{} ", s));
                                }

                                if let Some(Value::Number(n)) = &m.get("percentage") {
                                    value.push_str(&format!(
                                        "{} %",
                                        (n.as_f64().unwrap() * 100.00).round()
                                    ));
                                }

                                if let Some(Value::String(s)) = &m.get("message") {
                                    value.push_str(s);
                                }
                                // Add or update item
                                if self.status_items.contains(&id) {
                                    self.update_status_item(&id, &value);
                                } else {
                                    self.add_status_item(&id, &value, "left");
                                }
                            }
                        }
                    }
                    _ => warn!("Unexpected type"),
                }
            }
            _ => warn!("Unknown Notification from RLS: {} ", method),
        }
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::collections::HashMap;
use std::io::Error as IOError;

use jsonrpc_lite::Error as JsonRpcError;
use serde_json::Value;
use url::ParseError as UrlParseError;
use xi_plugin_lib::Error as PluginLibError;
use xi_rpc::RemoteError;

use crate::language_server_client::LanguageServerClient;
use crate::lsp_types::*;

pub enum LspHeader {
    ContentType,
    ContentLength(usize),
}

pub trait Callable: Send {
    fn call(
        self: Box<Self>,
        client: &mut LanguageServerClient,
        result: Result<Value, JsonRpcError>,
    );
}

impl<F: Send + FnOnce(&mut LanguageServerClient, Result<Value, JsonRpcError>)> Callable for F {
    fn call(self: Box<F>, client: &mut LanguageServerClient, result: Result<Value, JsonRpcError>) {
        (*self)(client, result)
    }
}

pub type Callback = Box<dyn Callable>;

#[derive(Serialize, Deserialize)]
/// Language Specific Configuration
pub struct LanguageConfig {
    pub language_name: String,
    pub start_command: String,
    pub start_arguments: Vec<String>,
    pub extensions: Vec<String>,
    pub supports_single_file: bool,
    pub workspace_identifier: Option<String>,
}

/// Represents the config for the Language Plugin
#[derive(Serialize, Deserialize)]
pub struct Config {
    pub language_config: HashMap<String, LanguageConfig>,
}

// Error Types

/// Type to represent errors occurred while parsing LSP RPCs
#[derive(Debug)]
pub enum ParseError {
    Io(std::io::Error),
    ParseInt(std::num::ParseIntError),
    Utf8(std::string::FromUtf8Error),
    Json(serde_json::Error),
    Unknown(String),
}

impl From<std::io::Error> for ParseError {
    fn from(err: std::io::Error) -> ParseError {
        ParseError::Io(err)
    }
}

impl From<std::string::FromUtf8Error> for ParseError {
    fn from(err: std::string::FromUtf8Error) -> ParseError {
        ParseError::Utf8(err)
    }
}

impl From<serde_json::Error> for ParseError {
    fn from(err: serde_json::Error) -> ParseError {
        ParseError::Json(err)
    }
}

impl From<std::num::ParseIntError> for ParseError {
    fn from(err: std::num::ParseIntError) -> ParseError {
        ParseError::ParseInt(err)
    }
}

impl From<String> for ParseError {
    fn from(s: String) -> ParseError {
        ParseError::Unknown(s)
    }
}

// TODO: Improve Error handling in module and add more types as necessary

/// Types to represent errors in the module.
#[derive(Debug)]
pub enum Error {
    PathError,
    FileUrlParseError,
    IOError(IOError),
    UrlParseError(UrlParseError),
}

impl From<UrlParseError> for Error {
    fn from(err: UrlParseError) -> Error {
        Error::UrlParseError(err)
    }
}

impl From<IOError> for Error {
    fn from(err: IOError) -> Error {
        Error::IOError(err)
    }
}

/// Possible Errors that can occur while handling Language Plugins
#[derive(Debug)]
pub enum LanguageResponseError {
    LanguageServerError(String),
    PluginLibError(PluginLibError),
    NullResponse,
    FallbackResponse,
}

impl From<PluginLibError> for LanguageResponseError {
    fn from(error: PluginLibError) -> Self {
        LanguageResponseError::PluginLibError(error)
    }
}

impl Into<RemoteError> for LanguageResponseError {
    fn into(self) -> RemoteError {
        match self {
            LanguageResponseError::NullResponse => {
                RemoteError::custom(0, "null response from server", None)
            }
            LanguageResponseError::FallbackResponse => {
                RemoteError::custom(1, "fallback response from server", None)
            }
            LanguageResponseError::LanguageServerError(error) => {
                RemoteError::custom(2, "language server error occured", Some(Value::String(error)))
            }
            LanguageResponseError::PluginLibError(error) => RemoteError::custom(
                3,
                "Plugin Lib Error",
                Some(Value::String(format!("{:?}", error))),
            ),
        }
    }
}

// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::ffi::OsStr;
use std::io::{BufReader, BufWriter};
use std::path::Path;
use std::process::{Command, Stdio};
use std::sync::{Arc, Mutex};

use url::Url;
use xi_plugin_lib::{Cache, ChunkCache, CoreProxy, Error as PluginLibError, View};
use xi_rope::rope::RopeDelta;

use crate::conversion_utils::*;
use crate::language_server_client::LanguageServerClient;
use crate::lsp_types::*;
use crate::parse_helper;
use crate::result_queue::ResultQueue;
use crate::types::Error;

/// Get contents changes of a document modeled according to Language Server Protocol
/// given the RopeDelta
pub fn get_document_content_changes<C: Cache>(
    delta: Option<&RopeDelta>,
    view: &mut View<C>,
) -> Result<Vec<TextDocumentContentChangeEvent>, PluginLibError> {
    if let Some(delta) = delta {
        let (interval, _) = delta.summary();
        let (start, end) = interval.start_end();

        // TODO: Handle more trivial cases like typing when there's a selection or transpose
        if let Some(node) = delta.as_simple_insert() {
            let text = String::from(node);

            let (start, end) = interval.start_end();
            let text_document_content_change_event = TextDocumentContentChangeEvent {
                range: Some(Range {
                    start: get_position_of_offset(view, start)?,
                    end: get_position_of_offset(view, end)?,
                }),
                range_length: Some((end - start) as u64),
                text,
            };

            return Ok(vec![text_document_content_change_event]);
        }
        // Or a simple delete
        else if delta.is_simple_delete() {
            let mut end_position = get_position_of_offset(view, end)?;

            // Hack around sending VSCode Style Positions to Language Server.
            // See this issue to understand: https://github.com/Microsoft/vscode/issues/23173
            if end_position.character == 0 {
                // There is an assumption here that the line separator character is exactly
                // 1 byte wide which is true for "\n" but it will be an issue if they are not
                // for example for u+2028
                let mut ep = get_position_of_offset(view, end - 1)?;
                ep.character += 1;
                end_position = ep;
            }

            let text_document_content_change_event = TextDocumentContentChangeEvent {
                range: Some(Range {
                    start: get_position_of_offset(view, start)?,
                    end: end_position,
                }),
                range_length: Some((end - start) as u64),
                text: String::new(),
            };

            return Ok(vec![text_document_content_change_event]);
        }
    }

    let text_document_content_change_event = TextDocumentContentChangeEvent {
        range: None,
        range_length: None,
        text: view.get_document()?,
    };

    Ok(vec![text_document_content_change_event])
}

/// Get changes to be sent to server depending upon the type of Sync supported
/// by server
pub fn get_change_for_sync_kind(
    sync_kind: TextDocumentSyncKind,
    view: &mut View<ChunkCache>,
    delta: Option<&RopeDelta>,
) -> Option<Vec<TextDocumentContentChangeEvent>> {
    match sync_kind {
        TextDocumentSyncKind::None => None,
        TextDocumentSyncKind::Full => {
            let text_document_content_change_event = TextDocumentContentChangeEvent {
                range: None,
                range_length: None,
                text: view.get_document().unwrap(),
            };
            Some(vec![text_document_content_change_event])
        }
        TextDocumentSyncKind::Incremental => match get_document_content_changes(delta, view) {
            Ok(result) => Some(result),
            Err(err) => {
                warn!("Error: {:?} Occured. Sending Whole Doc", err);
                let text_document_content_change_event = TextDocumentContentChangeEvent {
                    range: None,
                    range_length: None,
                    text: view.get_document().unwrap(),
                };
                Some(vec![text_document_content_change_event])
            }
        },
    }
}

/// Get workspace root using the Workspace Identifier and the opened document path
/// For example: Cargo.toml can be used to identify a Rust Workspace
/// This method traverses up to file tree to return the path to the Workspace root folder
pub fn get_workspace_root_uri(
    workspace_identifier: &str,
    document_path: &Path,
) -> Result<Url, Error> {
    let identifier_os_str = OsStr::new(&workspace_identifier);

    let mut current_path = document_path;
    loop {
        let parent_path = current_path.parent();
        if let Some(path) = parent_path {
            for entry in path.read_dir()? {
                if let Ok(entry) = entry {
                    if entry.file_name() == identifier_os_str {
                        return Url::from_file_path(path).map_err(|_| Error::FileUrlParseError);
                    };
                }
            }
            current_path = path;
        } else {
            break Err(Error::PathError);
        }
    }
}

/// Start a new Language Server Process by spawning a process given the parameters
/// Returns a Arc to the Language Server Client which abstracts connection to the
/// server
pub fn start_new_server(
    command: String,
    arguments: Vec<String>,
    file_extensions: Vec<String>,
    language_id: &str,
    core: CoreProxy,
    result_queue: ResultQueue,
) -> Result<Arc<Mutex<LanguageServerClient>>, String> {
    let mut process = Command::new(command)
        .args(arguments)
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .spawn()
        .expect("Error Occurred");

    let writer = Box::new(BufWriter::new(process.stdin.take().unwrap()));

    let language_server_client = Arc::new(Mutex::new(LanguageServerClient::new(
        writer,
        core,
        result_queue,
        language_id.to_owned(),
        file_extensions,
    )));

    {
        let ls_client = language_server_client.clone();
        let mut stdout = process.stdout;

        // Unwrap to indicate that we want thread to panic on failure
        std::thread::Builder::new()
            .name(format!("{}-lsp-stdout-Looper", language_id))
            .spawn(move || {
                let mut reader = Box::new(BufReader::new(stdout.take().unwrap()));
                loop {
                    match parse_helper::read_message(&mut reader) {
                        Ok(message_str) => {
                            let mut server_locked = ls_client.lock().unwrap();
                            server_locked.handle_message(message_str.as_ref());
                        }
                        Err(err) => error!("Error occurred {:?}", err),
                    };
                }
            })
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use crate::types::LspResponse;
use std::collections::VecDeque;
use std::sync::{Arc, Mutex};

#[derive(Clone, Debug, Default)]
pub struct ResultQueue(Arc<Mutex<VecDeque<(usize, LspResponse)>>>);

impl ResultQueue {
    pub fn new() -> Self {
        ResultQueue(Arc::new(Mutex::new(VecDeque::new())))
    }

    pub fn push_result(&mut self, request_id: usize, response: LspResponse) {
        let mut queue = self.0.lock().unwrap();
        queue.push_back((request_id, response));
    }

    pub fn pop_result(&mut self) -> Option<(usize, LspResponse)> {
        let mut queue = self.0.lock().unwrap();
        queue.pop_front()
    }
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Toy app for experimenting with ropes
extern crate xi_rope;

use xi_rope::Rope;

fn main() {
    let mut a = Rope::from("hello.");
    a.edit(5..6, "!");
    for i in 0..1000000 {
        let l = a.len();
        a.edit(l..l, &(i.to_string() + "\n"));
    }
    let l = a.len();
    for s in a.clone().iter_chunks(1000..3000) {
        println!("chunk {:?}", s);
    }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A data structure for representing multi-subsets of sequences (typically strings).

use std::cmp;

// These two imports are for the `apply` method only.
use crate::interval::Interval;
use crate::tree::{Node, NodeInfo, TreeBuilder};
use std::fmt;
use std::slice;

#[derive(Clone, PartialEq, Eq, Debug)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
struct Segment {
    len: usize,
    count: usize,
}

/// Represents a multi-subset of a string, that is a subset where elements can
/// be included multiple times. This is represented as each element of the
/// string having a "count" which is the number of times that element is
/// included in the set.
///
/// Internally, this is stored as a list of "segments" with a length and a count.
#[derive(Clone, PartialEq, Eq)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct Subset {
    /// Invariant, maintained by `SubsetBuilder`: all `Segment`s have non-zero
    /// length, and no `Segment` has the same count as the one before it.
    segments: Vec<Segment>,
}

#[derive(Default)]
pub struct SubsetBuilder {
    segments: Vec<Segment>,
    total_len: usize,
}

impl SubsetBuilder {
    pub fn new() -> SubsetBuilder {
        SubsetBuilder::default()
    }

    /// Intended for use with `add_range` to ensure the total length of the
    /// `Subset` corresponds to the document length.
    pub fn pad_to_len(&mut self, total_len: usize) {
        if total_len > self.total_len {
            let cur_len = self.total_len;
            self.push_segment(total_len - cur_len, 0);
        }
    }

    /// Sets the count for a given range. This method must be called with a
    /// non-empty range with `begin` not before the largest range or segment added
    /// so far. Gaps will be filled with a 0-count segment.
    pub fn add_range(&mut self, begin: usize, end: usize, count: usize) {
        assert!(begin >= self.total_len, "ranges must be added in non-decreasing order");
        // assert!(begin < end, "ranges added must be non-empty: [{},{})", begin, end);
        if begin >= end {
            return;
        }
        let len = end - begin;
        let cur_total_len = self.total_len;

        // add 0-count segment to fill any gap
        if begin > self.total_len {
            self.push_segment(begin - cur_total_len, 0);
        }

        self.push_segment(len, count);
    }

    /// Assign `count` to the next `len` elements in the string.
    /// Will panic if called with `len==0`.
    pub fn push_segment(&mut self, len: usize, count: usize) {
        assert!(len > 0, "can't push empty segment");
        self.total_len += len;

        // merge into previous segment if possible
        if let Some(last) = self.segments.last_mut() {
            if last.count == count {
                last.len += len;
                return;
            }
        }

        self.segments.push(Segment { len, count });
    }

    pub fn build(self) -> Subset {
        Subset { segments: self.segments }
    }
}

/// Determines which elements of a `Subset` a method applies to
/// based on the count of the element.
#[derive(Clone, Copy, Debug)]
pub enum CountMatcher {
    Zero,
    NonZero,
    All,
}

impl CountMatcher {
    fn matches(self, seg: &Segment) -> bool {
        match self {
            CountMatcher::Zero => (seg.count == 0),
            CountMatcher::NonZero => (seg.count != 0),
            CountMatcher::All => true,
        }
    }
}

impl Subset {
    /// Creates an empty `Subset` of a string of length `len`
    pub fn new(len: usize) -> Subset {
        let mut sb = SubsetBuilder::new();
        sb.pad_to_len(len);
        sb.build()
    }

    /// Mostly for testing.
    pub fn delete_from_string(&self, s: &str) -> String {
        let mut result = String::new();
        for (b, e) in self.range_iter(CountMatcher::Zero) {
            result.push_str(&s[b..e]);
        }
        result
    }

    // Maybe Subset should be a pure data structure and this method should
    // be a method of Node.
    /// Builds a version of `s` with all the elements in this `Subset` deleted from it.
    pub fn delete_from<N: NodeInfo>(&self, s: &Node<N>) -> Node<N> {
        let mut b = TreeBuilder::new();
        for (beg, end) in self.range_iter(CountMatcher::Zero) {
            s.push_subseq(&mut b, Interval::new(beg, end));
        }
        b.build()
    }

    /// The length of the resulting sequence after deleting this subset. A
    /// convenience alias for `self.count(CountMatcher::Zero)` to reduce
    /// thinking about what that means in the cases where the length after
    /// delete is what you want to know.
    ///
    /// `self.delete_from_string(s).len() = self.len(s.len())`
    pub fn len_after_delete(&self) -> usize {
        self.count(CountMatcher::Zero)
    }

    /// Count the total length of all the segments matching `matcher`.
    pub fn count(&self, matcher: CountMatcher) -> usize {
        self.segments.iter().filter(|seg| matcher.matches(seg)).map(|seg| seg.len).sum()
    }

    /// Convenience alias for `self.count(CountMatcher::All)`
    pub fn len(&self) -> usize {
        self.count(CountMatcher::All)
    }

    /// Determine whether the subset is empty.
    /// In this case deleting it would do nothing.
    pub fn is_empty(&self) -> bool {
        (self.segments.is_empty()) || ((self.segments.len() == 1) && (self.segments[0].count == 0))
    }

    /// Compute the union of two subsets. The count of an element in the
    /// result is the sum of the counts in the inputs.
    pub fn union(&self, other: &Subset) -> Subset {
        let mut sb = SubsetBuilder::new();
        for zseg in self.zip(other) {
            sb.push_segment(zseg.len, zseg.a_count + zseg.b_count);
        }
        sb.build()
    }

    /// Compute the difference of two subsets. The count of an element in the
    /// result is the subtraction of the counts of other from self.
    pub fn subtract(&self, other: &Subset) -> Subset {
        let mut sb = SubsetBuilder::new();
        for zseg in self.zip(other) {
            assert!(
                zseg.a_count >= zseg.b_count,
                "can't subtract {} from {}",
                zseg.a_count,
                zseg.b_count
            );
            sb.push_segment(zseg.len, zseg.a_count - zseg.b_count);
        }
        sb.build()
    }

    /// Compute the bitwise xor of two subsets, useful as a reversible
    /// difference. The count of an element in the result is the bitwise xor
    /// of the counts of the inputs. Unchanged segments will be 0.
    ///
    /// This works like set symmetric difference when all counts are 0 or 1
    /// but it extends nicely to the case of larger counts.
    pub fn bitxor(&self, other: &Subset) -> Subset {
        let mut sb = SubsetBuilder::new();
        for zseg in self.zip(other) {
            sb.push_segment(zseg.len, zseg.a_count ^ zseg.b_count);
        }
        sb.build()
    }

    /// Map the contents of `self` into the 0-regions of `other`.
    /// Precondition: `self.count(CountMatcher::All) == other.count(CountMatcher::Zero)`
    fn transform(&self, other: &Subset, union: bool) -> Subset {
        let mut sb = SubsetBuilder::new();
        let mut seg_iter = self.segments.iter();
        let mut cur_seg = Segment { len: 0, count: 0 };
        for oseg in &other.segments {
            if oseg.count > 0 {
                sb.push_segment(oseg.len, if union { oseg.count } else { 0 });
            } else {
                // fill 0-region with segments from self.
                let mut to_be_consumed = oseg.len;
                while to_be_consumed > 0 {
                    if cur_seg.len == 0 {
                        cur_seg = seg_iter
                            .next()
                            .expect("self must cover all 0-regions of other")
                            .clone();
                    }
                    // consume as much of the segment as possible and necessary
                    let to_consume = cmp::min(cur_seg.len, to_be_consumed);
                    sb.push_segment(to_consume, cur_seg.count);
                    to_be_consumed -= to_consume;
                    cur_seg.len -= to_consume;
                }
            }
        }
        assert_eq!(cur_seg.len, 0, "the 0-regions of other must be the size of self");
        assert_eq!(seg_iter.next(), None, "the 0-regions of other must be the size of self");
        sb.build()
    }

    /// Transform through coordinate transform represented by other.
    /// The equation satisfied is as follows:
    ///
    /// s1 = other.delete_from_string(s0)
    ///
    /// s2 = self.delete_from_string(s1)
    ///
    /// element in self.transform_expand(other).delete_from_string(s0) if (not in s1) or in s2
    pub fn transform_expand(&self, other: &Subset) -> Subset {
        self.transform(other, false)
    }

    /// The same as taking transform_expand and then unioning with `other`.
    pub fn transform_union(&self, other: &Subset) -> Subset {
        self.transform(other, true)
    }

    /// Transform subset through other coordinate transform, shrinking.
    /// The following equation is satisfied:
    ///
    /// C = A.transform_expand(B)
    ///
    /// B.transform_shrink(C).delete_from_string(C.delete_from_string(s)) =
    ///   A.delete_from_string(B.delete_from_string(s))
    pub fn transform_shrink(&self, other: &Subset) -> Subset {
        let mut sb = SubsetBuilder::new();
        // discard ZipSegments where the shrinking set has positive count
        for zseg in self.zip(other) {
            // TODO: should this actually do something like subtract counts?
            if zseg.b_count == 0 {
                sb.push_segment(zseg.len, zseg.a_count);
            }
        }
        sb.build()
    }

    /// Return an iterator over the ranges with a count matching the `matcher`.
    /// These will often be easier to work with than raw segments.
    pub fn range_iter(&self, matcher: CountMatcher) -> RangeIter {
        RangeIter { seg_iter: self.segments.iter(), consumed: 0, matcher }
    }

    /// Convenience alias for `self.range_iter(CountMatcher::Zero)`.
    /// Semantically iterates the ranges of the complement of this `Subset`.
    pub fn complement_iter(&self) -> RangeIter {
        self.range_iter(CountMatcher::Zero)
    }

    /// Return an iterator over `ZipSegment`s where each `ZipSegment` contains
    /// the count for both self and other in that range. The two `Subset`s
    /// must have the same total length.
    ///
    /// Each returned `ZipSegment` will differ in at least one count.
    pub fn zip<'a>(&'a self, other: &'a Subset) -> ZipIter<'a> {
        ZipIter {
            a_segs: self.segments.as_slice(),
            b_segs: other.segments.as_slice(),
            a_i: 0,
            b_i: 0,
            a_consumed: 0,
            b_consumed: 0,
            consumed: 0,
        }
    }

    /// Find the complement of this Subset. Every 0-count element will have a
    /// count of 1 and every non-zero element will have a count of 0.
    pub fn complement(&self) -> Subset {
        let mut sb = SubsetBuilder::new();
        for seg in &self.segments {
            if seg.count == 0 {
                sb.push_segment(seg.len, 1);
            } else {
                sb.push_segment(seg.len, 0);
            }
        }
        sb.build()
    }

    /// Return a `Mapper` that can be use to map coordinates in the document to coordinates
    /// in this `Subset`, but only in non-decreasing order for performance reasons.
    pub fn mapper(&self, matcher: CountMatcher) -> Mapper {
        Mapper {
            range_iter: self.range_iter(matcher),
            last_i: 0, // indices only need to be in non-decreasing order, not increasing
            cur_range: (0, 0), // will immediately try to consume next range
            subset_amount_consumed: 0,
        }
    }
}

impl fmt::Debug for Subset {
    /// Use the alternate flag (`#`) to print a more compact representation
    /// where each character represents the count of one element:
    /// '-' is 0, '#' is 1, 2-9 are digits, `+` is >9
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if f.alternate() {
            for s in &self.segments {
                let chr = if s.count == 0 {
                    '-'
                } else if s.count == 1 {
                    '#'
                } else if s.count <= 9 {
                    ((s.count as u8) + b'0') as char
                } else {
                    '+'
                };
                for _ in 0..s.len {
                    write!(f, "{}", chr)?;
                }
            }
            Ok(())
        } else {
            f.debug_tuple("Subset").field(&self.segments).finish()
        }
    }
}

pub struct RangeIter<'a> {
    seg_iter: slice::Iter<'a, Segment>,
    pub consumed: usize,
    matcher: CountMatcher,
}

impl<'a> Iterator for RangeIter<'a> {
    type Item = (usize, usize);

    fn next(&mut self) -> Option<(usize, usize)> {
        while let Some(seg) = self.seg_iter.next() {
            self.consumed += seg.len;
            if self.matcher.matches(seg) {
                return Some((self.consumed - seg.len, self.consumed));
            }
        }
        None
    }
}

/// See `Subset::zip`
pub struct ZipIter<'a> {
    a_segs: &'a [Segment],
    b_segs: &'a [Segment],
    a_i: usize,
    b_i: usize,
    a_consumed: usize,
    b_consumed: usize,
    pub consumed: usize,
}

/// See `Subset::zip`
#[derive(Clone, Debug)]
pub struct ZipSegment {
    len: usize,
    a_count: usize,
    b_count: usize,
}

impl<'a> Iterator for ZipIter<'a> {
    type Item = ZipSegment;

    /// Consume as far as possible from `self.consumed` until reaching a
    /// segment boundary in either `Subset`, and return the resulting
    /// `ZipSegment`. Will panic if it reaches the end of one `Subset` before
    /// the other, that is when they have different total length.
    fn next(&mut self) -> Option<ZipSegment> {
        match (self.a_segs.get(self.a_i), self.b_segs.get(self.b_i)) {
            (None, None) => None,
            (None, Some(_)) | (Some(_), None) => {
                panic!("can't zip Subsets of different base lengths.")
            }
            (
                Some(&Segment { len: a_len, count: a_count }),
                Some(&Segment { len: b_len, count: b_count }),
            ) => {
                let len = match (a_len + self.a_consumed).cmp(&(b_len + self.b_consumed)) {
                    cmp::Ordering::Equal => {
                        self.a_consumed += a_len;
                        self.a_i += 1;
                        self.b_consumed += b_len;
                        self.b_i += 1;
                        self.a_consumed - self.consumed
                    }
                    cmp::Ordering::Less => {
                        self.a_consumed += a_len;
                        self.a_i += 1;
                        self.a_consumed - self.consumed
                    }
                    cmp::Ordering::Greater => {
                        self.b_consumed += b_len;
                        self.b_i += 1;
                        self.b_consumed - self.consumed
                    }
                };
                self.consumed += len;
                Some(ZipSegment { len, a_count, b_count })
            }
        }
    }
}

pub struct Mapper<'a> {
    range_iter: RangeIter<'a>,
    // Not actually necessary for computation, just for dynamic checking of invariant
    last_i: usize,
    cur_range: (usize, usize),
    pub subset_amount_consumed: usize,
}

impl<'a> Mapper<'a> {
    /// Map a coordinate in the document this subset corresponds to, to a
    /// coordinate in the subset matched by the `CountMatcher`. For example,
    /// if the Subset is a set of deletions and the matcher is
    /// `CountMatcher::NonZero`, this would map indices in the union string to
    /// indices in the tombstones string.
    ///
    /// Will return the closest coordinate in the subset if the index is not
    /// in the subset. If the coordinate is past the end of the subset it will
    /// return one more than the largest index in the subset (i.e the length).
    /// This behaviour is suitable for mapping closed-open intervals in a
    /// string to intervals in a subset of the string.
    ///
    /// In order to guarantee good performance, this method must be called
    /// with `i` values in non-decreasing order or it will panic. This allows
    /// the total cost to be O(n) where `n = max(calls,ranges)` over all times
    /// called on a single `Mapper`.
    pub fn doc_index_to_subset(&mut self, i: usize) -> usize {
        assert!(
            i >= self.last_i,
            "method must be called with i in non-decreasing order. i={}<{}=last_i",
            i,
            self.last_i
        );
        self.last_i = i;

        while i >= self.cur_range.1 {
            self.subset_amount_consumed += self.cur_range.1 - self.cur_range.0;
            self.cur_range = match self.range_iter.next() {
                Some(range) => range,
                // past the end of the subset
                None => {
                    // ensure we don't try to consume any more
                    self.cur_range = (usize::max_value(), usize::max_value());
                    return self.subset_amount_consumed;
                }
            }
        }

        if i >= self.cur_range.0 {
            let dist_in_range = i - self.cur_range.0;
            dist_in_range + self.subset_amount_consumed
        } else {
            // not in the subset
            self.subset_amount_consumed
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::multiset::*;
    use crate::test_helpers::find_deletions;

    const TEST_STR: &'static str = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz";

    #[test]
    fn test_apply() {
        let mut sb = SubsetBuilder::new();
        for &(b, e) in &[
            (0, 1),
            (2, 4),
            (6, 11),
            (13, 14),
            (15, 18),
            (19, 23),
            (24, 26),
            (31, 32),
            (33, 35),
            (36, 37),
            (40, 44),
            (45, 48),
            (49, 51),
            (52, 57),
            (58, 59),
        ] {
            sb.add_range(b, e, 1);
        }
        sb.pad_to_len(TEST_STR.len());
        let s = sb.build();
        println!("{:?}", s);
        assert_eq!("145BCEINQRSTUWZbcdimpvxyz", s.delete_from_string(TEST_STR));
    }

    #[test]
    fn trivial() {
        let s = SubsetBuilder::new().build();
        assert!(s.is_empty());
    }

    #[test]
    fn test_find_deletions() {
        let substr = "015ABDFHJOPQVYdfgloprsuvz";
        let s = find_deletions(substr, TEST_STR);
        assert_eq!(substr, s.delete_from_string(TEST_STR));
        assert!(!s.is_empty())
    }

    #[test]
    fn test_complement() {
        let substr = "0456789DEFGHIJKLMNOPQRSTUVWXYZdefghijklmnopqrstuvw";
        let s = find_deletions(substr, TEST_STR);
        let c = s.complement();
        // deleting the complement of the deletions we found should yield the deletions
        assert_eq!("123ABCabcxyz", c.delete_from_string(TEST_STR));
    }

    #[test]
    fn test_mapper() {
        let substr = "469ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwz";
        let s = find_deletions(substr, TEST_STR);
        let mut m = s.mapper(CountMatcher::NonZero);
        // subset is {0123 5 78 xy}
        assert_eq!(0, m.doc_index_to_subset(0));
        assert_eq!(2, m.doc_index_to_subset(2));
        assert_eq!(2, m.doc_index_to_subset(2));
        assert_eq!(3, m.doc_index_to_subset(3));
        assert_eq!(4, m.doc_index_to_subset(4)); // not in subset
        assert_eq!(4, m.doc_index_to_subset(5));
        assert_eq!(5, m.doc_index_to_subset(7));
        assert_eq!(6, m.doc_index_to_subset(8));
        assert_eq!(6, m.doc_index_to_subset(8));
        assert_eq!(8, m.doc_index_to_subset(60));
        assert_eq!(9, m.doc_index_to_subset(61)); // not in subset
        assert_eq!(9, m.doc_index_to_subset(62)); // not in subset
    }

    #[test]
    #[should_panic(expected = "non-decreasing")]
    fn test_mapper_requires_non_decreasing() {
        let substr = "469ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvw";
        let s = find_deletions(substr, TEST_STR);
        let mut m = s.mapper(CountMatcher::NonZero);
        m.doc_index_to_subset(0);
        m.doc_index_to_subset(2);
        m.doc_index_to_subset(1);
    }

    #[test]
    fn union() {
        let s1 = find_deletions("024AEGHJKNQTUWXYZabcfgikqrvy", TEST_STR);
        let s2 = find_deletions("14589DEFGIKMOPQRUXZabcdefglnpsuxyz", TEST_STR);
        assert_eq!("4EGKQUXZabcfgy", s1.union(&s2).delete_from_string(TEST_STR));
    }

    fn transform_case(str1: &str, str2: &str, result: &str) {
        let s1 = find_deletions(str1, TEST_STR);
        let s2 = find_deletions(str2, str1);
        let s3 = s2.transform_expand(&s1);
        let str3 = s3.delete_from_string(TEST_STR);
        assert_eq!(result, str3);
        assert_eq!(str2, s1.transform_shrink(&s3).delete_from_string(&str3));
        assert_eq!(str2, s2.transform_union(&s1).delete_from_string(TEST_STR));
    }

    #[test]
    fn transform() {
        transform_case(
            "02345678BCDFGHKLNOPQRTUVXZbcefghjlmnopqrstwx",
            "027CDGKLOTUbcegopqrw",
            "01279ACDEGIJKLMOSTUWYabcdegikopqruvwyz",
        );
        transform_case(
            "01234678DHIKLMNOPQRUWZbcdhjostvy",
            "136KLPQZvy",
            "13569ABCEFGJKLPQSTVXYZaefgiklmnpqruvwxyz",
        );
        transform_case(
            "0125789BDEFIJKLMNPVXabdjmrstuwy",
            "12BIJVXjmrstu",
            "12346ABCGHIJOQRSTUVWXYZcefghijklmnopqrstuvxz",
        );
        transform_case(
            "12456789ABCEFGJKLMNPQRSTUVXYadefghkrtwxz",
            "15ACEFGKLPRUVYdhrtx",
            "0135ACDEFGHIKLOPRUVWYZbcdhijlmnopqrstuvxy",
        );
        transform_case(
            "0128ABCDEFGIJMNOPQXYZabcfgijkloqruvy",
            "2CEFGMZabijloruvy",
            "2345679CEFGHKLMRSTUVWZabdehijlmnoprstuvwxyz",
        );
        transform_case(
            "01245689ABCDGJKLMPQSTWXYbcdfgjlmnosvy",
            "01245ABCDJLQSWXYgsv",
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Trees for text.

#![allow(
    clippy::collapsible_if,
    clippy::len_without_is_empty,
    clippy::many_single_char_names,
    clippy::needless_range_loop,
    clippy::new_without_default,
    clippy::should_implement_trait,
    clippy::wrong_self_convention
)]

extern crate bytecount;
extern crate memchr;
extern crate regex;
extern crate unicode_segmentation;

#[cfg(feature = "serde")]
#[macro_use]
extern crate serde;

#[cfg(test)]
extern crate serde_json;
#[cfg(test)]
extern crate serde_test;

pub mod breaks;
pub mod compare;
pub mod delta;
pub mod diff;
pub mod engine;
pub mod find;
pub mod interval;
pub mod multiset;
pub mod rope;
#[cfg(feature = "serde")]
mod serde_impls;
pub mod spans;
#[cfg(test)]
mod test_helpers;
pub mod tree;
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Computing deltas between two ropes.

use std::borrow::Cow;
use std::collections::HashMap;

use crate::compare::RopeScanner;
use crate::delta::{Delta, DeltaElement};
use crate::interval::Interval;
use crate::rope::{LinesMetric, Rope, RopeDelta, RopeInfo};
use crate::tree::{Node, NodeInfo};

/// A trait implemented by various diffing strategies.
pub trait Diff<N: NodeInfo> {
    fn compute_delta(base: &Node<N>, target: &Node<N>) -> Delta<N>;
}

/// The minimum length of non-whitespace characters in a line before
/// we consider it for diffing purposes.
const MIN_SIZE: usize = 32;

/// A line-oriented, hash based diff algorithm.
///
/// This works by taking a hash of each line in either document that
/// has a length, ignoring leading whitespace, above some threshold.
///
/// Lines in the target document are matched against lines in the
/// base document. When a match is found, it is extended forwards
/// and backwards as far as possible.
///
/// This runs in O(n+m) in the lengths of the two ropes, and produces
/// results on a variety of workloads that are comparable in quality
/// (measured in terms of serialized diff size) with the results from
/// using a suffix array, while being an order of magnitude faster.
pub struct LineHashDiff;

impl Diff<RopeInfo> for LineHashDiff {
    fn compute_delta(base: &Rope, target: &Rope) -> RopeDelta {
        let mut builder = DiffBuilder::default();

        // before doing anything, scan top down and bottom up for like-ness.
        let mut scanner = RopeScanner::new(base, target);
        let (start_offset, diff_end) = scanner.find_min_diff_range();
        let target_end = target.len() - diff_end;

        if start_offset > 0 {
            builder.copy(0, 0, start_offset);
        }

        // if our preliminary scan finds no differences we're done
        if start_offset == base.len() && target.len() == base.len() {
            return builder.to_delta(base, target);
        }

        // if a continuous range of text got deleted, we're done
        if target.len() < base.len() && start_offset + diff_end == target.len() {
            builder.copy(base.len() - diff_end, target_end, diff_end);
            return builder.to_delta(base, target);
        }

        // if a continuous range of text got inserted, we're done
        if target.len() > base.len() && start_offset + diff_end == base.len() {
            builder.copy(base.len() - diff_end, target_end, diff_end);
            return builder.to_delta(base, target);
        }

        let line_hashes = make_line_hashes(&base, MIN_SIZE);

        let line_count = target.measure::<LinesMetric>() + 1;
        let mut matches = Vec::with_capacity(line_count);

        let mut targ_line_offset = 0;
        let mut prev_base = 0;

        let mut needs_subseq = false;
        for line in target.lines_raw(start_offset..target_end) {
            let non_ws = non_ws_offset(&line);
            if line.len() - non_ws >= MIN_SIZE {
                if let Some(base_off) = line_hashes.get(&line[non_ws..]) {
                    let targ_off = targ_line_offset + non_ws;
                    matches.push((start_offset + targ_off, *base_off));
                    if *base_off < prev_base {
                        needs_subseq = true;
                    }
                    prev_base = *base_off;
                }
            }
            targ_line_offset += line.len();
        }

        // we now have an ordered list of matches and their positions.
        // to ensure that our delta only copies non-decreasing base regions,
        // we take the longest increasing subsequence.
        // TODO: a possible optimization here would be to expand matches
        // to adjacent lines first? this would be at best a small win though..

        let longest_subseq =
            if needs_subseq { longest_increasing_region_set(&matches) } else { matches };

        // for each matching region, we extend it forwards and backwards.
        // we keep track of how far forward we extend it each time, to avoid
        // having a subsequent scan extend backwards over the same region.
        let mut prev_end = start_offset;

        for (targ_off, base_off) in longest_subseq {
            if targ_off <= prev_end {
                continue;
            }
            let (left_dist, mut right_dist) =
                expand_match(base, target, base_off, targ_off, prev_end);

            // don't let last match expand past target_end
            right_dist = right_dist.min(target_end - targ_off);

            let targ_start = targ_off - left_dist;
            let base_start = base_off - left_dist;
            let len = left_dist + right_dist;
            prev_end = targ_start + len;

            builder.copy(base_start, targ_start, len);
        }

        if diff_end > 0 {
            builder.copy(base.len() - diff_end, target.len() - diff_end, diff_end);
        }

        builder.to_delta(base, target)
    }
}

/// Given two ropes and the offsets of two equal bytes, finds the largest
/// identical substring shared between the two ropes which contains the offset.
///
/// The return value is a pair of offsets, each of which represents an absolute
/// distance. That is to say, the position of the start and end boundaries
/// relative to the input offset.
fn expand_match(
    base: &Rope,
    target: &Rope,
    base_off: usize,
    targ_off: usize,
    prev_match_targ_end: usize,
) -> (usize, usize) {
    let mut scanner = RopeScanner::new(base, target);
    let max_left = targ_off - prev_match_targ_end;
    let start = scanner.find_ne_char_back(base_off, targ_off, max_left);
    debug_assert!(start <= max_left, "{} <= {}", start, max_left);
    let end = scanner.find_ne_char(base_off, targ_off, None);
    (start.min(max_left), end)
}

/// Finds the longest increasing subset of copyable regions. This is essentially
/// the longest increasing subsequence problem. This implementation is adapted
/// from https://codereview.stackexchange.com/questions/187337/longest-increasing-subsequence-algorithm
fn longest_increasing_region_set(items: &[(usize, usize)]) -> Vec<(usize, usize)> {
    let mut result = vec![0];
    let mut prev_chain = vec![0; items.len()];

    for i in 1..items.len() {
        // If the next item is greater than the last item of the current longest
        // subsequence, push its index at the end of the result and continue.
        let last_idx = *result.last().unwrap();
        if items[last_idx].1 < items[i].1 {
            prev_chain[i] = last_idx;
            result.push(i);
            continue;
        }

        let next_idx = match result.binary_search_by(|&j| items[j].1.cmp(&items[i].1)) {
            Ok(_) => continue, // we ignore duplicates
            Err(idx) => idx,
        };

        if items[i].1 < items[result[next_idx]].1 {
            if next_idx > 0 {
                prev_chain[i] = result[next_idx - 1];
            }
            result[next_idx] = i;
        }
    }

    // walk backwards from the last item in result to build the final sequence
    let mut u = result.len();
    let mut v = *result.last().unwrap();
    while u != 0 {
        u -= 1;
        result[u] = v;
        v = prev_chain[v];
    }
    result.iter().map(|i| items[*i]).collect()
}

#[inline]
fn non_ws_offset(s: &str) -> usize {
    s.as_bytes().iter().take_while(|b| **b == b' ' || **b == b'\t').count()
}

/// Represents copying `len` bytes from base to target.
#[derive(Debug, Clone, Copy)]
struct DiffOp {
    target_idx: usize,
    base_idx: usize,
    len: usize,
}

/// Keeps track of copy ops during diff construction.
#[derive(Debug, Clone, Default)]
pub struct DiffBuilder {
    ops: Vec<DiffOp>,
}

impl DiffBuilder {
    fn copy(&mut self, base: usize, target: usize, len: usize) {
        if let Some(prev) = self.ops.last_mut() {
            let prev_end = prev.target_idx + prev.len;
            let base_end = prev.base_idx + prev.len;
            assert!(prev_end <= target, "{} <= {} prev {:?}", prev_end, target, prev);
            if prev_end == target && base_end == base {
                prev.len += len;
                return;
            }
        }
        self.ops.push(DiffOp { target_idx: target, base_idx: base, len })
    }

    fn to_delta(self, base: &Rope, target: &Rope) -> RopeDelta {
        let mut els = Vec::with_capacity(self.ops.len() * 2);
        let mut targ_pos = 0;
        for DiffOp { base_idx, target_idx, len } in self.ops {
            if target_idx > targ_pos {
                let iv = Interval::new(targ_pos, target_idx);
                els.push(DeltaElement::Insert(target.subseq(iv)));
            }
            els.push(DeltaElement::Copy(base_idx, base_idx + len));
            targ_pos = target_idx + len;
        }

        if targ_pos < target.len() {
            let iv = Interval::new(targ_pos, target.len());
            els.push(DeltaElement::Insert(target.subseq(iv)));
        }

        Delta { els, base_len: base.len() }
    }
}

/// Creates a map of lines to offsets, ignoring trailing whitespace, and only for those lines
/// where line.len() >= min_size. Offsets refer to the first non-whitespace byte in the line.
fn make_line_hashes<'a>(base: &'a Rope, min_size: usize) -> HashMap<Cow<'a, str>, usize> {
    let mut offset = 0;
    let mut line_hashes = HashMap::with_capacity(base.len() / 60);
    for line in base.lines_raw(..) {
        let non_ws = non_ws_offset(&line);
        if line.len() - non_ws >= min_size {
            let cow = match line {
                Cow::Owned(ref s) => Cow::Owned(s[non_ws..].to_string()),
                Cow::Borrowed(s) => Cow::Borrowed(&s[non_ws..]),
            };
            line_hashes.insert(cow, offset + non_ws);
        }
        offset += line.len();
    }
    line_hashes
}

#[cfg(test)]
mod tests {
    use super::*;

    static SMALL_ONE: &str = "This adds FixedSizeAdler32, that has a size set at construction, and keeps bytes in a cyclic buffer of that size to be removed when it fills up.

Current logic (and implementing Write) might be too much, since bytes will probably always be fed one by one anyway. Otherwise a faster way of removing a sequence might be needed (one by one is inefficient).";

    static SMALL_TWO: &str = "This adds some function, I guess?, that has a size set at construction, and keeps bytes in a cyclic buffer of that size to be ground up and injested when it fills up.

Currently my sense of smell (and the pain of implementing Write) might be too much, since bytes will probably always be fed one by one anyway. Otherwise crying might be needed (one by one is inefficient).";

    static INTERVAL_STR: &str = include_str!("../src/interval.rs");
    static BREAKS_STR: &str = include_str!("../src/breaks.rs");

    #[test]
    fn diff_smoke_test() {
        let one = SMALL_ONE.into();
        let two = SMALL_TWO.into();

        let delta = LineHashDiff::compute_delta(&one, &two);
        println!("delta: {:?}", &delta);

        let result = delta.apply(&one);
        assert_eq!(result, two);

        let delta = LineHashDiff::compute_delta(&one, &two);
        println!("delta: {:?}", &delta);

        let result = delta.apply(&one);
        assert_eq!(result, two);
    }

    #[test]
    fn simple_diff() {
        let one = "This is a simple string".into();
        let two = "This is a string".into();

        let delta = LineHashDiff::compute_delta(&one, &two);
        println!("delta: {:?}", &delta);

        let result = delta.apply(&one);
        assert_eq!(result, two);

        let delta = LineHashDiff::compute_delta(&two, &one);
        println!("delta: {:?}", &delta);

        let result = delta.apply(&two);
        assert_eq!(result, one);
    }

    #[test]
    fn test_larger_diff() {
        let one = INTERVAL_STR.into();
        let two = BREAKS_STR.into();

        let delta = LineHashDiff::compute_delta(&one, &two);
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A rope data structure with a line count metric and (soon) other useful
//! info.

#![allow(clippy::needless_return)]

use std::borrow::Cow;
use std::cmp::{max, min, Ordering};
use std::fmt;
use std::ops::Add;
use std::str::{self, FromStr};
use std::string::ParseError;

use crate::delta::{Delta, DeltaElement};
use crate::interval::{Interval, IntervalBounds};
use crate::tree::{Cursor, DefaultMetric, Leaf, Metric, Node, NodeInfo, TreeBuilder};

use memchr::{memchr, memrchr};
use unicode_segmentation::{GraphemeCursor, GraphemeIncomplete};

const MIN_LEAF: usize = 511;
const MAX_LEAF: usize = 1024;

/// A rope data structure.
///
/// A [rope](https://en.wikipedia.org/wiki/Rope_(data_structure)) is a data structure
/// for strings, specialized for incremental editing operations. Most operations
/// (such as insert, delete, substring) are O(log n). This module provides an immutable
/// (also known as [persistent](https://en.wikipedia.org/wiki/Persistent_data_structure))
/// version of Ropes, and if there are many copies of similar strings, the common parts
/// are shared.
///
/// Internally, the implementation uses thread safe reference counting.
/// Mutations are generally copy-on-write, though in-place edits are
/// supported as an optimization when only one reference exists, making the
/// implementation as efficient as a mutable version.
///
/// Also note: in addition to the `From` traits described below, this module
/// implements `From<Rope> for String` and `From<&Rope> for String`, for easy
/// conversions in both directions.
///
/// # Examples
///
/// Create a `Rope` from a `String`:
///
/// ```rust
/// # use xi_rope::Rope;
/// let a = Rope::from("hello ");
/// let b = Rope::from("world");
/// assert_eq!("hello world", String::from(a.clone() + b.clone()));
/// assert!("hello world" == String::from(a + b));
/// ```
///
/// Get a slice of a `Rope`:
///
/// ```rust
/// # use xi_rope::Rope;
/// let a = Rope::from("hello world");
/// let b = a.slice(1..9);
/// assert_eq!("ello wor", String::from(&b));
/// let c = b.slice(1..7);
/// assert_eq!("llo wo", String::from(c));
/// ```
///
/// Replace part of a `Rope`:
///
/// ```rust
/// # use xi_rope::Rope;
/// let mut a = Rope::from("hello world");
/// a.edit(1..9, "era");
/// assert_eq!("herald", String::from(a));
/// ```
pub type Rope = Node<RopeInfo>;

/// Represents a transform from one rope to another.
pub type RopeDelta = Delta<RopeInfo>;

/// An element in a `RopeDelta`.
pub type RopeDeltaElement = DeltaElement<RopeInfo>;

impl Leaf for String {
    fn len(&self) -> usize {
        self.len()
    }

    fn is_ok_child(&self) -> bool {
        self.len() >= MIN_LEAF
    }

    fn push_maybe_split(&mut self, other: &String, iv: Interval) -> Option<String> {
        //println!("push_maybe_split [{}] [{}] {:?}", self, other, iv);
        let (start, end) = iv.start_end();
        self.push_str(&other[start..end]);
        if self.len() <= MAX_LEAF {
            None
        } else {
            let splitpoint = find_leaf_split_for_merge(self);
            let right_str = self[splitpoint..].to_owned();
            self.truncate(splitpoint);
            self.shrink_to_fit();
            Some(right_str)
        }
    }
}

#[derive(Clone, Copy)]
pub struct RopeInfo {
    lines: usize,
    utf16_size: usize,
}

impl NodeInfo for RopeInfo {
    type L = String;

    fn accumulate(&mut self, other: &Self) {
        self.lines += other.lines;
        self.utf16_size += other.utf16_size;
    }

    fn compute_info(s: &String) -> Self {
        RopeInfo { lines: count_newlines(s), utf16_size: count_utf16_code_units(s) }
    }

    fn identity() -> Self {
        RopeInfo { lines: 0, utf16_size: 0 }
    }
}

impl DefaultMetric for RopeInfo {
    type DefaultMetric = BaseMetric;
}

//TODO: document metrics, based on https://github.com/google/xi-editor/issues/456
//See ../docs/MetricsAndBoundaries.md for more information.
/// This metric let us walk utf8 text by code point.
///
/// `BaseMetric` implements the trait [Metric].  Both its _measured unit_ and
/// its _base unit_ are utf8 code unit.
///
/// Offsets that do not correspond to codepoint boundaries are _invalid_, and
/// calling functions that assume valid offsets with invalid offets will panic
/// in debug mode.
///
/// Boundary is atomic and determined by codepoint boundary.  Atomicity is
/// implicit, because offsets between two utf8 code units that form a code
/// point is considered invalid. For example, if a string starts with a
/// 0xC2 byte, then `offset=1` is invalid.
#[derive(Clone, Copy)]
pub struct BaseMetric(());

impl Metric<RopeInfo> for BaseMetric {
    fn measure(_: &RopeInfo, len: usize) -> usize {
        len
    }

    fn to_base_units(s: &String, in_measured_units: usize) -> usize {
        debug_assert!(s.is_char_boundary(in_measured_units));
        in_measured_units
    }

    fn from_base_units(s: &String, in_base_units: usize) -> usize {
        debug_assert!(s.is_char_boundary(in_base_units));
        in_base_units
    }

    fn is_boundary(s: &String, offset: usize) -> bool {
        s.is_char_boundary(offset)
    }

    fn prev(s: &String, offset: usize) -> Option<usize> {
        if offset == 0 {
            // I think it's a precondition that this will never be called
            // with offset == 0, but be defensive.
            None
        } else {
            let mut len = 1;
            while !s.is_char_boundary(offset - len) {
                len += 1;
            }
            Some(offset - len)
        }
    }

    fn next(s: &String, offset: usize) -> Option<usize> {
        if offset == s.len() {
            // I think it's a precondition that this will never be called
            // with offset == s.len(), but be defensive.
            None
        } else {
            let b = s.as_bytes()[offset];
            Some(offset + len_utf8_from_first_byte(b))
        }
    }

    fn can_fragment() -> bool {
        false
    }
}

/// Given the inital byte of a UTF-8 codepoint, returns the number of
/// bytes required to represent the codepoint.
/// RFC reference : https://tools.ietf.org/html/rfc3629#section-4
pub fn len_utf8_from_first_byte(b: u8) -> usize {
    match b {
        b if b < 0x80 => 1,
        b if b < 0xe0 => 2,
        b if b < 0xf0 => 3,
        _ => 4,
    }
}

#[derive(Clone, Copy)]
pub struct LinesMetric(usize); // number of lines

/// Measured unit is newline amount.
/// Base unit is utf8 code unit.
/// Boundary is trailing and determined by a newline char.
impl Metric<RopeInfo> for LinesMetric {
    fn measure(info: &RopeInfo, _: usize) -> usize {
        info.lines
    }

    fn is_boundary(s: &String, offset: usize) -> bool {
        if offset == 0 {
            // shouldn't be called with this, but be defensive
            false
        } else {
            s.as_bytes()[offset - 1] == b'\n'
        }
    }

    fn to_base_units(s: &String, in_measured_units: usize) -> usize {
        let mut offset = 0;
        for _ in 0..in_measured_units {
            match memchr(b'\n', &s.as_bytes()[offset..]) {
                Some(pos) => offset += pos + 1,
                _ => panic!("to_base_units called with arg too large"),
            }
        }
        offset
    }

    fn from_base_units(s: &String, in_base_units: usize) -> usize {
        count_newlines(&s[..in_base_units])
    }

    fn prev(s: &String, offset: usize) -> Option<usize> {
        debug_assert!(offset > 0, "caller is responsible for validating input");
        memrchr(b'\n', &s.as_bytes()[..offset - 1]).map(|pos| pos + 1)
    }

    fn next(s: &String, offset: usize) -> Option<usize> {
        memchr(b'\n', &s.as_bytes()[offset..]).map(|pos| offset + pos + 1)
    }

    fn can_fragment() -> bool {
        true
    }
}

#[derive(Clone, Copy)]
pub struct Utf16CodeUnitsMetric(usize);

impl Metric<RopeInfo> for Utf16CodeUnitsMetric {
    fn measure(info: &RopeInfo, _: usize) -> usize {
        info.utf16_size
    }

    fn is_boundary(s: &String, offset: usize) -> bool {
        s.is_char_boundary(offset)
    }

    fn to_base_units(s: &String, in_measured_units: usize) -> usize {
        let mut cur_len_utf16 = 0;
        let mut cur_len_utf8 = 0;
        for u in s.chars() {
            if cur_len_utf16 >= in_measured_units {
                break;
            }
            cur_len_utf16 += u.len_utf16();
            cur_len_utf8 += u.len_utf8();
        }
        cur_len_utf8
    }

    fn from_base_units(s: &String, in_base_units: usize) -> usize {
        count_utf16_code_units(&s[..in_base_units])
    }

    fn prev(s: &String, offset: usize) -> Option<usize> {
        if offset == 0 {
            // I think it's a precondition that this will never be called
            // with offset == 0, but be defensive.
            None
        } else {
            let mut len = 1;
            while !s.is_char_boundary(offset - len) {
                len += 1;
            }
            Some(offset - len)
        }
    }

    fn next(s: &String, offset: usize) -> Option<usize> {
        if offset == s.len() {
            // I think it's a precondition that this will never be called
            // with offset == s.len(), but be defensive.
            None
        } else {
            let b = s.as_bytes()[offset];
            Some(offset + len_utf8_from_first_byte(b))
        }
    }

    fn can_fragment() -> bool {
        false
    }
}

// Low level functions

pub fn count_newlines(s: &str) -> usize {
    bytecount::count(s.as_bytes(), b'\n')
}

fn count_utf16_code_units(s: &str) -> usize {
    let mut utf16_count = 0;
    for &b in s.as_bytes() {
        if (b as i8) >= -0x40 {
            utf16_count += 1;
        }
        if b >= 0xf0 {
            utf16_count += 1;
        }
    }
    utf16_count
}

fn find_leaf_split_for_bulk(s: &str) -> usize {
    find_leaf_split(s, MIN_LEAF)
}

fn find_leaf_split_for_merge(s: &str) -> usize {
    find_leaf_split(s, max(MIN_LEAF, s.len() - MAX_LEAF))
}

// Try to split at newline boundary (leaning left), if not, then split at codepoint
fn find_leaf_split(s: &str, minsplit: usize) -> usize {
    let mut splitpoint = min(MAX_LEAF, s.len() - MIN_LEAF);
    match memrchr(b'\n', &s.as_bytes()[minsplit - 1..splitpoint]) {
        Some(pos) => minsplit + pos,
        None => {
            while !s.is_char_boundary(splitpoint) {
                splitpoint -= 1;
            }
            splitpoint
        }
    }
}

// Additional APIs custom to strings

impl FromStr for Rope {
    type Err = ParseError;
    fn from_str(s: &str) -> Result<Rope, Self::Err> {
        let mut b = TreeBuilder::new();
        b.push_str(s);
        Ok(b.build())
    }
}

impl Rope {
    /// Edit the string, replacing the byte range [`start`..`end`] with `new`.
    ///
    /// Time complexity: O(log n)
    #[deprecated(since = "0.3.0", note = "Use Rope::edit instead")]
    pub fn edit_str<T: IntervalBounds>(&mut self, iv: T, new: &str) {
        self.edit(iv, new)
    }

    /// Returns a new Rope with the contents of the provided range.
    pub fn slice<T: IntervalBounds>(&self, iv: T) -> Rope {
        self.subseq(iv)
    }

    // encourage callers to use Cursor instead?

    /// Determine whether `offset` lies on a codepoint boundary.
    pub fn is_codepoint_boundary(&self, offset: usize) -> bool {
        let mut cursor = Cursor::new(self, offset);
        cursor.is_boundary::<BaseMetric>()
    }

    /// Return the offset of the codepoint before `offset`.
    pub fn prev_codepoint_offset(&self, offset: usize) -> Option<usize> {
        let mut cursor = Cursor::new(self, offset);
        cursor.prev::<BaseMetric>()
    }

    /// Return the offset of the codepoint after `offset`.
    pub fn next_codepoint_offset(&self, offset: usize) -> Option<usize> {
        let mut cursor = Cursor::new(self, offset);
        cursor.next::<BaseMetric>()
    }

    /// Returns `offset` if it lies on a codepoint boundary. Otherwise returns
    /// the codepoint after `offset`.
    pub fn at_or_next_codepoint_boundary(&self, offset: usize) -> Option<usize> {
        if self.is_codepoint_boundary(offset) {
            Some(offset)
        } else {
            self.next_codepoint_offset(offset)
        }
    }

    /// Returns `offset` if it lies on a codepoint boundary. Otherwise returns
    /// the codepoint before `offset`.
    pub fn at_or_prev_codepoint_boundary(&self, offset: usize) -> Option<usize> {
        if self.is_codepoint_boundary(offset) {
            Some(offset)
        } else {
            self.prev_codepoint_offset(offset)
        }
    }

    pub fn prev_grapheme_offset(&self, offset: usize) -> Option<usize> {
        let mut cursor = Cursor::new(self, offset);
        cursor.prev_grapheme()
    }

    pub fn next_grapheme_offset(&self, offset: usize) -> Option<usize> {
        let mut cursor = Cursor::new(self, offset);
        cursor.next_grapheme()
    }

    /// Return the line number corresponding to the byte index `offset`.
    ///
    /// The line number is 0-based, thus this is equivalent to the count of newlines
    /// in the slice up to `offset`.
    ///
    /// Time complexity: O(log n)
    ///
    /// # Panics
    ///
    /// This function will panic if `offset > self.len()`. Callers are expected to
    /// validate their input.
    pub fn line_of_offset(&self, offset: usize) -> usize {
        self.count::<LinesMetric>(offset)
    }

    /// Return the byte offset corresponding to the line number `line`.
    /// If `line` is equal to one plus the current number of lines,
    /// this returns the offset of the end of the rope. Arguments higher
    /// than this will panic.
    ///
    /// The line number is 0-based.
    ///
    /// Time complexity: O(log n)
    ///
    /// # Panics
    ///
    /// This function will panic if `line > self.measure::<LinesMetric>() + 1`.
    /// Callers are expected to validate their input.
    pub fn offset_of_line(&self, line: usize) -> usize {
        let max_line = self.measure::<LinesMetric>() + 1;
        match line.cmp(&max_line) {
            Ordering::Greater => {
                panic!("line number {} beyond last line {}", line, max_line);
            }
            Ordering::Equal => {
                return self.len();
            }
            Ordering::Less => self.count_base_units::<LinesMetric>(line),
        }
    }

    /// Returns an iterator over chunks of the rope.
    ///
    /// Each chunk is a `&str` slice borrowed from the rope's storage. The size
    /// of the chunks is indeterminate but for large strings will generally be
    /// in the range of 511-1024 bytes.
    ///
    /// The empty string will yield a single empty slice. In all other cases, the
    /// slices will be nonempty.
    ///
    /// Time complexity: technically O(n log n), but the constant factor is so
    /// tiny it is effectively O(n). This iterator does not allocate.
    pub fn iter_chunks<T: IntervalBounds>(&self, range: T) -> ChunkIter {
        let Interval { start, end } = range.into_interval(self.len());

        ChunkIter { cursor: Cursor::new(self, start), end }
    }

    /// An iterator over the raw lines. The lines, except the last, include the
    /// terminating newline.
    ///
    /// The return type is a `Cow<str>`, and in most cases the lines are slices
    /// borrowed from the rope.
    pub fn lines_raw<T: IntervalBounds>(&self, range: T) -> LinesRaw {
        LinesRaw { inner: self.iter_chunks(range), fragment: "" }
    }

    /// An iterator over the lines of a rope.
    ///
    /// Lines are ended with either Unix (`\n`) or MS-DOS (`\r\n`) style line endings.
    /// The line ending is stripped from the resulting string. The final line ending
    /// is optional.
    ///
    /// The return type is a `Cow<str>`, and in most cases the lines are slices borrowed
    /// from the rope.
    ///
    /// The semantics are intended to match `str::lines()`.
    pub fn lines<T: IntervalBounds>(&self, range: T) -> Lines {
        Lines { inner: self.lines_raw(range) }
    }

    // callers should be encouraged to use cursor instead
    pub fn byte_at(&self, offset: usize) -> u8 {
        let cursor = Cursor::new(self, offset);
        let (leaf, pos) = cursor.get_leaf().unwrap();
        leaf.as_bytes()[pos]
    }

    pub fn slice_to_cow<T: IntervalBounds>(&self, range: T) -> Cow<str> {
        let mut iter = self.iter_chunks(range);
        let first = iter.next();
        let second = iter.next();

        match (first, second) {
            (None, None) => Cow::from(""),
            (Some(s), None) => Cow::from(s),
            (Some(one), Some(two)) => {
                let mut result = [one, two].concat();
                for chunk in iter {
                    result.push_str(chunk);
                }
                Cow::from(result)
            }
            (None, Some(_)) => unreachable!(),
        }
    }
}

// should make this generic, but most leaf types aren't going to be sliceable
pub struct ChunkIter<'a> {
    cursor: Cursor<'a, RopeInfo>,
    end: usize,
}

impl<'a> Iterator for ChunkIter<'a> {
    type Item = &'a str;

    fn next(&mut self) -> Option<&'a str> {
        if self.cursor.pos() >= self.end {
            return None;
        }
        let (leaf, start_pos) = self.cursor.get_leaf().unwrap();
        let len = min(self.end - self.cursor.pos(), leaf.len() - start_pos);
        self.cursor.next_leaf();
        Some(&leaf[start_pos..start_pos + len])
    }
}

impl TreeBuilder<RopeInfo> {
    /// Push a string on the accumulating tree in the naive way.
    ///
    /// Splits the provided string in chunks that fit in a leaf
    /// and pushes the leaves one by one onto the tree by calling
    /// `push_leaf` on the builder.
    pub fn push_str(&mut self, mut s: &str) {
        if s.len() <= MAX_LEAF {
            if !s.is_empty() {
                self.push_leaf(s.to_owned());
            }
            return;
        }
        while !s.is_empty() {
            let splitpoint = if s.len() > MAX_LEAF { find_leaf_split_for_bulk(s) } else { s.len() };
            self.push_leaf(s[..splitpoint].to_owned());
            s = &s[splitpoint..];
        }
    }
}

impl<T: AsRef<str>> From<T> for Rope {
    fn from(s: T) -> Rope {
        Rope::from_str(s.as_ref()).unwrap()
    }
}

impl From<Rope> for String {
    // maybe explore grabbing leaf? would require api in tree
    fn from(r: Rope) -> String {
        String::from(&r)
    }
}

impl<'a> From<&'a Rope> for String {
    fn from(r: &Rope) -> String {
        r.slice_to_cow(..).into_owned()
    }
}

impl fmt::Display for Rope {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        for s in self.iter_chunks(..) {
            write!(f, "{}", s)?;
        }
        Ok(())
    }
}

impl fmt::Debug for Rope {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if f.alternate() {
            write!(f, "{}", String::from(self))
        } else {
            write!(f, "Rope({:?})", String::from(self))
        }
    }
}

impl Add for Rope {
    type Output = Rope;
    fn add(self, rhs: Rope) -> Rope {
        let mut b = TreeBuilder::new();
        b.push(self);
        b.push(rhs);
        b.build()
    }
}

//additional cursor features

impl<'a> Cursor<'a, RopeInfo> {
    /// Get previous codepoint before cursor position, and advance cursor backwards.
    pub fn prev_codepoint(&mut self) -> Option<char> {
        self.prev::<BaseMetric>();
        if let Some((l, offset)) = self.get_leaf() {
            l[offset..].chars().next()
        } else {
            None
        }
    }

    /// Get next codepoint after cursor position, and advance cursor.
    pub fn next_codepoint(&mut self) -> Option<char> {
        if let Some((l, offset)) = self.get_leaf() {
            self.next::<BaseMetric>();
            l[offset..].chars().next()
        } else {
            None
        }
    }

    /// Get the next codepoint after the cursor position, without advancing
    /// the cursor.
    pub fn peek_next_codepoint(&self) -> Option<char> {
        self.get_leaf().and_then(|(l, off)| l[off..].chars().next())
    }

    pub fn next_grapheme(&mut self) -> Option<usize> {
        let (mut l, mut offset) = self.get_leaf()?;
        let mut pos = self.pos();
        while offset < l.len() && !l.is_char_boundary(offset) {
            pos -= 1;
            offset -= 1;
        }
        let mut leaf_offset = pos - offset;
        let mut c = GraphemeCursor::new(pos, self.total_len(), true);
        let mut next_boundary = c.next_boundary(&l, leaf_offset);
        while let Err(incomp) = next_boundary {
            if let GraphemeIncomplete::PreContext(_) = incomp {
                let (pl, poffset) = self.prev_leaf()?;
                c.provide_context(&pl, self.pos() - poffset);
            } else if incomp == GraphemeIncomplete::NextChunk {
                self.set(pos);
                let (nl, noffset) = self.next_leaf()?;
                l = nl;
                leaf_offset = self.pos() - noffset;
                pos = leaf_offset + nl.len();
            } else {
                return None;
            }
            next_boundary = c.next_boundary(&l, leaf_offset);
        }
        next_boundary.unwrap_or(None)
    }

    pub fn prev_grapheme(&mut self) -> Option<usize> {
        let (mut l, mut offset) = self.get_leaf()?;
        let mut pos = self.pos();
        while offset < l.len() && !l.is_char_boundary(offset) {
            pos += 1;
            offset += 1;
        }
        let mut leaf_offset = pos - offset;
        let mut c = GraphemeCursor::new(pos, l.len() + leaf_offset, true);
        let mut prev_boundary = c.prev_boundary(&l, leaf_offset);
        while let Err(incomp) = prev_boundary {
            if let GraphemeIncomplete::PreContext(_) = incomp {
                let (pl, poffset) = self.prev_leaf()?;
                c.provide_context(&pl, self.pos() - poffset);
            } else if incomp == GraphemeIncomplete::PrevChunk {
                self.set(pos);
                let (pl, poffset) = self.prev_leaf()?;
                l = pl;
                leaf_offset = self.pos() - poffset;
                pos = leaf_offset + pl.len();
            } else {
                return None;
            }
            prev_boundary = c.prev_boundary(&l, leaf_offset);
        }
        prev_boundary.unwrap_or(None)
    }
}

// line iterators

pub struct LinesRaw<'a> {
    inner: ChunkIter<'a>,
    fragment: &'a str,
}

fn cow_append<'a>(a: Cow<'a, str>, b: &'a str) -> Cow<'a, str> {
    if a.is_empty() {
        Cow::from(b)
    } else {
        Cow::from(a.into_owned() + b)
    }
}

impl<'a> Iterator for LinesRaw<'a> {
    type Item = Cow<'a, str>;

    fn next(&mut self) -> Option<Cow<'a, str>> {
        let mut result = Cow::from("");
        loop {
            if self.fragment.is_empty() {
                match self.inner.next() {
                    Some(chunk) => self.fragment = chunk,
                    None => return if result.is_empty() { None } else { Some(result) },
                }
                if self.fragment.is_empty() {
                    // can only happen on empty input
                    return None;
                }
            }
            match memchr(b'\n', self.fragment.as_bytes()) {
                Some(i) => {
                    result = cow_append(result, &self.fragment[..=i]);
                    self.fragment = &self.fragment[i + 1..];
                    return Some(result);
                }
                None => {
                    result = cow_append(result, self.fragment);
                    self.fragment = "";
                }
            }
        }
    }
}

pub struct Lines<'a> {
    inner: LinesRaw<'a>,
}

impl<'a> Iterator for Lines<'a> {
    type Item = Cow<'a, str>;

    fn next(&mut self) -> Option<Cow<'a, str>> {
        match self.inner.next() {
            Some(Cow::Borrowed(mut s)) => {
                if s.ends_with('\n') {
                    s = &s[..s.len() - 1];
                    if s.ends_with('\r') {
                        s = &s[..s.len() - 1];
                    }
                }
                Some(Cow::from(s))
            }
            Some(Cow::Owned(mut s)) => {
                if s.ends_with('\n') {
                    let _ = s.pop();
                    if s.ends_with('\r') {
                        let _ = s.pop();
                    }
                }
                Some(Cow::from(s))
            }
            None => None,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn replace_small() {
        let mut a = Rope::from("hello world");
        a.edit(1..9, "era");
        assert_eq!("herald", String::from(a));
    }

    #[test]
    fn lines_raw_small() {
        let a = Rope::from("a\nb\nc");
        assert_eq!(vec!["a\n", "b\n", "c"], a.lines_raw(..).collect::<Vec<_>>());
        assert_eq!(vec!["a\n", "b\n", "c"], a.lines_raw(..).collect::<Vec<_>>());

        let a = Rope::from("a\nb\n");
        assert_eq!(vec!["a\n", "b\n"], a.lines_raw(..).collect::<Vec<_>>());

        let a = Rope::from("\n");
        assert_eq!(vec!["\n"], a.lines_raw(..).collect::<Vec<_>>());

        let a = Rope::from("");
        assert_eq!(0, a.lines_raw(..).count());
    }

    #[test]
    fn lines_small() {
        let a = Rope::from("a\nb\nc");
        assert_eq!(vec!["a", "b", "c"], a.lines(..).collect::<Vec<_>>());
        assert_eq!(String::from(&a).lines().collect::<Vec<_>>(), a.lines(..).collect::<Vec<_>>());

        let a = Rope::from("a\nb\n");
        assert_eq!(vec!["a", "b"], a.lines(..).collect::<Vec<_>>());
        assert_eq!(String::from(&a).lines().collect::<Vec<_>>(), a.lines(..).collect::<Vec<_>>());

        let a = Rope::from("\n");
        assert_eq!(vec![""], a.lines(..).collect::<Vec<_>>());
        assert_eq!(String::from(&a).lines().collect::<Vec<_>>(), a.lines(..).collect::<Vec<_>>());

        let a = Rope::from("");
        assert_eq!(0, a.lines(..).count());
        assert_eq!(String::from(&a).lines().collect::<Vec<_>>(), a.lines(..).collect::<Vec<_>>());

        let a = Rope::from("a\r\nb\r\nc");
        assert_eq!(vec!["a", "b", "c"], a.lines(..).collect::<Vec<_>>());
        assert_eq!(String::from(&a).lines().collect::<Vec<_>>(), a.lines(..).collect::<Vec<_>>());

        let a = Rope::from("a\rb\rc");
        assert_eq!(vec!["a\rb\rc"], a.lines(..).collect::<Vec<_>>());
        assert_eq!(String::from(&a).lines().collect::<Vec<_>>(), a.lines(..).collect::<Vec<_>>());
    }

    #[test]
    fn lines_med() {
        let mut a = String::new();
        let mut b = String::new();
        let line_len = MAX_LEAF + MIN_LEAF - 1;
        for _ in 0..line_len {
            a.push('a');
            b.push('b');
        }
        a.push('\n');
        b.push('\n');
        let r = Rope::from(&a[..MAX_LEAF]);
        let r = r + Rope::from(String::from(&a[MAX_LEAF..]) + &b[..MIN_LEAF]);
        let r = r + Rope::from(&b[MIN_LEAF..]);
        //println!("{:?}", r.iter_chunks().collect::<Vec<_>>());

        assert_eq!(vec![a.as_str(), b.as_str()], r.lines_raw(..).collect::<Vec<_>>());
        assert_eq!(vec![&a[..line_len], &b[..line_len]], r.lines(..).collect::<Vec<_>>());
        assert_eq!(String::from(&r).lines().collect::<Vec<_>>(), r.lines(..).collect::<Vec<_>>());

        // additional tests for line indexing
        assert_eq!(a.len(), r.offset_of_line(1));
        assert_eq!(r.len(), r.offset_of_line(2));
        assert_eq!(0, r.line_of_offset(a.len() - 1));
        assert_eq!(1, r.line_of_offset(a.len()));
        assert_eq!(1, r.line_of_offset(r.len() - 1));
        assert_eq!(2, r.line_of_offset(r.len()));
    }

    #[test]
    fn append_large() {
        let mut a = Rope::from("");
        let mut b = String::new();
        for i in 0..5_000 {
            let c = i.to_string() + "\n";
            b.push_str(&c);
            a = a + Rope::from(&c);
        }
        assert_eq!(b, String::from(a));
    }

    #[test]
    fn prev_codepoint_offset_small() {
        let a = Rope::from("a\u{00A1}\u{4E00}\u{1F4A9}");
        assert_eq!(Some(6), a.prev_codepoint_offset(10));
        assert_eq!(Some(3), a.prev_codepoint_offset(6));
        assert_eq!(Some(1), a.prev_codepoint_offset(3));
        assert_eq!(Some(0), a.prev_codepoint_offset(1));
        assert_eq!(None, a.prev_codepoint_offset(0));
        let b = a.slice(1..10);
        assert_eq!(Some(5), b.prev_codepoint_offset(9));
        assert_eq!(Some(2), b.prev_codepoint_offset(5));
        assert_eq!(Some(0), b.prev_codepoint_offset(2));
        assert_eq!(None, b.prev_codepoint_offset(0));
    }

    #[test]
    fn next_codepoint_offset_small() {
        let a = Rope::from("a\u{00A1}\u{4E00}\u{1F4A9}");
        assert_eq!(Some(10), a.next_codepoint_offset(6));
        assert_eq!(Some(6), a.next_codepoint_offset(3));
        assert_eq!(Some(3), a.next_codepoint_offset(1));
        assert_eq!(Some(1), a.next_codepoint_offset(0));
        assert_eq!(None, a.next_codepoint_offset(10));
        let b = a.slice(1..10);
        assert_eq!(Some(9), b.next_codepoint_offset(5));
        assert_eq!(Some(5), b.next_codepoint_offset(2));
        assert_eq!(Some(2), b.next_codepoint_offset(0));
        assert_eq!(None, b.next_codepoint_offset(9));
    }

    #[test]
    fn peek_next_codepoint() {
        let inp = Rope::from("$¢€£💶");
        let mut cursor = Cursor::new(&inp, 0);
        assert_eq!(cursor.peek_next_codepoint(), Some('$'));
        assert_eq!(cursor.peek_next_codepoint(), Some('$'));
        assert_eq!(cursor.next_codepoint(), Some('$'));
        assert_eq!(cursor.peek_next_codepoint(), Some('¢'));
        assert_eq!(cursor.prev_codepoint(), Some('$'));
        assert_eq!(cursor.peek_next_codepoint(), Some('$'));
        assert_eq!(cursor.next_codepoint(), Some('$'));
        assert_eq!(cursor.next_codepoint(), Some('¢'));
        assert_eq!(cursor.peek_next_codepoint(), Some('€'));
        assert_eq!(cursor.next_codepoint(), Some('€'));
        assert_eq!(cursor.peek_next_codepoint(), Some('£'));
        assert_eq!(cursor.next_codepoint(), Some('£'));
        assert_eq!(cursor.peek_next_codepoint(), Some('💶'));
        assert_eq!(cursor.next_codepoint(), Some('💶'));
        assert_eq!(cursor.peek_next_codepoint(), None);
        assert_eq!(cursor.next_codepoint(), None);
        assert_eq!(cursor.peek_next_codepoint(), None);
    }

    #[test]
    fn prev_grapheme_offset() {
        // A with ring, hangul, regional indicator "US"
        let a = Rope::from("A\u{030a}\u{110b}\u{1161}\u{1f1fa}\u{1f1f8}");
        assert_eq!(Some(9), a.prev_grapheme_offset(17));
        assert_eq!(Some(3), a.prev_grapheme_offset(9));
        assert_eq!(Some(0), a.prev_grapheme_offset(3));
        assert_eq!(None, a.prev_grapheme_offset(0));
    }

    #[test]
    fn next_grapheme_offset() {
        // A with ring, hangul, regional indicator "US"
        let a = Rope::from("A\u{030a}\u{110b}\u{1161}\u{1f1fa}\u{1f1f8}");
        assert_eq!(Some(3), a.next_grapheme_offset(0));
        assert_eq!(Some(9), a.next_grapheme_offset(3));
        assert_eq!(Some(17), a.next_grapheme_offset(9));
        assert_eq!(None, a.next_grapheme_offset(17));
    }

    #[test]
    fn next_grapheme_offset_with_ris_of_leaf_boundaries() {
        let s1 = "\u{1f1fa}\u{1f1f8}".repeat(100);
        let a = Rope::concat(
            Rope::from(s1.clone()),
            Rope::concat(
                Rope::from(String::from(s1.clone()) + "\u{1f1fa}"),
                Rope::from(s1.clone()),
            ),
        );
        for i in 1..(s1.len() * 3) {
            assert_eq!(Some((i - 1) / 8 * 8), a.prev_grapheme_offset(i));
            assert_eq!(Some(i / 8 * 8 + 8), a.next_grapheme_offset(i));
        }
        for i in (s1.len() * 3 + 1)..(s1.len() * 3 + 4) {
            assert_eq!(Some(s1.len() * 3), a.prev_grapheme_offset(i));
            assert_eq!(Some(s1.len() * 3 + 4), a.next_grapheme_offset(i));
        }
        assert_eq!(None, a.prev_grapheme_offset(0));
        assert_eq!(Some(8), a.next_grapheme_offset(0));
        assert_eq!(Some(s1.len() * 3), a.prev_grapheme_offset(s1.len() * 3 + 4));
        assert_eq!(None, a.next_grapheme_offset(s1.len() * 3 + 4));
    }

    #[test]
    fn line_of_offset_small() {
        let a = Rope::from("a\nb\nc");
        assert_eq!(0, a.line_of_offset(0));
        assert_eq!(0, a.line_of_offset(1));
        assert_eq!(1, a.line_of_offset(2));
        assert_eq!(1, a.line_of_offset(3));
        assert_eq!(2, a.line_of_offset(4));
        assert_eq!(2, a.line_of_offset(5));
        let b = a.slice(2..4);
        assert_eq!(0, b.line_of_offset(0));
        assert_eq!(0, b.line_of_offset(1));
        assert_eq!(1, b.line_of_offset(2));
    }

    #[test]
    fn offset_of_line_small() {
        let a = Rope::from("a\nb\nc");
        assert_eq!(0, a.offset_of_line(0));
        assert_eq!(2, a.offset_of_line(1));
        assert_eq!(4, a.offset_of_line(2));
        assert_eq!(5, a.offset_of_line(3));
        let b = a.slice(2..4);
        assert_eq!(0, b.offset_of_line(0));
        assert_eq!(2, b.offset_of_line(1));
    }

    #[test]
    fn eq_small() {
        let a = Rope::from("a");
        let a2 = Rope::from("a");
        let b = Rope::from("b");
        let empty = Rope::from("");
        assert!(a == a2);
        assert!(a != b);
        assert!(a != empty);
        assert!(empty == empty);
        assert!(a.slice(0..0) == empty);
    }

    #[test]
    fn eq_med() {
        let mut a = String::new();
        let mut b = String::new();
        let line_len = MAX_LEAF + MIN_LEAF - 1;
        for _ in 0..line_len {
            a.push('a');
            b.push('b');
        }
        a.push('\n');
        b.push('\n');
        let r = Rope::from(&a[..MAX_LEAF]);
        let r = r + Rope::from(String::from(&a[MAX_LEAF..]) + &b[..MIN_LEAF]);
        let r = r + Rope::from(&b[MIN_LEAF..]);

        let a_rope = Rope::from(&a);
        let b_rope = Rope::from(&b);
        assert!(r != a_rope);
        assert!(r.clone().slice(..a.len()) == a_rope);
        assert!(r.clone().slice(a.len()..) == b_rope);
        assert!(r == a_rope.clone() + b_rope.clone());
        assert!(r != b_rope + a_rope);
    }

    #[test]
    fn line_offsets() {
        let rope = Rope::from("hi\ni'm\nfour\nlines");
        assert_eq!(rope.offset_of_line(0), 0);
        assert_eq!(rope.offset_of_line(1), 3);
        assert_eq!(rope.line_of_offset(0), 0);
        assert_eq!(rope.line_of_offset(3), 1);
        // interior of first line should be first line
        assert_eq!(rope.line_of_offset(1), 0);
        // interior of last line should be last line
        assert_eq!(rope.line_of_offset(15), 3);
        assert_eq!(rope.offset_of_line(4), rope.len());
    }

    #[test]
    fn default_metric_test() {
        let rope = Rope::from("hi\ni'm\nfour\nlines\n");
        assert_eq!(
            rope.convert_metrics::<BaseMetric, LinesMetric>(rope.len()),
            rope.count::<LinesMetric>(rope.len())
        );
        assert_eq!(
            rope.convert_metrics::<LinesMetric, BaseMetric>(2),
            rope.count_base_units::<LinesMetric>(2)
        );
    }

    #[test]
    #[should_panic]
    fn line_of_offset_panic() {
        let rope = Rope::from("hi\ni'm\nfour\nlines");
        rope.line_of_offset(20);
    }

    #[test]
    #[should_panic]
    fn offset_of_line_panic() {
        let rope = Rope::from("hi\ni'm\nfour\nlines");
        rope.offset_of_line(5);
    }

    #[test]
    fn utf16_code_units_metric() {
        let rope = Rope::from("hi\ni'm\nfour\nlines");
        let utf16_units = rope.measure::<Utf16CodeUnitsMetric>();
        assert_eq!(utf16_units, 17);

        // position after 'f' in four
        let utf8_offset = 9;
        let utf16_units = rope.count::<Utf16CodeUnitsMetric>(utf8_offset);
        assert_eq!(utf16_units, 9);

        let utf8_offset = rope.count_base_units::<Utf16CodeUnitsMetric>(utf16_units);
        assert_eq!(utf8_offset, 9);

        let rope_with_emoji = Rope::from("hi\ni'm\n😀 four\nlines");
        let utf16_units = rope_with_emoji.measure::<Utf16CodeUnitsMetric>();

        assert_eq!(utf16_units, 20);

        // position after 'f' in four
        let utf8_offset = 13;
        let utf16_units = rope_with_emoji.count::<Utf16CodeUnitsMetric>(utf8_offset);
        assert_eq!(utf16_units, 11);

        let utf8_offset = rope_with_emoji.count_base_units::<Utf16CodeUnitsMetric>(utf16_units);
        assert_eq!(utf8_offset, 13);

        //for next line
        let utf8_offset = 19;
        let utf16_units = rope_with_emoji.count::<Utf16CodeUnitsMetric>(utf8_offset);
        assert_eq!(utf16_units, 17);

        let utf8_offset = rope_with_emoji.count_base_units::<Utf16CodeUnitsMetric>(utf16_units);
        assert_eq!(utf8_offset, 19);
    }

    #[test]
    fn slice_to_cow_small_string() {
        let short_text = "hi, i'm a small piece of text.";

        let rope = Rope::from(short_text);

        let cow = rope.slice_to_cow(..);

        assert!(short_text.len() <= 1024);
        assert_eq!(cow, Cow::Borrowed(short_text) as Cow<str>);
    }

    #[test]
    fn slice_to_cow_long_string_long_slice() {
        // 32 char long string, repeat it 33 times so it is longer than 1024 bytes
        let long_text =
            "1234567812345678123456781234567812345678123456781234567812345678".repeat(33);

        let rope = Rope::from(&long_text);

        let cow = rope.slice_to_cow(..);

        assert!(long_text.len() > 1024);
        assert_eq!(cow, Cow::Owned(long_text) as Cow<str>);
    }

    #[test]
    fn slice_to_cow_long_string_short_slice() {
        // 32 char long string, repeat it 33 times so it is longer than 1024 bytes
        let long_text =
            "1234567812345678123456781234567812345678123456781234567812345678".repeat(33);

        let rope = Rope::from(&long_text);

        let cow = rope.slice_to_cow(..500);

        assert!(long_text.len() > 1024);
        assert_eq!(cow, Cow::Borrowed(&long_text[..500]));
    }
}

#[cfg(all(test, feature = "serde"))]
mod serde_tests {
    use super::*;
    use crate::Rope;
    use serde_test::{assert_tokens, Token};

    #[test]
    fn serialize_and_deserialize() {
        const TEST_LINE: &str = "test line\n";

        // repeat test line enough times to exceed maximum leaf size
        let n_seg = MAX_LEAF / TEST_LINE.len() + 1;
        let test_str = TEST_LINE.repeat(n_seg);

        let rope = Rope::from(test_str.as_str());
        let json = serde_json::to_string(&rope).expect("error serializing");
        let deserialized_rope =
            serde_json::from_str::<Rope>(json.as_str()).expect("error deserializing");
        assert_eq!(rope, deserialized_rope);
    }

    #[test]
    fn test_ser_de() {
        let rope = Rope::from("a\u{00A1}\u{4E00}\u{1F4A9}");
        assert_tokens(&rope, &[Token::Str("a\u{00A1}\u{4E00}\u{1F4A9}")]);
        assert_tokens(&rope, &[Token::String("a\u{00A1}\u{4E00}\u{1F4A9}")]);
        assert_tokens(&rope, &[Token::BorrowedStr("a\u{00A1}\u{4E00}\u{1F4A9}")]);
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A general b-tree structure suitable for ropes and the like.

use std::cmp::{min, Ordering};
use std::marker::PhantomData;
use std::sync::Arc;

use crate::interval::{Interval, IntervalBounds};

const MIN_CHILDREN: usize = 4;
const MAX_CHILDREN: usize = 8;

pub trait NodeInfo: Clone {
    /// The type of the leaf.
    ///
    /// A given `NodeInfo` is for exactly one type of leaf. That is why
    /// the leaf type is an associated type rather than a type parameter.
    type L: Leaf;

    /// An operator that combines info from two subtrees. It is intended
    /// (but not strictly enforced) that this operator be associative and
    /// obey an identity property. In mathematical terms, the accumulate
    /// method is the operation of a monoid.
    fn accumulate(&mut self, other: &Self);

    /// A mapping from a leaf into the info type. It is intended (but
    /// not strictly enforced) that applying the accumulate method to
    /// the info derived from two leaves gives the same result as
    /// deriving the info from the concatenation of the two leaves. In
    /// mathematical terms, the compute_info method is a monoid
    /// homomorphism.
    fn compute_info(_: &Self::L) -> Self;

    /// The identity of the monoid. Need not be implemented because it
    /// can be computed from the leaf default.
    ///
    /// This is here to demonstrate that this is a monoid.
    fn identity() -> Self {
        Self::compute_info(&Self::L::default())
    }

    /// The interval covered by the first `len` base units of this node. The
    /// default impl is sufficient for most types, but interval trees may need
    /// to override it.
    fn interval(&self, len: usize) -> Interval {
        Interval::new(0, len)
    }
}

/// A trait indicating the default metric of a NodeInfo.
///
/// Adds quality of life functions to
/// Node\<N\>, where N is a DefaultMetric.
/// For example, [Node\<DefaultMetric\>.count](struct.Node.html#method.count).
pub trait DefaultMetric: NodeInfo {
    type DefaultMetric: Metric<Self>;
}

/// A trait for the leaves of trees of type [Node](struct.Node.html).
///
/// Two leafs can be concatenated using `push_maybe_split`.
pub trait Leaf: Sized + Clone + Default {
    /// Measurement of leaf in base units.
    /// A 'base unit' refers to the smallest discrete unit
    /// by which a given concrete type can be indexed.
    /// Concretely, for Rust's String type the base unit is the byte.
    fn len(&self) -> usize;

    /// Generally a minimum size requirement for leaves.
    fn is_ok_child(&self) -> bool;

    /// Combine the part `other` denoted by the `Interval` `iv` into `self`,
    /// optionly splitting off a new `Leaf` if `self` would have become too big.
    /// Returns either `None` if no splitting was needed, or `Some(rest)` if
    /// `rest` was split off.
    ///
    /// Interval is in "base units".  Generally implements a maximum size.
    ///
    /// # Invariants:
    /// - If one or the other input is empty, then no split.
    /// - If either input satisfies `is_ok_child`, then, on return, `self`
    ///   satisfies this, as does the optional split.
    fn push_maybe_split(&mut self, other: &Self, iv: Interval) -> Option<Self>;

    /// Same meaning as push_maybe_split starting from an empty
    /// leaf, but maybe can be implemented more efficiently?
    ///
    // TODO: remove if it doesn't pull its weight
    fn subseq(&self, iv: Interval) -> Self {
        let mut result = Self::default();
        if result.push_maybe_split(self, iv).is_some() {
            panic!("unexpected split");
        }
        result
    }
}

/// A b-tree node storing leaves at the bottom, and with info
/// retained at each node. It is implemented with atomic reference counting
/// and copy-on-write semantics, so an immutable clone is a very cheap
/// operation, and nodes can be shared across threads. Even so, it is
/// designed to be updated in place, with efficiency similar to a mutable
/// data structure, using uniqueness of reference count to detect when
/// this operation is safe.
///
/// When the leaf is a string, this is a rope data structure (a persistent
/// rope in functional programming jargon). However, it is not restricted
/// to strings, and it is expected to be the basis for a number of data
/// structures useful for text processing.
#[derive(Clone)]
pub struct Node<N: NodeInfo>(Arc<NodeBody<N>>);

#[derive(Clone)]
struct NodeBody<N: NodeInfo> {
    height: usize,
    len: usize,
    info: N,
    val: NodeVal<N>,
}

#[derive(Clone)]
enum NodeVal<N: NodeInfo> {
    Leaf(N::L),
    Internal(Vec<Node<N>>),
}

// also consider making Metric a newtype for usize, so type system can
// help separate metrics

/// A trait for quickly processing attributes of a
/// [NodeInfo](struct.NodeInfo.html).
///
/// For the conceptual background see the
/// [blog post, Rope science, part 2: metrics](https://github.com/google/xi-editor/blob/master/docs/docs/rope_science_02.md).
pub trait Metric<N: NodeInfo> {
    /// Return the size of the
    /// [NodeInfo::L](trait.NodeInfo.html#associatedtype.L), as measured by this
    /// metric.
    ///
    /// The usize argument is the total size/length of the node, in base units.
    ///
    /// # Examples
    /// For the [LinesMetric](../rope/struct.LinesMetric.html), this gives the number of
    /// lines in string contained in the leaf. For the
    /// [BaseMetric](../rope/struct.BaseMetric.html), this gives the size of the string
    /// in uft8 code units, that is, bytes.
    ///
    fn measure(info: &N, len: usize) -> usize;

    /// Returns the smallest offset, in base units, for an offset in measured units.
    ///
    /// # Invariants:
    ///
    /// - `from_base_units(to_base_units(x)) == x` is True for valid `x`
    fn to_base_units(l: &N::L, in_measured_units: usize) -> usize;

    /// Returns the smallest offset in measured units corresponding to an offset in base units.
    ///
    /// # Invariants:
    ///
    /// - `from_base_units(to_base_units(x)) == x` is True for valid `x`
    fn from_base_units(l: &N::L, in_base_units: usize) -> usize;

    /// Return whether the offset in base units is a boundary of this metric.
    /// If a boundary is at end of a leaf then this method must return true.
    /// However, a boundary at the beginning of a leaf is optional
    /// (the previous leaf will be queried).
    fn is_boundary(l: &N::L, offset: usize) -> bool;

    /// Returns the index of the boundary directly preceding offset,
    /// or None if no such boundary exists. Input and result are in base units.
    fn prev(l: &N::L, offset: usize) -> Option<usize>;

    /// Returns the index of the first boundary for which index > offset,
    /// or None if no such boundary exists. Input and result are in base units.
    fn next(l: &N::L, offset: usize) -> Option<usize>;

    /// Returns true if the measured units in this metric can span multiple
    /// leaves.  As an example, in a metric that measures lines in a rope, a
    /// line may start in one leaf and end in another; however in a metric
    /// measuring bytes, storage of a single byte cannot extend across leaves.
    fn can_fragment() -> bool;
}

impl<N: NodeInfo> Node<N> {
    pub fn from_leaf(l: N::L) -> Node<N> {
        let len = l.len();
        let info = N::compute_info(&l);
        Node(Arc::new(NodeBody { height: 0, len, info, val: NodeVal::Leaf(l) }))
    }

    /// Create a node from a vec of nodes.
    ///
    /// The input must satisfy the following balancing requirements:
    /// * The length of `nodes` must be <= MAX_CHILDREN and > 1.
    /// * All the nodes are the same height.
    /// * All the nodes must satisfy is_ok_child.
    fn from_nodes(nodes: Vec<Node<N>>) -> Node<N> {
        debug_assert!(nodes.len() > 1);
        debug_assert!(nodes.len() <= MAX_CHILDREN);
        let height = nodes[0].0.height + 1;
        let mut len = nodes[0].0.len;
        let mut info = nodes[0].0.info.clone();
        debug_assert!(nodes[0].is_ok_child());
        for child in &nodes[1..] {
            debug_assert_eq!(child.height() + 1, height);
            debug_assert!(child.is_ok_child());
            len += child.0.len;
            info.accumulate(&child.0.info);
        }
        Node(Arc::new(NodeBody { height, len, info, val: NodeVal::Internal(nodes) }))
    }

    pub fn len(&self) -> usize {
        self.0.len
    }

    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Returns `true` if these two `Node`s share the same underlying data.
    ///
    /// This is principally intended to be used by the druid crate, without needing
    /// to actually add a feature and implement druid's `Data` trait.
    pub fn ptr_eq(&self, other: &Self) -> bool {
        Arc::ptr_eq(&self.0, &other.0)
    }

    fn height(&self) -> usize {
        self.0.height
    }

    fn is_leaf(&self) -> bool {
        self.0.height == 0
    }

    fn interval(&self) -> Interval {
        self.0.info.interval(self.0.len)
    }

    fn get_children(&self) -> &[Node<N>] {
        if let NodeVal::Internal(ref v) = self.0.val {
            v
        } else {
            panic!("get_children called on leaf node");
        }
    }

    fn get_leaf(&self) -> &N::L {
        if let NodeVal::Leaf(ref l) = self.0.val {
            l
        } else {
            panic!("get_leaf called on internal node");
        }
    }

    /// Call a callback with a mutable reference to a leaf.
    ///
    /// This clones the leaf if the reference is shared. It also recomputes
    /// length and info after the leaf is mutated.
    fn with_leaf_mut<T>(&mut self, f: impl FnOnce(&mut N::L) -> T) -> T {
        let inner = Arc::make_mut(&mut self.0);
        if let NodeVal::Leaf(ref mut l) = inner.val {
            let result = f(l);
            inner.len = l.len();
            inner.info = N::compute_info(l);
            result
        } else {
            panic!("with_leaf_mut called on internal node");
        }
    }

    fn is_ok_child(&self) -> bool {
        match self.0.val {
            NodeVal::Leaf(ref l) => l.is_ok_child(),
            NodeVal::Internal(ref nodes) => (nodes.len() >= MIN_CHILDREN),
        }
    }

    fn merge_nodes(children1: &[Node<N>], children2: &[Node<N>]) -> Node<N> {
        let n_children = children1.len() + children2.len();
        if n_children <= MAX_CHILDREN {
            Node::from_nodes([children1, children2].concat())
        } else {
            // Note: this leans left. Splitting at midpoint is also an option
            let splitpoint = min(MAX_CHILDREN, n_children - MIN_CHILDREN);
            let mut iter = children1.iter().chain(children2.iter()).cloned();
            let left = iter.by_ref().take(splitpoint).collect();
            let right = iter.collect();
            let parent_nodes = vec![Node::from_nodes(left), Node::from_nodes(right)];
            Node::from_nodes(parent_nodes)
        }
    }

    fn merge_leaves(mut rope1: Node<N>, rope2: Node<N>) -> Node<N> {
        debug_assert!(rope1.is_leaf() && rope2.is_leaf());

        let both_ok = rope1.get_leaf().is_ok_child() && rope2.get_leaf().is_ok_child();
        if both_ok {
            return Node::from_nodes(vec![rope1, rope2]);
        }
        match {
            let node1 = Arc::make_mut(&mut rope1.0);
            let leaf2 = rope2.get_leaf();
            if let NodeVal::Leaf(ref mut leaf1) = node1.val {
                let leaf2_iv = Interval::new(0, leaf2.len());
                let new = leaf1.push_maybe_split(leaf2, leaf2_iv);
                node1.len = leaf1.len();
                node1.info = N::compute_info(leaf1);
                new
            } else {
                panic!("merge_leaves called on non-leaf");
            }
        } {
            Some(new) => Node::from_nodes(vec![rope1, Node::from_leaf(new)]),
            None => rope1,
        }
    }

    pub fn concat(rope1: Node<N>, rope2: Node<N>) -> Node<N> {
        let h1 = rope1.height();
        let h2 = rope2.height();

        match h1.cmp(&h2) {
            Ordering::Less => {
                let children2 = rope2.get_children();
                if h1 == h2 - 1 && rope1.is_ok_child() {
                    return Node::merge_nodes(&[rope1], children2);
                }
                let newrope = Node::concat(rope1, children2[0].clone());
                if newrope.height() == h2 - 1 {
                    Node::merge_nodes(&[newrope], &children2[1..])
                } else {
                    Node::merge_nodes(newrope.get_children(), &children2[1..])
                }
            }
            Ordering::Equal => {
                if rope1.is_ok_child() && rope2.is_ok_child() {
                    return Node::from_nodes(vec![rope1, rope2]);
                }
                if h1 == 0 {
                    return Node::merge_leaves(rope1, rope2);
                }
                Node::merge_nodes(rope1.get_children(), rope2.get_children())
            }
            Ordering::Greater => {
                let children1 = rope1.get_children();
                if h2 == h1 - 1 && rope2.is_ok_child() {
                    return Node::merge_nodes(children1, &[rope2]);
                }
                let lastix = children1.len() - 1;
                let newrope = Node::concat(children1[lastix].clone(), rope2);
                if newrope.height() == h1 - 1 {
                    Node::merge_nodes(&children1[..lastix], &[newrope])
                } else {
                    Node::merge_nodes(&children1[..lastix], newrope.get_children())
                }
            }
        }
    }

    pub fn measure<M: Metric<N>>(&self) -> usize {
        M::measure(&self.0.info, self.0.len)
    }

    pub(crate) fn push_subseq(&self, b: &mut TreeBuilder<N>, iv: Interval) {
        if iv.is_empty() {
            return;
        }
        if iv == self.interval() {
            b.push(self.clone());
            return;
        }
        match self.0.val {
            NodeVal::Leaf(ref l) => {
                b.push_leaf_slice(l, iv);
            }
            NodeVal::Internal(ref v) => {
                let mut offset = 0;
                for child in v {
                    if iv.is_before(offset) {
                        break;
                    }
                    let child_iv = child.interval();
                    // easier just to use signed ints?
                    let rec_iv = iv.intersect(child_iv.translate(offset)).translate_neg(offset);
                    child.push_subseq(b, rec_iv);
                    offset += child.len();
                }
            }
        }
    }

    pub fn subseq<T: IntervalBounds>(&self, iv: T) -> Node<N> {
        let iv = iv.into_interval(self.len());
        let mut b = TreeBuilder::new();
        self.push_subseq(&mut b, iv);
        b.build()
    }

    pub fn edit<T, IV>(&mut self, iv: IV, new: T)
    where
        T: Into<Node<N>>,
        IV: IntervalBounds,
    {
        let mut b = TreeBuilder::new();
        let iv = iv.into_interval(self.len());
        let self_iv = self.interval();
        self.push_subseq(&mut b, self_iv.prefix(iv));
        b.push(new.into());
        self.push_subseq(&mut b, self_iv.suffix(iv));
        *self = b.build();
    }

    // doesn't deal with endpoint, handle that specially if you need it
    pub fn convert_metrics<M1: Metric<N>, M2: Metric<N>>(&self, mut m1: usize) -> usize {
        if m1 == 0 {
            return 0;
        }
        // If M1 can fragment, then we must land on the leaf containing
        // the m1 boundary. Otherwise, we can land on the beginning of
        // the leaf immediately following the M1 boundary, which may be
        // more efficient.
        let m1_fudge = if M1::can_fragment() { 1 } else { 0 };
        let mut m2 = 0;
        let mut node = self;
        while node.height() > 0 {
            for child in node.get_children() {
                let child_m1 = child.measure::<M1>();
                if m1 < child_m1 + m1_fudge {
                    node = child;
                    break;
                }
                m2 += child.measure::<M2>();
                m1 -= child_m1;
            }
        }
        let l = node.get_leaf();
        let base = M1::to_base_units(l, m1);
        m2 + M2::from_base_units(l, base)
    }
}

impl<N: DefaultMetric> Node<N> {
    /// Measures the length of the text bounded by ``DefaultMetric::measure(offset)`` with another metric.
    ///
    /// # Examples
    /// ```
    /// use crate::xi_rope::{Rope, LinesMetric};
    ///
    /// // the default metric of Rope is BaseMetric (aka number of bytes)
    /// let my_rope = Rope::from("first line \n second line \n");
    ///
    /// // count the number of lines in my_rope
    /// let num_lines = my_rope.count::<LinesMetric>(my_rope.len());
    /// assert_eq!(2, num_lines);
    /// ```
    pub fn count<M: Metric<N>>(&self, offset: usize) -> usize {
        self.convert_metrics::<N::DefaultMetric, M>(offset)
    }

    /// Measures the length of the text bounded by ``M::measure(offset)`` with the default metric.
    ///
    /// # Examples
    /// ```
    /// use crate::xi_rope::{Rope, LinesMetric};
    ///
    /// // the default metric of Rope is BaseMetric (aka number of bytes)
    /// let my_rope = Rope::from("first line \n second line \n");
    ///
    /// // get the byte offset of the line at index 1
    /// let byte_offset = my_rope.count_base_units::<LinesMetric>(1);
    /// assert_eq!(12, byte_offset);
    /// ```
    pub fn count_base_units<M: Metric<N>>(&self, offset: usize) -> usize {
        self.convert_metrics::<M, N::DefaultMetric>(offset)
    }
}

impl<N: NodeInfo> Default for Node<N> {
    fn default() -> Node<N> {
        Node::from_leaf(N::L::default())
    }
}

/// A builder for creating new trees.
pub struct TreeBuilder<N: NodeInfo> {
    // A stack of partially built trees. These are kept in order of
    // strictly descending height, and all vectors have a length less
    // than MAX_CHILDREN and greater than zero.
    //
    // In addition, there is a balancing invariant: for each vector
    // of length greater than one, all elements satisfy `is_ok_child`.
    stack: Vec<Vec<Node<N>>>,
}

impl<N: NodeInfo> TreeBuilder<N> {
    /// A new, empty builder.
    pub fn new() -> TreeBuilder<N> {
        TreeBuilder { stack: Vec::new() }
    }

    /// Append a node to the tree being built.
    pub fn push(&mut self, mut n: Node<N>) {
        loop {
            let ord = if let Some(last) = self.stack.last() {
                last[0].height().cmp(&n.height())
            } else {
                Ordering::Greater
            };
            match ord {
                Ordering::Less => {
                    n = Node::concat(self.pop(), n);
                }
                Ordering::Equal => {
                    let tos = self.stack.last_mut().unwrap();
                    if tos.last().unwrap().is_ok_child() && n.is_ok_child() {
                        tos.push(n);
                    } else if n.height() == 0 {
                        let iv = Interval::new(0, n.len());
                        let new_leaf = tos
                            .last_mut()
                            .unwrap()
                            .with_leaf_mut(|l| l.push_maybe_split(n.get_leaf(), iv));
                        if let Some(new_leaf) = new_leaf {
                            tos.push(Node::from_leaf(new_leaf));
                        }
                    } else {
                        let last = tos.pop().unwrap();
                        let children1 = last.get_children();
                        let children2 = n.get_children();
                        let n_children = children1.len() + children2.len();
                        if n_children <= MAX_CHILDREN {
                            tos.push(Node::from_nodes([children1, children2].concat()));
                        } else {
                            // Note: this leans left. Splitting at midpoint is also an option
                            let splitpoint = min(MAX_CHILDREN, n_children - MIN_CHILDREN);
                            let mut iter = children1.iter().chain(children2.iter()).cloned();
                            let left = iter.by_ref().take(splitpoint).collect();
                            let right = iter.collect();
                            tos.push(Node::from_nodes(left));
                            tos.push(Node::from_nodes(right));
                        }
                    }
                    if tos.len() < MAX_CHILDREN {
                        break;
                    }
                    n = self.pop()
                }
                Ordering::Greater => {
                    self.stack.push(vec![n]);
                    break;
                }
            }
        }
    }

    /// Append a sequence of leaves.
    pub fn push_leaves(&mut self, leaves: impl IntoIterator<Item = N::L>) {
        for leaf in leaves.into_iter() {
            self.push(Node::from_leaf(leaf));
        }
    }

    /// Append a single leaf.
    pub fn push_leaf(&mut self, l: N::L) {
        self.push(Node::from_leaf(l))
    }

    /// Append a slice of a single leaf.
    pub fn push_leaf_slice(&mut self, l: &N::L, iv: Interval) {
        self.push(Node::from_leaf(l.subseq(iv)))
    }

    /// Build the final tree.
    ///
    /// The tree is the concatenation of all the nodes and leaves that have been pushed
    /// on the builder, in order.
    pub fn build(mut self) -> Node<N> {
        if self.stack.is_empty() {
            Node::from_leaf(N::L::default())
        } else {
            let mut n = self.pop();
            while !self.stack.is_empty() {
                n = Node::concat(self.pop(), n);
            }
            n
        }
    }

    /// Pop the last vec-of-nodes off the stack, resulting in a node.
    fn pop(&mut self) -> Node<N> {
        let nodes = self.stack.pop().unwrap();
        if nodes.len() == 1 {
            nodes.into_iter().next().unwrap()
        } else {
            Node::from_nodes(nodes)
        }
    }
}

const CURSOR_CACHE_SIZE: usize = 4;

/// A data structure for traversing boundaries in a tree.
///
/// It is designed to be efficient both for random access and for iteration. The
/// cursor itself is agnostic to which [`Metric`] is used to determine boundaries, but
/// the methods to find boundaries are parametrized on the [`Metric`].
///
/// A cursor can be valid or invalid. It is always valid when created or after
/// [`set`](#method.set) is called, and becomes invalid after [`prev`](#method.prev)
/// or [`next`](#method.next) fails to find a boundary.
///
/// [`Metric`]: struct.Metric.html
pub struct Cursor<'a, N: 'a + NodeInfo> {
    /// The tree being traversed by this cursor.
    root: &'a Node<N>,
    /// The current position of the cursor.
    ///
    /// It is always less than or equal to the tree length.
    position: usize,
    /// The cache holds the tail of the path from the root to the current leaf.
    ///
    /// Each entry is a reference to the parent node and the index of the child. It
    /// is stored bottom-up; `cache[0]` is the parent of the leaf and the index of
    /// the leaf within that parent.
    ///
    /// The main motivation for this being a fixed-size array is to keep the cursor
    /// an allocation-free data structure.
    cache: [Option<(&'a Node<N>, usize)>; CURSOR_CACHE_SIZE],
    /// The leaf containing the current position, when the cursor is valid.
    ///
    /// The position is only at the end of the leaf when it is at the end of the tree.
    leaf: Option<&'a N::L>,
    /// The offset of `leaf` within the tree.
    offset_of_leaf: usize,
}

impl<'a, N: NodeInfo> Cursor<'a, N> {
    /// Create a new cursor at the given position.
    pub fn new(n: &'a Node<N>, position: usize) -> Cursor<'a, N> {
        let mut result = Cursor {
            root: n,
            position,
            cache: [None; CURSOR_CACHE_SIZE],
            leaf: None,
            offset_of_leaf: 0,
        };
        result.descend();
        result
    }

    /// The length of the tree.
    pub fn total_len(&self) -> usize {
        self.root.len()
    }

    /// Return a reference to the root node of the tree.
    pub fn root(&self) -> &'a Node<N> {
        self.root
    }

    /// Get the current leaf of the cursor.
    ///
    /// If the cursor is valid, returns the leaf containing the current position,
    /// and the offset of the current position within the leaf. That offset is equal
    /// to the leaf length only at the end, otherwise it is less than the leaf length.
    pub fn get_leaf(&self) -> Option<(&'a N::L, usize)> {
        self.leaf.map(|l| (l, self.position - self.offset_of_leaf))
    }

    /// Set the position of the cursor.
    ///
    /// The cursor is valid after this call.
    ///
    /// Precondition: `position` is less than or equal to the length of the tree.
    pub fn set(&mut self, position: usize) {
        self.position = position;
        if let Some(l) = self.leaf {
            if self.position >= self.offset_of_leaf && self.position < self.offset_of_leaf + l.len()
            {
                return;
            }
        }
        // TODO: walk up tree to find leaf if nearby
        self.descend();
    }

    /// Get the position of the cursor.
    pub fn pos(&self) -> usize {
        self.position
    }

    /// Determine whether the current position is a boundary.
    ///
    /// Note: the beginning and end of the tree may or may not be boundaries, depending on the
    /// metric. If the metric is not `can_fragment`, then they always are.
    pub fn is_boundary<M: Metric<N>>(&mut self) -> bool {
        if self.leaf.is_none() {
            // not at a valid position
            return false;
        }
        if self.position == self.offset_of_leaf && !M::can_fragment() {
            return true;
        }
        if self.position == 0 || self.position > self.offset_of_leaf {
            return M::is_boundary(self.leaf.unwrap(), self.position - self.offset_of_leaf);
        }
        // tricky case, at beginning of leaf, need to query end of previous
        // leaf; TODO: would be nice if we could do it another way that didn't
        // make the method &mut self.
        let l = self.prev_leaf().unwrap().0;
        let result = M::is_boundary(l, l.len());
        let _ = self.next_leaf();
        result
    }

    /// Moves the cursor to the previous boundary.
    ///
    /// When there is no previous boundary, returns `None` and the cursor becomes invalid.
    ///
    /// Return value: the position of the boundary, if it exists.
    pub fn prev<M: Metric<N>>(&mut self) -> Option<usize> {
        if self.position == 0 || self.leaf.is_none() {
            self.leaf = None;
            return None;
        }
        let orig_pos = self.position;
        let offset_in_leaf = orig_pos - self.offset_of_leaf;
        if offset_in_leaf > 0 {
            let l = self.leaf.unwrap();
            if let Some(offset_in_leaf) = M::prev(l, offset_in_leaf) {
                self.position = self.offset_of_leaf + offset_in_leaf;
                return Some(self.position);
            }
        }

        // not in same leaf, need to scan backwards
        self.prev_leaf()?;
        if let Some(offset) = self.last_inside_leaf::<M>(orig_pos) {
            return Some(offset);
        }

        // Not found in previous leaf, find using measurement.
        let measure = self.measure_leaf::<M>(self.position);
        if measure == 0 {
            self.leaf = None;
            self.position = 0;
            return None;
        }
        self.descend_metric::<M>(measure);
        self.last_inside_leaf::<M>(orig_pos)
    }

    /// Moves the cursor to the next boundary.
    ///
    /// When there is no next boundary, returns `None` and the cursor becomes invalid.
    ///
    /// Return value: the position of the boundary, if it exists.
    pub fn next<M: Metric<N>>(&mut self) -> Option<usize> {
        if self.position >= self.root.len() || self.leaf.is_none() {
            self.leaf = None;
            return None;
        }

        if let Some(offset) = self.next_inside_leaf::<M>() {
            return Some(offset);
        }

        self.next_leaf()?;
        if let Some(offset) = self.next_inside_leaf::<M>() {
            return Some(offset);
        }

        // Leaf is 0-measure (otherwise would have already succeeded).
        let measure = self.measure_leaf::<M>(self.position);
        self.descend_metric::<M>(measure + 1);
        if let Some(offset) = self.next_inside_leaf::<M>() {
            return Some(offset);
        }

        // Not found, properly invalidate cursor.
        self.position = self.root.len();
        self.leaf = None;
        None
    }

    /// Returns the current position if it is a boundary in this [`Metric`],
    /// else behaves like [`next`](#method.next).
    ///
    /// [`Metric`]: struct.Metric.html
    pub fn at_or_next<M: Metric<N>>(&mut self) -> Option<usize> {
        if self.is_boundary::<M>() {
            Some(self.pos())
        } else {
            self.next::<M>()
        }
    }

    /// Returns the current position if it is a boundary in this [`Metric`],
    /// else behaves like [`prev`](#method.prev).
    ///
    /// [`Metric`]: struct.Metric.html
    pub fn at_or_prev<M: Metric<N>>(&mut self) -> Option<usize> {
        if self.is_boundary::<M>() {
            Some(self.pos())
        } else {
            self.prev::<M>()
        }
    }

    /// Returns an iterator with this cursor over the given [`Metric`].
    ///
    /// # Examples:
    ///
    /// ```
    /// # use xi_rope::{Cursor, LinesMetric, Rope};
    /// #
    /// let text: Rope = "one line\ntwo line\nred line\nblue".into();
    /// let mut cursor = Cursor::new(&text, 0);
    /// let line_offsets = cursor.iter::<LinesMetric>().collect::<Vec<_>>();
    /// assert_eq!(line_offsets, vec![9, 18, 27]);
    ///
    /// ```
    /// [`Metric`]: struct.Metric.html
    pub fn iter<'c, M: Metric<N>>(&'c mut self) -> CursorIter<'c, 'a, N, M> {
        CursorIter { cursor: self, _metric: PhantomData }
    }

    /// Tries to find the last boundary in the leaf the cursor is currently in.
    ///
    /// If the last boundary is at the end of the leaf, it is only counted if
    /// it is less than `orig_pos`.
    #[inline]
    fn last_inside_leaf<M: Metric<N>>(&mut self, orig_pos: usize) -> Option<usize> {
        let l = self.leaf.expect("inconsistent, shouldn't get here");
        let len = l.len();
        if self.offset_of_leaf + len < orig_pos && M::is_boundary(l, len) {
            let _ = self.next_leaf();
            return Some(self.position);
        }
        let offset_in_leaf = M::prev(l, len)?;
        self.position = self.offset_of_leaf + offset_in_leaf;
        Some(self.position)
    }

    /// Tries to find the next boundary in the leaf the cursor is currently in.
    #[inline]
    fn next_inside_leaf<M: Metric<N>>(&mut self) -> Option<usize> {
        let l = self.leaf.expect("inconsistent, shouldn't get here");
        let offset_in_leaf = self.position - self.offset_of_leaf;
        let offset_in_leaf = M::next(l, offset_in_leaf)?;
        if offset_in_leaf == l.len() && self.offset_of_leaf + offset_in_leaf != self.root.len() {
            let _ = self.next_leaf();
        } else {
            self.position = self.offset_of_leaf + offset_in_leaf;
        }
        Some(self.position)
    }

    /// Move to beginning of next leaf.
    ///
    /// Return value: same as [`get_leaf`](#method.get_leaf).
    pub fn next_leaf(&mut self) -> Option<(&'a N::L, usize)> {
        let leaf = self.leaf?;
        self.position = self.offset_of_leaf + leaf.len();
        for i in 0..CURSOR_CACHE_SIZE {
            if self.cache[i].is_none() {
                // this probably can't happen
                self.leaf = None;
                return None;
            }
            let (node, j) = self.cache[i].unwrap();
            if j + 1 < node.get_children().len() {
                self.cache[i] = Some((node, j + 1));
                let mut node_down = &node.get_children()[j + 1];
                for k in (0..i).rev() {
                    self.cache[k] = Some((node_down, 0));
                    node_down = &node_down.get_children()[0];
                }
                self.leaf = Some(node_down.get_leaf());
                self.offset_of_leaf = self.position;
                return self.get_leaf();
            }
        }
        if self.offset_of_leaf + self.leaf.unwrap().len() == self.root.len() {
            self.leaf = None;
            return None;
        }
        self.descend();
        self.get_leaf()
    }

    /// Move to beginning of previous leaf.
    ///
    /// Return value: same as [`get_leaf`](#method.get_leaf).
    pub fn prev_leaf(&mut self) -> Option<(&'a N::L, usize)> {
        if self.offset_of_leaf == 0 {
            self.leaf = None;
            self.position = 0;
            return None;
        }
        for i in 0..CURSOR_CACHE_SIZE {
            if self.cache[i].is_none() {
                // this probably can't happen
                self.leaf = None;
                return None;
            }
            let (node, j) = self.cache[i].unwrap();
            if j > 0 {
                self.cache[i] = Some((node, j - 1));
                let mut node_down = &node.get_children()[j - 1];
                for k in (0..i).rev() {
                    let last_ix = node_down.get_children().len() - 1;
                    self.cache[k] = Some((node_down, last_ix));
                    node_down = &node_down.get_children()[last_ix];
                }
                let leaf = node_down.get_leaf();
                self.leaf = Some(leaf);
                self.offset_of_leaf -= leaf.len();
                self.position = self.offset_of_leaf;
                return self.get_leaf();
            }
        }
        self.position = self.offset_of_leaf - 1;
        self.descend();
        self.position = self.offset_of_leaf;
        self.get_leaf()
    }

    /// Go to the leaf containing the current position.
    ///
    /// Sets `leaf` to the leaf containing `position`, and updates `cache` and
    /// `offset_of_leaf` to be consistent.
    fn descend(&mut self) {
        let mut node = self.root;
        let mut offset = 0;
        while node.height() > 0 {
            let children = node.get_children();
            let mut i = 0;
            loop {
                if i + 1 == children.len() {
                    break;
                }
                let nextoff = offset + children[i].len();
                if nextoff > self.position {
                    break;
                }
                offset = nextoff;
                i += 1;
            }
            let cache_ix = node.height() - 1;
            if cache_ix < CURSOR_CACHE_SIZE {
                self.cache[cache_ix] = Some((node, i));
            }
            node = &children[i];
        }
        self.leaf = Some(node.get_leaf());
        self.offset_of_leaf = offset;
    }

    /// Returns the measure at the beginning of the leaf containing `pos`.
    ///
    /// This method is O(log n) no matter the current cursor state.
    fn measure_leaf<M: Metric<N>>(&self, mut pos: usize) -> usize {
        let mut node = self.root;
        let mut metric = 0;
        while node.height() > 0 {
            for child in node.get_children() {
                let len = child.len();
                if pos < len {
                    node = child;
                    break;
                }
                pos -= len;
                metric += child.measure::<M>();
            }
        }
        metric
    }

    /// Find the leaf having the given measure.
    ///
    /// This function sets `self.position` to the beginning of the leaf
    /// containing the smallest offset with the given metric, and also updates
    /// state as if [`descend`](#method.descend) was called.
    ///
    /// If `measure` is greater than the measure of the whole tree, then moves
    /// to the last node.
    fn descend_metric<M: Metric<N>>(&mut self, mut measure: usize) {
        let mut node = self.root;
        let mut offset = 0;
        while node.height() > 0 {
            let children = node.get_children();
            let mut i = 0;
            loop {
                if i + 1 == children.len() {
                    break;
                }
                let child = &children[i];
                let child_m = child.measure::<M>();
                if child_m >= measure {
                    break;
                }
                offset += child.len();
                measure -= child_m;
                i += 1;
            }
            let cache_ix = node.height() - 1;
            if cache_ix < CURSOR_CACHE_SIZE {
                self.cache[cache_ix] = Some((node, i));
            }
            node = &children[i];
        }
        self.leaf = Some(node.get_leaf());
        self.position = offset;
        self.offset_of_leaf = offset;
    }
}

/// An iterator generated by a [`Cursor`], for some [`Metric`].
///
/// [`Cursor`]: struct.Cursor.html
/// [`Metric`]: struct.Metric.html
pub struct CursorIter<'c, 'a: 'c, N: 'a + NodeInfo, M: 'a + Metric<N>> {
    cursor: &'c mut Cursor<'a, N>,
    _metric: PhantomData<&'a M>,
}

impl<'c, 'a, N: NodeInfo, M: Metric<N>> Iterator for CursorIter<'c, 'a, N, M> {
    type Item = usize;

    fn next(&mut self) -> Option<usize> {
        self.cursor.next::<M>()
    }
}

impl<'c, 'a, N: NodeInfo, M: Metric<N>> CursorIter<'c, 'a, N, M> {
    /// Returns the current position of the underlying [`Cursor`].
    ///
    /// [`Cursor`]: struct.Cursor.html
    pub fn pos(&self) -> usize {
        self.cursor.pos()
    }
}

#[cfg(test)]
mod test {
    use super::*;
    use crate::rope::*;

    fn build_triangle(n: u32) -> String {
        let mut s = String::new();
        let mut line = String::new();
        for _ in 0..n {
            s += &line;
            s += "\n";
            line += "a";
        }
        s
    }

    #[test]
    fn eq_rope_with_pieces() {
        let n = 2_000;
        let s = build_triangle(n);
        let mut builder_default = TreeBuilder::new();
        let mut concat_rope = Rope::default();
        builder_default.push_str(&s);
        let mut i = 0;
        while i < s.len() {
            let j = (i + 1000).min(s.len());
            concat_rope = concat_rope + s[i..j].into();
            i = j;
        }
        let built_rope = builder_default.build();
        assert_eq!(built_rope, concat_rope);
    }

    #[test]
    fn cursor_next_triangle() {
        let n = 2_000;
        let text = Rope::from(build_triangle(n));

        let mut cursor = Cursor::new(&text, 0);
        let mut prev_offset = cursor.pos();
        for i in 1..(n + 1) as usize {
            let offset = cursor.next::<LinesMetric>().expect("arrived at the end too soon");
            assert_eq!(offset - prev_offset, i);
            prev_offset = offset;
        }
        assert_eq!(cursor.next::<LinesMetric>(), None);
    }

    #[test]
    fn node_is_empty() {
        let text = Rope::from(String::new());
        assert_eq!(text.is_empty(), true);
    }

    #[test]
    fn cursor_next_empty() {
        let text = Rope::from(String::new());
        let mut cursor = Cursor::new(&text, 0);
        assert_eq!(cursor.next::<LinesMetric>(), None);
        assert_eq!(cursor.pos(), 0);
    }

    #[test]
    fn cursor_iter() {
        let text: Rope = build_triangle(50).into();
        let mut cursor = Cursor::new(&text, 0);
        let mut manual = Vec::new();
        while let Some(nxt) = cursor.next::<LinesMetric>() {
            manual.push(nxt);
        }

        cursor.set(0);
        let auto = cursor.iter::<LinesMetric>().collect::<Vec<_>>();
        assert_eq!(manual, auto);
    }

    #[test]
    fn cursor_next_misc() {
        cursor_next_for("toto");
        cursor_next_for("toto\n");
        cursor_next_for("toto\ntata");
        cursor_next_for("歴史\n科学的");
        cursor_next_for("\n歴史\n科学的\n");
        cursor_next_for(&build_triangle(100));
    }

    fn cursor_next_for(s: &str) {
        let r = Rope::from(s.to_owned());
        for i in 0..r.len() {
            let mut c = Cursor::new(&r, i);
            let it = c.next::<LinesMetric>();
            let pos = c.pos();
            assert!(s.as_bytes()[i..pos - 1].iter().all(|c| *c != b'\n'), "missed linebreak");
            if pos < s.len() {
                assert!(it.is_some(), "must be Some(_)");
                assert!(s.as_bytes()[pos - 1] == b'\n', "not a linebreak");
            } else {
                if s.as_bytes()[s.len() - 1] == b'\n' {
                    assert!(it.is_some(), "must be Some(_)");
                } else {
                    assert!(it.is_none());
                    assert!(c.get_leaf().is_none());
                }
            }
        }
    }

    #[test]
    fn cursor_prev_misc() {
        cursor_prev_for("toto");
        cursor_prev_for("a\na\n");
        cursor_prev_for("toto\n");
        cursor_prev_for("toto\ntata");
        cursor_prev_for("歴史\n科学的");
        cursor_prev_for("\n歴史\n科学的\n");
        cursor_prev_for(&build_triangle(100));
    }

    fn cursor_prev_for(s: &str) {
        let r = Rope::from(s.to_owned());
        for i in 0..r.len() {
            let mut c = Cursor::new(&r, i);
            let it = c.prev::<LinesMetric>();
            let pos = c.pos();

            //Should countain at most one linebreak
            assert!(
                s.as_bytes()[pos..i].iter().filter(|c| **c == b'\n').count() <= 1,
                "missed linebreak"
            );

            if i == 0 && s.as_bytes()[i] == b'\n' {
                assert_eq!(pos, 0);
            }

            if pos > 0 {
                assert!(it.is_some(), "must be Some(_)");
                assert!(s.as_bytes()[pos - 1] == b'\n', "not a linebreak");
            }
        }
    }

    #[test]
    fn at_or_next() {
        let text: Rope = "this\nis\nalil\nstring".into();
        let mut cursor = Cursor::new(&text, 0);
        assert_eq!(cursor.at_or_next::<LinesMetric>(), Some(5));
        assert_eq!(cursor.at_or_next::<LinesMetric>(), Some(5));
        cursor.set(1);
        assert_eq!(cursor.at_or_next::<LinesMetric>(), Some(5));
        assert_eq!(cursor.at_or_prev::<LinesMetric>(), Some(5));
        cursor.set(6);
        assert_eq!(cursor.at_or_prev::<LinesMetric>(), Some(5));
        cursor.set(6);
        assert_eq!(cursor.at_or_next::<LinesMetric>(), Some(8));
        assert_eq!(cursor.at_or_next::<LinesMetric>(), Some(8));
    }

    #[test]
    fn next_zero_measure_large() {
        let mut text = Rope::from("a");
        for _ in 0..24 {
            text = Node::concat(text.clone(), text);
            let mut cursor = Cursor::new(&text, 0);
            assert_eq!(cursor.next::<LinesMetric>(), None);
            // Test that cursor is properly invalidated and at end of text.
            assert_eq!(cursor.get_leaf(), None);
            assert_eq!(cursor.pos(), text.len());

            cursor.set(text.len());
            assert_eq!(cursor.prev::<LinesMetric>(), None);
            // Test that cursor is properly invalidated and at beginning of text.
            assert_eq!(cursor.get_leaf(), None);
            assert_eq!(cursor.pos(), 0);
        }
    }

    #[test]
    fn prev_line_large() {
        let s: String = format!("{}{}", "\n", build_triangle(1000));
        let rope = Rope::from(s);
        let mut expected_pos = rope.len();
        let mut cursor = Cursor::new(&rope, rope.len());

        for i in (1..1001).rev() {
            expected_pos = expected_pos - i;
            assert_eq!(expected_pos, cursor.prev::<LinesMetric>().unwrap());
        }

        assert_eq!(None, cursor.prev::<LinesMetric>());
    }

    #[test]
    fn prev_line_small() {
        let empty_rope = Rope::from("\n");
        let mut cursor = Cursor::new(&empty_rope, empty_rope.len());
        assert_eq!(None, cursor.prev::<LinesMetric>());

        let rope = Rope::from("\n\n\n\n\n\n\n\n\n\n");
        cursor = Cursor::new(&rope, rope.len());
        let mut expected_pos = rope.len();
        for _ in (1..10).rev() {
            expected_pos -= 1;
            assert_eq!(expected_pos, cursor.prev::<LinesMetric>().unwrap());
        }

        assert_eq!(None, cursor.prev::<LinesMetric>());
    }

    #[test]
    fn balance_invariant() {
        let mut tb = TreeBuilder::<RopeInfo>::new();
        let leaves: Vec<String> = (0..1000).map(|i| i.to_string().into()).collect();
        tb.push_leaves(leaves);
        let tree = tb.build();
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! An engine for handling edits (possibly from async sources) and undo. It
//! conceptually represents the current text and all edit history for that
//! text.
//!
//! This module actually implements a mini Conflict-free Replicated Data Type
//! under `Engine::edit_rev`, which is considerably simpler than the usual
//! CRDT implementation techniques, because all operations are serialized in
//! this central engine. It provides the ability to apply edits that depend on
//! a previously committed version of the text rather than the current text,
//! which is sufficient for asynchronous plugins that can only have one
//! pending edit in flight each.
//!
//! There is also a full CRDT merge operation implemented under
//! `Engine::merge`, which is more powerful but considerably more complex.
//! It enables support for full asynchronous and even peer-to-peer editing.

use std::borrow::Cow;
use std::collections::hash_map::DefaultHasher;
use std::collections::BTreeSet;

use crate::delta::{Delta, InsertDelta};
use crate::interval::Interval;
use crate::multiset::{CountMatcher, Subset};
use crate::rope::{Rope, RopeInfo};

/// Represents the current state of a document and all of its history
#[derive(Debug)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct Engine {
    /// The session ID used to create new `RevId`s for edits made on this device
    #[cfg_attr(feature = "serde", serde(default = "default_session", skip_serializing))]
    session: SessionId,
    /// The incrementing revision number counter for this session used for `RevId`s
    #[cfg_attr(feature = "serde", serde(default = "initial_revision_counter", skip_serializing))]
    rev_id_counter: u32,
    /// The current contents of the document as would be displayed on screen
    text: Rope,
    /// Storage for all the characters that have been deleted  but could
    /// return if a delete is un-done or an insert is re- done.
    tombstones: Rope,
    /// Imagine a "union string" that contained all the characters ever
    /// inserted, including the ones that were later deleted, in the locations
    /// they would be if they hadn't been deleted.
    ///
    /// This is a `Subset` of the "union string" representing the characters
    /// that are currently deleted, and thus in `tombstones` rather than
    /// `text`. The count of a character in `deletes_from_union` represents
    /// how many times it has been deleted, so if a character is deleted twice
    /// concurrently it will have count `2` so that undoing one delete but not
    /// the other doesn't make it re-appear.
    ///
    /// You could construct the "union string" from `text`, `tombstones` and
    /// `deletes_from_union` by splicing a segment of `tombstones` into `text`
    /// wherever there's a non-zero-count segment in `deletes_from_union`.
    deletes_from_union: Subset,
    // TODO: switch to a persistent Set representation to avoid O(n) copying
    undone_groups: BTreeSet<usize>, // set of undo_group id's
    /// The revision history of the document
    revs: Vec<Revision>,
}

// The advantage of using a session ID over random numbers is that it can be
// easily delta-compressed later.
#[derive(Debug, Clone, Copy, PartialOrd, Ord, PartialEq, Eq, Hash)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct RevId {
    // 96 bits has a 10^(-12) chance of collision with 400 million sessions and 10^(-6) with 100 billion.
    // `session1==session2==0` is reserved for initialization which is the same on all sessions.
    // A colliding session will break merge invariants and the document will start crashing Xi.
    session1: u64,
    // if this was a tuple field instead of two fields, alignment padding would add 8 more bytes.
    session2: u32,
    // There will probably never be a document with more than 4 billion edits
    // in a single session.
    num: u32,
}

#[derive(Debug)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
struct Revision {
    /// This uniquely represents the identity of this revision and it stays
    /// the same even if it is rebased or merged between devices.
    rev_id: RevId,
    /// The largest undo group number of any edit in the history up to this
    /// point. Used to optimize undo to not look further back.
    max_undo_so_far: usize,
    edit: Contents,
}

/// Valid within a session. If there's a collision the most recent matching
/// Revision will be used, which means only the (small) set of concurrent edits
/// could trigger incorrect behavior if they collide, so u64 is safe.
pub type RevToken = u64;

/// the session ID component of a `RevId`
pub type SessionId = (u64, u32);

/// Type for errors that occur during CRDT operations.
#[derive(Clone)]
pub enum Error {
    /// An edit specified a revision that did not exist. The revision may
    /// have been GC'd, or it may have specified incorrectly.
    MissingRevision(RevToken),
    /// A delta was applied which had a `base_len` that did not match the length
    /// of the revision it was applied to.
    MalformedDelta { rev_len: usize, delta_len: usize },
}

#[derive(Clone, Copy, PartialOrd, Ord, PartialEq, Eq)]
struct FullPriority {
    priority: usize,
    session_id: SessionId,
}

use self::Contents::*;

#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
enum Contents {
    Edit {
        /// Used to order concurrent inserts, for example auto-indentation
        /// should go before typed text.
        priority: usize,
        /// Groups related edits together so that they are undone and re-done
        /// together. For example, an auto-indent insertion would be un-done
        /// along with the newline that triggered it.
        undo_group: usize,
        /// The subset of the characters of the union string from after this
        /// revision that were added by this revision.
        inserts: Subset,
        /// The subset of the characters of the union string from after this
        /// revision that were deleted by this revision.
        deletes: Subset,
    },
    Undo {
        /// The set of groups toggled between undone and done.
        /// Just the `symmetric_difference` (XOR) of the two sets.
        toggled_groups: BTreeSet<usize>, // set of undo_group id's
        /// Used to store a reversible difference between the old
        /// and new deletes_from_union
        deletes_bitxor: Subset,
    },
}

/// for single user cases, used by serde and ::empty
fn default_session() -> (u64, u32) {
    (1, 0)
}

/// Revision 0 is always an Undo of the empty set of groups
#[cfg(feature = "serde")]
fn initial_revision_counter() -> u32 {
    1
}

impl RevId {
    /// Returns a u64 that will be equal for equivalent revision IDs and
    /// should be as unlikely to collide as two random u64s.
    pub fn token(&self) -> RevToken {
        use std::hash::{Hash, Hasher};
        // Rust is unlikely to break the property that this hash is strongly collision-resistant
        // and it only needs to be consistent over one execution.
        let mut hasher = DefaultHasher::new();
        self.hash(&mut hasher);
        hasher.finish()
    }

    pub fn session_id(&self) -> SessionId {
        (self.session1, self.session2)
    }
}

impl Engine {
    /// Create a new Engine with a single edit that inserts `initial_contents`
    /// if it is non-empty. It needs to be a separate commit rather than just
    /// part of the initial contents since any two `Engine`s need a common
    /// ancestor in order to be mergeable.
    pub fn new(initial_contents: Rope) -> Engine {
        let mut engine = Engine::empty();
        if !initial_contents.is_empty() {
            let first_rev = engine.get_head_rev_id().token();
            let delta = Delta::simple_edit(Interval::new(0, 0), initial_contents, 0);
            engine.edit_rev(0, 0, first_rev, delta);
        }
        engine
    }

    pub fn empty() -> Engine {
        let deletes_from_union = Subset::new(0);
        let rev = Revision {
            rev_id: RevId { session1: 0, session2: 0, num: 0 },
            edit: Undo {
                toggled_groups: BTreeSet::new(),
                deletes_bitxor: deletes_from_union.clone(),
            },
            max_undo_so_far: 0,
        };
        Engine {
            session: default_session(),
            rev_id_counter: 1,
            text: Rope::default(),
            tombstones: Rope::default(),
            deletes_from_union,
            undone_groups: BTreeSet::new(),
            revs: vec![rev],
        }
    }

    fn next_rev_id(&self) -> RevId {
        RevId { session1: self.session.0, session2: self.session.1, num: self.rev_id_counter }
    }

    fn find_rev(&self, rev_id: RevId) -> Option<usize> {
        self.revs
            .iter()
            .enumerate()
            .rev()
            .find(|&(_, ref rev)| rev.rev_id == rev_id)
            .map(|(i, _)| i)
    }

    fn find_rev_token(&self, rev_token: RevToken) -> Option<usize> {
        self.revs
            .iter()
            .enumerate()
            .rev()
            .find(|&(_, ref rev)| rev.rev_id.token() == rev_token)
            .map(|(i, _)| i)
    }

    // TODO: does Cow really help much here? It certainly won't after making Subsets a rope.
    /// Find what the `deletes_from_union` field in Engine would have been at the time
    /// of a certain `rev_index`. In other words, the deletes from the union string at that time.
    fn deletes_from_union_for_index(&self, rev_index: usize) -> Cow<Subset> {
        self.deletes_from_union_before_index(rev_index + 1, true)
    }

    /// Garbage collection means undo can sometimes need to replay the very first
    /// revision, and so needs a way to get the deletion set before then.
    fn deletes_from_union_before_index(&self, rev_index: usize, invert_undos: bool) -> Cow<Subset> {
        let mut deletes_from_union = Cow::Borrowed(&self.deletes_from_union);
        let mut undone_groups = Cow::Borrowed(&self.undone_groups);

        // invert the changes to deletes_from_union starting in the present and working backwards
        for rev in self.revs[rev_index..].iter().rev() {
            deletes_from_union = match rev.edit {
                Edit { ref inserts, ref deletes, ref undo_group, .. } => {
                    if undone_groups.contains(undo_group) {
                        // no need to un-delete undone inserts since we'll just shrink them out
                        Cow::Owned(deletes_from_union.transform_shrink(inserts))
                    } else {
                        let un_deleted = deletes_from_union.subtract(deletes);
                        Cow::Owned(un_deleted.transform_shrink(inserts))
                    }
                }
                Undo { ref toggled_groups, ref deletes_bitxor } => {
                    if invert_undos {
                        let new_undone =
                            undone_groups.symmetric_difference(toggled_groups).cloned().collect();
                        undone_groups = Cow::Owned(new_undone);
                        Cow::Owned(deletes_from_union.bitxor(deletes_bitxor))
                    } else {
                        deletes_from_union
                    }
                }
            }
        }
        deletes_from_union
    }

    /// Get the contents of the document at a given revision number
    fn rev_content_for_index(&self, rev_index: usize) -> Rope {
        let old_deletes_from_union = self.deletes_from_cur_union_for_index(rev_index);
        let delta =
            Delta::synthesize(&self.tombstones, &self.deletes_from_union, &old_deletes_from_union);
        delta.apply(&self.text)
    }

    /// Get the Subset to delete from the current union string in order to obtain a revision's content
    fn deletes_from_cur_union_for_index(&self, rev_index: usize) -> Cow<Subset> {
        let mut deletes_from_union = self.deletes_from_union_for_index(rev_index);
        for rev in &self.revs[rev_index + 1..] {
            if let Edit { ref inserts, .. } = rev.edit {
                if !inserts.is_empty() {
                    deletes_from_union = Cow::Owned(deletes_from_union.transform_union(inserts));
                }
            }
        }
        deletes_from_union
    }

    /// Returns the largest undo group ID used so far
    pub fn max_undo_group_id(&self) -> usize {
        self.revs.last().unwrap().max_undo_so_far
    }

    /// Get revision id of head revision.
    pub fn get_head_rev_id(&self) -> RevId {
        self.revs.last().unwrap().rev_id
    }

    /// Get text of head revision.
    pub fn get_head(&self) -> &Rope {
        &self.text
    }

    /// Get text of a given revision, if it can be found.
    pub fn get_rev(&self, rev: RevToken) -> Option<Rope> {
        self.find_rev_token(rev).map(|rev_index| self.rev_content_for_index(rev_index))
    }

    /// A delta that, when applied to `base_rev`, results in the current head. Returns
    /// an error if there is not at least one edit.
    pub fn try_delta_rev_head(&self, base_rev: RevToken) -> Result<Delta<RopeInfo>, Error> {
        let ix = self.find_rev_token(base_rev).ok_or(Error::MissingRevision(base_rev))?;
        let prev_from_union = self.deletes_from_cur_union_for_index(ix);
        // TODO: this does 2 calls to Delta::synthesize and 1 to apply, this probably could be better.
        let old_tombstones = shuffle_tombstones(
            &self.text,
            &self.tombstones,
            &self.deletes_from_union,
            &prev_from_union,
        );
        Ok(Delta::synthesize(&old_tombstones, &prev_from_union, &self.deletes_from_union))
    }

    // TODO: don't construct transform if subsets are empty
    // TODO: maybe switch to using a revision index for `base_rev` once we disable GC
    /// Returns a tuple of a new `Revision` representing the edit based on the
    /// current head, a new text `Rope`, a new tombstones `Rope` and a new `deletes_from_union`.
    /// Returns an [`Error`] if `base_rev` cannot be found, or `delta.base_len`
    /// does not equal the length of the text at `base_rev`.
    fn mk_new_rev(
        &self,
        new_priority: usize,
        undo_group: usize,
        base_rev: RevToken,
        delta: Delta<RopeInfo>,
    ) -> Result<(Revision, Rope, Rope, Subset), Error> {
        let ix = self.find_rev_token(base_rev).ok_or(Error::MissingRevision(base_rev))?;

        let (ins_delta, deletes) = delta.factor();

        // rebase delta to be on the base_rev union instead of the text
        let deletes_at_rev = self.deletes_from_union_for_index(ix);

        // validate delta
        if ins_delta.base_len != deletes_at_rev.len_after_delete() {
            return Err(Error::MalformedDelta {
                delta_len: ins_delta.base_len,
                rev_len: deletes_at_rev.len_after_delete(),
            });
        }

        let mut union_ins_delta = ins_delta.transform_expand(&deletes_at_rev, true);
        let mut new_deletes = deletes.transform_expand(&deletes_at_rev);

        // rebase the delta to be on the head union instead of the base_rev union
        let new_full_priority = FullPriority { priority: new_priority, session_id: self.session };
        for r in &self.revs[ix + 1..] {
            if let Edit { priority, ref inserts, .. } = r.edit {
                if !inserts.is_empty() {
                    let full_priority =
                        FullPriority { priority, session_id: r.rev_id.session_id() };
                    let after = new_full_priority >= full_priority; // should never be ==
                    union_ins_delta = union_ins_delta.transform_expand(inserts, after);
                    new_deletes = new_deletes.transform_expand(inserts);
                }
            }
        }

        // rebase the deletion to be after the inserts instead of directly on the head union
        let new_inserts = union_ins_delta.inserted_subset();
        if !new_inserts.is_empty() {
            new_deletes = new_deletes.transform_expand(&new_inserts);
        }

        // rebase insertions on text and apply
        let cur_deletes_from_union = &self.deletes_from_union;
        let text_ins_delta = union_ins_delta.transform_shrink(cur_deletes_from_union);
        let text_with_inserts = text_ins_delta.apply(&self.text);
        let rebased_deletes_from_union = cur_deletes_from_union.transform_expand(&new_inserts);

        // is the new edit in an undo group that was already undone due to concurrency?
        let undone = self.undone_groups.contains(&undo_group);
        let new_deletes_from_union = {
            let to_delete = if undone { &new_inserts } else { &new_deletes };
            rebased_deletes_from_union.union(to_delete)
        };

        // move deleted or undone-inserted things from text to tombstones
        let (new_text, new_tombstones) = shuffle(
            &text_with_inserts,
            &self.tombstones,
            &rebased_deletes_from_union,
            &new_deletes_from_union,
        );

        let head_rev = &self.revs.last().unwrap();
        Ok((
            Revision {
                rev_id: self.next_rev_id(),
                max_undo_so_far: std::cmp::max(undo_group, head_rev.max_undo_so_far),
                edit: Edit {
                    priority: new_priority,
                    undo_group,
                    inserts: new_inserts,
                    deletes: new_deletes,
                },
            },
            new_text,
            new_tombstones,
            new_deletes_from_union,
        ))
    }
    // NOTE: maybe just deprecate this? we can panic on the other side of
    // the call if/when that makes sense.
    /// Create a new edit based on `base_rev`.
    ///
    /// # Panics
    ///
    /// Panics if `base_rev` does not exist, or if `delta` is poorly formed.
    pub fn edit_rev(
        &mut self,
        priority: usize,
        undo_group: usize,
        base_rev: RevToken,
        delta: Delta<RopeInfo>,
    ) {
        self.try_edit_rev(priority, undo_group, base_rev, delta).unwrap();
    }

    // TODO: have `base_rev` be an index so that it can be used maximally
    // efficiently with the head revision, a token or a revision ID.
    // Efficiency loss of token is negligible but unfortunate.
    /// Attempts to apply a new edit based on the [`Revision`] specified by `base_rev`,
    /// Returning an [`Error`] if the `Revision` cannot be found.
    pub fn try_edit_rev(
        &mut self,
        priority: usize,
        undo_group: usize,
        base_rev: RevToken,
        delta: Delta<RopeInfo>,
    ) -> Result<(), Error> {
        let (new_rev, new_text, new_tombstones, new_deletes_from_union) =
            self.mk_new_rev(priority, undo_group, base_rev, delta)?;
        self.rev_id_counter += 1;
        self.revs.push(new_rev);
        self.text = new_text;
        self.tombstones = new_tombstones;
        self.deletes_from_union = new_deletes_from_union;
        Ok(())
    }

    // since undo and gc replay history with transforms, we need an empty set
    // of the union string length *before* the first revision.
    fn empty_subset_before_first_rev(&self) -> Subset {
        let first_rev = &self.revs.first().unwrap();
        // it will be immediately transform_expanded by inserts if it is an Edit, so length must be before
        let len = match first_rev.edit {
            Edit { ref inserts, .. } => inserts.count(CountMatcher::Zero),
            Undo { ref deletes_bitxor, .. } => deletes_bitxor.count(CountMatcher::All),
        };
        Subset::new(len)
    }

    /// Find the first revision that could be affected by toggling a set of undo groups
    fn find_first_undo_candidate_index(&self, toggled_groups: &BTreeSet<usize>) -> usize {
        // find the lowest toggled undo group number
        if let Some(lowest_group) = toggled_groups.iter().cloned().next() {
            for (i, rev) in self.revs.iter().enumerate().rev() {
                if rev.max_undo_so_far < lowest_group {
                    return i + 1; // +1 since we know the one we just found doesn't have it
                }
            }
            0
        } else {
            // no toggled groups, return past end
            self.revs.len()
        }
    }

    // This computes undo all the way from the beginning. An optimization would be to not
    // recompute the prefix up to where the history diverges, but it's not clear that's
    // even worth the code complexity.
    fn compute_undo(&self, groups: &BTreeSet<usize>) -> (Revision, Subset) {
        let toggled_groups = self.undone_groups.symmetric_difference(&groups).cloned().collect();
        let first_candidate = self.find_first_undo_candidate_index(&toggled_groups);
        // the `false` below: don't invert undos since our first_candidate is based on the current undo set, not past
        let mut deletes_from_union =
            self.deletes_from_union_before_index(first_candidate, false).into_owned();

        for rev in &self.revs[first_candidate..] {
            if let Edit { ref undo_group, ref inserts, ref deletes, .. } = rev.edit {
                if groups.contains(undo_group) {
                    if !inserts.is_empty() {
                        deletes_from_union = deletes_from_union.transform_union(inserts);
                    }
                } else {
                    if !inserts.is_empty() {
                        deletes_from_union = deletes_from_union.transform_expand(inserts);
                    }
                    if !deletes.is_empty() {
                        deletes_from_union = deletes_from_union.union(deletes);
                    }
                }
            }
        }

        let deletes_bitxor = self.deletes_from_union.bitxor(&deletes_from_union);
        let max_undo_so_far = self.revs.last().unwrap().max_undo_so_far;
        (
            Revision {
                rev_id: self.next_rev_id(),
                max_undo_so_far,
                edit: Undo { toggled_groups, deletes_bitxor },
            },
            deletes_from_union,
        )
    }

    // TODO: maybe refactor this API to take a toggle set
    pub fn undo(&mut self, groups: BTreeSet<usize>) {
        let (new_rev, new_deletes_from_union) = self.compute_undo(&groups);

        let (new_text, new_tombstones) = shuffle(
            &self.text,
            &self.tombstones,
            &self.deletes_from_union,
            &new_deletes_from_union,
        );

        self.text = new_text;
        self.tombstones = new_tombstones;
        self.deletes_from_union = new_deletes_from_union;
        self.undone_groups = groups;
        self.revs.push(new_rev);
        self.rev_id_counter += 1;
    }

    pub fn is_equivalent_revision(&self, base_rev: RevId, other_rev: RevId) -> bool {
        let base_subset = self
            .find_rev(base_rev)
            .map(|rev_index| self.deletes_from_cur_union_for_index(rev_index));
        let other_subset = self
            .find_rev(other_rev)
            .map(|rev_index| self.deletes_from_cur_union_for_index(rev_index));

        base_subset.is_some() && base_subset == other_subset
    }

    // Note: this function would need some work to handle retaining arbitrary revisions,
    // partly because the reachability calculation would become more complicated (a
    // revision might hold content from an undo group that would otherwise be gc'ed),
    // and partly because you need to retain more undo history, to supply input to the
    // reachability calculation.
    //
    // Thus, it's easiest to defer gc to when all plugins quiesce, but it's certainly
    // possible to fix it so that's not necessary.
    pub fn gc(&mut self, gc_groups: &BTreeSet<usize>) {
        let mut gc_dels = self.empty_subset_before_first_rev();
        // TODO: want to let caller retain more rev_id's.
        let mut retain_revs = BTreeSet::new();
        if let Some(last) = self.revs.last() {
            retain_revs.insert(last.rev_id);
        }
        {
            for rev in &self.revs {
                if let Edit { ref undo_group, ref inserts, ref deletes, .. } = rev.edit {
                    if !retain_revs.contains(&rev.rev_id) && gc_groups.contains(undo_group) {
                        if self.undone_groups.contains(undo_group) {
                            if !inserts.is_empty() {
                                gc_dels = gc_dels.transform_union(inserts);
                            }
                        } else {
                            if !inserts.is_empty() {
                                gc_dels = gc_dels.transform_expand(inserts);
                            }
                            if !deletes.is_empty() {
                                gc_dels = gc_dels.union(deletes);
                            }
                        }
                    } else if !inserts.is_empty() {
                        gc_dels = gc_dels.transform_expand(inserts);
                    }
                }
            }
        }
        if !gc_dels.is_empty() {
            let not_in_tombstones = self.deletes_from_union.complement();
            let dels_from_tombstones = gc_dels.transform_shrink(&not_in_tombstones);
            self.tombstones = dels_from_tombstones.delete_from(&self.tombstones);
            self.deletes_from_union = self.deletes_from_union.transform_shrink(&gc_dels);
        }
        let old_revs = std::mem::replace(&mut self.revs, Vec::new());
        for rev in old_revs.into_iter().rev() {
            match rev.edit {
                Edit { priority, undo_group, inserts, deletes } => {
                    let new_gc_dels = if inserts.is_empty() {
                        None
                    } else {
                        Some(gc_dels.transform_shrink(&inserts))
                    };
                    if retain_revs.contains(&rev.rev_id) || !gc_groups.contains(&undo_group) {
                        let (inserts, deletes) = if gc_dels.is_empty() {
                            (inserts, deletes)
                        } else {
                            (inserts.transform_shrink(&gc_dels), deletes.transform_shrink(&gc_dels))
                        };
                        self.revs.push(Revision {
                            rev_id: rev.rev_id,
                            max_undo_so_far: rev.max_undo_so_far,
                            edit: Edit { priority, undo_group, inserts, deletes },
                        });
                    }
                    if let Some(new_gc_dels) = new_gc_dels {
                        gc_dels = new_gc_dels;
                    }
                }
                Undo { toggled_groups, deletes_bitxor } => {
                    // We're super-aggressive about dropping these; after gc, the history
                    // of which undos were used to compute deletes_from_union in edits may be lost.
                    if retain_revs.contains(&rev.rev_id) {
                        let new_deletes_bitxor = if gc_dels.is_empty() {
                            deletes_bitxor
                        } else {
                            deletes_bitxor.transform_shrink(&gc_dels)
                        };
                        self.revs.push(Revision {
                            rev_id: rev.rev_id,
                            max_undo_so_far: rev.max_undo_so_far,
                            edit: Undo {
                                toggled_groups: &toggled_groups - gc_groups,
                                deletes_bitxor: new_deletes_bitxor,
                            },
                        })
                    }
                }
            }
        }
        self.revs.reverse();
    }

    /// Merge the new content from another Engine into this one with a CRDT merge
    pub fn merge(&mut self, other: &Engine) {
        let (mut new_revs, text, tombstones, deletes_from_union) = {
            let base_index = find_base_index(&self.revs, &other.revs);
            let a_to_merge = &self.revs[base_index..];
            let b_to_merge = &other.revs[base_index..];

            let common = find_common(a_to_merge, b_to_merge);

            let a_new = rearrange(a_to_merge, &common, self.deletes_from_union.len());
            let b_new = rearrange(b_to_merge, &common, other.deletes_from_union.len());

            let b_deltas =
                compute_deltas(&b_new, &other.text, &other.tombstones, &other.deletes_from_union);
            let expand_by = compute_transforms(a_new);

            let max_undo = self.max_undo_group_id();
            rebase(
                expand_by,
                b_deltas,
                self.text.clone(),
                self.tombstones.clone(),
                self.deletes_from_union.clone(),
                max_undo,
            )
        };

        self.text = text;
        self.tombstones = tombstones;
        self.deletes_from_union = deletes_from_union;
        self.revs.append(&mut new_revs);
    }

    /// When merging between multiple concurrently-editing sessions, each session should have a unique ID
    /// set with this function, which will make the revisions they create not have colliding IDs.
    /// For safety, this will panic if any revisions have already been added to the Engine.
    ///
    /// Merge may panic or return incorrect results if session IDs collide, which is why they can be
    /// 96 bits which is more than sufficient for this to never happen.
    pub fn set_session_id(&mut self, session: SessionId) {
        assert_eq!(
            1,
            self.revs.len(),
            "Revisions were added to an Engine before set_session_id, these may collide."
        );
        self.session = session;
    }
}

// ======== Generic helpers

/// Move sections from text to tombstones and out of tombstones based on a new and old set of deletions
fn shuffle_tombstones(
    text: &Rope,
    tombstones: &Rope,
    old_deletes_from_union: &Subset,
    new_deletes_from_union: &Subset,
) -> Rope {
    // Taking the complement of deletes_from_union leads to an interleaving valid for swapped text and tombstones,
    // allowing us to use the same method to insert the text into the tombstones.
    let inverse_tombstones_map = old_deletes_from_union.complement();
    let move_delta =
        Delta::synthesize(text, &inverse_tombstones_map, &new_deletes_from_union.complement());
    move_delta.apply(tombstones)
}

/// Move sections from text to tombstones and vice versa based on a new and old set of deletions.
/// Returns a tuple of a new text `Rope` and a new `Tombstones` rope described by `new_deletes_from_union`.
fn shuffle(
    text: &Rope,
    tombstones: &Rope,
    old_deletes_from_union: &Subset,
    new_deletes_from_union: &Subset,
) -> (Rope, Rope) {
    // Delta that deletes the right bits from the text
    let del_delta = Delta::synthesize(tombstones, old_deletes_from_union, new_deletes_from_union);
    let new_text = del_delta.apply(text);
    // println!("shuffle: old={:?} new={:?} old_text={:?} new_text={:?} old_tombstones={:?}",
    //     old_deletes_from_union, new_deletes_from_union, text, new_text, tombstones);
    (new_text, shuffle_tombstones(text, tombstones, old_deletes_from_union, new_deletes_from_union))
}

// ======== Merge helpers

/// Find an index before which everything is the same
fn find_base_index(a: &[Revision], b: &[Revision]) -> usize {
    assert!(!a.is_empty() && !b.is_empty());
    assert!(a[0].rev_id == b[0].rev_id);
    // TODO find the maximum base revision.
    // this should have the same behavior, but worse performance
    1
}

/// Find a set of revisions common to both lists
fn find_common(a: &[Revision], b: &[Revision]) -> BTreeSet<RevId> {
    // TODO make this faster somehow?
    let a_ids: BTreeSet<RevId> = a.iter().map(|r| r.rev_id).collect();
    let b_ids: BTreeSet<RevId> = b.iter().map(|r| r.rev_id).collect();
    a_ids.intersection(&b_ids).cloned().collect()
}

/// Returns the operations in `revs` that don't have their `rev_id` in
/// `base_revs`, but modified so that they are in the same order but based on
/// the `base_revs`. This allows the rest of the merge to operate on only
/// revisions not shared by both sides.
///
/// Conceptually, see the diagram below, with `.` being base revs and `n` being
/// non-base revs, `N` being transformed non-base revs, and rearranges it:
/// .n..n...nn..  -> ........NNNN -> returns vec![N,N,N,N]
fn rearrange(revs: &[Revision], base_revs: &BTreeSet<RevId>, head_len: usize) -> Vec<Revision> {
    // transform representing the characters added by common revisions after a point.
    let mut s = Subset::new(head_len);

    let mut out = Vec::with_capacity(revs.len() - base_revs.len());
    for rev in revs.iter().rev() {
        let is_base = base_revs.contains(&rev.rev_id);
        let contents = match rev.edit {
            Contents::Edit { priority, undo_group, ref inserts, ref deletes } => {
                if is_base {
                    s = inserts.transform_union(&s);
                    None
                } else {
                    // fast-forward this revision over all common ones after it
                    let transformed_inserts = inserts.transform_expand(&s);
                    let transformed_deletes = deletes.transform_expand(&s);
                    // we don't want new revisions before this to be transformed after us
                    s = s.transform_shrink(&transformed_inserts);
                    Some(Contents::Edit {
                        inserts: transformed_inserts,
                        deletes: transformed_deletes,
                        priority,
                        undo_group,
                    })
                }
            }
            Contents::Undo { .. } => panic!("can't merge undo yet"),
        };
        if let Some(edit) = contents {
            out.push(Revision { edit, rev_id: rev.rev_id, max_undo_so_far: rev.max_undo_so_far });
        }
    }

    out.as_mut_slice().reverse();
    out
}

#[derive(Clone, Debug)]
struct DeltaOp {
    rev_id: RevId,
    priority: usize,
    undo_group: usize,
    inserts: InsertDelta<RopeInfo>,
    deletes: Subset,
}

/// Transform `revs`, which doesn't include information on the actual content of the operations,
/// into an `InsertDelta`-based representation that does by working backward from the text and tombstones.
fn compute_deltas(
    revs: &[Revision],
    text: &Rope,
    tombstones: &Rope,
    deletes_from_union: &Subset,
) -> Vec<DeltaOp> {
    let mut out = Vec::with_capacity(revs.len());

    let mut cur_all_inserts = Subset::new(deletes_from_union.len());
    for rev in revs.iter().rev() {
        match rev.edit {
            Contents::Edit { priority, undo_group, ref inserts, ref deletes } => {
                let older_all_inserts = inserts.transform_union(&cur_all_inserts);

                // TODO could probably be more efficient by avoiding shuffling from head every time
                let tombstones_here =
                    shuffle_tombstones(text, tombstones, deletes_from_union, &older_all_inserts);
                let delta =
                    Delta::synthesize(&tombstones_here, &older_all_inserts, &cur_all_inserts);
                // TODO create InsertDelta directly and more efficiently instead of factoring
                let (ins, _) = delta.factor();
                out.push(DeltaOp {
                    rev_id: rev.rev_id,
                    priority,
                    undo_group,
                    inserts: ins,
                    deletes: deletes.clone(),
                });

                cur_all_inserts = older_all_inserts;
            }
            Contents::Undo { .. } => panic!("can't merge undo yet"),
        }
    }

    out.as_mut_slice().reverse();
    out
}

/// Computes a series of priorities and transforms for the deltas on the right
/// from the new revisions on the left.
///
/// Applies an optimization where it combines sequential revisions with the
/// same priority into one transform to decrease the number of transforms that
/// have to be considered in `rebase` substantially for normal editing
/// patterns. Any large runs of typing in the same place by the same user (e.g
/// typing a paragraph) will be combined into a single segment in a transform
/// as opposed to thousands of revisions.
fn compute_transforms(revs: Vec<Revision>) -> Vec<(FullPriority, Subset)> {
    let mut out = Vec::new();
    let mut last_priority: Option<usize> = None;
    for r in revs {
        if let Contents::Edit { priority, inserts, .. } = r.edit {
            if inserts.is_empty() {
                continue;
            }
            if Some(priority) == last_priority {
                let last: &mut (FullPriority, Subset) = out.last_mut().unwrap();
                last.1 = last.1.transform_union(&inserts);
            } else {
                last_priority = Some(priority);
                let prio = FullPriority { priority, session_id: r.rev_id.session_id() };
                out.push((prio, inserts));
            }
        }
    }
    out
}

/// Rebase `b_new` on top of `expand_by` and return revision contents that can be appended as new
/// revisions on top of the revisions represented by `expand_by`.
fn rebase(
    mut expand_by: Vec<(FullPriority, Subset)>,
    b_new: Vec<DeltaOp>,
    mut text: Rope,
    mut tombstones: Rope,
    mut deletes_from_union: Subset,
    mut max_undo_so_far: usize,
) -> (Vec<Revision>, Rope, Rope, Subset) {
    let mut out = Vec::with_capacity(b_new.len());

    let mut next_expand_by = Vec::with_capacity(expand_by.len());
    for op in b_new {
        let DeltaOp { rev_id, priority, undo_group, mut inserts, mut deletes } = op;
        let full_priority = FullPriority { priority, session_id: rev_id.session_id() };
        // expand by each in expand_by
        for &(trans_priority, ref trans_inserts) in &expand_by {
            let after = full_priority >= trans_priority; // should never be ==
                                                         // d-expand by other
            inserts = inserts.transform_expand(trans_inserts, after);
            // trans-expand other by expanded so they have the same context
            let inserted = inserts.inserted_subset();
            let new_trans_inserts = trans_inserts.transform_expand(&inserted);
            // The deletes are already after our inserts, but we need to include the other inserts
            deletes = deletes.transform_expand(&new_trans_inserts);
            // On the next step we want things in expand_by to have op in the context
            next_expand_by.push((trans_priority, new_trans_inserts));
        }

        let text_inserts = inserts.transform_shrink(&deletes_from_union);
        let text_with_inserts = text_inserts.apply(&text);
        let inserted = inserts.inserted_subset();

        let expanded_deletes_from_union = deletes_from_union.transform_expand(&inserted);
        let new_deletes_from_union = expanded_deletes_from_union.union(&deletes);
        let (new_text, new_tombstones) = shuffle(
            &text_with_inserts,
            &tombstones,
            &expanded_deletes_from_union,
            &new_deletes_from_union,
        );

        text = new_text;
        tombstones = new_tombstones;
        deletes_from_union = new_deletes_from_union;

        max_undo_so_far = std::cmp::max(max_undo_so_far, undo_group);
        out.push(Revision {
            rev_id,
            max_undo_so_far,
            edit: Contents::Edit { priority, undo_group, deletes, inserts: inserted },
        });

        expand_by = next_expand_by;
        next_expand_by = Vec::with_capacity(expand_by.len());
    }

    (out, text, tombstones, deletes_from_union)
}

impl std::fmt::Display for Error {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            Error::MissingRevision(_) => write!(f, "Revision not found"),
            Error::MalformedDelta { delta_len, rev_len } => {
                write!(f, "Delta base_len {} does not match revision length {}", delta_len, rev_len)
            }
        }
    }
}

impl std::fmt::Debug for Error {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        std::fmt::Display::fmt(self, f)
    }
}

impl std::error::Error for Error {}

#[cfg(test)]
#[rustfmt::skip]
mod tests {
    use crate::engine::*;
    use crate::rope::{Rope, RopeInfo};
    use crate::delta::{Builder, Delta, DeltaElement};
    use crate::multiset::Subset;
    use crate::interval::Interval;
    use std::collections::BTreeSet;
    use crate::test_helpers::{parse_subset_list, parse_subset, parse_delta, debug_subsets};

    const TEST_STR: &'static str = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz";

    fn build_delta_1() -> Delta<RopeInfo> {
        let mut d_builder = Builder::new(TEST_STR.len());
        d_builder.delete(Interval::new(10, 36));
        d_builder.replace(Interval::new(39, 42), Rope::from("DEEF"));
        d_builder.replace(Interval::new(54, 54), Rope::from("999"));
        d_builder.delete(Interval::new(58, 61));
        d_builder.build()
    }

    fn build_delta_2() -> Delta<RopeInfo> {
        let mut d_builder = Builder::new(TEST_STR.len());
        d_builder.replace(Interval::new(1, 3), Rope::from("!"));
        d_builder.delete(Interval::new(10, 36));
        d_builder.replace(Interval::new(42, 45), Rope::from("GI"));
        d_builder.replace(Interval::new(54, 54), Rope::from("888"));
        d_builder.replace(Interval::new(59, 60), Rope::from("HI"));
        d_builder.build()
    }

    #[test]
    fn edit_rev_simple() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(0, 1, first_rev, build_delta_1());
        assert_eq!("0123456789abcDEEFghijklmnopqr999stuvz", String::from(engine.get_head()));
    }

    #[test]
    fn edit_rev_empty() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        let delta = Delta {
            base_len: TEST_STR.len(),
            els: vec![DeltaElement::Copy(0, TEST_STR.len())],
        };
        engine.edit_rev(0, 1, first_rev, delta.clone());
        assert_eq!(TEST_STR, String::from(engine.get_head()));
        engine.edit_rev(0, 1, first_rev, delta.clone());
        assert_eq!(TEST_STR, String::from(engine.get_head()));
    }

    #[test]
    fn edit_rev_concurrent() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, build_delta_1());
        engine.edit_rev(0, 2, first_rev, build_delta_2());
        assert_eq!("0!3456789abcDEEFGIjklmnopqr888999stuvHIz", String::from(engine.get_head()));
    }

    #[test]
    #[should_panic(expected = "Delta base_len 5 does not match revision length 6")]
    fn edit_rev_bad_delta_len() {
        let test_str = "hello";
        let mut engine = Engine::new(Rope::from(test_str));
        let iv = Interval::new(1, 1);

        let mut builder = Builder::new(test_str.len());
        builder.replace(iv, "1".into());
        let delta1 = builder.build();

        let mut builder = Builder::new(test_str.len());
        builder.replace(iv, "2".into());
        let delta2 = builder.build();

        let rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, rev, delta1);

        // this second delta now has an incorrect length for the engine
        let rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 2, rev, delta2);
    }

    fn undo_test(before: bool, undos : BTreeSet<usize>, output: &str) {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        if before {
            engine.undo(undos.clone());
        }
        engine.edit_rev(1, 1, first_rev, build_delta_1());
        engine.edit_rev(0, 2, first_rev, build_delta_2());
        if !before {
            engine.undo(undos);
        }
        assert_eq!(output, String::from(engine.get_head()));
    }

    #[test]
    fn edit_rev_undo() {
        undo_test(true, [1,2].iter().cloned().collect(), TEST_STR);
    }

    #[test]
    fn edit_rev_undo_2() {
        undo_test(true, [2].iter().cloned().collect(), "0123456789abcDEEFghijklmnopqr999stuvz");
    }

    #[test]
    fn edit_rev_undo_3() {
        undo_test(true, [1].iter().cloned().collect(), "0!3456789abcdefGIjklmnopqr888stuvwHIyz");
    }

    #[test]
    fn try_delta_rev_head() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, build_delta_1());
        let d = engine.try_delta_rev_head(first_rev).unwrap();
        assert_eq!(String::from(engine.get_head()), d.apply_to_string(TEST_STR));
    }

    #[test]
    fn try_delta_rev_head_2() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, build_delta_1());
        engine.edit_rev(0, 2, first_rev, build_delta_2());
        let d = engine.try_delta_rev_head(first_rev).unwrap();
        assert_eq!(String::from(engine.get_head()), d.apply_to_string(TEST_STR));
    }

    #[test]
    fn try_delta_rev_head_3() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, build_delta_1());
        let after_first_edit = engine.get_head_rev_id().token();
        engine.edit_rev(0, 2, first_rev, build_delta_2());
        let d = engine.try_delta_rev_head(after_first_edit).unwrap();
        assert_eq!(String::from(engine.get_head()), d.apply_to_string("0123456789abcDEEFghijklmnopqr999stuvz"));
    }

    #[test]
    fn try_delta_rev_head_missing_token() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let first_rev = engine.get_head_rev_id().token();
        let bad_rev = RevToken::default();
        engine.edit_rev(1, 1, first_rev, build_delta_1());
        let d = engine.try_delta_rev_head(bad_rev);
        assert!(d.is_err());
    }

    #[test]
    fn undo() {
        undo_test(false, [1,2].iter().cloned().collect(), TEST_STR);
    }

    #[test]
    fn undo_2() {
        undo_test(false, [2].iter().cloned().collect(), "0123456789abcDEEFghijklmnopqr999stuvz");
    }

    #[test]
    fn undo_3() {
        undo_test(false, [1].iter().cloned().collect(), "0!3456789abcdefGIjklmnopqr888stuvwHIyz");
    }

    #[test]
    fn undo_4() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let d1 = Delta::simple_edit(Interval::new(0,0), Rope::from("a"), TEST_STR.len());
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, d1.clone());
        let new_head = engine.get_head_rev_id().token();
        engine.undo([1].iter().cloned().collect());
        let d2 = Delta::simple_edit(Interval::new(0,0), Rope::from("a"), TEST_STR.len()+1);
        engine.edit_rev(1, 2, new_head, d2); // note this is based on d1 before, not the undo
        let new_head_2 = engine.get_head_rev_id().token();
        let d3 = Delta::simple_edit(Interval::new(0,0), Rope::from("b"), TEST_STR.len()+1);
        engine.edit_rev(1, 3, new_head_2, d3);
        engine.undo([1,3].iter().cloned().collect());
        assert_eq!("a0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", String::from(engine.get_head()));
    }

    #[test]
    fn undo_5() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let d1 = Delta::simple_edit(Interval::new(0,10), Rope::from(""), TEST_STR.len());
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, d1.clone());
        engine.edit_rev(1, 2, first_rev, d1.clone());
        engine.undo([1].iter().cloned().collect());
        assert_eq!("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", String::from(engine.get_head()));
        engine.undo([1,2].iter().cloned().collect());
        assert_eq!(TEST_STR, String::from(engine.get_head()));
        engine.undo([].iter().cloned().collect());
        assert_eq!("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", String::from(engine.get_head()));
    }

    #[test]
    fn gc() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let d1 = Delta::simple_edit(Interval::new(0,0), Rope::from("c"), TEST_STR.len());
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, d1);
        let new_head = engine.get_head_rev_id().token();
        engine.undo([1].iter().cloned().collect());
        let d2 = Delta::simple_edit(Interval::new(0,0), Rope::from("a"), TEST_STR.len()+1);
        engine.edit_rev(1, 2, new_head, d2);
        let gc : BTreeSet<usize> = [1].iter().cloned().collect();
        engine.gc(&gc);
        let d3 = Delta::simple_edit(Interval::new(0,0), Rope::from("b"), TEST_STR.len()+1);
        let new_head_2 = engine.get_head_rev_id().token();
        engine.edit_rev(1, 3, new_head_2, d3);
        engine.undo([3].iter().cloned().collect());
        assert_eq!("a0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", String::from(engine.get_head()));
    }

    /// This case is a regression test reproducing a panic I found while using the UI.
    /// It does undos and gcs in a pattern that can actually happen when using the editor.
    fn gc_scenario(edits: usize, max_undos: usize) {
        let mut engine = Engine::new(Rope::from(""));

        // insert `edits` letter "b"s in separate undo groups
        for i in 0..edits {
            let d = Delta::simple_edit(Interval::new(0,0), Rope::from("b"), i);
            let head = engine.get_head_rev_id().token();
            engine.edit_rev(1, i+1, head, d);
            if i >= max_undos {
                let to_gc : BTreeSet<usize> = [i-max_undos].iter().cloned().collect();
                engine.gc(&to_gc)
            }
        }

        // spam cmd+z until the available undo history is exhausted
        let mut to_undo = BTreeSet::new();
        for i in ((edits-max_undos)..edits).rev() {
            to_undo.insert(i+1);
            engine.undo(to_undo.clone());
        }

        // insert a character at the beginning
        let d1 = Delta::simple_edit(Interval::new(0,0), Rope::from("h"), engine.get_head().len());
        let head = engine.get_head_rev_id().token();
        engine.edit_rev(1, edits+1, head, d1);

        // since character was inserted after gc, editor gcs all undone things
        engine.gc(&to_undo);

        // insert character at end, when this test was added, it panic'd here
        let chars_left = (edits-max_undos)+1;
        let d2 = Delta::simple_edit(Interval::new(chars_left, chars_left), Rope::from("f"), engine.get_head().len());
        let head2 = engine.get_head_rev_id().token();
        engine.edit_rev(1, edits+1, head2, d2);

        let mut soln = String::from("h");
        for _ in 0..(edits-max_undos) {
            soln.push('b');
        }
        soln.push('f');
        assert_eq!(soln, String::from(engine.get_head()));
    }

    #[test]
    fn gc_2() {
        // the smallest values with which it still fails:
        gc_scenario(4,3);
    }

    #[test]
    fn gc_3() {
        // original values this test was created/found with in the UI:
        gc_scenario(35,20);
    }

    #[test]
    fn gc_4() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let d1 = Delta::simple_edit(Interval::new(0,10), Rope::from(""), TEST_STR.len());
        let first_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, first_rev, d1.clone());
        engine.edit_rev(1, 2, first_rev, d1.clone());
        let gc : BTreeSet<usize> = [1].iter().cloned().collect();
        engine.gc(&gc);
        // shouldn't do anything since it was double-deleted and one was GC'd
        engine.undo([1,2].iter().cloned().collect());
        assert_eq!("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", String::from(engine.get_head()));
    }

    #[test]
    fn gc_5() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let d1 = Delta::simple_edit(Interval::new(0,10), Rope::from(""), TEST_STR.len());
        let initial_rev = engine.get_head_rev_id().token();
        engine.undo([1].iter().cloned().collect());
        engine.edit_rev(1, 1, initial_rev, d1.clone());
        engine.edit_rev(1, 2, initial_rev, d1.clone());
        let gc : BTreeSet<usize> = [1].iter().cloned().collect();
        engine.gc(&gc);
        // only one of the deletes was gc'd, the other should still be in effect
        assert_eq!("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", String::from(engine.get_head()));
        // since one of the two deletes was gc'd this should undo the one that wasn't
        engine.undo([2].iter().cloned().collect());
        assert_eq!(TEST_STR, String::from(engine.get_head()));
    }

    #[test]
    fn gc_6() {
        let mut engine = Engine::new(Rope::from(TEST_STR));
        let d1 = Delta::simple_edit(Interval::new(0,10), Rope::from(""), TEST_STR.len());
        let initial_rev = engine.get_head_rev_id().token();
        engine.edit_rev(1, 1, initial_rev, d1.clone());
        engine.undo([1,2].iter().cloned().collect());
        engine.edit_rev(1, 2, initial_rev, d1.clone());
        let gc : BTreeSet<usize> = [1].iter().cloned().collect();
        engine.gc(&gc);
        assert_eq!(TEST_STR, String::from(engine.get_head()));
        // since one of the two deletes was gc'd this should re-do the one that wasn't
        engine.undo([].iter().cloned().collect());
        assert_eq!("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", String::from(engine.get_head()));
    }

    fn basic_rev(i: usize) -> RevId {
        RevId { session1: 1, session2: 0, num: i as u32 }
    }

    fn basic_insert_ops(inserts: Vec<Subset>, priority: usize) -> Vec<Revision> {
        inserts.into_iter().enumerate().map(|(i, inserts)| {
            let deletes = Subset::new(inserts.len());
            Revision {
                rev_id: basic_rev(i+1),
                max_undo_so_far: i+1,
                edit: Contents::Edit {
                    priority, inserts, deletes,
                    undo_group: i+1,
                }
            }
        }).collect()
    }

    #[test]
    fn rearrange_1() {
        let inserts = parse_subset_list("
        ##
        -#-
        #---
        ---#-
        -----#
        #------
        ");
        let revs = basic_insert_ops(inserts, 1);
        let base: BTreeSet<RevId> = [3,5].iter().cloned().map(basic_rev).collect();

        let rearranged = rearrange(&revs, &base, 7);
        let rearranged_inserts: Vec<Subset> = rearranged.into_iter().map(|c| {
            match c.edit {
                Contents::Edit {inserts, ..} => inserts,
                Contents::Undo { .. } => panic!(),
            }
        }).collect();

        debug_subsets(&rearranged_inserts);
        let correct = parse_subset_list("
        -##-
        --#--
        ---#--
        #------
        ");
        assert_eq!(correct, rearranged_inserts);
    }

    fn ids_to_fake_revs(ids: &[usize]) -> Vec<Revision> {
        let contents = Contents::Edit {
            priority: 0,
            undo_group: 0,
            inserts: Subset::new(0),
            deletes: Subset::new(0),
        };

        ids.iter().cloned().map(|i| {
            Revision {
                rev_id: basic_rev(i),
                max_undo_so_far: i,
                edit: contents.clone()
            }
        }).collect()
    }

    #[test]
    fn find_common_1() {
        let a: Vec<Revision> = ids_to_fake_revs(&[0,2,4,6,8,10,12]);
        let b: Vec<Revision> = ids_to_fake_revs(&[0,1,2,4,5,8,9]);
        let res = find_common(&a, &b);

        let correct: BTreeSet<RevId> = [0,2,4,8].iter().cloned().map(basic_rev).collect();
        assert_eq!(correct, res);
    }


    #[test]
    fn find_base_1() {
        let a: Vec<Revision> = ids_to_fake_revs(&[0,2,4,6,8,10,12]);
        let b: Vec<Revision> = ids_to_fake_revs(&[0,1,2,4,5,8,9]);
        let res = find_base_index(&a, &b);

        assert_eq!(1, res);
    }

    #[test]
    fn compute_deltas_1() {
        let inserts = parse_subset_list("
        -##-
        --#--
        ---#--
        #------
        ");
        let revs = basic_insert_ops(inserts, 1);

        let text = Rope::from("13456");
        let tombstones = Rope::from("27");
        let deletes_from_union = parse_subset("-#----#");
        let delta_ops = compute_deltas(&revs, &text, &tombstones, &deletes_from_union);

        println!("{:#?}", delta_ops);

        let mut r = Rope::from("27");
        for op in &delta_ops {
            r = op.inserts.apply(&r);
        }
        assert_eq!("1234567", String::from(r));
    }

    #[test]
    fn compute_transforms_1() {
        let inserts = parse_subset_list("
        -##-
        --#--
        ---#--
        #------
        ");
        let revs = basic_insert_ops(inserts, 1);

        let expand_by = compute_transforms(revs);
        assert_eq!(1, expand_by.len());
        assert_eq!(1, expand_by[0].0.priority);
        let subset_str = format!("{:#?}", expand_by[0].1);
        assert_eq!("#-####-", &subset_str);
    }

    #[test]
    fn compute_transforms_2() {
        let inserts_1 = parse_subset_list("
        -##-
        --#--
        ");
        let mut revs = basic_insert_ops(inserts_1, 1);
        let inserts_2 = parse_subset_list("
        ----
        ");
        let mut revs_2 = basic_insert_ops(inserts_2, 4);
        revs.append(&mut revs_2);
        let inserts_3 = parse_subset_list("
        ---#--
        #------
        ");
        let mut revs_3 = basic_insert_ops(inserts_3, 2);
        revs.append(&mut revs_3);

        let expand_by = compute_transforms(revs);
        assert_eq!(2, expand_by.len());
        assert_eq!(1, expand_by[0].0.priority);
        assert_eq!(2, expand_by[1].0.priority);

        let subset_str = format!("{:#?}", expand_by[0].1);
        assert_eq!("-###-", &subset_str);
        let subset_str = format!("{:#?}", expand_by[1].1);
        assert_eq!("#---#--", &subset_str);
    }

    #[test]
    fn rebase_1() {
        let inserts = parse_subset_list("
        --#-
        ----#
        ");
        let a_revs = basic_insert_ops(inserts.clone(), 1);
        let b_revs = basic_insert_ops(inserts, 2);

        let text_b = Rope::from("zpbj");
        let tombstones_b = Rope::from("a");
        let deletes_from_union_b = parse_subset("-#---");
        let b_delta_ops = compute_deltas(&b_revs, &text_b, &tombstones_b, &deletes_from_union_b);

        println!("{:#?}", b_delta_ops);

        let text_a = Rope::from("zcbd");
        let tombstones_a = Rope::from("a");
        let deletes_from_union_a = parse_subset("-#---");
        let expand_by = compute_transforms(a_revs);

        let (revs, text_2, tombstones_2, deletes_from_union_2) =
            rebase(expand_by, b_delta_ops, text_a, tombstones_a, deletes_from_union_a, 0);

        let rebased_inserts: Vec<Subset> = revs.into_iter().map(|c| {
            match c.edit {
                Contents::Edit {inserts, ..} => inserts,
                Contents::Undo { .. } => panic!(),
            }
        }).collect();

        debug_subsets(&rebased_inserts);
        let correct = parse_subset_list("
        ---#--
        ------#
        ");
        assert_eq!(correct, rebased_inserts);


        assert_eq!("zcpbdj", String::from(&text_2));
        assert_eq!("a", String::from(&tombstones_2));
        assert_eq!("-#-----", format!("{:#?}", deletes_from_union_2));
    }

    // ============== Merge script tests

    #[derive(Clone, Debug)]
    enum MergeTestOp {
        Merge(usize, usize),
        Assert(usize, String),
        AssertAll(String),
        AssertMaxUndoSoFar(usize, usize),
        Edit { ei: usize, p: usize, u: usize, d: Delta<RopeInfo> },
    }

    #[derive(Debug)]
    struct MergeTestState {
        peers: Vec<Engine>,
    }

    impl MergeTestState {
        fn new(count: usize) -> MergeTestState {
            let mut peers = Vec::with_capacity(count);
            for i in 0..count {
                let mut peer = Engine::new(Rope::from(""));
                peer.set_session_id(((i*1000) as u64, 0));
                peers.push(peer);
            }
            MergeTestState { peers }
        }

        fn run_op(&mut self, op: &MergeTestOp) {
            match *op {
                MergeTestOp::Merge(ai, bi) => {
                    let (start, end) = self.peers.split_at_mut(ai);
                    let (a, rest) = end.split_first_mut().unwrap();
                    let b = if bi < ai {
                        &mut start[bi]
                    } else {
                        &mut rest[bi - ai - 1]
                    };
                    a.merge(b);
                },
                MergeTestOp::Assert(ei, ref correct) => {
                    let e = &mut self.peers[ei];
                    assert_eq!(correct, &String::from(e.get_head()), "for peer {}", ei);
                },
                MergeTestOp::AssertMaxUndoSoFar(ei, correct) => {
                    let e = &mut self.peers[ei];
                    assert_eq!(correct, e.max_undo_group_id(), "for peer {}", ei);
                },
                MergeTestOp::AssertAll(ref correct) => {
                    for (ei, e) in self.peers.iter().enumerate() {
                        assert_eq!(correct, &String::from(e.get_head()), "for peer {}", ei);
                    }
                },
                MergeTestOp::Edit { ei, p, u, d: ref delta } => {
                    let e = &mut self.peers[ei];
                    let head = e.get_head_rev_id().token();
                    e.edit_rev(p, u, head, delta.clone());
                },
            }
        }

        fn run_script(&mut self, script: &[MergeTestOp]) {
            for (i, op) in script.iter().enumerate() {
                println!("running {:?} at index {}", op, i);
                self.run_op(op);
            }
        }
    }

    /// Like the scanned whiteboard diagram I have, but without deleting 'a'
    #[test]
    fn merge_insert_only_whiteboard() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("ab") },
            Merge(0,2), Merge(1, 2),
            Assert(0, "ab".to_owned()),
            Assert(1, "ab".to_owned()),
            Assert(2, "ab".to_owned()),
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("-c-") },
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("---d") },
            Assert(0, "acbd".to_owned()),
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("-p-") },
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("---j") },
            Assert(1, "apbj".to_owned()),
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("z--") },
            Merge(0,2), Merge(1, 2),
            Assert(0, "zacbd".to_owned()),
            Assert(1, "zapbj".to_owned()),
            Merge(0,1),
            Assert(0, "zacpbdj".to_owned()),
        ];
        MergeTestState::new(3).run_script(&script[..]);
    }

    /// Tests that priorities are used to break ties correctly
    #[test]
    fn merge_priorities() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("ab") },
            Merge(0,2), Merge(1, 2),
            Assert(0, "ab".to_owned()),
            Assert(1, "ab".to_owned()),
            Assert(2, "ab".to_owned()),
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("-c-") },
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("---d") },
            Assert(0, "acbd".to_owned()),
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("-p-") },
            Assert(1, "apb".to_owned()),
            Edit { ei: 2, p: 4, u: 1, d: parse_delta("-r-") },
            Merge(0,2), Merge(1, 2),
            Assert(0, "acrbd".to_owned()),
            Assert(1, "arpb".to_owned()),
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("----j") },
            Assert(1, "arpbj".to_owned()),
            Edit { ei: 2, p: 4, u: 1, d: parse_delta("---z") },
            Merge(0,2), Merge(1, 2),
            Assert(0, "acrbdz".to_owned()),
            Assert(1, "arpbzj".to_owned()),
            Merge(0,1),
            Assert(0, "acrpbdzj".to_owned()),
        ];
        MergeTestState::new(3).run_script(&script[..]);
    }

    /// Tests that merging again when there are no new revisions does nothing
    #[test]
    fn merge_idempotent() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("ab") },
            Merge(0,2), Merge(1, 2),
            Assert(0, "ab".to_owned()),
            Assert(1, "ab".to_owned()),
            Assert(2, "ab".to_owned()),
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("-c-") },
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("---d") },
            Assert(0, "acbd".to_owned()),
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("-p-") },
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("---j") },
            Merge(0,1),
            Assert(0, "acpbdj".to_owned()),
            Merge(0,1), Merge(1,0), Merge(0,1), Merge(1,0),
            Assert(0, "acpbdj".to_owned()),
            Assert(1, "acpbdj".to_owned()),
        ];
        MergeTestState::new(3).run_script(&script[..]);
    }

    #[test]
    fn merge_associative() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("ab") },
            Merge(0,2), Merge(1, 2),
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("-c-") },
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("-p-") },
            Edit { ei: 2, p: 2, u: 1, d: parse_delta("z--") },
            // copy the current state
            Merge(3, 0), Merge(4, 1), Merge(5, 2),
            // Do the merge one direction
            Merge(1,2),
            Merge(0,1),
            Assert(0, "zacpb".to_owned()),
            // Do it the other way on the copy
            Merge(4,3),
            Merge(5,4),
            Assert(5, "zacpb".to_owned()),
            // Go crazy
            Merge(0,5), Merge(2,5), Merge(4,5), Merge(1,4),
            Merge(3,1), Merge(5,3),
            AssertAll("zacpb".to_owned()),
        ];
        MergeTestState::new(6).run_script(&script[..]);
    }

    #[test]
    fn merge_simple_delete_1() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 0, p: 1, u: 1, d: parse_delta("abc") },
            Merge(1,0),
            Assert(0, "abc".to_owned()),
            Assert(1, "abc".to_owned()),
            Edit { ei: 0, p: 1, u: 1, d: parse_delta("!-d-") },
            Assert(0, "bdc".to_owned()),
            Edit { ei: 1, p: 3, u: 1, d: parse_delta("--efg!") },
            Assert(1, "abefg".to_owned()),
            Merge(1,0),
            Assert(1, "bdefg".to_owned()),
        ];
        MergeTestState::new(2).run_script(&script[..]);
    }

    #[test]
    fn merge_simple_delete_2() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 0, p: 1, u: 1, d: parse_delta("ab") },
            Merge(1,0),
            Assert(0, "ab".to_owned()),
            Assert(1, "ab".to_owned()),
            Edit { ei: 0, p: 1, u: 1, d: parse_delta("!-") },
            Assert(0, "b".to_owned()),
            Edit { ei: 1, p: 3, u: 1, d: parse_delta("-c-") },
            Assert(1, "acb".to_owned()),
            Merge(1,0),
            Assert(1, "cb".to_owned()),
        ];
        MergeTestState::new(2).run_script(&script[..]);
    }

    /// I have a scanned whiteboard diagram of doing this merge by hand, good for reference
    #[test]
    fn merge_whiteboard() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("ab") },
            Merge(0,2), Merge(1, 2), Merge(3, 2),
            Assert(0, "ab".to_owned()),
            Assert(1, "ab".to_owned()),
            Assert(2, "ab".to_owned()),
            Assert(3, "ab".to_owned()),
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("!-") },
            Assert(2, "b".to_owned()),
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("-c-") },
            Edit { ei: 0, p: 3, u: 1, d: parse_delta("---d") },
            Assert(0, "acbd".to_owned()),
            Merge(0,2),
            Assert(0, "cbd".to_owned()),
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("-p-") },
            Merge(1,2),
            Assert(1, "pb".to_owned()),
            Edit { ei: 1, p: 5, u: 1, d: parse_delta("--j") },
            Assert(1, "pbj".to_owned()),
            // to replicate whiteboard, z must be before a tombstone
            // which we can do with another peer that inserts before a and merges.
            Edit { ei: 3, p: 7, u: 1, d: parse_delta("z--") },
            Merge(2,3),
            Merge(0,2), Merge(1, 2),
            Assert(0, "zcbd".to_owned()),
            Assert(1, "zpbj".to_owned()),
            Merge(0,1), // the merge from the whiteboard scan
            Assert(0, "zcpbdj".to_owned()),
        ];
        MergeTestState::new(4).run_script(&script[..]);
    }

    #[test]
    fn merge_max_undo_so_far() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 0, p: 1, u: 1, d: parse_delta("ab") },
            Merge(1,0), Merge(2,0),
            AssertMaxUndoSoFar(1,1),
            Edit { ei: 0, p: 1, u: 2, d: parse_delta("!-") },
            Edit { ei: 1, p: 3, u: 3, d: parse_delta("-!") },
            Merge(1,0),
            AssertMaxUndoSoFar(1,3),
            AssertMaxUndoSoFar(0,2),
            Merge(0,1),
            AssertMaxUndoSoFar(0,3),
            Edit { ei: 2, p: 1, u: 1, d: parse_delta("!!") },
            Merge(1,2),
            AssertMaxUndoSoFar(1,3),
        ];
        MergeTestState::new(3).run_script(&script[..]);
    }

    /// This is a regression test to ensure that session IDs are used to break
    /// ties in edit priorities. Otherwise the results may be inconsistent.
    #[test]
    fn merge_session_priorities() {
        use self::MergeTestOp::*;
        let script = vec![
            Edit { ei: 0, p: 1, u: 1, d: parse_delta("ac") },
            Merge(1,0),
            Merge(2,0),
            AssertAll("ac".to_owned()),
            Edit { ei: 0, p: 1, u: 1, d: parse_delta("-d-") },
            Assert(0, "adc".to_owned()),
            Edit { ei: 1, p: 1, u: 1, d: parse_delta("-f-") },
            Merge(2,1),
            Assert(1, "afc".to_owned()),
            Assert(2, "afc".to_owned()),
            Merge(2,0),
            Merge(0,1),
            // These two will be different without using session IDs
            Assert(2, "adfc".to_owned()),
            Assert(0, "adfc".to_owned()),
        ];
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Fast comparison of rope regions, principally for diffing.
use crate::rope::{BaseMetric, Rope, RopeInfo};
use crate::tree::Cursor;

#[allow(dead_code)]
const SSE_STRIDE: usize = 16;

/// Given two 16-byte slices, returns a bitmask where the 1 bits indicate
/// the positions of non-equal bytes.
///
/// The least significant bit in the mask refers to the byte in position 0;
/// that is, you read the mask right to left.
///
/// # Examples
///
/// ```
/// # use xi_rope::compare::sse_compare_mask;
/// # if is_x86_feature_detected!("sse4.2") {
/// let one = "aaaaaaaaaaaaaaaa";
/// let two = "aa3aaaaa9aaaEaaa";
/// let exp = "0001000100000100";
/// let mask = unsafe { sse_compare_mask(one.as_bytes(), two.as_bytes()) };
/// let result = format!("{:016b}", mask);
/// assert_eq!(result.as_str(), exp);
/// # }
/// ```
///
#[allow(clippy::cast_ptr_alignment, clippy::unreadable_literal)]
#[doc(hidden)]
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "sse4.2")]
pub unsafe fn sse_compare_mask(one: &[u8], two: &[u8]) -> i32 {
    use std::arch::x86_64::*;

    // too lazy to figure out the bit-fiddly way to get this mask
    const HIGH_HALF_MASK: u32 = 0b11111111111111110000000000000000;

    debug_assert!(is_x86_feature_detected!("sse4.2"));

    let onev = _mm_loadu_si128(one.as_ptr() as *const _);
    let twov = _mm_loadu_si128(two.as_ptr() as *const _);
    let mask = _mm_cmpeq_epi8(onev, twov);
    (!_mm_movemask_epi8(mask)) ^ HIGH_HALF_MASK as i32
}

#[allow(dead_code)]
const AVX_STRIDE: usize = 32;

/// Like above but with 32 byte slices
#[allow(clippy::cast_ptr_alignment, clippy::unreadable_literal)]
#[doc(hidden)]
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "avx2")]
pub unsafe fn avx_compare_mask(one: &[u8], two: &[u8]) -> i32 {
    use std::arch::x86_64::*;
    let onev = _mm256_loadu_si256(one.as_ptr() as *const _);
    let twov = _mm256_loadu_si256(two.as_ptr() as *const _);
    let mask = _mm256_cmpeq_epi8(onev, twov);
    !_mm256_movemask_epi8(mask)
}

/// Returns the lowest `i` for which `one[i] != two[i]`, if one exists.
pub fn ne_idx(one: &[u8], two: &[u8]) -> Option<usize> {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("avx2") {
            return unsafe { ne_idx_avx(one, two) };
        } else if is_x86_feature_detected!("sse4.2") {
            return unsafe { ne_idx_sse(one, two) };
        }
    }
    ne_idx_fallback(one, two)
}

/// Returns the lowest `i` such that `one[one.len()-i] != two[two.len()-i]`,
/// if one exists.
pub fn ne_idx_rev(one: &[u8], two: &[u8]) -> Option<usize> {
    #[cfg(target_arch = "x86_64")]
    {
        if is_x86_feature_detected!("sse4.2") {
            return unsafe { ne_idx_rev_sse(one, two) };
        }
    }
    ne_idx_rev_fallback(one, two)
}

#[doc(hidden)]
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "avx2")]
pub unsafe fn ne_idx_avx(one: &[u8], two: &[u8]) -> Option<usize> {
    let min_len = one.len().min(two.len());
    let mut idx = 0;
    while idx < min_len {
        let stride_len = AVX_STRIDE.min(min_len - idx);
        let mask = avx_compare_mask(
            &one.get_unchecked(idx..idx + stride_len),
            &two.get_unchecked(idx..idx + stride_len),
        );
        // at the end of the slice the mask might include garbage bytes, so
        // we ignore matches that are OOB
        if mask != 0 && idx + (mask.trailing_zeros() as usize) < min_len {
            return Some(idx + mask.trailing_zeros() as usize);
        }
        idx += AVX_STRIDE;
    }
    None
}

#[doc(hidden)]
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "sse4.2")]
pub unsafe fn ne_idx_sse(one: &[u8], two: &[u8]) -> Option<usize> {
    let min_len = one.len().min(two.len());
    let mut idx = 0;
    while idx < min_len {
        let stride_len = SSE_STRIDE.min(min_len - idx);
        let mask = sse_compare_mask(
            &one.get_unchecked(idx..idx + stride_len),
            &two.get_unchecked(idx..idx + stride_len),
        );
        if mask != 0 && idx + (mask.trailing_zeros() as usize) < min_len {
            return Some(idx + mask.trailing_zeros() as usize);
        }
        idx += SSE_STRIDE;
    }
    None
}

#[doc(hidden)]
#[cfg(target_arch = "x86_64")]
#[target_feature(enable = "sse4.2")]
pub unsafe fn ne_idx_rev_sse(one: &[u8], two: &[u8]) -> Option<usize> {
    let min_len = one.len().min(two.len());
    let one = &one[one.len() - min_len..];
    let two = &two[two.len() - min_len..];
    debug_assert_eq!(one.len(), two.len());
    let mut idx = min_len;
    loop {
        let mask = if idx < SSE_STRIDE {
            let mut one_buf: [u8; SSE_STRIDE] = [0; SSE_STRIDE];
            let mut two_buf: [u8; SSE_STRIDE] = [0; SSE_STRIDE];
            one_buf[SSE_STRIDE - idx..].copy_from_slice(&one[..idx]);
            two_buf[SSE_STRIDE - idx..].copy_from_slice(&two[..idx]);
            sse_compare_mask(&one_buf, &two_buf)
        } else {
            sse_compare_mask(&one[idx - SSE_STRIDE..idx], &two[idx - SSE_STRIDE..idx])
        };
        let i = mask.leading_zeros() as usize - SSE_STRIDE;
        if i != SSE_STRIDE {
            return Some(min_len - (idx - i));
        }
        if idx < SSE_STRIDE {
            break;
        }
        idx -= SSE_STRIDE;
    }
    None
}

#[inline]
#[allow(dead_code)]
#[doc(hidden)]
pub fn ne_idx_fallback(one: &[u8], two: &[u8]) -> Option<usize> {
    one.iter().zip(two.iter()).position(|(a, b)| a != b)
}

#[inline]
#[allow(dead_code)]
#[doc(hidden)]
pub fn ne_idx_rev_fallback(one: &[u8], two: &[u8]) -> Option<usize> {
    one.iter().rev().zip(two.iter().rev()).position(|(a, b)| a != b)
}

/// Utility for efficiently comparing two ropes.
pub struct RopeScanner<'a> {
    base: Cursor<'a, RopeInfo>,
    target: Cursor<'a, RopeInfo>,
    base_chunk: &'a str,
    target_chunk: &'a str,
    scanned: usize,
}

impl<'a> RopeScanner<'a> {
    pub fn new(base: &'a Rope, target: &'a Rope) -> Self {
        RopeScanner {
            base: Cursor::new(base, 0),
            target: Cursor::new(target, 0),
            base_chunk: "",
            target_chunk: "",
            scanned: 0,
        }
    }

    /// Starting from the two provided offsets in the corresponding ropes,
    /// Returns the distance, moving backwards, to the first non-equal codepoint.
    /// If no such position exists, returns the distance to the closest 0 offset.
    ///
    /// if `stop` is not None, the scan will stop at if it reaches this value.
    ///
    /// # Examples
    ///
    /// ```
    /// # use xi_rope::compare::RopeScanner;
    /// # use xi_rope::Rope;
    ///
    /// let one = Rope::from("hiii");
    /// let two = Rope::from("siii");
    /// let mut scanner = RopeScanner::new(&one, &two);
    /// assert_eq!(scanner.find_ne_char_back(one.len(), two.len(), None), 3);
    /// assert_eq!(scanner.find_ne_char_back(one.len(), two.len(), 2), 2);
    /// ```
    pub fn find_ne_char_back<T>(&mut self, base_off: usize, targ_off: usize, stop: T) -> usize
    where
        T: Into<Option<usize>>,
    {
        let stop = stop.into().unwrap_or(usize::max_value());
        self.base.set(base_off);
        self.target.set(targ_off);
        self.scanned = 0;

        let (base_leaf, base_leaf_off) = self.base.get_leaf().unwrap();
        let (target_leaf, target_leaf_off) = self.target.get_leaf().unwrap();

        debug_assert!(self.target.is_boundary::<BaseMetric>());
        debug_assert!(self.base.is_boundary::<BaseMetric>());
        debug_assert!(base_leaf.is_char_boundary(base_leaf_off));
        debug_assert!(target_leaf.is_char_boundary(target_leaf_off));

        self.base_chunk = &base_leaf[..base_leaf_off];
        self.target_chunk = &target_leaf[..target_leaf_off];

        loop {
            if let Some(mut idx) =
                ne_idx_rev(self.base_chunk.as_bytes(), self.target_chunk.as_bytes())
            {
                // find nearest codepoint boundary
                while idx > 1 && !self.base_chunk.is_char_boundary(self.base_chunk.len() - idx) {
                    idx -= 1;
                }
                return stop.min(self.scanned + idx);
            }
            let scan_len = self.target_chunk.len().min(self.base_chunk.len());
            self.base_chunk = &self.base_chunk[..self.base_chunk.len() - scan_len];
            self.target_chunk = &self.target_chunk[..self.target_chunk.len() - scan_len];
            self.scanned += scan_len;

            if stop <= self.scanned {
                break;
            }
            self.load_prev_chunk();
            if self.base_chunk.is_empty() || self.target_chunk.is_empty() {
                break;
            }
        }
        stop.min(self.scanned)
    }

    /// Starting from the two provided offsets into the two ropes, returns
    /// the distance (in bytes) to the first non-equal codepoint. If no such
    /// position exists, returns the shortest distance to the end of a rope.
    ///
    /// This can be thought of as the length of the longest common substring
    /// between `base[base_off..]` and `target[targ_off..]`.
    ///
    /// if `stop` is not None, the scan will stop at if it reaches this value.
    ///
    /// # Examples
    ///
    /// ```
    /// # use xi_rope::compare::RopeScanner;
    /// # use xi_rope::Rope;
    ///
    /// let one = Rope::from("uh-oh🙈");
    /// let two = Rope::from("uh-oh🙉");
    /// let mut scanner = RopeScanner::new(&one, &two);
    /// assert_eq!(scanner.find_ne_char(0, 0, None), 5);
    /// assert_eq!(scanner.find_ne_char(0, 0, 3), 3);
    /// ```
    pub fn find_ne_char<T>(&mut self, base_off: usize, targ_off: usize, stop: T) -> usize
    where
        T: Into<Option<usize>>,
    {
        let stop = stop.into().unwrap_or(usize::max_value());
        self.base.set(base_off);
        self.target.set(targ_off);
        self.scanned = 0;

        let (base_leaf, base_leaf_off) = self.base.get_leaf().unwrap();
        let (target_leaf, target_leaf_off) = self.target.get_leaf().unwrap();

        debug_assert!(base_leaf.is_char_boundary(base_leaf_off));
        debug_assert!(target_leaf.is_char_boundary(target_leaf_off));

        self.base_chunk = &base_leaf[base_leaf_off..];
        self.target_chunk = &target_leaf[target_leaf_off..];

        loop {
            if let Some(mut idx) = ne_idx(self.base_chunk.as_bytes(), self.target_chunk.as_bytes())
            {
                while idx > 0 && !self.base_chunk.is_char_boundary(idx) {
                    idx -= 1;
                }
                return stop.min(self.scanned + idx);
            }
            let scan_len = self.target_chunk.len().min(self.base_chunk.len());
            self.base_chunk = &self.base_chunk[scan_len..];
            self.target_chunk = &self.target_chunk[scan_len..];
            debug_assert!(self.base_chunk.is_empty() || self.target_chunk.is_empty());
            self.scanned += scan_len;
            if stop <= self.scanned {
                break;
            }
            self.load_next_chunk();
            if self.base_chunk.is_empty() || self.target_chunk.is_empty() {
                break;
            }
        }
        stop.min(self.scanned)
    }

    /// Returns the positive offset from the start of the rope to the first
    /// non-equal byte, and the negative offset from the end of the rope to
    /// the first non-equal byte.
    ///
    /// The two offsets are guaranteed not to overlap;
    /// thus `sum(start_offset, end_offset) <= min(one.len(), two.len())`.
    ///
    /// # Examples
    ///
    /// ```
    /// # use xi_rope::compare::RopeScanner;
    /// # use xi_rope::Rope;
    ///
    /// let one = Rope::from("123xxx12345");
    /// let two = Rope::from("123ZZZ12345");
    /// let mut scanner = RopeScanner::new(&one, &two);
    /// assert_eq!(scanner.find_min_diff_range(), (3, 5));
    ///
    ///
    /// let one = Rope::from("friends");
    /// let two = Rope::from("fiends");
    /// let mut scanner = RopeScanner::new(&one, &two);
    /// assert_eq!(scanner.find_min_diff_range(), (1, 5))
    /// ```
    pub fn find_min_diff_range(&mut self) -> (usize, usize) {
        let b_end = self.base.total_len();
        let t_end = self.target.total_len();
        let start = self.find_ne_char(0, 0, None);

        // scanning from the end of the document, we should stop at whatever
        // offset we reached scanning from the start.
        let unscanned = b_end.min(t_end) - start;

        let end = match unscanned {
            0 => 0,
            n => self.find_ne_char_back(b_end, t_end, n),
        };

        (start, end)
    }

    fn load_prev_chunk(&mut self) {
        if self.base_chunk.is_empty() {
            if let Some(prev) = self.base.prev_leaf() {
                self.base_chunk = prev.0;
            }
        }

        if self.target_chunk.is_empty() {
            if let Some(prev) = self.target.prev_leaf() {
                self.target_chunk = prev.0;
            }
        }
    }

    fn load_next_chunk(&mut self) {
        if self.base_chunk.is_empty() {
            if let Some(next) = self.base.next_leaf() {
                self.base_chunk = next.0;
            }
        }

        if self.target_chunk.is_empty() {
            if let Some(next) = self.target.next_leaf() {
                self.target_chunk = next.0;
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::iter;

    #[test]
    fn ne_len() {
        // we should only match up to the length of the shortest input
        let one = "aaaaaa";
        let two = "aaaa";
        let tre = "aaba";
        let fur = "";
        assert!(ne_idx_fallback(one.as_bytes(), two.as_bytes()).is_none());
        assert_eq!(ne_idx_fallback(one.as_bytes(), tre.as_bytes()), Some(2));
        assert_eq!(ne_idx_fallback(one.as_bytes(), fur.as_bytes()), None);
    }

    #[test]
    #[cfg(target_arch = "x86_64")]
    fn ne_len_simd() {
        // we should only match up to the length of the shortest input
        let one = "aaaaaa";
        let two = "aaaa";
        let tre = "aaba";
        let fur = "";
        unsafe {
            if is_x86_feature_detected!("sse4.2") {
                assert!(ne_idx_sse(one.as_bytes(), two.as_bytes()).is_none());
                assert_eq!(ne_idx_sse(one.as_bytes(), tre.as_bytes()), Some(2));
                assert_eq!(ne_idx_sse(one.as_bytes(), fur.as_bytes()), None);
            }
            if is_x86_feature_detected!("avx2") {
                assert!(ne_idx_avx(one.as_bytes(), two.as_bytes()).is_none());
                assert_eq!(ne_idx_avx(one.as_bytes(), tre.as_bytes()), Some(2));
                assert_eq!(ne_idx_avx(one.as_bytes(), fur.as_bytes()), None);
            }
        }
    }

    #[test]
    fn ne_len_rev() {
        let one = "aaaaaa";
        let two = "aaaa";
        let tre = "aaba";
        let fur = "";
        assert!(ne_idx_rev_fallback(one.as_bytes(), two.as_bytes()).is_none());
        assert_eq!(ne_idx_rev_fallback(one.as_bytes(), tre.as_bytes()), Some(1));
        assert_eq!(ne_idx_rev_fallback(one.as_bytes(), fur.as_bytes()), None);
    }

    #[test]
    #[cfg(target_arch = "x86_64")]
    fn ne_len_rev_sse() {
        if !is_x86_feature_detected!("sse4.2") {
            return;
        }
        let one = "aaaaaa";
        let two = "aaaa";
        let tre = "aaba";
        let fur = "";
        unsafe {
            assert!(ne_idx_rev_sse(one.as_bytes(), two.as_bytes()).is_none());
            assert_eq!(ne_idx_rev_sse(one.as_bytes(), tre.as_bytes()), Some(1));
            assert_eq!(ne_idx_rev_sse(one.as_bytes(), fur.as_bytes()), None);
        }
    }

    #[test]
    fn ne_rev_regression1() {
        let one: &[u8] = &[
            101, 119, 58, 58, 123, 83, 116, 121, 108, 101, 44, 32, 86, 105, 101, 119, 125, 59, 10,
            10,
        ];

        let two: &[u8] = &[
            101, 119, 58, 58, 123, 83, 101, 32, 118, 105, 101, 119, 58, 58, 86, 105, 101, 119, 59,
            10,
        ];

        assert_eq!(ne_idx_rev_fallback(one, two), Some(1));
        if is_x86_feature_detected!("sse4.2") {
            unsafe {
                assert_eq!(ne_idx_rev_sse(one, two), Some(1));
            }
        }
    }

    fn make_lines(n: usize) -> String {
        let mut s = String::with_capacity(n * 81);
        let line: String = iter::repeat('a').take(79).chain(iter::once('\n')).collect();
        for _ in 0..n {
            s.push_str(&line);
        }
        s
    }

    #[test]
    fn scanner_forward_simple() {
        let rope = Rope::from("aaaaaaaaaaaaaaaa");
        let chunk1 = Rope::from("aaaaaaaaaaaaaaaa");
        let chunk2 = Rope::from("baaaaaaaaaaaaaaa");
        let chunk3 = Rope::from("abaaaaaaaaaaaaaa");
        let chunk4 = Rope::from("aaaaaabaaaaaaaaa");
        {
            let mut scanner = RopeScanner::new(&rope, &chunk1);
            assert_eq!(scanner.find_ne_char(0, 0, None), 16);
        }

        {
            let mut scanner = RopeScanner::new(&rope, &chunk2);
            assert_eq!(scanner.find_ne_char(0, 0, None), 0);
        }

        {
            let mut scanner = RopeScanner::new(&rope, &chunk3);
            assert_eq!(scanner.find_ne_char(0, 0, None), 1);
        }

        {
            let mut scanner = RopeScanner::new(&rope, &chunk4);
            assert_eq!(scanner.find_ne_char(0, 0, None), 6);
        }
    }

    #[test]
    fn scanner_backward_simple() {
        let rope = Rope::from("aaaaaaaaaaaaaaaa");
        let chunk1 = Rope::from("aaaaaaaaaaaaaaaa");
        let chunk2 = Rope::from("aaaaaaaaaaaaaaba");
        let chunk3 = Rope::from("aaaaaaaaaaaaaaab");
        let chunk4 = Rope::from("aaaaaabaaaaaaaaa");
        {
            let mut scanner = RopeScanner::new(&rope, &chunk1);
            assert_eq!(scanner.find_ne_char_back(rope.len(), chunk1.len(), None), 16);
        }

        {
            let mut scanner = RopeScanner::new(&rope, &chunk2);
            assert_eq!(scanner.find_ne_char_back(rope.len(), chunk2.len(), None), 1);
        }

        {
            let mut scanner = RopeScanner::new(&rope, &chunk3);
            assert_eq!(scanner.find_ne_char_back(rope.len(), chunk3.len(), None), 0);
        }

        {
            let mut scanner = RopeScanner::new(&rope, &chunk4);
            assert_eq!(scanner.find_ne_char_back(rope.len(), chunk4.len(), None), 9);
        }
    }

    #[test]
    fn scan_back_ne_lens() {
        let rope = Rope::from("aaaaaaaaaaaaaaaa");
        let chunk1 = Rope::from("aaaaaaaaaaaaa");
        let chunk2 = Rope::from("aaaaaaaaaaaaab");

        {
            let mut scanner = RopeScanner::new(&rope, &chunk1);
            assert_eq!(scanner.find_ne_char_back(rope.len(), chunk1.len(), None), 13);
        }

        {
            let mut scanner = RopeScanner::new(&rope, &chunk2);
            assert_eq!(scanner.find_ne_char_back(rope.len(), chunk2.len(), None), 0);
        }
    }

    #[test]
    fn find_diff_range() {
        let one = Rope::from("aaaaaaaaa");
        let two = Rope::from("baaaaaaab");
        let mut scanner = RopeScanner::new(&one, &two);
        let (start, end) = scanner.find_min_diff_range();
        assert_eq!((start, end), (0, 0));

        let one = Rope::from("aaaaaaaaa");
        let two = Rope::from("abaaaaaba");
        let mut scanner = RopeScanner::new(&one, &two);
        let (start, end) = scanner.find_min_diff_range();
        assert_eq!((start, end), (1, 1));

        let one = Rope::from("XXX");
        let two = Rope::from("XXX");
        let mut scanner = RopeScanner::new(&one, &two);
        let (start, end) = scanner.find_min_diff_range();
        assert_eq!((start, end), (3, 0));
    }

    #[test]
    fn find_diff_range_ne_lens() {
        let one = Rope::from("this is a great bit of text");
        let two = Rope::from("this is a great bit of text, with some bonus bytes");
        let mut scanner = RopeScanner::new(&one, &two);
        let (start, end) = scanner.find_min_diff_range();
        assert_eq!((start, end), (27, 0));

        let one = Rope::from("this is a great bit of text");
        let two = Rope::from("xtra bytes precede this is a great bit of text");
        let mut scanner = RopeScanner::new(&one, &two);
        let (start, end) = scanner.find_min_diff_range();
        assert_eq!((start, end), (0, 27));
    }

    #[test]
    fn scanner_back() {
        let rope = Rope::from(make_lines(10));
        let mut chunk = String::from("bbb");
        chunk.push_str(&make_lines(5));
        let targ = Rope::from(chunk);

        {
            let mut scanner = RopeScanner::new(&rope, &targ);
            let result = scanner.find_ne_char_back(rope.len(), targ.len(), None);
            assert_eq!(result, 400);
        }

        let mut targ = String::from(targ);
        targ.push('x');
        targ.push('\n');
        let targ = Rope::from(&targ);
        let mut scanner = RopeScanner::new(&rope, &targ);
        let result = scanner.find_ne_char_back(rope.len(), targ.len(), None);
        assert_eq!(result, 1);
    }

    #[test]
    fn find_forward_utf8() {
        // make sure we don't include the matching non-boundary bytes
        let one = Rope::from("aaaa🙈");
        let two = Rope::from("aaaa🙉");

        let mut scanner = RopeScanner::new(&one, &two);
        let result = scanner.find_ne_char(0, 0, None);
        assert_eq!(result, 4);
    }

    #[test]
    fn find_back_utf8() {
        let zer = Rope::from("baaaa");
        let one = Rope::from("🍄aaaa"); // F0 9F 8D 84 61 61 61 61;
        let two = Rope::from("🙄aaaa"); // F0 9F 99 84 61 61 61 61;
        let tri = Rope::from("🝄aaaa"); // F0 AF 8D 84 61 61 61 61;

        let mut scanner = RopeScanner::new(&zer, &one);
        let result = scanner.find_ne_char_back(zer.len(), one.len(), None);
        assert_eq!(result, 4);

        let mut scanner = RopeScanner::new(&one, &two);
        let result = scanner.find_ne_char_back(one.len(), two.len(), None);
        assert_eq!(result, 4);

        let mut scanner = RopeScanner::new(&one, &tri);
        let result = scanner.find_ne_char_back(one.len(), tri.len(), None);
        assert_eq!(result, 4);
    }

    #[test]
    fn ne_idx_rev_utf8() {
        // there was a weird failure in `find_back_utf8` non_simd, drilling down:
        let zer = "baaaa";
        let one = "🍄aaaa"; // F0 9F 8D 84 61 61 61 61;
        let two = "🙄aaaa"; // F0 9F 99 84 61 61 61 61;
        if is_x86_feature_detected!("sse4.2") {
            unsafe {
                assert_eq!(ne_idx_rev_sse(zer.as_bytes(), one.as_bytes()), Some(4));
                assert_eq!(ne_idx_rev_sse(one.as_bytes(), two.as_bytes()), Some(5));
            }
        }
        assert_eq!(ne_idx_rev_fallback(zer.as_bytes(), one.as_bytes()), Some(4));
        assert_eq!(ne_idx_rev_fallback(one.as_bytes(), two.as_bytes()), Some(5));
    }

    #[test]
    fn avx_mask() {
        if !is_x86_feature_detected!("avx2") {
            return;
        }
        let one = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa";
        let two = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa";
        let mask = unsafe { avx_compare_mask(one.as_bytes(), two.as_bytes()) };
        assert_eq!(mask, 0);
        assert_eq!(mask.trailing_zeros(), 32);
        let two = "aaaaaaaa_aaaaaaaaaaaaaaaaaaaaaaa";
        let mask = unsafe { avx_compare_mask(one.as_bytes(), two.as_bytes()) };
        assert_eq!(mask.trailing_zeros(), 8);
        let two = "bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb";
        let mask = unsafe { avx_compare_mask(one.as_bytes(), two.as_bytes()) };
        assert_eq!(mask.trailing_zeros(), 0);
    }

    #[test]
    fn ne_avx() {
        if !is_x86_feature_detected!("avx2") {
            return;
        }
        let one = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa";
        let two = "bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb";
        unsafe {
            assert_eq!(ne_idx_avx(one.as_bytes(), two.as_bytes()), Some(0));
            let two = "aaaaaaa_aaaaaaaaaaaaaaaaaaaaaaaa";
            assert_eq!(ne_idx_avx(one.as_bytes(), two.as_bytes()), Some(7));
            let two = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa";
            assert_eq!(ne_idx_avx(one.as_bytes(), two.as_bytes()), None);

            let one = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa";
            assert_eq!(ne_idx_avx(one.as_bytes(), one.as_bytes()), None);
            let two = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_aaaaaaaaaaaaaaaaaaaaaaaaa";
            assert_eq!(ne_idx_avx(one.as_bytes(), two.as_bytes()), Some(38));
            let two = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_";
            assert_eq!(ne_idx_avx(one.as_bytes(), two.as_bytes()), Some(63));

            let one = "________________________________________";
            let two = "______________________________________0_";
            assert_eq!(ne_idx_avx(one.as_bytes(), two.as_bytes()), Some(38));
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Closed-open intervals, and operations on them.

//NOTE: intervals used to be more fancy, and could be open or closed on either
//end. It may now be worth considering replacing intervals with Range<usize> or similar.

use std::cmp::{max, min};
use std::fmt;
use std::ops::{Range, RangeFrom, RangeFull, RangeInclusive, RangeTo, RangeToInclusive};

/// A fancy version of Range<usize>, representing a closed-open range;
/// the interval [5, 7) is the set {5, 6}.
///
/// It is an invariant that `start <= end`. An interval where `end < start` is
/// considered empty.
#[derive(Clone, Copy, PartialEq, Eq)]
pub struct Interval {
    pub start: usize,
    pub end: usize,
}

impl Interval {
    /// Construct a new `Interval` representing the range [start..end).
    /// It is an invariant that `start <= end`.
    pub fn new(start: usize, end: usize) -> Interval {
        debug_assert!(start <= end);
        Interval { start, end }
    }

    #[deprecated(since = "0.3.0", note = "all intervals are now closed_open, use Interval::new")]
    pub fn new_closed_open(start: usize, end: usize) -> Interval {
        Self::new(start, end)
    }

    #[deprecated(since = "0.3.0", note = "all intervals are now closed_open")]
    pub fn new_open_closed(start: usize, end: usize) -> Interval {
        Self::new(start, end)
    }

    #[deprecated(since = "0.3.0", note = "all intervals are now closed_open")]
    pub fn new_closed_closed(start: usize, end: usize) -> Interval {
        Self::new(start, end)
    }

    #[deprecated(since = "0.3.0", note = "all intervals are now closed_open")]
    pub fn new_open_open(start: usize, end: usize) -> Interval {
        Self::new(start, end)
    }

    pub fn start(&self) -> usize {
        self.start
    }

    pub fn end(&self) -> usize {
        self.end
    }

    pub fn start_end(&self) -> (usize, usize) {
        (self.start, self.end)
    }

    // The following 3 methods define a trisection, exactly one is true.
    // (similar to std::cmp::Ordering, but "Equal" is not the same as "contains")

    /// the interval is before the point (the point is after the interval)
    pub fn is_before(&self, val: usize) -> bool {
        self.end <= val
    }

    /// the point is inside the interval
    pub fn contains(&self, val: usize) -> bool {
        self.start <= val && val < self.end
    }

    /// the interval is after the point (the point is before the interval)
    pub fn is_after(&self, val: usize) -> bool {
        self.start > val
    }

    pub fn is_empty(&self) -> bool {
        self.end <= self.start
    }

    // impl BitAnd would be completely valid for this
    pub fn intersect(&self, other: Interval) -> Interval {
        let start = max(self.start, other.start);
        let end = min(self.end, other.end);
        Interval { start, end: max(start, end) }
    }

    // smallest interval that encloses both inputs; if the inputs are
    // disjoint, then it fills in the hole.
    pub fn union(&self, other: Interval) -> Interval {
        if self.is_empty() {
            return other;
        }
        if other.is_empty() {
            return *self;
        }
        let start = min(self.start, other.start);
        let end = max(self.end, other.end);
        Interval { start, end }
    }

    // the first half of self - other
    pub fn prefix(&self, other: Interval) -> Interval {
        Interval { start: min(self.start, other.start), end: min(self.end, other.start) }
    }

    // the second half of self - other
    pub fn suffix(&self, other: Interval) -> Interval {
        Interval { start: max(self.start, other.end), end: max(self.end, other.end) }
    }

    // could impl Add trait, but that's probably too cute
    pub fn translate(&self, amount: usize) -> Interval {
        Interval { start: self.start + amount, end: self.end + amount }
    }

    // as above for Sub trait
    pub fn translate_neg(&self, amount: usize) -> Interval {
        debug_assert!(self.start >= amount);
        Interval { start: self.start - amount, end: self.end - amount }
    }

    // insensitive to open or closed ends, just the size of the interior
    pub fn size(&self) -> usize {
        self.end - self.start
    }
}

impl fmt::Display for Interval {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "[{}, {})", self.start(), self.end())
    }
}

impl fmt::Debug for Interval {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        fmt::Display::fmt(self, f)
    }
}

impl From<Range<usize>> for Interval {
    fn from(src: Range<usize>) -> Interval {
        let Range { start, end } = src;
        Interval { start, end }
    }
}

impl From<RangeTo<usize>> for Interval {
    fn from(src: RangeTo<usize>) -> Interval {
        Interval::new(0, src.end)
    }
}

impl From<RangeInclusive<usize>> for Interval {
    fn from(src: RangeInclusive<usize>) -> Interval {
        Interval::new(*src.start(), src.end().saturating_add(1))
    }
}

impl From<RangeToInclusive<usize>> for Interval {
    fn from(src: RangeToInclusive<usize>) -> Interval {
        Interval::new(0, src.end.saturating_add(1))
    }
}

/// A trait for types that represent unbounded ranges; they need an explicit
/// upper bound in order to be converted to `Interval`s.
///
/// This exists so that some methods that use `Interval` under the hood can
/// accept arguments like `..` or `10..`.
///
/// This trait should only be used when the idea of taking all of something
/// makes sense.
pub trait IntervalBounds {
    fn into_interval(self, upper_bound: usize) -> Interval;
}

impl<T: Into<Interval>> IntervalBounds for T {
    fn into_interval(self, _upper_bound: usize) -> Interval {
        self.into()
    }
}

impl IntervalBounds for RangeFrom<usize> {
    fn into_interval(self, upper_bound: usize) -> Interval {
        Interval::new(self.start, upper_bound)
    }
}

impl IntervalBounds for RangeFull {
    fn into_interval(self, upper_bound: usize) -> Interval {
        Interval::new(0, upper_bound)
    }
}

#[cfg(test)]
mod tests {
    use crate::interval::Interval;

    #[test]
    fn contains() {
        let i = Interval::new(2, 42);
        assert!(!i.contains(1));
        assert!(i.contains(2));
        assert!(i.contains(3));
        assert!(i.contains(41));
        assert!(!i.contains(42));
        assert!(!i.contains(43));
    }

    #[test]
    fn before() {
        let i = Interval::new(2, 42);
        assert!(!i.is_before(1));
        assert!(!i.is_before(2));
        assert!(!i.is_before(3));
        assert!(!i.is_before(41));
        assert!(i.is_before(42));
        assert!(i.is_before(43));
    }

    #[test]
    fn after() {
        let i = Interval::new(2, 42);
        assert!(i.is_after(1));
        assert!(!i.is_after(2));
        assert!(!i.is_after(3));
        assert!(!i.is_after(41));
        assert!(!i.is_after(42));
        assert!(!i.is_after(43));
    }

    #[test]
    fn translate() {
        let i = Interval::new(2, 42);
        assert_eq!(Interval::new(5, 45), i.translate(3));
        assert_eq!(Interval::new(1, 41), i.translate_neg(1));
    }

    #[test]
    fn empty() {
        assert!(Interval::new(0, 0).is_empty());
        assert!(Interval::new(1, 1).is_empty());
        assert!(!Interval::new(1, 2).is_empty());
    }

    #[test]
    fn intersect() {
        assert_eq!(Interval::new(2, 3), Interval::new(1, 3).intersect(Interval::new(2, 4)));
        assert!(Interval::new(1, 2).intersect(Interval::new(2, 43)).is_empty());
    }

    #[test]
    fn prefix() {
        assert_eq!(Interval::new(1, 2), Interval::new(1, 4).prefix(Interval::new(2, 3)));
    }

    #[test]
    fn suffix() {
        assert_eq!(Interval::new(3, 4), Interval::new(1, 4).suffix(Interval::new(2, 3)));
    }

    #[test]
    fn size() {
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A module for representing a set of breaks, typically used for
//! storing the result of line breaking.

use crate::interval::Interval;
use crate::tree::{DefaultMetric, Leaf, Metric, Node, NodeInfo, TreeBuilder};
use std::cmp::min;
use std::mem;

/// A set of indexes. A motivating use is storing line breaks.
pub type Breaks = Node<BreaksInfo>;

const MIN_LEAF: usize = 32;
const MAX_LEAF: usize = 64;

// Here the base units are arbitrary, but most commonly match the base units
// of the rope storing the underlying string.

#[derive(Clone, Debug, Default, PartialEq, Eq)]
pub struct BreaksLeaf {
    /// Length, in base units.
    len: usize,
    /// Indexes, represent as offsets from the start of the leaf.
    data: Vec<usize>,
}

/// The number of breaks.
#[derive(Clone, Debug)]
pub struct BreaksInfo(usize);

impl Leaf for BreaksLeaf {
    fn len(&self) -> usize {
        self.len
    }

    fn is_ok_child(&self) -> bool {
        self.data.len() >= MIN_LEAF
    }

    fn push_maybe_split(&mut self, other: &BreaksLeaf, iv: Interval) -> Option<BreaksLeaf> {
        //eprintln!("push_maybe_split {:?} {:?} {}", self, other, iv);
        let (start, end) = iv.start_end();
        for &v in &other.data {
            if start < v && v <= end {
                self.data.push(v - start + self.len);
            }
        }
        // the min with other.len() shouldn't be needed
        self.len += min(end, other.len()) - start;

        if self.data.len() <= MAX_LEAF {
            None
        } else {
            let splitpoint = self.data.len() / 2; // number of breaks
            let splitpoint_units = self.data[splitpoint - 1];

            let mut new = self.data.split_off(splitpoint);
            for x in &mut new {
                *x -= splitpoint_units;
            }

            let new_len = self.len - splitpoint_units;
            self.len = splitpoint_units;
            Some(BreaksLeaf { len: new_len, data: new })
        }
    }
}

impl NodeInfo for BreaksInfo {
    type L = BreaksLeaf;

    fn accumulate(&mut self, other: &Self) {
        self.0 += other.0;
    }

    fn compute_info(l: &BreaksLeaf) -> BreaksInfo {
        BreaksInfo(l.data.len())
    }
}

impl DefaultMetric for BreaksInfo {
    type DefaultMetric = BreaksBaseMetric;
}

impl BreaksLeaf {
    /// Exposed for testing.
    #[doc(hidden)]
    pub fn get_data_cloned(&self) -> Vec<usize> {
        self.data.clone()
    }
}

#[derive(Copy, Clone)]
pub struct BreaksMetric(());

impl Metric<BreaksInfo> for BreaksMetric {
    fn measure(info: &BreaksInfo, _: usize) -> usize {
        info.0
    }

    fn to_base_units(l: &BreaksLeaf, in_measured_units: usize) -> usize {
        if in_measured_units > l.data.len() {
            l.len + 1
        } else if in_measured_units == 0 {
            0
        } else {
            l.data[in_measured_units - 1]
        }
    }

    fn from_base_units(l: &BreaksLeaf, in_base_units: usize) -> usize {
        match l.data.binary_search(&in_base_units) {
            Ok(n) => n + 1,
            Err(n) => n,
        }
    }

    fn is_boundary(l: &BreaksLeaf, offset: usize) -> bool {
        l.data.binary_search(&offset).is_ok()
    }

    fn prev(l: &BreaksLeaf, offset: usize) -> Option<usize> {
        for i in 0..l.data.len() {
            if offset <= l.data[i] {
                if i == 0 {
                    return None;
                } else {
                    return Some(l.data[i - 1]);
                }
            }
        }
        l.data.last().cloned()
    }

    fn next(l: &BreaksLeaf, offset: usize) -> Option<usize> {
        let n = match l.data.binary_search(&offset) {
            Ok(n) => n + 1,
            Err(n) => n,
        };

        if n == l.data.len() {
            None
        } else {
            Some(l.data[n])
        }
    }

    fn can_fragment() -> bool {
        true
    }
}

#[derive(Copy, Clone)]
pub struct BreaksBaseMetric(());

impl Metric<BreaksInfo> for BreaksBaseMetric {
    fn measure(_: &BreaksInfo, len: usize) -> usize {
        len
    }

    fn to_base_units(_: &BreaksLeaf, in_measured_units: usize) -> usize {
        in_measured_units
    }

    fn from_base_units(_: &BreaksLeaf, in_base_units: usize) -> usize {
        in_base_units
    }

    fn is_boundary(l: &BreaksLeaf, offset: usize) -> bool {
        BreaksMetric::is_boundary(l, offset)
    }

    fn prev(l: &BreaksLeaf, offset: usize) -> Option<usize> {
        BreaksMetric::prev(l, offset)
    }

    fn next(l: &BreaksLeaf, offset: usize) -> Option<usize> {
        BreaksMetric::next(l, offset)
    }

    fn can_fragment() -> bool {
        true
    }
}

// Additional functions specific to breaks

impl Breaks {
    // a length with no break, useful in edit operations; for
    // other use cases, use the builder.
    pub fn new_no_break(len: usize) -> Breaks {
        let leaf = BreaksLeaf { len, data: vec![] };
        Node::from_leaf(leaf)
    }
}

pub struct BreakBuilder {
    b: TreeBuilder<BreaksInfo>,
    leaf: BreaksLeaf,
}

impl Default for BreakBuilder {
    fn default() -> BreakBuilder {
        BreakBuilder { b: TreeBuilder::new(), leaf: BreaksLeaf::default() }
    }
}

impl BreakBuilder {
    pub fn new() -> BreakBuilder {
        BreakBuilder::default()
    }

    pub fn add_break(&mut self, len: usize) {
        if self.leaf.data.len() == MAX_LEAF {
            let leaf = mem::take(&mut self.leaf);
            self.b.push(Node::from_leaf(leaf));
        }
        self.leaf.len += len;
        self.leaf.data.push(self.leaf.len);
    }

    pub fn add_no_break(&mut self, len: usize) {
        self.leaf.len += len;
    }

    pub fn build(mut self) -> Breaks {
        self.b.push(Node::from_leaf(self.leaf));
        self.b.build()
    }
}

#[cfg(test)]
mod tests {
    use crate::breaks::{BreakBuilder, BreaksInfo, BreaksLeaf, BreaksMetric};
    use crate::interval::Interval;
    use crate::tree::{Cursor, Node};

    fn gen(n: usize) -> Node<BreaksInfo> {
        let mut node = Node::default();
        let mut b = BreakBuilder::new();
        b.add_break(10);
        let testnode = b.build();
        if n == 1 {
            return testnode;
        }
        for _ in 0..n {
            let len = node.len();
            let empty_interval_at_end = Interval::new(len, len);
            node.edit(empty_interval_at_end, testnode.clone());
        }
        node
    }

    #[test]
    fn empty() {
        let n = gen(0);
        assert_eq!(0, n.len());
    }

    #[test]
    fn fromleaf() {
        let testnode = gen(1);
        assert_eq!(10, testnode.len());
    }

    #[test]
    fn one() {
        let testleaf = BreaksLeaf { len: 10, data: vec![10] };
        let testnode = Node::<BreaksInfo>::from_leaf(testleaf.clone());
        assert_eq!(10, testnode.len());
        let mut c = Cursor::new(&testnode, 0);
        assert_eq!(c.get_leaf().unwrap().0, &testleaf);
        assert_eq!(10, c.next::<BreaksMetric>().unwrap());
        assert!(c.next::<BreaksMetric>().is_none());
        c.set(0);
        assert!(!c.is_boundary::<BreaksMetric>());
        c.set(1);
        assert!(!c.is_boundary::<BreaksMetric>());
        c.set(10);
        assert!(c.is_boundary::<BreaksMetric>());
        assert!(c.prev::<BreaksMetric>().is_none());
    }

    #[test]
    fn concat() {
        let left = gen(1);
        let right = gen(1);
        let node = Node::concat(left.clone(), right);
        assert_eq!(node.len(), 20);
        let mut c = Cursor::new(&node, 0);
        assert_eq!(10, c.next::<BreaksMetric>().unwrap());
        assert_eq!(20, c.next::<BreaksMetric>().unwrap());
        assert!(c.next::<BreaksMetric>().is_none());
    }

    #[test]
    fn larger() {
        let node = gen(100);
        assert_eq!(node.len(), 1000);
    }

    #[test]
    fn default_metric_test() {
        use super::BreaksBaseMetric;

        let breaks = gen(10);
        assert_eq!(
            breaks.convert_metrics::<BreaksBaseMetric, BreaksMetric>(5),
            breaks.count::<BreaksMetric>(5)
        );
        assert_eq!(
            breaks.convert_metrics::<BreaksMetric, BreaksBaseMetric>(7),
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A data structure for representing editing operations on ropes.
//! It's useful to explicitly represent these operations so they can be
//! shared across multiple subsystems.

use crate::interval::{Interval, IntervalBounds};
use crate::multiset::{CountMatcher, Subset, SubsetBuilder};
use crate::tree::{Node, NodeInfo, TreeBuilder};
use std::cmp::min;
use std::fmt;
use std::ops::Deref;
use std::slice;

#[derive(Clone)]
pub enum DeltaElement<N: NodeInfo> {
    /// Represents a range of text in the base document. Includes beginning, excludes end.
    Copy(usize, usize), // note: for now, we lose open/closed info at interval endpoints
    Insert(Node<N>),
}

/// Represents changes to a document by describing the new document as a
/// sequence of sections copied from the old document and of new inserted
/// text. Deletions are represented by gaps in the ranges copied from the old
/// document.
///
/// For example, Editing "abcd" into "acde" could be represented as:
/// `[Copy(0,1),Copy(2,4),Insert("e")]`
#[derive(Clone)]
pub struct Delta<N: NodeInfo> {
    pub els: Vec<DeltaElement<N>>,
    pub base_len: usize,
}

/// A struct marking that a Delta contains only insertions. That is, it copies
/// all of the old document in the same order. It has a `Deref` impl so all
/// normal `Delta` methods can also be used on it.
#[derive(Clone)]
pub struct InsertDelta<N: NodeInfo>(Delta<N>);

impl<N: NodeInfo> Delta<N> {
    pub fn simple_edit<T: IntervalBounds>(interval: T, rope: Node<N>, base_len: usize) -> Delta<N> {
        let mut builder = Builder::new(base_len);
        if rope.is_empty() {
            builder.delete(interval);
        } else {
            builder.replace(interval, rope);
        }
        builder.build()
    }

    /// If this delta represents a simple insertion, returns the inserted node.
    pub fn as_simple_insert(&self) -> Option<&Node<N>> {
        let mut iter = self.els.iter();
        let mut el = iter.next();
        let mut i = 0;
        if let Some(&DeltaElement::Copy(beg, end)) = el {
            if beg != 0 {
                return None;
            }
            i = end;
            el = iter.next();
        }
        if let Some(&DeltaElement::Insert(ref n)) = el {
            el = iter.next();
            if el.is_none() {
                if i == self.base_len {
                    return Some(n);
                }
            } else if let Some(&DeltaElement::Copy(beg, end)) = el {
                if i == beg && end == self.base_len && iter.next().is_none() {
                    return Some(n);
                }
            }
        }
        None
    }

    /// Returns `true` if this delta represents a single deletion without
    /// any insertions.
    ///
    /// Note that this is `false` for the trivial delta, as well as for a deletion
    /// from an empty `Rope`.
    pub fn is_simple_delete(&self) -> bool {
        if self.els.is_empty() {
            return self.base_len > 0;
        }
        if let DeltaElement::Copy(beg, end) = self.els[0] {
            if beg == 0 {
                if self.els.len() == 1 {
                    // Deletion at end
                    end < self.base_len
                } else if let DeltaElement::Copy(b1, e1) = self.els[1] {
                    // Deletion in middle
                    self.els.len() == 2 && end < b1 && e1 == self.base_len
                } else {
                    false
                }
            } else {
                // Deletion at beginning
                end == self.base_len && self.els.len() == 1
            }
        } else {
            false
        }
    }

    /// Returns `true` if applying the delta will cause no change.
    pub fn is_identity(&self) -> bool {
        let len = self.els.len();
        // Case 1: Everything from beginning to end is getting copied.
        if len == 1 {
            if let DeltaElement::Copy(beg, end) = self.els[0] {
                return beg == 0 && end == self.base_len;
            }
        }

        // Case 2: The rope is empty and the entire rope is getting deleted.
        len == 0 && self.base_len == 0
    }

    /// Apply the delta to the given rope. May not work well if the length of the rope
    /// is not compatible with the construction of the delta.
    pub fn apply(&self, base: &Node<N>) -> Node<N> {
        debug_assert_eq!(base.len(), self.base_len, "must apply Delta to Node of correct length");
        let mut b = TreeBuilder::new();
        for elem in &self.els {
            match *elem {
                DeltaElement::Copy(beg, end) => base.push_subseq(&mut b, Interval::new(beg, end)),
                DeltaElement::Insert(ref n) => b.push(n.clone()),
            }
        }
        b.build()
    }

    /// Factor the delta into an insert-only delta and a subset representing deletions.
    /// Applying the insert then the delete yields the same result as the original delta:
    ///
    /// ```no_run
    /// # use xi_rope::rope::{Rope, RopeInfo};
    /// # use xi_rope::delta::Delta;
    /// # use std::str::FromStr;
    /// fn test_factor(d : &Delta<RopeInfo>, r : &Rope) {
    ///     let (ins, del) = d.clone().factor();
    ///     let del2 = del.transform_expand(&ins.inserted_subset());
    ///     assert_eq!(String::from(del2.delete_from(&ins.apply(r))), String::from(d.apply(r)));
    /// }
    /// ```
    pub fn factor(self) -> (InsertDelta<N>, Subset) {
        let mut ins = Vec::new();
        let mut sb = SubsetBuilder::new();
        let mut b1 = 0;
        let mut e1 = 0;
        for elem in self.els {
            match elem {
                DeltaElement::Copy(b, e) => {
                    sb.add_range(e1, b, 1);
                    e1 = e;
                }
                DeltaElement::Insert(n) => {
                    if e1 > b1 {
                        ins.push(DeltaElement::Copy(b1, e1));
                    }
                    b1 = e1;
                    ins.push(DeltaElement::Insert(n));
                }
            }
        }
        if b1 < self.base_len {
            ins.push(DeltaElement::Copy(b1, self.base_len));
        }
        sb.add_range(e1, self.base_len, 1);
        sb.pad_to_len(self.base_len);
        (InsertDelta(Delta { els: ins, base_len: self.base_len }), sb.build())
    }

    /// Synthesize a delta from a "union string" and two subsets: an old set
    /// of deletions and a new set of deletions from the union. The Delta is
    /// from text to text, not union to union; anything in both subsets will
    /// be assumed to be missing from the Delta base and the new text. You can
    /// also think of these as a set of insertions and one of deletions, with
    /// overlap doing nothing. This is basically the inverse of `factor`.
    ///
    /// Since only the deleted portions of the union string are necessary,
    /// instead of requiring a union string the function takes a `tombstones`
    /// rope which contains the deleted portions of the union string. The
    /// `from_dels` subset must be the interleaving of `tombstones` into the
    /// union string.
    ///
    /// ```no_run
    /// # use xi_rope::rope::{Rope, RopeInfo};
    /// # use xi_rope::delta::Delta;
    /// # use std::str::FromStr;
    /// fn test_synthesize(d : &Delta<RopeInfo>, r : &Rope) {
    ///     let (ins_d, del) = d.clone().factor();
    ///     let ins = ins_d.inserted_subset();
    ///     let del2 = del.transform_expand(&ins);
    ///     let r2 = ins_d.apply(&r);
    ///     let tombstones = ins.complement().delete_from(&r2);
    ///     let d2 = Delta::synthesize(&tombstones, &ins, &del);
    ///     assert_eq!(String::from(d2.apply(r)), String::from(d.apply(r)));
    /// }
    /// ```
    // For if last_old.is_some() && last_old.unwrap().0 <= beg {. Clippy complaints
    // about not using if-let, but that'd change the meaning of the conditional.
    #[allow(clippy::unnecessary_unwrap)]
    pub fn synthesize(tombstones: &Node<N>, from_dels: &Subset, to_dels: &Subset) -> Delta<N> {
        let base_len = from_dels.len_after_delete();
        let mut els = Vec::new();
        let mut x = 0;
        let mut old_ranges = from_dels.complement_iter();
        let mut last_old = old_ranges.next();
        let mut m = from_dels.mapper(CountMatcher::NonZero);
        // For each segment of the new text
        for (b, e) in to_dels.complement_iter() {
            // Fill the whole segment
            let mut beg = b;
            while beg < e {
                // Skip over ranges in old text until one overlaps where we want to fill
                while let Some((ib, ie)) = last_old {
                    if ie > beg {
                        break;
                    }
                    x += ie - ib;
                    last_old = old_ranges.next();
                }
                // If we have a range in the old text with the character at beg, then we Copy
                if last_old.is_some() && last_old.unwrap().0 <= beg {
                    let (ib, ie) = last_old.unwrap();
                    let end = min(e, ie);
                    // Try to merge contiguous Copys in the output
                    let xbeg = beg + x - ib; // "beg - ib + x" better for overflow?
                    let xend = end + x - ib; // ditto
                    let merged =
                        if let Some(&mut DeltaElement::Copy(_, ref mut le)) = els.last_mut() {
                            if *le == xbeg {
                                *le = xend;
                                true
                            } else {
                                false
                            }
                        } else {
                            false
                        };
                    if !merged {
                        els.push(DeltaElement::Copy(xbeg, xend));
                    }
                    beg = end;
                } else {
                    // if the character at beg isn't in the old text, then we Insert
                    // Insert up until the next old range we could Copy from, or the end of this segment
                    let mut end = e;
                    if let Some((ib, _)) = last_old {
                        end = min(end, ib)
                    }
                    // Note: could try to aggregate insertions, but not sure of the win.
                    // Use the mapper to insert the corresponding section of the tombstones rope
                    let interval =
                        Interval::new(m.doc_index_to_subset(beg), m.doc_index_to_subset(end));
                    els.push(DeltaElement::Insert(tombstones.subseq(interval)));
                    beg = end;
                }
            }
        }
        Delta { els, base_len }
    }

    /// Produce a summary of the delta. Everything outside the returned interval
    /// is unchanged, and the old contents of the interval are replaced by new
    /// contents of the returned length. Equations:
    ///
    /// `(iv, new_len) = self.summary()`
    ///
    /// `new_s = self.apply(s)`
    ///
    /// `new_s = simple_edit(iv, new_s.subseq(iv.start(), iv.start() + new_len), s.len()).apply(s)`
    pub fn summary(&self) -> (Interval, usize) {
        let mut els = self.els.as_slice();
        let mut iv_start = 0;
        if let Some((&DeltaElement::Copy(0, end), rest)) = els.split_first() {
            iv_start = end;
            els = rest;
        }
        let mut iv_end = self.base_len;
        if let Some((&DeltaElement::Copy(beg, end), init)) = els.split_last() {
            if end == iv_end {
                iv_end = beg;
                els = init;
            }
        }
        (Interval::new(iv_start, iv_end), Delta::total_element_len(els))
    }

    /// Returns the length of the new document. In other words, the length of
    /// the transformed string after this Delta is applied.
    ///
    /// `d.apply(r).len() == d.new_document_len()`
    pub fn new_document_len(&self) -> usize {
        Delta::total_element_len(self.els.as_slice())
    }

    fn total_element_len(els: &[DeltaElement<N>]) -> usize {
        els.iter().fold(0, |sum, el| {
            sum + match *el {
                DeltaElement::Copy(beg, end) => end - beg,
                DeltaElement::Insert(ref n) => n.len(),
            }
        })
    }

    /// Returns the sum length of the inserts of the delta.
    pub fn inserts_len(&self) -> usize {
        self.els.iter().fold(0, |sum, el| {
            sum + match *el {
                DeltaElement::Copy(_, _) => 0,
                DeltaElement::Insert(ref s) => s.len(),
            }
        })
    }

    /// Iterates over all the inserts of the delta.
    pub fn iter_inserts(&self) -> InsertsIter<N> {
        InsertsIter { pos: 0, last_end: 0, els_iter: self.els.iter() }
    }

    /// Iterates over all the deletions of the delta.
    pub fn iter_deletions(&self) -> DeletionsIter<N> {
        DeletionsIter { pos: 0, last_end: 0, base_len: self.base_len, els_iter: self.els.iter() }
    }
}

impl<N: NodeInfo> fmt::Debug for Delta<N>
where
    Node<N>: fmt::Debug,
{
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        if f.alternate() {
            for el in &self.els {
                match *el {
                    DeltaElement::Copy(beg, end) => {
                        write!(f, "{}", "-".repeat(end - beg))?;
                    }
                    DeltaElement::Insert(ref node) => {
                        node.fmt(f)?;
                    }
                }
            }
        } else {
            write!(f, "Delta(")?;
            for el in &self.els {
                match *el {
                    DeltaElement::Copy(beg, end) => {
                        write!(f, "[{},{}) ", beg, end)?;
                    }
                    DeltaElement::Insert(ref node) => {
                        write!(f, "<ins:{}> ", node.len())?;
                    }
                }
            }
            write!(f, "base_len: {})", self.base_len)?;
        }
        Ok(())
    }
}

impl<N: NodeInfo> fmt::Debug for InsertDelta<N>
where
    Node<N>: fmt::Debug,
{
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        self.0.fmt(f)
    }
}

impl<N: NodeInfo> InsertDelta<N> {
    #![allow(clippy::many_single_char_names)]
    /// Do a coordinate transformation on an insert-only delta. The `after` parameter
    /// controls whether the insertions in `self` come after those specific in the
    /// coordinate transform.
    //
    // TODO: write accurate equations
    pub fn transform_expand(&self, xform: &Subset, after: bool) -> InsertDelta<N> {
        let cur_els = &self.0.els;
        let mut els = Vec::new();
        let mut x = 0; // coordinate within self
        let mut y = 0; // coordinate within xform
        let mut i = 0; // index into self.els
        let mut b1 = 0;
        let mut xform_ranges = xform.complement_iter();
        let mut last_xform = xform_ranges.next();
        let l = xform.count(CountMatcher::All);
        while y < l || i < cur_els.len() {
            let next_iv_beg = if let Some((xb, _)) = last_xform { xb } else { l };
            if after && y < next_iv_beg {
                y = next_iv_beg;
            }
            while i < cur_els.len() {
                match cur_els[i] {
                    DeltaElement::Insert(ref n) => {
                        if y > b1 {
                            els.push(DeltaElement::Copy(b1, y));
                        }
                        b1 = y;
                        els.push(DeltaElement::Insert(n.clone()));
                        i += 1;
                    }
                    DeltaElement::Copy(_b, e) => {
                        if y >= next_iv_beg {
                            let mut next_y = e + y - x;
                            if let Some((_, xe)) = last_xform {
                                next_y = min(next_y, xe);
                            }
                            x += next_y - y;
                            y = next_y;
                            if x == e {
                                i += 1;
                            }
                            if let Some((_, xe)) = last_xform {
                                if y == xe {
                                    last_xform = xform_ranges.next();
                                }
                            }
                        }
                        break;
                    }
                }
            }
            if !after && y < next_iv_beg {
                y = next_iv_beg;
            }
        }
        if y > b1 {
            els.push(DeltaElement::Copy(b1, y));
        }
        InsertDelta(Delta { els, base_len: l })
    }

    // TODO: it is plausible this method also works on Deltas with deletes
    /// Shrink a delta through a deletion of some of its copied regions with
    /// the same base. For example, if `self` applies to a union string, and
    /// `xform` is the deletions from that union, the resulting Delta will
    /// apply to the text.
    pub fn transform_shrink(&self, xform: &Subset) -> InsertDelta<N> {
        let mut m = xform.mapper(CountMatcher::Zero);
        let els = self
            .0
            .els
            .iter()
            .map(|elem| match *elem {
                DeltaElement::Copy(b, e) => {
                    DeltaElement::Copy(m.doc_index_to_subset(b), m.doc_index_to_subset(e))
                }
                DeltaElement::Insert(ref n) => DeltaElement::Insert(n.clone()),
            })
            .collect();
        InsertDelta(Delta { els, base_len: xform.len_after_delete() })
    }

    /// Return a Subset containing the inserted ranges.
    ///
    /// `d.inserted_subset().delete_from_string(d.apply_to_string(s)) == s`
    pub fn inserted_subset(&self) -> Subset {
        let mut sb = SubsetBuilder::new();
        for elem in &self.0.els {
            match *elem {
                DeltaElement::Copy(b, e) => {
                    sb.push_segment(e - b, 0);
                }
                DeltaElement::Insert(ref n) => {
                    sb.push_segment(n.len(), 1);
                }
            }
        }
        sb.build()
    }
}

/// An InsertDelta is a certain kind of Delta, and anything that applies to a
/// Delta that may include deletes also applies to one that definitely
/// doesn't. This impl allows implicit use of those methods.
impl<N: NodeInfo> Deref for InsertDelta<N> {
    type Target = Delta<N>;

    fn deref(&self) -> &Delta<N> {
        &self.0
    }
}

/// A mapping from coordinates in the source sequence to coordinates in the sequence after
/// the delta is applied.

// TODO: this doesn't need the new strings, so it should either be based on a new structure
// like Delta but missing the strings, or perhaps the two subsets it's synthesized from.
pub struct Transformer<'a, N: NodeInfo + 'a> {
    delta: &'a Delta<N>,
}

impl<'a, N: NodeInfo + 'a> Transformer<'a, N> {
    /// Create a new transformer from a delta.
    pub fn new(delta: &'a Delta<N>) -> Self {
        Transformer { delta }
    }

    /// Transform a single coordinate. The `after` parameter indicates whether it
    /// it should land before or after an inserted region.

    // TODO: implement a cursor so we're not scanning from the beginning every time.
    pub fn transform(&mut self, ix: usize, after: bool) -> usize {
        if ix == 0 && !after {
            return 0;
        }
        let mut result = 0;
        for el in &self.delta.els {
            match *el {
                DeltaElement::Copy(beg, end) => {
                    if ix <= beg {
                        return result;
                    }
                    if ix < end || (ix == end && !after) {
                        return result + ix - beg;
                    }
                    result += end - beg;
                }
                DeltaElement::Insert(ref n) => {
                    result += n.len();
                }
            }
        }
        result
    }

    /// Determine whether a given interval is untouched by the transformation.
    pub fn interval_untouched<T: IntervalBounds>(&mut self, iv: T) -> bool {
        let iv = iv.into_interval(self.delta.base_len);
        let mut last_was_ins = true;
        for el in &self.delta.els {
            match *el {
                DeltaElement::Copy(beg, end) => {
                    if iv.is_before(end) {
                        if last_was_ins {
                            if iv.is_after(beg) {
                                return true;
                            }
                        } else {
                            if !iv.is_before(beg) {
                                return true;
                            }
                        }
                    } else {
                        return false;
                    }
                    last_was_ins = false;
                }
                _ => {
                    last_was_ins = true;
                }
            }
        }
        false
    }
}

/// A builder for creating new `Delta` objects.
///
/// Note that all edit operations must be sorted; the start point of each
/// interval must be no less than the end point of the previous one.
pub struct Builder<N: NodeInfo> {
    delta: Delta<N>,
    last_offset: usize,
}

impl<N: NodeInfo> Builder<N> {
    /// Creates a new builder, applicable to a base rope of length `base_len`.
    pub fn new(base_len: usize) -> Builder<N> {
        Builder { delta: Delta { els: Vec::new(), base_len }, last_offset: 0 }
    }

    /// Deletes the given interval. Panics if interval is not properly sorted.
    pub fn delete<T: IntervalBounds>(&mut self, interval: T) {
        let interval = interval.into_interval(self.delta.base_len);
        let (start, end) = interval.start_end();
        assert!(start >= self.last_offset, "Delta builder: intervals not properly sorted");
        if start > self.last_offset {
            self.delta.els.push(DeltaElement::Copy(self.last_offset, start));
        }
        self.last_offset = end;
    }

    /// Replaces the given interval with the new rope. Panics if interval
    /// is not properly sorted.
    pub fn replace<T: IntervalBounds>(&mut self, interval: T, rope: Node<N>) {
        self.delete(interval);
        if !rope.is_empty() {
            self.delta.els.push(DeltaElement::Insert(rope));
        }
    }

    /// Determines if delta would be a no-op transformation if built.
    pub fn is_empty(&self) -> bool {
        self.last_offset == 0 && self.delta.els.is_empty()
    }

    /// Builds the `Delta`.
    pub fn build(mut self) -> Delta<N> {
        if self.last_offset < self.delta.base_len {
            self.delta.els.push(DeltaElement::Copy(self.last_offset, self.delta.base_len));
        }
        self.delta
    }
}

pub struct InsertsIter<'a, N: NodeInfo + 'a> {
    pos: usize,
    last_end: usize,
    els_iter: slice::Iter<'a, DeltaElement<N>>,
}

#[derive(Debug, PartialEq)]
pub struct DeltaRegion {
    pub old_offset: usize,
    pub new_offset: usize,
    pub len: usize,
}

impl DeltaRegion {
    fn new(old_offset: usize, new_offset: usize, len: usize) -> Self {
        DeltaRegion { old_offset, new_offset, len }
    }
}

impl<'a, N: NodeInfo> Iterator for InsertsIter<'a, N> {
    type Item = DeltaRegion;

    fn next(&mut self) -> Option<Self::Item> {
        let mut result = None;
        while let Some(elem) = self.els_iter.next() {
            match *elem {
                DeltaElement::Copy(b, e) => {
                    self.pos += e - b;
                    self.last_end = e;
                }
                DeltaElement::Insert(ref n) => {
                    result = Some(DeltaRegion::new(self.last_end, self.pos, n.len()));
                    self.pos += n.len();
                    self.last_end += n.len();
                    break;
                }
            }
        }
        result
    }
}

pub struct DeletionsIter<'a, N: NodeInfo + 'a> {
    pos: usize,
    last_end: usize,
    base_len: usize,
    els_iter: slice::Iter<'a, DeltaElement<N>>,
}

impl<'a, N: NodeInfo> Iterator for DeletionsIter<'a, N> {
    type Item = DeltaRegion;

    fn next(&mut self) -> Option<Self::Item> {
        let mut result = None;
        while let Some(elem) = self.els_iter.next() {
            match *elem {
                DeltaElement::Copy(b, e) => {
                    if b > self.last_end {
                        result = Some(DeltaRegion::new(self.last_end, self.pos, b - self.last_end));
                    }
                    self.pos += e - b;
                    self.last_end = e;
                    if result.is_some() {
                        break;
                    }
                }
                DeltaElement::Insert(ref n) => {
                    self.pos += n.len();
                    self.last_end += n.len();
                }
            }
        }
        if result.is_none() && self.last_end < self.base_len {
            result = Some(DeltaRegion::new(self.last_end, self.pos, self.base_len - self.last_end));
            self.last_end = self.base_len;
        }
        result
    }
}

#[cfg(test)]
mod tests {
    use crate::delta::{Builder, Delta, DeltaElement, DeltaRegion};
    use crate::interval::Interval;
    use crate::rope::{Rope, RopeInfo};
    use crate::test_helpers::find_deletions;

    const TEST_STR: &'static str = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz";

    #[test]
    fn simple() {
        let d = Delta::simple_edit(Interval::new(1, 9), Rope::from("era"), 11);
        assert_eq!("herald", d.apply_to_string("hello world"));
        assert_eq!(6, d.new_document_len());
    }

    #[test]
    fn factor() {
        let d = Delta::simple_edit(Interval::new(1, 9), Rope::from("era"), 11);
        let (d1, ss) = d.factor();
        assert_eq!("heraello world", d1.apply_to_string("hello world"));
        assert_eq!("hld", ss.delete_from_string("hello world"));
    }

    #[test]
    fn synthesize() {
        let d = Delta::simple_edit(Interval::new(1, 9), Rope::from("era"), 11);
        let (d1, del) = d.factor();
        let ins = d1.inserted_subset();
        let del = del.transform_expand(&ins);
        let union_str = d1.apply_to_string("hello world");
        let tombstones = ins.complement().delete_from_string(&union_str);
        let new_d = Delta::synthesize(&Rope::from(&tombstones), &ins, &del);
        assert_eq!("herald", new_d.apply_to_string("hello world"));
        let text = del.complement().delete_from_string(&union_str);
        let inv_d = Delta::synthesize(&Rope::from(&text), &del, &ins);
        assert_eq!("hello world", inv_d.apply_to_string("herald"));
    }

    #[test]
    fn inserted_subset() {
        let d = Delta::simple_edit(Interval::new(1, 9), Rope::from("era"), 11);
        let (d1, _ss) = d.factor();
        assert_eq!("hello world", d1.inserted_subset().delete_from_string("heraello world"));
    }

    #[test]
    fn transform_expand() {
        let str1 = "01259DGJKNQTUVWXYcdefghkmopqrstvwxy";
        let s1 = find_deletions(str1, TEST_STR);
        let d = Delta::simple_edit(Interval::new(10, 12), Rope::from("+"), str1.len());
        assert_eq!("01259DGJKN+UVWXYcdefghkmopqrstvwxy", d.apply_to_string(str1));
        let (d2, _ss) = d.factor();
        assert_eq!("01259DGJKN+QTUVWXYcdefghkmopqrstvwxy", d2.apply_to_string(str1));
        let d3 = d2.transform_expand(&s1, false);
        assert_eq!(
            "0123456789ABCDEFGHIJKLMN+OPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz",
            d3.apply_to_string(TEST_STR)
        );
        let d4 = d2.transform_expand(&s1, true);
        assert_eq!(
            "0123456789ABCDEFGHIJKLMNOP+QRSTUVWXYZabcdefghijklmnopqrstuvwxyz",
            d4.apply_to_string(TEST_STR)
        );
    }

    #[test]
    fn transform_shrink() {
        let d = Delta::simple_edit(Interval::new(10, 12), Rope::from("+"), TEST_STR.len());
        let (d2, _ss) = d.factor();
        assert_eq!(
            "0123456789+ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz",
            d2.apply_to_string(TEST_STR)
        );

        let str1 = "0345678BCxyz";
        let s1 = find_deletions(str1, TEST_STR);
        let d3 = d2.transform_shrink(&s1);
        assert_eq!("0345678+BCxyz", d3.apply_to_string(str1));

        let str2 = "356789ABCx";
        let s2 = find_deletions(str2, TEST_STR);
        let d4 = d2.transform_shrink(&s2);
        assert_eq!("356789+ABCx", d4.apply_to_string(str2));
    }

    #[test]
    fn iter_inserts() {
        let mut builder = Builder::new(10);
        builder.replace(Interval::new(2, 2), Rope::from("a"));
        builder.delete(Interval::new(3, 5));
        builder.replace(Interval::new(6, 8), Rope::from("b"));
        let delta = builder.build();

        assert_eq!("01a25b89", delta.apply_to_string("0123456789"));

        let mut iter = delta.iter_inserts();
        assert_eq!(Some(DeltaRegion::new(2, 2, 1)), iter.next());
        assert_eq!(Some(DeltaRegion::new(6, 5, 1)), iter.next());
        assert_eq!(None, iter.next());
    }

    #[test]
    fn iter_deletions() {
        let mut builder = Builder::new(10);
        builder.delete(Interval::new(0, 2));
        builder.delete(Interval::new(4, 6));
        builder.delete(Interval::new(8, 10));
        let delta = builder.build();

        assert_eq!("2367", delta.apply_to_string("0123456789"));

        let mut iter = delta.iter_deletions();
        assert_eq!(Some(DeltaRegion::new(0, 0, 2)), iter.next());
        assert_eq!(Some(DeltaRegion::new(4, 2, 2)), iter.next());
        assert_eq!(Some(DeltaRegion::new(8, 4, 2)), iter.next());
        assert_eq!(None, iter.next());
    }

    #[test]
    fn fancy_bounds() {
        let mut builder = Builder::new(10);
        builder.delete(..2);
        builder.delete(4..=5);
        builder.delete(8..);
        let delta = builder.build();
        assert_eq!("2367", delta.apply_to_string("0123456789"));
    }

    #[test]
    fn is_simple_delete() {
        let d = Delta::simple_edit(10..12, Rope::from("+"), TEST_STR.len());
        assert_eq!(false, d.is_simple_delete());

        let d = Delta::simple_edit(Interval::new(0, 0), Rope::from(""), 0);
        assert_eq!(false, d.is_simple_delete());

        let d = Delta::simple_edit(Interval::new(10, 11), Rope::from(""), TEST_STR.len());
        assert_eq!(true, d.is_simple_delete());

        let mut builder = Builder::<RopeInfo>::new(10);
        builder.delete(Interval::new(0, 2));
        builder.delete(Interval::new(4, 6));
        let d = builder.build();
        assert_eq!(false, d.is_simple_delete());

        let builder = Builder::<RopeInfo>::new(10);
        let d = builder.build();
        assert_eq!(false, d.is_simple_delete());

        let delta = Delta {
            els: vec![
                DeltaElement::Copy(0, 10),
                DeltaElement::Copy(12, 20),
                DeltaElement::Insert(Rope::from("hi")),
            ],
            base_len: 20,
        };

        assert!(!delta.is_simple_delete());
    }

    #[test]
    fn is_identity() {
        let d = Delta::simple_edit(10..12, Rope::from("+"), TEST_STR.len());
        assert_eq!(false, d.is_identity());

        let d = Delta::simple_edit(0..0, Rope::from(""), TEST_STR.len());
        assert_eq!(true, d.is_identity());

        let d = Delta::simple_edit(0..0, Rope::from(""), 0);
        assert_eq!(true, d.is_identity());
    }

    #[test]
    fn as_simple_insert() {
        let d = Delta::simple_edit(Interval::new(10, 11), Rope::from("+"), TEST_STR.len());
        assert_eq!(None, d.as_simple_insert());

        let d = Delta::simple_edit(Interval::new(10, 10), Rope::from("+"), TEST_STR.len());
        assert_eq!(Some(Rope::from("+")).as_ref(), d.as_simple_insert());
    }
}

#[cfg(all(test, feature = "serde"))]
mod serde_tests {
    use crate::rope::{Rope, RopeInfo};
    use crate::{Delta, Interval};
    use serde_json;

    const TEST_STR: &'static str = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz";

    #[test]
    fn delta_serde() {
        let d = Delta::simple_edit(Interval::new(10, 12), Rope::from("+"), TEST_STR.len());
        let ser = serde_json::to_value(d.clone()).expect("serialize failed");
        eprintln!("{:?}", &ser);
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A module for representing spans (in an interval tree), useful for rich text
//! annotations. It is parameterized over a data type, so can be used for
//! storing different annotations.

use std::fmt;
use std::marker::PhantomData;
use std::mem;

use crate::delta::{Delta, DeltaElement, Transformer};
use crate::interval::{Interval, IntervalBounds};
use crate::tree::{Cursor, Leaf, Node, NodeInfo, TreeBuilder};

const MIN_LEAF: usize = 32;
const MAX_LEAF: usize = 64;

pub type Spans<T> = Node<SpansInfo<T>>;

#[derive(Clone)]
pub struct Span<T: Clone> {
    iv: Interval,
    data: T,
}

#[derive(Clone)]
pub struct SpansLeaf<T: Clone> {
    len: usize, // measured in base units
    spans: Vec<Span<T>>,
}

// It would be preferable to derive Default.
// This would however require T to implement Default due to an issue in Rust.
// See: https://github.com/rust-lang/rust/issues/26925
impl<T: Clone> Default for SpansLeaf<T> {
    fn default() -> Self {
        SpansLeaf { len: 0, spans: vec![] }
    }
}

#[derive(Clone)]
pub struct SpansInfo<T> {
    n_spans: usize,
    iv: Interval,
    phantom: PhantomData<T>,
}

impl<T: Clone> Leaf for SpansLeaf<T> {
    fn len(&self) -> usize {
        self.len
    }

    fn is_ok_child(&self) -> bool {
        self.spans.len() >= MIN_LEAF
    }

    fn push_maybe_split(&mut self, other: &Self, iv: Interval) -> Option<Self> {
        let iv_start = iv.start();
        for span in &other.spans {
            let span_iv = span.iv.intersect(iv).translate_neg(iv_start).translate(self.len);

            if !span_iv.is_empty() {
                self.spans.push(Span { iv: span_iv, data: span.data.clone() });
            }
        }
        self.len += iv.size();

        if self.spans.len() <= MAX_LEAF {
            None
        } else {
            let splitpoint = self.spans.len() / 2; // number of spans
            let splitpoint_units = self.spans[splitpoint].iv.start();
            let mut new = self.spans.split_off(splitpoint);
            for span in &mut new {
                span.iv = span.iv.translate_neg(splitpoint_units);
            }
            let new_len = self.len - splitpoint_units;
            self.len = splitpoint_units;
            Some(SpansLeaf { len: new_len, spans: new })
        }
    }
}

impl<T: Clone> NodeInfo for SpansInfo<T> {
    type L = SpansLeaf<T>;

    fn accumulate(&mut self, other: &Self) {
        self.n_spans += other.n_spans;
        self.iv = self.iv.union(other.iv);
    }

    fn compute_info(l: &SpansLeaf<T>) -> Self {
        let mut iv = Interval::new(0, 0); // should be Interval::default?
        for span in &l.spans {
            iv = iv.union(span.iv);
        }
        SpansInfo { n_spans: l.spans.len(), iv, phantom: PhantomData }
    }
}

pub struct SpansBuilder<T: Clone> {
    b: TreeBuilder<SpansInfo<T>>,
    leaf: SpansLeaf<T>,
    len: usize,
    total_len: usize,
}

impl<T: Clone> SpansBuilder<T> {
    pub fn new(total_len: usize) -> Self {
        SpansBuilder { b: TreeBuilder::new(), leaf: SpansLeaf::default(), len: 0, total_len }
    }

    // Precondition: spans must be added in nondecreasing start order.
    // Maybe take Span struct instead of separate iv, data args?
    pub fn add_span<IV: IntervalBounds>(&mut self, iv: IV, data: T) {
        let iv = iv.into_interval(self.total_len);
        if self.leaf.spans.len() == MAX_LEAF {
            let mut leaf = mem::take(&mut self.leaf);
            leaf.len = iv.start() - self.len;
            self.len = iv.start();
            self.b.push(Node::from_leaf(leaf));
        }
        self.leaf.spans.push(Span { iv: iv.translate_neg(self.len), data })
    }

    // Would make slightly more implementation sense to take total_len as an argument
    // here, but that's not quite the usual builder pattern.
    pub fn build(mut self) -> Spans<T> {
        self.leaf.len = self.total_len - self.len;
        self.b.push(Node::from_leaf(self.leaf));
        self.b.build()
    }
}

pub struct SpanIter<'a, T: 'a + Clone> {
    cursor: Cursor<'a, SpansInfo<T>>,
    ix: usize,
}

impl<T: Clone> Spans<T> {
    /// Perform operational transformation on a spans object intended to be edited into
    /// a sequence at the given offset.

    // Note: this implementation is not efficient for very large Spans objects, as it
    // traverses all spans linearly. A more sophisticated approach would be to traverse
    // the tree, and only delve into subtrees that are transformed.
    pub fn transform<N: NodeInfo>(
        &self,
        base_start: usize,
        base_end: usize,
        xform: &mut Transformer<N>,
    ) -> Self {
        // TODO: maybe should take base as an Interval and figure out "after" from that
        let new_start = xform.transform(base_start, false);
        let new_end = xform.transform(base_end, true);
        let mut builder = SpansBuilder::new(new_end - new_start);
        for (iv, data) in self.iter() {
            let start = xform.transform(iv.start() + base_start, false) - new_start;
            let end = xform.transform(iv.end() + base_start, false) - new_start;
            if start < end {
                let iv = Interval::new(start, end);
                // TODO: could imagine using a move iterator and avoiding clone, but it's not easy.
                builder.add_span(iv, data.clone());
            }
        }
        builder.build()
    }

    /// Creates a new Spans instance by merging spans from `other` with `self`,
    /// using a closure to transform values.
    ///
    /// New spans are created from non-overlapping regions of existing spans,
    /// and by combining overlapping regions into new spans. In all cases,
    /// new values are generated by calling a closure that transforms the
    /// value of the existing span or spans.
    ///
    /// # Panics
    ///
    /// Panics if `self` and `other` have different lengths.
    ///
    pub fn merge<F, O>(&self, other: &Self, mut f: F) -> Spans<O>
    where
        F: FnMut(&T, Option<&T>) -> O,
        O: Clone,
    {
        //TODO: confirm that this is sensible behaviour
        assert_eq!(self.len(), other.len());
        let mut sb = SpansBuilder::new(self.len());

        // red/blue is just a better name than one/two or me/other
        let mut iter_red = self.iter();
        let mut iter_blue = other.iter();

        let mut next_red = iter_red.next();
        let mut next_blue = iter_blue.next();

        loop {
            // exit conditions:
            if next_red.is_none() && next_blue.is_none() {
                // all merged.
                break;
            } else if next_red.is_none() != next_blue.is_none() {
                // one side is exhausted; append remaining items from other side.
                let iter = if next_red.is_some() { iter_red } else { iter_blue };
                // add this item
                let (iv, val) = next_red.or(next_blue).unwrap();
                sb.add_span(iv, f(val, None));

                for (iv, val) in iter {
                    sb.add_span(iv, f(val, None))
                }
                break;
            }

            // body:
            let (mut red_iv, red_val) = next_red.unwrap();
            let (mut blue_iv, blue_val) = next_blue.unwrap();

            if red_iv.intersect(blue_iv).is_empty() {
                // spans do not overlap. Add the leading span & advance that iter.
                if red_iv.is_before(blue_iv.start()) {
                    sb.add_span(red_iv, f(red_val, None));
                    next_red = iter_red.next();
                } else {
                    sb.add_span(blue_iv, f(blue_val, None));
                    next_blue = iter_blue.next();
                }
                continue;
            }
            assert!(!red_iv.intersect(blue_iv).is_empty());

            // if these two spans do not share a start point, create a new span from
            // the prefix of the leading span.
            use std::cmp::Ordering;

            match red_iv.start().cmp(&blue_iv.start()) {
                Ordering::Less => {
                    let iv = red_iv.prefix(blue_iv);
                    sb.add_span(iv, f(red_val, None));
                    red_iv = red_iv.suffix(iv);
                }
                Ordering::Greater => {
                    let iv = blue_iv.prefix(red_iv);
                    sb.add_span(iv, f(blue_val, None));
                    blue_iv = blue_iv.suffix(iv);
                }
                Ordering::Equal => {}
            }

            assert!(red_iv.start() == blue_iv.start());
            // create a new span by merging the overlapping regions.
            let iv = red_iv.intersect(blue_iv);
            assert!(!iv.is_empty());
            sb.add_span(iv, f(red_val, Some(blue_val)));

            // if an old span was consumed by this new span, advance
            // else reuse remaining span (set next_red/blue) for the next loop iteration
            red_iv = red_iv.suffix(iv);
            blue_iv = blue_iv.suffix(iv);
            assert!(red_iv.is_empty() || blue_iv.is_empty());

            if red_iv.is_empty() {
                next_red = iter_red.next();
            } else {
                next_red = Some((red_iv, red_val));
            }

            if blue_iv.is_empty() {
                next_blue = iter_blue.next();
            } else {
                next_blue = Some((blue_iv, blue_val));
            }
        }
        sb.build()
    }

    // possible future: an iterator that takes an interval, so results are the same as
    // taking a subseq on the spans object. Would require specialized Cursor.
    pub fn iter(&self) -> SpanIter<T> {
        SpanIter { cursor: Cursor::new(self, 0), ix: 0 }
    }

    /// Applies a generic delta to `self`, inserting empty spans for any
    /// added regions.
    ///
    /// This is intended to be used to keep spans up to date with a `Rope`
    /// as edits occur.
    pub fn apply_shape<M: NodeInfo>(&mut self, delta: &Delta<M>) {
        let mut b = TreeBuilder::new();
        for elem in &delta.els {
            match *elem {
                DeltaElement::Copy(beg, end) => b.push(self.subseq(Interval::new(beg, end))),
                DeltaElement::Insert(ref n) => b.push(SpansBuilder::new(n.len()).build()),
            }
        }
        *self = b.build();
    }

    /// Deletes all spans that intersect with `interval` and that come after.
    pub fn delete_after(&mut self, interval: Interval) {
        let mut builder = SpansBuilder::new(self.len());

        for (iv, data) in self.iter() {
            // check if spans overlaps with interval
            if iv.intersect(interval).is_empty() {
                // keep the ones that are not overlapping
                builder.add_span(iv, data.clone());
            } else {
                // all remaining spans are invalid
                break;
            }
        }
        *self = builder.build();
    }
}

impl<T: Clone + fmt::Debug> fmt::Debug for Spans<T> {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        let strs =
            self.iter().map(|(iv, val)| format!("{}: {:?}", iv, val)).collect::<Vec<String>>();
        write!(f, "len: {}\nspans:\n\t{}", self.len(), &strs.join("\n\t"))
    }
}

impl<'a, T: Clone> Iterator for SpanIter<'a, T> {
    type Item = (Interval, &'a T);

    fn next(&mut self) -> Option<(Interval, &'a T)> {
        if let Some((leaf, start_pos)) = self.cursor.get_leaf() {
            if leaf.spans.is_empty() {
                return None;
            }
            let leaf_start = self.cursor.pos() - start_pos;
            let span = &leaf.spans[self.ix];
            self.ix += 1;
            if self.ix == leaf.spans.len() {
                let _ = self.cursor.next_leaf();
                self.ix = 0;
            }
            return Some((span.iv.translate(leaf_start), &span.data));
        }
        None
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    #[test]

    fn test_merge() {
        // merging 1 1 1 1 1 1 1 1 1 16
        // with    2 2 4 4     8 8
        // ==      3 3 5 5 1 1 9 9 1 16
        let mut sb = SpansBuilder::new(10);
        sb.add_span(Interval::new(0, 9), 1u32);
        sb.add_span(Interval::new(9, 10), 16);
        let red = sb.build();

        let mut sb = SpansBuilder::new(10);
        sb.add_span(Interval::new(0, 2), 2);
        sb.add_span(Interval::new(2, 4), 4);
        sb.add_span(Interval::new(6, 8), 8);
        let blue = sb.build();
        let merged = red.merge(&blue, |r, b| b.map(|b| b + r).unwrap_or(*r));

        let mut merged_iter = merged.iter();
        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(0, 2));
        assert_eq!(*val, 3);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(2, 4));
        assert_eq!(*val, 5);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(4, 6));
        assert_eq!(*val, 1);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(6, 8));
        assert_eq!(*val, 9);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(8, 9));
        assert_eq!(*val, 1);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(9, 10));
        assert_eq!(*val, 16);

        assert!(merged_iter.next().is_none());
    }

    #[test]
    fn test_merge_2() {
        // 1 1 1   4 4
        //   2 2 2 2     8 9
        let mut sb = SpansBuilder::new(9);
        sb.add_span(Interval::new(0, 3), 1);
        sb.add_span(Interval::new(4, 6), 4);
        let blue = sb.build();

        let mut sb = SpansBuilder::new(9);
        sb.add_span(Interval::new(1, 5), 2);
        sb.add_span(Interval::new(7, 8), 8);
        sb.add_span(Interval::new(8, 9), 9);
        let red = sb.build();

        let merged = red.merge(&blue, |r, b| b.map(|b| b + r).unwrap_or(*r));

        let mut merged_iter = merged.iter();
        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(0, 1));
        assert_eq!(*val, 1);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(1, 3));
        assert_eq!(*val, 3);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(3, 4));
        assert_eq!(*val, 2);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(4, 5));
        assert_eq!(*val, 6);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(5, 6));
        assert_eq!(*val, 4);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(7, 8));
        assert_eq!(*val, 8);

        let (iv, val) = merged_iter.next().unwrap();
        assert_eq!(iv, Interval::new(8, 9));
        assert_eq!(*val, 9);

        assert!(merged_iter.next().is_none());
    }

    #[test]
    fn test_delete_after() {
        let mut sb = SpansBuilder::new(11);
        sb.add_span(Interval::new(1, 2), 2);
        sb.add_span(Interval::new(3, 5), 8);
        sb.add_span(Interval::new(6, 8), 9);
        sb.add_span(Interval::new(9, 10), 1);
        sb.add_span(Interval::new(10, 11), 1);
        let mut spans = sb.build();

        spans.delete_after(Interval::new(4, 7));

        assert_eq!(spans.iter().count(), 1);

        let (iv, val) = spans.iter().next().unwrap();
        assert_eq!(iv, Interval::new(1, 2));
        assert_eq!(*val, 2);
    }

    #[test]
    fn delete_after_big_at_start() {
        let mut sb = SpansBuilder::new(10);
        sb.add_span(0..10, 0);

        let mut spans = sb.build();
        assert_eq!(spans.iter().count(), 1);

        spans.delete_after(Interval::new(1, 2));
        assert_eq!(spans.iter().count(), 0);
    }

    #[test]
    fn delete_after_big_and_small() {
        let mut sb = SpansBuilder::new(10);
        sb.add_span(0..10, 0);
        sb.add_span(3..10, 1);

        let mut spans = sb.build();
        assert_eq!(spans.iter().count(), 2);

        spans.delete_after(Interval::new(1, 2));
        assert_eq!(spans.iter().count(), 0);
    }

    #[test]
    fn delete_after_empty() {
        let mut sb = SpansBuilder::new(10);
        sb.add_span(0..3, 0);

        let mut spans = sb.build();
        assert_eq!(spans.iter().count(), 1);

        spans.delete_after(Interval::new(5, 7));
        assert_eq!(spans.iter().count(), 1);
    }
// Copyright 2019 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::fmt;
use std::str::FromStr;

use serde::de::{self, Deserialize, Deserializer, Visitor};
use serde::ser::{Serialize, SerializeStruct, SerializeTupleVariant, Serializer};

use crate::tree::Node;
use crate::{Delta, DeltaElement, Rope, RopeInfo};

impl Serialize for Rope {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(&String::from(self))
    }
}

impl<'de> Deserialize<'de> for Rope {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        deserializer.deserialize_str(RopeVisitor)
    }
}

struct RopeVisitor;

impl<'de> Visitor<'de> for RopeVisitor {
    type Value = Rope;

    fn expecting(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "a string")
    }

    fn visit_str<E>(self, s: &str) -> Result<Self::Value, E>
    where
        E: de::Error,
    {
        Rope::from_str(s).map_err(|_| de::Error::invalid_value(de::Unexpected::Str(s), &self))
    }
}

impl Serialize for DeltaElement<RopeInfo> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        match *self {
            DeltaElement::Copy(ref start, ref end) => {
                let mut el = serializer.serialize_tuple_variant("DeltaElement", 0, "copy", 2)?;
                el.serialize_field(start)?;
                el.serialize_field(end)?;
                el.end()
            }
            DeltaElement::Insert(ref node) => {
                serializer.serialize_newtype_variant("DeltaElement", 1, "insert", node)
            }
        }
    }
}

impl Serialize for Delta<RopeInfo> {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let mut delta = serializer.serialize_struct("Delta", 2)?;
        delta.serialize_field("els", &self.els)?;
        delta.serialize_field("base_len", &self.base_len)?;
        delta.end()
    }
}

impl<'de> Deserialize<'de> for Delta<RopeInfo> {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        // NOTE: we derive to an interim representation and then convert
        // that into our actual target.
        #[derive(Serialize, Deserialize)]
        #[serde(rename_all = "snake_case")]
        enum RopeDeltaElement_ {
            Copy(usize, usize),
            Insert(Node<RopeInfo>),
        }

        #[derive(Serialize, Deserialize)]
        struct RopeDelta_ {
            els: Vec<RopeDeltaElement_>,
            base_len: usize,
        }

        impl From<RopeDeltaElement_> for DeltaElement<RopeInfo> {
            fn from(elem: RopeDeltaElement_) -> DeltaElement<RopeInfo> {
                match elem {
                    RopeDeltaElement_::Copy(start, end) => DeltaElement::Copy(start, end),
                    RopeDeltaElement_::Insert(rope) => DeltaElement::Insert(rope),
                }
            }
        }

        impl From<RopeDelta_> for Delta<RopeInfo> {
            fn from(mut delta: RopeDelta_) -> Delta<RopeInfo> {
                Delta {
                    els: delta.els.drain(..).map(DeltaElement::from).collect(),
                    base_len: delta.base_len,
                }
            }
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use crate::delta::{self, Delta};
use crate::interval::Interval;
use crate::multiset::{Subset, SubsetBuilder};
use crate::rope::{Rope, RopeInfo};

/// Creates a `Subset` of `s` by scanning through `substr` and finding which
/// characters of `s` are missing from it in order. Returns a `Subset` which
/// when deleted from `s` yields `substr`.
pub fn find_deletions(substr: &str, s: &str) -> Subset {
    let mut sb = SubsetBuilder::new();
    let mut j = 0;
    for i in 0..s.len() {
        if j < substr.len() && substr.as_bytes()[j] == s.as_bytes()[i] {
            j += 1;
        } else {
            sb.add_range(i, i + 1, 1);
        }
    }
    sb.pad_to_len(s.len());
    sb.build()
}

impl Delta<RopeInfo> {
    pub fn apply_to_string(&self, s: &str) -> String {
        String::from(self.apply(&Rope::from(s)))
    }
}

impl PartialEq for Rope {
    fn eq(&self, other: &Rope) -> bool {
        String::from(self) == String::from(other)
    }
}

pub fn parse_subset(s: &str) -> Subset {
    let mut sb = SubsetBuilder::new();

    for c in s.chars() {
        if c == '#' {
            sb.push_segment(1, 1);
        } else if c == 'e' {
            // do nothing, used for empty subsets
        } else {
            sb.push_segment(1, 0);
        }
    }

    sb.build()
}

pub fn parse_subset_list(s: &str) -> Vec<Subset> {
    s.lines().map(|s| s.trim()).filter(|s| !s.is_empty()).map(parse_subset).collect()
}

pub fn debug_subsets(subsets: &[Subset]) {
    for s in subsets {
        println!("{:#?}", s);
    }
}

pub fn parse_delta(s: &str) -> Delta<RopeInfo> {
    let base_len = s.chars().filter(|c| *c == '-' || *c == '!').count();
    let mut b = delta::Builder::new(base_len);

    let mut i = 0;
    for c in s.chars() {
        if c == '-' {
            i += 1;
        } else if c == '!' {
            b.delete(Interval::new(i, i + 1));
            i += 1;
        } else {
            let inserted = format!("{}", c);
            b.replace(Interval::new(i, i), Rope::from(inserted));
        }
    }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Implementation of string finding in ropes.

use std::cmp::min;

use memchr::{memchr, memchr2, memchr3};

use crate::rope::BaseMetric;
use crate::rope::LinesRaw;
use crate::rope::RopeInfo;
use crate::tree::Cursor;
use regex::Regex;
use std::borrow::Cow;
use std::iter::FromIterator;
use std::str;

/// The result of a [`find`][find] operation.
///
/// [find]: fn.find.html
pub enum FindResult {
    /// The pattern was found at this position.
    Found(usize),
    /// The pattern was not found.
    NotFound,
    /// The cursor has been advanced by some amount. The pattern is not
    /// found before the new cursor, but may be at or beyond it.
    TryAgain,
}

/// A policy for case matching. There may be more choices in the future (for
/// example, an even more forgiving mode that ignores accents, or possibly
/// handling Unicode normalization).
#[derive(Clone, Copy, PartialEq)]
pub enum CaseMatching {
    /// Require an exact codepoint-for-codepoint match (implies case sensitivity).
    Exact,
    /// Case insensitive match. Guaranteed to work for the ASCII case, and
    /// reasonably well otherwise (it is currently defined in terms of the
    /// `to_lowercase` methods in the Rust standard library).
    CaseInsensitive,
}

/// Finds a pattern string in the rope referenced by the cursor, starting at
/// the current location of the cursor (and finding the first match). Both
/// case sensitive and case insensitive matching is provided, controlled by
/// the `cm` parameter. The `regex` parameter controls whether the query
/// should be considered as a regular expression.
///
/// On success, the cursor is updated to immediately follow the found string.
/// On failure, the cursor's position is indeterminate.
///
/// Can panic if `pat` is empty.
pub fn find(
    cursor: &mut Cursor<RopeInfo>,
    lines: &mut LinesRaw,
    cm: CaseMatching,
    pat: &str,
    regex: Option<&Regex>,
) -> Option<usize> {
    match find_progress(cursor, lines, cm, pat, usize::max_value(), regex) {
        FindResult::Found(start) => Some(start),
        FindResult::NotFound => None,
        FindResult::TryAgain => unreachable!("find_progress got stuck"),
    }
}

/// A variant of [`find`][find] that makes a bounded amount of progress, then either
/// returns or suspends (returning `TryAgain`).
///
/// The `num_steps` parameter controls the number of "steps" processed per
/// call. The unit of "step" is not formally defined but is typically
/// scanning one leaf (using a memchr-like scan) or testing one candidate
/// when scanning produces a result. It should be empirically tuned for a
/// balance between overhead and impact on interactive performance, but the
/// exact value is probably not critical.
///
/// [find]: fn.find.html
pub fn find_progress(
    cursor: &mut Cursor<RopeInfo>,
    lines: &mut LinesRaw,
    cm: CaseMatching,
    pat: &str,
    num_steps: usize,
    regex: Option<&Regex>,
) -> FindResult {
    // empty search string
    if pat.is_empty() {
        return FindResult::NotFound;
    }

    match regex {
        Some(r) => find_progress_iter(
            cursor,
            lines,
            pat,
            |_| Some(0),
            |cursor, lines, pat| compare_cursor_regex(cursor, lines, pat, &r),
            num_steps,
        ),
        None => {
            match cm {
                CaseMatching::Exact => {
                    let b = pat.as_bytes()[0];
                    let scanner = |s: &str| memchr(b, s.as_bytes());
                    let matcher = compare_cursor_str;
                    find_progress_iter(cursor, lines, pat, scanner, matcher, num_steps)
                }
                CaseMatching::CaseInsensitive => {
                    let pat_lower = pat.to_lowercase();
                    let b = pat_lower.as_bytes()[0];
                    let matcher = compare_cursor_str_casei;
                    if b == b'i' {
                        // 0xC4 is first utf-8 byte of 'İ'
                        let scanner = |s: &str| memchr3(b'i', b'I', 0xC4, s.as_bytes());
                        find_progress_iter(cursor, lines, &pat_lower, scanner, matcher, num_steps)
                    } else if b == b'k' {
                        // 0xE2 is first utf-8 byte of u+212A (kelvin sign)
                        let scanner = |s: &str| memchr3(b'k', b'K', 0xE2, s.as_bytes());
                        find_progress_iter(cursor, lines, &pat_lower, scanner, matcher, num_steps)
                    } else if b >= b'a' && b <= b'z' {
                        let scanner = |s: &str| memchr2(b, b - 0x20, s.as_bytes());
                        find_progress_iter(cursor, lines, &pat_lower, scanner, matcher, num_steps)
                    } else if b < 0x80 {
                        let scanner = |s: &str| memchr(b, s.as_bytes());
                        find_progress_iter(cursor, lines, &pat_lower, scanner, matcher, num_steps)
                    } else {
                        let c = pat.chars().next().unwrap();
                        let scanner = |s: &str| scan_lowercase(c, s);
                        find_progress_iter(cursor, lines, &pat_lower, scanner, matcher, num_steps)
                    }
                }
            }
        }
    }
}

// Run the core repeatedly until there is a result, up to a certain number of steps.
fn find_progress_iter(
    cursor: &mut Cursor<RopeInfo>,
    lines: &mut LinesRaw,
    pat: &str,
    scanner: impl Fn(&str) -> Option<usize>,
    matcher: impl Fn(&mut Cursor<RopeInfo>, &mut LinesRaw, &str) -> Option<usize>,
    num_steps: usize,
) -> FindResult {
    for _ in 0..num_steps {
        match find_core(cursor, lines, pat, &scanner, &matcher) {
            FindResult::TryAgain => (),
            result => return result,
        }
    }
    FindResult::TryAgain
}

// The core of the find algorithm. It takes a "scanner", which quickly
// scans through a single leaf searching for some prefix of the pattern,
// then a "matcher" which confirms that such a candidate actually matches
// in the full rope.
fn find_core(
    cursor: &mut Cursor<RopeInfo>,
    lines: &mut LinesRaw,
    pat: &str,
    scanner: impl Fn(&str) -> Option<usize>,
    matcher: impl Fn(&mut Cursor<RopeInfo>, &mut LinesRaw, &str) -> Option<usize>,
) -> FindResult {
    let orig_pos = cursor.pos();

    // if cursor reached the end of the text then no match has been found
    if orig_pos == cursor.total_len() {
        return FindResult::NotFound;
    }

    if let Some((leaf, pos_in_leaf)) = cursor.get_leaf() {
        if let Some(off) = scanner(&leaf[pos_in_leaf..]) {
            let candidate_pos = orig_pos + off;
            cursor.set(candidate_pos);
            if let Some(actual_pos) = matcher(cursor, lines, pat) {
                return FindResult::Found(actual_pos);
            }
        } else {
            let _ = cursor.next_leaf();
        }

        FindResult::TryAgain
    } else {
        FindResult::NotFound
    }
}

/// Compare whether the substring beginning at the current cursor location
/// is equal to the provided string. Leaves the cursor at an indeterminate
/// position on failure, but the end of the string on success. Returns the
/// start position of the match.
pub fn compare_cursor_str(
    cursor: &mut Cursor<RopeInfo>,
    _lines: &mut LinesRaw,
    mut pat: &str,
) -> Option<usize> {
    let start_position = cursor.pos();
    if pat.is_empty() {
        return Some(start_position);
    }
    let success_pos = cursor.pos() + pat.len();
    while let Some((leaf, pos_in_leaf)) = cursor.get_leaf() {
        let n = min(pat.len(), leaf.len() - pos_in_leaf);
        if leaf.as_bytes()[pos_in_leaf..pos_in_leaf + n] != pat.as_bytes()[..n] {
            cursor.set(start_position);
            cursor.next::<BaseMetric>();
            return None;
        }
        pat = &pat[n..];
        if pat.is_empty() {
            cursor.set(success_pos);
            return Some(start_position);
        }
        let _ = cursor.next_leaf();
    }
    cursor.set(start_position);
    cursor.next::<BaseMetric>();
    None
}

/// Like `compare_cursor_str` but case invariant (using to_lowercase() to
/// normalize both strings before comparison). Returns the start position
/// of the match.
pub fn compare_cursor_str_casei(
    cursor: &mut Cursor<RopeInfo>,
    _lines: &mut LinesRaw,
    pat: &str,
) -> Option<usize> {
    let start_position = cursor.pos();
    let mut pat_iter = pat.chars();
    let mut c = pat_iter.next().unwrap();
    loop {
        if let Some(rope_c) = cursor.next_codepoint() {
            for lc_c in rope_c.to_lowercase() {
                if c != lc_c {
                    cursor.set(start_position);
                    cursor.next::<BaseMetric>();
                    return None;
                }
                if let Some(next_c) = pat_iter.next() {
                    c = next_c;
                } else {
                    return Some(start_position);
                }
            }
        } else {
            // end of string before pattern is complete
            cursor.set(start_position);
            cursor.next::<BaseMetric>();
            return None;
        }
    }
}

/// Compare whether the substring beginning at the cursor location matches
/// the provided regular expression. The substring begins at the beginning
/// of the start of the line.
/// If the regular expression can match multiple lines then the entire text
/// is consumed and matched against the regular expression. Otherwise only
/// the current line is matched. Returns the start position of the match.
pub fn compare_cursor_regex(
    cursor: &mut Cursor<RopeInfo>,
    lines: &mut LinesRaw,
    pat: &str,
    regex: &Regex,
) -> Option<usize> {
    let orig_position = cursor.pos();

    if pat.is_empty() {
        return Some(orig_position);
    }

    let text: Cow<str>;

    if is_multiline_regex(pat) {
        // consume all of the text if regex is multi line matching
        text = Cow::from(String::from_iter(lines));
    } else {
        match lines.next() {
            Some(line) => text = line,
            _ => return None,
        }
    }

    // match regex against text
    match regex.find(&text) {
        Some(mat) => {
            // calculate start position based on where the match starts
            let start_position = orig_position + mat.start();

            // update cursor and set to end of match
            let end_position = orig_position + mat.end();
            cursor.set(end_position);
            Some(start_position)
        }
        None => {
            cursor.set(orig_position + text.len());
            None
        }
    }
}

/// Checks if a regular expression can match multiple lines.
pub fn is_multiline_regex(regex: &str) -> bool {
    // regex characters that match line breaks
    // todo: currently multiline mode is ignored
    let multiline_indicators = vec![r"\n", r"\r", r"[[:space:]]"];

    multiline_indicators.iter().any(|&i| regex.contains(i))
}

/// Scan for a codepoint that, after conversion to lowercase, matches the probe.
fn scan_lowercase(probe: char, s: &str) -> Option<usize> {
    for (i, c) in s.char_indices() {
        if c.to_lowercase().next().unwrap() == probe {
            return Some(i);
        }
    }
    None
}

#[cfg(test)]
mod tests {
    use super::CaseMatching::{CaseInsensitive, Exact};
    use super::*;
    use crate::rope::Rope;
    use crate::tree::Cursor;
    use regex::RegexBuilder;

    const REGEX_SIZE_LIMIT: usize = 1000000;

    #[test]
    fn find_small() {
        let a = Rope::from("Löwe 老虎 Léopard");
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(..);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", None), Some(0));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", None), Some(13));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Léopard", None), Some(13));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Léopard", None), None);
        c.set(0);
        // Note: these two characters both start with 0xE8 in utf-8
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "老虎", None), Some(6));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "老虎", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "虎", None), Some(9));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "虎", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Tiger", None), None);
    }

    #[test]
    fn find_medium() {
        let mut s = String::new();
        for _ in 0..4000 {
            s.push('x');
        }
        s.push_str("Löwe 老虎 Léopard");
        let a = Rope::from(&s);
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", None), Some(4000));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", None), Some(4013));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Léopard", None), Some(4013));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Léopard", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "老虎", None), Some(4006));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "老虎", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "虎", None), Some(4009));
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "虎", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Tiger", None), None);
    }

    #[test]
    fn find_casei_small() {
        let a = Rope::from("Löwe 老虎 Léopard");
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "l", None), Some(0));
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "l", None), Some(13));
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "l", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "léopard", None), Some(13));
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "léopard", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "LÉOPARD", None), Some(13));
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "LÉOPARD", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "老虎", None), Some(6));
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "老虎", None), None);
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "Tiger", None), None);
    }

    #[test]
    fn find_casei_ascii_nonalpha() {
        let a = Rope::from("![cfg(test)]");
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "(test)", None), Some(5));
        c.set(0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "(TEST)", None), Some(5));
    }

    #[test]
    fn find_casei_special() {
        let a = Rope::from("İ");
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "i̇", None), Some(0));

        let a = Rope::from("i̇");
        let mut c = Cursor::new(&a, 0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "İ", None), Some(0));

        let a = Rope::from("\u{212A}");
        let mut c = Cursor::new(&a, 0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "k", None), Some(0));

        let a = Rope::from("k");
        let mut c = Cursor::new(&a, 0);
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "\u{212A}", None), Some(0));
    }

    #[test]
    fn find_casei_0xc4() {
        let a = Rope::from("\u{0100}I");
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "i", None), Some(2));
    }

    #[test]
    fn find_regex_small_casei() {
        let a = Rope::from("Löwe 老虎 Léopard\nSecond line");
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        let regex =
            RegexBuilder::new("L").size_limit(REGEX_SIZE_LIMIT).case_insensitive(true).build().ok();
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "L", regex.as_ref()), Some(0));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "L", regex.as_ref()), Some(13));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "L", regex.as_ref()), Some(29));
        c.set(0);
        let regex = RegexBuilder::new("Léopard")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(
            find(&mut c, &mut raw_lines, CaseInsensitive, "Léopard", regex.as_ref()),
            Some(13)
        );
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "Léopard", regex.as_ref()), None);
        c.set(0);
        let mut raw_lines = a.lines_raw(0..a.len());
        let regex = RegexBuilder::new("老虎")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "老虎", regex.as_ref()), Some(6));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "老虎", regex.as_ref()), None);
        c.set(0);
        let regex = RegexBuilder::new("Tiger")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "Tiger", regex.as_ref()), None);
        c.set(0);
        let regex =
            RegexBuilder::new(".").size_limit(REGEX_SIZE_LIMIT).case_insensitive(true).build().ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, ".", regex.as_ref()), Some(0));
        raw_lines = a.lines_raw(c.pos()..a.len());
        let regex = RegexBuilder::new("\\s")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "\\s", regex.as_ref()), Some(5));
        raw_lines = a.lines_raw(c.pos()..a.len());
        let regex = RegexBuilder::new("\\sLéopard\n.*")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        assert_eq!(
            find(&mut c, &mut raw_lines, CaseInsensitive, "\\sLéopard\n.*", regex.as_ref()),
            Some(12)
        );
    }

    #[test]
    fn find_regex_small() {
        let a = Rope::from("Löwe 老虎 Léopard\nSecond line");
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        let regex = RegexBuilder::new("L")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(false)
            .build()
            .ok();
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", regex.as_ref()), Some(0));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", regex.as_ref()), Some(13));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "L", regex.as_ref()), None);
        c.set(0);
        let regex = RegexBuilder::new("Léopard")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(false)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Léopard", regex.as_ref()), Some(13));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Léopard", regex.as_ref()), None);
        c.set(0);
        let regex = RegexBuilder::new("老虎")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(false)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "老虎", regex.as_ref()), Some(6));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "老虎", regex.as_ref()), None);
        c.set(0);
        let regex = RegexBuilder::new("Tiger")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(false)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "Tiger", regex.as_ref()), None);
        c.set(0);
        let regex = RegexBuilder::new(".")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(false)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, Exact, ".", regex.as_ref()), Some(0));
        raw_lines = a.lines_raw(c.pos()..a.len());
        let regex = RegexBuilder::new("\\s")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(false)
            .build()
            .ok();
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "\\s", regex.as_ref()), Some(5));
        raw_lines = a.lines_raw(c.pos()..a.len());
        let regex = RegexBuilder::new("\\sLéopard\n.*")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(false)
            .build()
            .ok();
        assert_eq!(find(&mut c, &mut raw_lines, Exact, "\\sLéopard\n.*", regex.as_ref()), Some(12));
    }

    #[test]
    fn find_regex_medium() {
        let mut s = String::new();
        for _ in 0..4000 {
            s.push('x');
        }
        s.push_str("Löwe 老虎 Léopard\nSecond line");
        let a = Rope::from(&s);
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        let regex =
            RegexBuilder::new("L").size_limit(REGEX_SIZE_LIMIT).case_insensitive(true).build().ok();
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "L", regex.as_ref()), Some(4000));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "L", regex.as_ref()), Some(4013));
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "L", regex.as_ref()), Some(4029));
        c.set(0);
        let mut raw_lines = a.lines_raw(0..a.len());
        let regex = RegexBuilder::new("Léopard")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        assert_eq!(
            find(&mut c, &mut raw_lines, CaseInsensitive, "Léopard", regex.as_ref()),
            Some(4013)
        );
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "Léopard", regex.as_ref()), None);
        c.set(0);
        let regex = RegexBuilder::new("老虎")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(
            find(&mut c, &mut raw_lines, CaseInsensitive, "老虎", regex.as_ref()),
            Some(4006)
        );
        raw_lines = a.lines_raw(c.pos()..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "老虎", regex.as_ref()), None);
        c.set(0);
        let regex = RegexBuilder::new("Tiger")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        let mut raw_lines = a.lines_raw(0..a.len());
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, "Tiger", regex.as_ref()), None);
        c.set(0);
        let mut raw_lines = a.lines_raw(0..a.len());
        let regex =
            RegexBuilder::new(".").size_limit(REGEX_SIZE_LIMIT).case_insensitive(true).build().ok();
        assert_eq!(find(&mut c, &mut raw_lines, CaseInsensitive, ".", regex.as_ref()), Some(0));
        raw_lines = a.lines_raw(c.pos()..a.len());
        let regex = RegexBuilder::new("\\s")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        assert_eq!(
            find(&mut c, &mut raw_lines, CaseInsensitive, "\\s", regex.as_ref()),
            Some(4005)
        );
        raw_lines = a.lines_raw(c.pos()..a.len());
        let regex = RegexBuilder::new("\\sLéopard\n.*")
            .size_limit(REGEX_SIZE_LIMIT)
            .case_insensitive(true)
            .build()
            .ok();
        assert_eq!(
            find(&mut c, &mut raw_lines, CaseInsensitive, "\\sLéopard\n.*", regex.as_ref()),
            Some(4012)
        );
    }

    #[test]
    fn compare_cursor_regex_singleline() {
        let regex = Regex::new(r"^(\*+)(?: +(.*?))?[ \t]*$").unwrap();
        let rope = Rope::from("** level 2 headline");
        let mut c = Cursor::new(&rope, 0);
        let mut l = rope.lines_raw(c.pos()..rope.len());
        assert!(compare_cursor_regex(&mut c, &mut l, regex.as_str(), &regex).is_some());

        c.set(3);
        l = rope.lines_raw(c.pos()..rope.len());
        assert!(compare_cursor_regex(&mut c, &mut l, regex.as_str(), &regex).is_none());
    }

    #[test]
    fn compare_cursor_regex_multiline() {
        let regex = Regex::new(
            r"^[ \t]*:PROPERTIES:[ \t]*\n(?:[ \t]*:\S+:(?: .*)?[ \t]*\n)*?[ \t]*:END:[ \t]*\n",
        )
        .unwrap();

        // taken from http://doc.norang.ca/org-mode.html#DiaryForAppointments
        let s = "\
                 #+FILETAGS: PERSONAL\
                 \n* Appointments\
                 \n  :PROPERTIES:\
                 \n  :CATEGORY: Appt\
                 \n  :ARCHIVE:  %s_archive::* Appointments\
                 \n  :END:\
                 \n** Holidays\
                 \n   :PROPERTIES:\
                 \n   :Category: Holiday\
                 \n   :END:\
                 \n   %%(org-calendar-holiday)\
                 \n** Some other Appointment\n";
        let rope = Rope::from(s);
        let mut c = Cursor::new(&rope, 0);
        let mut l = rope.lines_raw(c.pos()..rope.len());
        assert!(compare_cursor_regex(&mut c, &mut l, regex.as_str(), &regex).is_none());

        // move to the next line after "* Appointments"
        c.set(36);
        l = rope.lines_raw(c.pos()..rope.len());
        assert!(compare_cursor_regex(&mut c, &mut l, regex.as_str(), &regex).is_some());
        assert_eq!(117, c.pos());
        assert_eq!(Some('*'), c.next_codepoint());

        // move to the next line after "** Holidays"
        c.set(129);
        l = rope.lines_raw(c.pos()..rope.len());
        assert!(compare_cursor_regex(&mut c, &mut l, regex.as_str(), &regex).is_some());
        c.next_codepoint();
        c.next_codepoint();
        c.next_codepoint();
        assert_eq!(Some('%'), c.next_codepoint());
    }

    #[test]
    fn compare_cursor_str_small() {
        let a = Rope::from("Löwe 老虎 Léopard");
        let mut c = Cursor::new(&a, 0);
        let pat = "Löwe 老虎 Léopard";
        let mut raw_lines = a.lines_raw(0..a.len());
        assert!(compare_cursor_str(&mut c, &mut raw_lines, pat).is_some());
        assert_eq!(c.pos(), pat.len());
        c.set(0);
        let pat = "Löwe";
        assert!(compare_cursor_str(&mut c, &mut raw_lines, pat).is_some());
        assert_eq!(c.pos(), pat.len());
        c.set(0);
        // Empty string is valid for compare_cursor_str (but not find)
        let pat = "";
        assert!(compare_cursor_str(&mut c, &mut raw_lines, pat).is_some());
        assert_eq!(c.pos(), pat.len());
        c.set(0);
        assert!(compare_cursor_str(&mut c, &mut raw_lines, "Löwe 老虎 Léopardfoo").is_none());
    }

    #[test]
    fn compare_cursor_str_medium() {
        let mut s = String::new();
        for _ in 0..4000 {
            s.push('x');
        }
        s.push_str("Löwe 老虎 Léopard");
        let a = Rope::from(&s);
        let mut c = Cursor::new(&a, 0);
        let mut raw_lines = a.lines_raw(0..a.len());
        assert!(compare_cursor_str(&mut c, &mut raw_lines, &s).is_some());
        c.set(2000);
        assert!(compare_cursor_str(&mut c, &mut raw_lines, &s[2000..]).is_some());
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#![feature(test)]

extern crate test;
extern crate xi_rope;

use test::Bencher;
use xi_rope::rope::{LinesMetric, Rope};
use xi_rope::tree::*;

fn run_down_rope(text: &Rope) {
    let mut cursor = Cursor::new(&text, 0);

    while cursor.pos() < text.len() - 2 {
        cursor.next::<LinesMetric>();
    }
}

fn build_triangle(n: usize) -> String {
    let mut s = String::new();
    let mut line = String::new();
    for _ in 0..n {
        s += &line;
        s += "\n";
        line += "a";
    }
    s
}

fn build_short_lines(n: usize) -> String {
    let line = "match s.as_bytes()[minsplit - 1..splitpoint].iter().rposition(|&c| c == b'\n') {";
    let mut s = String::new();
    for _ in 0..n {
        s += line;
    }
    s
}

fn build_few_big_lines(size: usize) -> String {
    let mut s = String::with_capacity(size * 10 + 20);
    for _ in 0..10 {
        for _ in 0..size {
            s += "a";
        }
        s += "\n";
    }
    s
}

#[bench]
fn benchmark_triangle(b: &mut Bencher) {
    let text = Rope::from(build_triangle(50_000));
    b.iter(|| run_down_rope(&text));
}

#[bench]
fn benchmark_short_lines(b: &mut Bencher) {
    let text = Rope::from(build_short_lines(1_000_000));
    b.iter(|| run_down_rope(&text));
}

#[bench]
fn benchmark_few_big_lines(b: &mut Bencher) {
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#![feature(test)]

extern crate test;
extern crate xi_rope;

use test::Bencher;
use xi_rope::compare;
use xi_rope::diff::{Diff, LineHashDiff};
use xi_rope::rope::{Rope, RopeDelta};

static EDITOR_STR: &str = include_str!("../../core-lib/src/editor.rs");
static VIEW_STR: &str = include_str!("../../core-lib/src/view.rs");

static INTERVAL_STR: &str = include_str!("../src/interval.rs");
static BREAKS_STR: &str = include_str!("../src/breaks.rs");

static BASE_STR: &str = "This adds FixedSizeAdler32, that has a size set at construction, and keeps bytes in a cyclic buffer of that size to be removed when it fills up.

Current logic (and implementing Write) might be too much, since bytes will probably always be fed one by one anyway. Otherwise a faster way of removing a sequence might be needed (one by one is inefficient).";

static TARG_STR: &str = "This adds some function, I guess?, that has a size set at construction, and keeps bytes in a cyclic buffer of that size to be ground up and injested when it fills up.

Currently my sense of smell (and the pain of implementing Write) might be too much, since bytes will probably always be fed one by one anyway. Otherwise crying might be needed (one by one is inefficient).";

fn make_test_data() -> (Vec<u8>, Vec<u8>) {
    let one = [EDITOR_STR, VIEW_STR, INTERVAL_STR, BREAKS_STR].concat().into_bytes();
    let mut two = one.clone();
    let idx = one.len() / 2;
    two[idx] = 0x02;
    (one, two)
}

#[bench]
fn ne_idx_sw(b: &mut Bencher) {
    let (one, two) = make_test_data();

    b.iter(|| {
        compare::ne_idx_fallback(&one, &one);
        compare::ne_idx_fallback(&one, &two);
    })
}

#[bench]
#[cfg(target_arch = "x86_64")]
fn ne_idx_sse(b: &mut Bencher) {
    if !is_x86_feature_detected!("sse4.2") {
        return;
    }
    let (one, two) = make_test_data();

    let mut x = 0;
    b.iter(|| {
        x += unsafe { compare::ne_idx_sse(&one, &one).unwrap_or_default() };
        x += unsafe { compare::ne_idx_sse(&one, &two).unwrap_or_default() };
    })
}

#[bench]
#[cfg(target_arch = "x86_64")]
fn ne_idx_avx(b: &mut Bencher) {
    if !is_x86_feature_detected!("avx2") {
        return;
    }
    let (one, two) = make_test_data();

    let mut dont_opt_me = 0;
    b.iter(|| {
        dont_opt_me += unsafe { compare::ne_idx_avx(&one, &two).unwrap_or_default() };
        dont_opt_me += unsafe { compare::ne_idx_avx(&one, &one).unwrap_or_default() };
    })
}

#[bench]
fn ne_idx_detect(b: &mut Bencher) {
    let (one, two) = make_test_data();

    let mut dont_opt_me = 0;
    b.iter(|| {
        dont_opt_me += compare::ne_idx(&one, &two).unwrap_or_default();
        dont_opt_me += compare::ne_idx(&one, &one).unwrap_or_default();
    })
}

#[bench]
fn ne_idx_rev_sw(b: &mut Bencher) {
    let (one, two) = make_test_data();

    let mut x = 0;
    b.iter(|| {
        x += compare::ne_idx_rev_fallback(&one, &one).unwrap_or_default();
        x += compare::ne_idx_rev_fallback(&one, &two).unwrap_or_default();
    })
}

#[bench]
#[cfg(target_arch = "x86_64")]
fn ne_idx_rev_sse(b: &mut Bencher) {
    if !is_x86_feature_detected!("sse4.2") {
        return;
    }
    let (one, two) = make_test_data();

    b.iter(|| unsafe {
        compare::ne_idx_rev_sse(&one, &one);
        compare::ne_idx_rev_sse(&one, &two);
    })
}

#[bench]
fn scanner(b: &mut Bencher) {
    let (one, two) = make_test_data();
    let one = Rope::from(String::from_utf8(one).unwrap());
    let two = Rope::from(String::from_utf8(two).unwrap());

    let mut scanner = compare::RopeScanner::new(&one, &two);
    b.iter(|| {
        scanner.find_ne_char(0, 0, None);
        scanner.find_ne_char_back(one.len(), two.len(), None);
    })
}

#[bench]
fn hash_diff(b: &mut Bencher) {
    let one = BASE_STR.into();
    let two = TARG_STR.into();
    let mut delta: Option<RopeDelta> = None;
    b.iter(|| {
        delta = Some(LineHashDiff::compute_delta(&one, &two));
    });

    let _result = delta.unwrap().apply(&one);
    assert_eq!(String::from(_result), String::from(&two));
}

#[bench]
fn hash_diff_med(b: &mut Bencher) {
    let one = INTERVAL_STR.into();
    let two = BREAKS_STR.into();
    let mut delta: Option<RopeDelta> = None;
    b.iter(|| {
        delta = Some(LineHashDiff::compute_delta(&one, &two));
    });

    let _result = delta.unwrap().apply(&one);
    assert_eq!(String::from(_result), String::from(&two));
}

#[bench]
fn hash_diff_big(b: &mut Bencher) {
    let one = EDITOR_STR.into();
    let two = VIEW_STR.into();
    let mut delta: Option<RopeDelta> = None;
    b.iter(|| {
        delta = Some(LineHashDiff::compute_delta(&one, &two));
    });

    let _result = delta.unwrap().apply(&one);
    assert_eq!(String::from(_result), String::from(&two));
}

#[bench]
fn simple_insertion(b: &mut Bencher) {
    let one: Rope =
        ["start", EDITOR_STR, VIEW_STR, INTERVAL_STR, BREAKS_STR, "end"].concat().into();
    let two = "startend".into();
    let mut delta: Option<RopeDelta> = None;
    b.iter(|| {
        delta = Some(LineHashDiff::compute_delta(&one, &two));
    });

    let _result = delta.unwrap().apply(&one);
    assert_eq!(String::from(_result), String::from(&two));
}

#[bench]
fn simple_deletion(b: &mut Bencher) {
    let one: Rope =
        ["start", EDITOR_STR, VIEW_STR, INTERVAL_STR, BREAKS_STR, "end"].concat().into();
    let two = "startend".into();
    let mut delta: Option<RopeDelta> = None;
    b.iter(|| {
        delta = Some(LineHashDiff::compute_delta(&two, &one));
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#![feature(test)]

extern crate test;
extern crate xi_rope;

use test::Bencher;
use xi_rope::rope::Rope;

fn build_triangle(n: usize) -> String {
    let mut s = String::new();
    let mut line = String::new();
    for _ in 0..n {
        s += &line;
        s += "\n";
        line += "a";
    }
    s
}

fn build_short_lines(n: usize) -> String {
    let line = "match s.as_bytes()[minsplit - 1..splitpoint].iter().rposition(|&c| c == b'\n') {";
    let mut s = String::new();
    for _ in 0..n {
        s += line;
    }
    s
}

fn build_few_big_lines(size: usize) -> String {
    let mut s = String::with_capacity(size * 10 + 20);
    for _ in 0..10 {
        for _ in 0..size {
            s += "a";
        }
        s += "\n";
    }
    s
}

#[bench]
fn benchmark_file_load_short_lines(b: &mut Bencher) {
    let text = build_short_lines(50_000);
    b.iter(|| {
        Rope::from(&text);
    });
}

#[bench]
fn benchmark_file_load_few_big_lines(b: &mut Bencher) {
    let text = build_few_big_lines(1_000_000);
    b.iter(|| {
        Rope::from(&text);
    });
}

#[bench]
fn benchmark_char_insertion_one_line_edit(b: &mut Bencher) {
    let mut text = Rope::from("b".repeat(100));
    let mut offset = 100;
    b.iter(|| {
        text.edit(offset..=offset, "a");
        offset += 1;
    });
}

#[bench]
fn benchmark_paste_into_line(b: &mut Bencher) {
    let mut text = Rope::from(build_short_lines(50_000));
    let insertion = "a".repeat(50);
    let mut offset = 100;
    b.iter(|| {
        text.edit(offset..=offset, &insertion);
        offset += 150;
    });
}

#[bench]
fn benchmark_insert_newline(b: &mut Bencher) {
    let mut text = Rope::from(build_few_big_lines(1_000_000));
    let mut offset = 1000;
    b.iter(|| {
        text.edit(offset..=offset, "\n");
        offset += 1001;
    });
}

#[bench]
fn benchmark_overwrite_into_line(b: &mut Bencher) {
    let mut text = Rope::from(build_short_lines(50_000));
    let mut offset = 100;
    let insertion = "a".repeat(50);
    b.iter(|| {
        // TODO: if the method runs too quickly, this may generate a fault
        // since there's an upper limit to how many times this can run.
        text.edit(offset..=offset + 20, &insertion);
        offset += 30;
    });
}

#[bench]
fn benchmark_triangle_concat_inplace(b: &mut Bencher) {
    let mut text = Rope::from("");
    let insertion = build_triangle(3000);
    let insertion_len = insertion.len();
    let mut offset = 0;
    b.iter(|| {
        text.edit(offset..=offset, &insertion);
        offset += insertion_len;
    });
}

#[bench]
fn real_world_editing_scenario(b: &mut Bencher) {
    b.iter(|| {
        let mut text = Rope::default();
        let mut cursor = 0;
        for i in 1..10_000 {
            let s = if i % 80 == 0 { "\n" } else { "a" };
            text.edit(cursor..cursor, s);
            if i % 123 == 0 {
                // periodically do some deletes
                text.edit(cursor - 5..cursor, "");
            }

            // periodically move cursor:
            cursor = match i {
                1000 => 200,
                2000 => 1800,
                3000 => 1000,
                4000 => text.len() - 1,
                5000 => 404,
                6000 => 4444,
                7000 => 6990,
                8000 => 6990,
                9000 => 100,
                n if n % 123 == 0 => cursor - 5, // the delete case
                _ => cursor + 1,
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#![cfg_attr(feature = "benchmarks", feature(test))]
#![allow(clippy::identity_op, clippy::new_without_default, clippy::trivially_copy_pass_by_ref)]

#[macro_use]
extern crate lazy_static;
extern crate time;

#[macro_use]
extern crate serde_derive;

extern crate serde;

#[macro_use]
extern crate log;

extern crate libc;

#[cfg(feature = "benchmarks")]
extern crate test;

#[cfg(any(test, feature = "json_payload", feature = "chroma_trace_dump"))]
#[cfg_attr(any(test), macro_use)]
extern crate serde_json;

mod fixed_lifo_deque;
mod sys_pid;
mod sys_tid;

#[cfg(feature = "chrome_trace_event")]
pub mod chrome_trace_dump;

use crate::fixed_lifo_deque::FixedLifoDeque;
use std::borrow::Cow;
use std::cmp;
use std::collections::HashMap;
use std::fmt;
use std::fs;
use std::hash::{Hash, Hasher};
use std::mem::size_of;
use std::path::Path;
use std::string::ToString;
use std::sync::atomic::{AtomicBool, Ordering as AtomicOrdering};
use std::sync::Mutex;

pub type StrCow = Cow<'static, str>;

#[derive(Clone, Debug)]
pub enum CategoriesT {
    StaticArray(&'static [&'static str]),
    DynamicArray(Vec<String>),
}

trait StringArrayEq<Rhs: ?Sized = Self> {
    fn arr_eq(&self, other: &Rhs) -> bool;
}

impl StringArrayEq<[&'static str]> for Vec<String> {
    fn arr_eq(&self, other: &[&'static str]) -> bool {
        if self.len() != other.len() {
            return false;
        }

        for i in 0..self.len() {
            if self[i] != other[i] {
                return false;
            }
        }
        true
    }
}

impl StringArrayEq<Vec<String>> for &'static [&'static str] {
    fn arr_eq(&self, other: &Vec<String>) -> bool {
        if self.len() != other.len() {
            return false;
        }
        for i in 0..self.len() {
            if self[i] != other[i] {
                return false;
            }
        }
        true
    }
}

impl PartialEq for CategoriesT {
    fn eq(&self, other: &CategoriesT) -> bool {
        match *self {
            CategoriesT::StaticArray(ref self_arr) => match *other {
                CategoriesT::StaticArray(ref other_arr) => self_arr.eq(other_arr),
                CategoriesT::DynamicArray(ref other_arr) => self_arr.arr_eq(other_arr),
            },
            CategoriesT::DynamicArray(ref self_arr) => match *other {
                CategoriesT::StaticArray(ref other_arr) => self_arr.arr_eq(other_arr),
                CategoriesT::DynamicArray(ref other_arr) => self_arr.eq(other_arr),
            },
        }
    }
}

impl Eq for CategoriesT {}

impl serde::Serialize for CategoriesT {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        self.join(",").serialize(serializer)
    }
}

impl<'de> serde::Deserialize<'de> for CategoriesT {
    fn deserialize<D>(deserializer: D) -> Result<CategoriesT, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        use serde::de::Visitor;
        struct CategoriesTVisitor;

        impl<'de> Visitor<'de> for CategoriesTVisitor {
            type Value = CategoriesT;

            fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {
                formatter.write_str("comma-separated strings")
            }

            fn visit_str<E>(self, v: &str) -> Result<CategoriesT, E>
            where
                E: serde::de::Error,
            {
                let categories = v.split(',').map(ToString::to_string).collect();
                Ok(CategoriesT::DynamicArray(categories))
            }
        }

        deserializer.deserialize_str(CategoriesTVisitor)
    }
}

impl CategoriesT {
    pub fn join(&self, sep: &str) -> String {
        match *self {
            CategoriesT::StaticArray(ref arr) => arr.join(sep),
            CategoriesT::DynamicArray(ref vec) => vec.join(sep),
        }
    }
}

macro_rules! categories_from_constant_array {
    ($num_args: expr) => {
        impl From<&'static [&'static str; $num_args]> for CategoriesT {
            fn from(c: &'static [&'static str; $num_args]) -> CategoriesT {
                CategoriesT::StaticArray(c)
            }
        }
    };
}

categories_from_constant_array!(0);
categories_from_constant_array!(1);
categories_from_constant_array!(2);
categories_from_constant_array!(3);
categories_from_constant_array!(4);
categories_from_constant_array!(5);
categories_from_constant_array!(6);
categories_from_constant_array!(7);
categories_from_constant_array!(8);
categories_from_constant_array!(9);
categories_from_constant_array!(10);

impl From<Vec<String>> for CategoriesT {
    fn from(c: Vec<String>) -> CategoriesT {
        CategoriesT::DynamicArray(c)
    }
}

#[cfg(not(feature = "json_payload"))]
pub type TracePayloadT = StrCow;

#[cfg(feature = "json_payload")]
pub type TracePayloadT = serde_json::Value;

/// How tracing should be configured.
#[derive(Copy, Clone)]
pub struct Config {
    sample_limit_count: usize,
}

impl Config {
    /// The maximum number of bytes the tracing data should take up.  This limit
    /// won't be exceeded by the underlying storage itself (i.e. rounds down).
    pub fn with_limit_bytes(size: usize) -> Self {
        Self::with_limit_count(size / size_of::<Sample>())
    }

    /// The maximum number of entries the tracing data should allow.  Total
    /// storage allocated will be limit * size_of<Sample>
    pub fn with_limit_count(limit: usize) -> Self {
        Self { sample_limit_count: limit }
    }

    /// The default amount of storage to allocate for tracing.  Currently 1 MB.
    pub fn default() -> Self {
        // 1 MB
        Self::with_limit_bytes(1 * 1024 * 1024)
    }

    /// The maximum amount of space the tracing data will take up.  This does
    /// not account for any overhead of storing the data itself (i.e. pointer to
    /// the heap, counters, etc); just the data itself.
    pub fn max_size_in_bytes(self) -> usize {
        self.sample_limit_count * size_of::<Sample>()
    }

    /// The maximum number of samples that should be stored.
    pub fn max_samples(self) -> usize {
        self.sample_limit_count
    }
}

#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum SampleEventType {
    DurationBegin,
    DurationEnd,
    CompleteDuration,
    Instant,
    AsyncStart,
    AsyncInstant,
    AsyncEnd,
    FlowStart,
    FlowInstant,
    FlowEnd,
    ObjectCreated,
    ObjectSnapshot,
    ObjectDestroyed,
    Metadata,
}

impl SampleEventType {
    // TODO(vlovich): Replace all of this with serde flatten + rename once
    // https://github.com/serde-rs/serde/issues/1189 is fixed.
    #[inline]
    fn into_chrome_id(self) -> char {
        match self {
            SampleEventType::DurationBegin => 'B',
            SampleEventType::DurationEnd => 'E',
            SampleEventType::CompleteDuration => 'X',
            SampleEventType::Instant => 'i',
            SampleEventType::AsyncStart => 'b',
            SampleEventType::AsyncInstant => 'n',
            SampleEventType::AsyncEnd => 'e',
            SampleEventType::FlowStart => 's',
            SampleEventType::FlowInstant => 't',
            SampleEventType::FlowEnd => 'f',
            SampleEventType::ObjectCreated => 'N',
            SampleEventType::ObjectSnapshot => 'O',
            SampleEventType::ObjectDestroyed => 'D',
            SampleEventType::Metadata => 'M',
        }
    }

    #[inline]
    fn from_chrome_id(symbol: char) -> Self {
        match symbol {
            'B' => SampleEventType::DurationBegin,
            'E' => SampleEventType::DurationEnd,
            'X' => SampleEventType::CompleteDuration,
            'i' => SampleEventType::Instant,
            'b' => SampleEventType::AsyncStart,
            'n' => SampleEventType::AsyncInstant,
            'e' => SampleEventType::AsyncEnd,
            's' => SampleEventType::FlowStart,
            't' => SampleEventType::FlowInstant,
            'f' => SampleEventType::FlowEnd,
            'N' => SampleEventType::ObjectCreated,
            'O' => SampleEventType::ObjectSnapshot,
            'D' => SampleEventType::ObjectDestroyed,
            'M' => SampleEventType::Metadata,
            _ => panic!("Unexpected chrome sample type '{}'", symbol),
        }
    }
}

#[derive(Clone, Debug, PartialEq, Eq)]
enum MetadataType {
    ProcessName {
        name: String,
    },
    #[allow(dead_code)]
    ProcessLabels {
        labels: String,
    },
    #[allow(dead_code)]
    ProcessSortIndex {
        sort_index: i32,
    },
    ThreadName {
        name: String,
    },
    #[allow(dead_code)]
    ThreadSortIndex {
        sort_index: i32,
    },
}

impl MetadataType {
    fn sample_name(&self) -> &'static str {
        match *self {
            MetadataType::ProcessName { .. } => "process_name",
            MetadataType::ProcessLabels { .. } => "process_labels",
            MetadataType::ProcessSortIndex { .. } => "process_sort_index",
            MetadataType::ThreadName { .. } => "thread_name",
            MetadataType::ThreadSortIndex { .. } => "thread_sort_index",
        }
    }

    fn consume(self) -> (Option<String>, Option<i32>) {
        match self {
            MetadataType::ProcessName { name } => (Some(name), None),
            MetadataType::ThreadName { name } => (Some(name), None),
            MetadataType::ProcessSortIndex { sort_index } => (None, Some(sort_index)),
            MetadataType::ThreadSortIndex { sort_index } => (None, Some(sort_index)),
            MetadataType::ProcessLabels { .. } => (None, None),
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct SampleArgs {
    /// An arbitrary payload to associate with the sample.  The type is
    /// controlled by features (default string).
    #[serde(rename = "xi_payload")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub payload: Option<TracePayloadT>,

    /// The name to associate with the pid/tid.  Whether it's associated with
    /// the pid or the tid depends on the name of the event
    /// via process_name/thread_name respectively.
    #[serde(rename = "name")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub metadata_name: Option<StrCow>,

    /// Sorting priority between processes/threads in the view.
    #[serde(rename = "sort_index")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub metadata_sort_index: Option<i32>,
}

#[inline]
fn ns_to_us(ns: u64) -> u64 {
    ns / 1000
}

//NOTE: serde requires this to take a reference
fn serialize_event_type<S>(ph: &SampleEventType, s: S) -> Result<S::Ok, S::Error>
where
    S: serde::Serializer,
{
    s.serialize_char(ph.into_chrome_id())
}

fn deserialize_event_type<'de, D>(d: D) -> Result<SampleEventType, D::Error>
where
    D: serde::Deserializer<'de>,
{
    serde::Deserialize::deserialize(d).map(SampleEventType::from_chrome_id)
}

/// Stores the relevant data about a sample for later serialization.
/// The payload associated with any sample is by default a string but may be
/// configured via the `json_payload` feature (there is an
/// associated performance hit across the board for turning it on).
#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Sample {
    /// The name of the event to be shown.
    pub name: StrCow,
    /// List of categories the event applies to.
    #[serde(rename = "cat")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub categories: Option<CategoriesT>,
    /// When was the sample started.
    #[serde(rename = "ts")]
    pub timestamp_us: u64,
    /// What kind of sample this is.
    #[serde(rename = "ph")]
    #[serde(serialize_with = "serialize_event_type")]
    #[serde(deserialize_with = "deserialize_event_type")]
    pub event_type: SampleEventType,
    #[serde(rename = "dur")]
    #[serde(skip_serializing_if = "Option::is_none")]
    pub duration_us: Option<u64>,
    /// The process the sample was captured in.
    pub pid: u64,
    /// The thread the sample was captured on.  Omitted for Metadata events that
    /// want to set the process name (if provided then sets the thread name).
    pub tid: u64,
    #[serde(skip_serializing)]
    pub thread_name: Option<StrCow>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub args: Option<SampleArgs>,
}

fn to_cow_str<S>(s: S) -> StrCow
where
    S: Into<StrCow>,
{
    s.into()
}

impl Sample {
    fn thread_name() -> Option<StrCow> {
        let thread = std::thread::current();
        thread.name().map(|ref s| to_cow_str((*s).to_string()))
    }

    /// Constructs a Begin or End sample.  Should not be used directly.  Instead
    /// should be constructed via SampleGuard.
    pub fn new_duration_marker<S, C>(
        name: S,
        categories: C,
        payload: Option<TracePayloadT>,
        event_type: SampleEventType,
    ) -> Self
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
    {
        Self {
            name: name.into(),
            categories: Some(categories.into()),
            timestamp_us: ns_to_us(time::precise_time_ns()),
            event_type,
            duration_us: None,
            tid: sys_tid::current_tid().unwrap(),
            thread_name: Sample::thread_name(),
            pid: sys_pid::current_pid(),
            args: Some(SampleArgs { payload, metadata_name: None, metadata_sort_index: None }),
        }
    }

    /// Constructs a Duration sample.  For use via xi_trace::closure.
    pub fn new_duration<S, C>(
        name: S,
        categories: C,
        payload: Option<TracePayloadT>,
        start_ns: u64,
        duration_ns: u64,
    ) -> Self
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
    {
        Self {
            name: name.into(),
            categories: Some(categories.into()),
            timestamp_us: ns_to_us(start_ns),
            event_type: SampleEventType::CompleteDuration,
            duration_us: Some(ns_to_us(duration_ns)),
            tid: sys_tid::current_tid().unwrap(),
            thread_name: Sample::thread_name(),
            pid: sys_pid::current_pid(),
            args: Some(SampleArgs { payload, metadata_name: None, metadata_sort_index: None }),
        }
    }

    /// Constructs an instantaneous sample.
    pub fn new_instant<S, C>(name: S, categories: C, payload: Option<TracePayloadT>) -> Self
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
    {
        Self {
            name: name.into(),
            categories: Some(categories.into()),
            timestamp_us: ns_to_us(time::precise_time_ns()),
            event_type: SampleEventType::Instant,
            duration_us: None,
            tid: sys_tid::current_tid().unwrap(),
            thread_name: Sample::thread_name(),
            pid: sys_pid::current_pid(),
            args: Some(SampleArgs { payload, metadata_name: None, metadata_sort_index: None }),
        }
    }

    fn new_metadata(timestamp_ns: u64, meta: MetadataType, tid: u64) -> Self {
        let sample_name = to_cow_str(meta.sample_name());
        let (metadata_name, sort_index) = meta.consume();

        Self {
            name: sample_name,
            categories: None,
            timestamp_us: ns_to_us(timestamp_ns),
            event_type: SampleEventType::Metadata,
            duration_us: None,
            tid,
            thread_name: None,
            pid: sys_pid::current_pid(),
            args: Some(SampleArgs {
                payload: None,
                metadata_name: metadata_name.map(Cow::Owned),
                metadata_sort_index: sort_index,
            }),
        }
    }
}

impl PartialEq for Sample {
    fn eq(&self, other: &Sample) -> bool {
        self.timestamp_us == other.timestamp_us
            && self.name == other.name
            && self.categories == other.categories
            && self.pid == other.pid
            && self.tid == other.tid
            && self.event_type == other.event_type
            && self.args == other.args
    }
}

impl Eq for Sample {}

impl PartialOrd for Sample {
    fn partial_cmp(&self, other: &Sample) -> Option<cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for Sample {
    fn cmp(&self, other: &Sample) -> cmp::Ordering {
        self.timestamp_us.cmp(&other.timestamp_us)
    }
}

impl Hash for Sample {
    fn hash<H: Hasher>(&self, state: &mut H) {
        (self.pid, self.timestamp_us).hash(state);
    }
}

#[must_use]
pub struct SampleGuard<'a> {
    sample: Option<Sample>,
    trace: Option<&'a Trace>,
}

impl<'a> SampleGuard<'a> {
    #[inline]
    pub fn new_disabled() -> Self {
        Self { sample: None, trace: None }
    }

    #[inline]
    fn new<S, C>(trace: &'a Trace, name: S, categories: C, payload: Option<TracePayloadT>) -> Self
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
    {
        // TODO(vlovich): optimize this path to use the Complete event type
        // rather than emitting an explicit start/stop to reduce the size of
        // the generated JSON.
        let guard = Self {
            sample: Some(Sample::new_duration_marker(
                name,
                categories,
                payload,
                SampleEventType::DurationBegin,
            )),
            trace: Some(&trace),
        };
        trace.record(guard.sample.as_ref().unwrap().clone());
        guard
    }
}

impl<'a> Drop for SampleGuard<'a> {
    fn drop(&mut self) {
        if let Some(ref mut trace) = self.trace {
            let mut sample = self.sample.take().unwrap();
            sample.timestamp_us = ns_to_us(time::precise_time_ns());
            sample.event_type = SampleEventType::DurationEnd;
            trace.record(sample);
        }
    }
}

/// Returns the file name of the EXE if possible, otherwise the full path, or
/// None if an irrecoverable error occured.
fn exe_name() -> Option<String> {
    match std::env::current_exe() {
        Ok(exe_name) => match exe_name.file_name() {
            Some(filename) => filename.to_str().map(ToString::to_string),
            None => {
                let full_path = exe_name.into_os_string();
                let full_path_str = full_path.into_string();
                match full_path_str {
                    Ok(s) => Some(s),
                    Err(e) => {
                        warn!("Failed to get string representation: {:?}", e);
                        None
                    }
                }
            }
        },
        Err(ref e) => {
            warn!("Failed to get path to current exe: {:?}", e);
            None
        }
    }
}

/// Stores the tracing data.
pub struct Trace {
    enabled: AtomicBool,
    samples: Mutex<FixedLifoDeque<Sample>>,
}

impl Trace {
    pub fn disabled() -> Self {
        Self { enabled: AtomicBool::new(false), samples: Mutex::new(FixedLifoDeque::new()) }
    }

    pub fn enabled(config: Config) -> Self {
        Self {
            enabled: AtomicBool::new(true),
            samples: Mutex::new(FixedLifoDeque::with_limit(config.max_samples())),
        }
    }

    pub fn disable(&self) {
        let mut all_samples = self.samples.lock().unwrap();
        all_samples.reset_limit(0);
        self.enabled.store(false, AtomicOrdering::Relaxed);
    }

    #[inline]
    pub fn enable(&self) {
        self.enable_config(Config::default());
    }

    pub fn enable_config(&self, config: Config) {
        let mut all_samples = self.samples.lock().unwrap();
        all_samples.reset_limit(config.max_samples());
        self.enabled.store(true, AtomicOrdering::Relaxed);
    }

    /// Generally racy since the underlying storage might be mutated in a separate thread.
    /// Exposed for unit tests.
    pub fn get_samples_count(&self) -> usize {
        self.samples.lock().unwrap().len()
    }

    /// Exposed for unit tests only.
    pub fn get_samples_limit(&self) -> usize {
        self.samples.lock().unwrap().limit()
    }

    #[inline]
    pub(crate) fn record(&self, sample: Sample) {
        let mut all_samples = self.samples.lock().unwrap();
        all_samples.push_back(sample);
    }

    pub fn is_enabled(&self) -> bool {
        self.enabled.load(AtomicOrdering::Relaxed)
    }

    pub fn instant<S, C>(&self, name: S, categories: C)
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
    {
        if self.is_enabled() {
            self.record(Sample::new_instant(name, categories, None));
        }
    }

    pub fn instant_payload<S, C, P>(&self, name: S, categories: C, payload: P)
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
        P: Into<TracePayloadT>,
    {
        if self.is_enabled() {
            self.record(Sample::new_instant(name, categories, Some(payload.into())));
        }
    }

    pub fn block<S, C>(&self, name: S, categories: C) -> SampleGuard
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
    {
        if !self.is_enabled() {
            SampleGuard::new_disabled()
        } else {
            SampleGuard::new(&self, name, categories, None)
        }
    }

    pub fn block_payload<S, C, P>(&self, name: S, categories: C, payload: P) -> SampleGuard
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
        P: Into<TracePayloadT>,
    {
        if !self.is_enabled() {
            SampleGuard::new_disabled()
        } else {
            SampleGuard::new(&self, name, categories, Some(payload.into()))
        }
    }

    pub fn closure<S, C, F, R>(&self, name: S, categories: C, closure: F) -> R
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
        F: FnOnce() -> R,
    {
        // TODO: simplify this through the use of scopeguard crate
        let start = time::precise_time_ns();
        let result = closure();
        let end = time::precise_time_ns();
        if self.is_enabled() {
            self.record(Sample::new_duration(name, categories, None, start, end - start));
        }
        result
    }

    pub fn closure_payload<S, C, P, F, R>(
        &self,
        name: S,
        categories: C,
        closure: F,
        payload: P,
    ) -> R
    where
        S: Into<StrCow>,
        C: Into<CategoriesT>,
        P: Into<TracePayloadT>,
        F: FnOnce() -> R,
    {
        // TODO: simplify this through the use of scopeguard crate
        let start = time::precise_time_ns();
        let result = closure();
        let end = time::precise_time_ns();
        if self.is_enabled() {
            self.record(Sample::new_duration(
                name,
                categories,
                Some(payload.into()),
                start,
                end - start,
            ));
        }
        result
    }

    pub fn samples_cloned_unsorted(&self) -> Vec<Sample> {
        let all_samples = self.samples.lock().unwrap();
        if all_samples.is_empty() {
            return Vec::with_capacity(0);
        }

        let mut as_vec = Vec::with_capacity(all_samples.len() + 10);
        let first_sample_timestamp = all_samples.front().map_or(0, |ref s| s.timestamp_us);
        let tid =
            all_samples.front().map_or_else(|| sys_tid::current_tid().unwrap(), |ref s| s.tid);

        if let Some(exe_name) = exe_name() {
            as_vec.push(Sample::new_metadata(
                first_sample_timestamp,
                MetadataType::ProcessName { name: exe_name },
                tid,
            ));
        }

        let mut thread_names: HashMap<u64, StrCow> = HashMap::new();

        for sample in all_samples.iter() {
            if let Some(ref thread_name) = sample.thread_name {
                let previous_name = thread_names.insert(sample.tid, thread_name.clone());
                if previous_name.is_none() || previous_name.unwrap() != *thread_name {
                    as_vec.push(Sample::new_metadata(
                        first_sample_timestamp,
                        MetadataType::ThreadName { name: thread_name.to_string() },
                        sample.tid,
                    ));
                }
            }
        }

        as_vec.extend(all_samples.iter().cloned());
        as_vec
    }

    #[inline]
    pub fn samples_cloned_sorted(&self) -> Vec<Sample> {
        let mut samples = self.samples_cloned_unsorted();
        samples.sort_unstable();
        samples
    }

    pub fn save<P: AsRef<Path>>(
        &self,
        path: P,
        sort: bool,
    ) -> Result<(), chrome_trace_dump::Error> {
        let traces = if sort { samples_cloned_sorted() } else { samples_cloned_unsorted() };
        let path: &Path = path.as_ref();

        if path.exists() {
            return Err(chrome_trace_dump::Error::already_exists());
        }

        let mut trace_file = fs::File::create(&path)?;

        chrome_trace_dump::serialize(&traces, &mut trace_file)
    }
}

lazy_static! {
    static ref TRACE: Trace = Trace::disabled();
}

/// Enable tracing with the default configuration.  See Config::default.
/// Tracing is disabled initially on program launch.
#[inline]
pub fn enable_tracing() {
    TRACE.enable();
}

/// Enable tracing with a specific configuration. Tracing is disabled initially
/// on program launch.
#[inline]
pub fn enable_tracing_with_config(config: Config) {
    TRACE.enable_config(config);
}

/// Disable tracing.  This clears all trace data (& frees the memory).
#[inline]
pub fn disable_tracing() {
    TRACE.disable();
}

/// Is tracing enabled.  Technically doesn't guarantee any samples will be
/// stored as tracing could still be enabled but set with a limit of 0.
#[inline]
pub fn is_enabled() -> bool {
    TRACE.is_enabled()
}

/// Create an instantaneous sample without any payload.  This is the lowest
/// overhead tracing routine available.
///
/// # Performance
/// The `json_payload` feature makes this ~1.3-~1.5x slower.
/// See `trace_payload` for a more complete discussion.
///
/// # Arguments
///
/// * `name` - A string that provides some meaningful name to this sample.
/// Usage of static strings is encouraged for best performance to avoid copies.
/// However, anything that can be converted into a Cow string can be passed as
/// an argument.
///
/// * `categories` - A static array of static strings that tags the samples in
/// some way.
///
/// # Examples
///
/// ```
/// xi_trace::trace("something happened", &["rpc", "response"]);
/// ```
#[inline]
pub fn trace<S, C>(name: S, categories: C)
where
    S: Into<StrCow>,
    C: Into<CategoriesT>,
{
    TRACE.instant(name, categories);
}

/// Create an instantaneous sample with a payload.  The type the payload
/// conforms to is currently determined by the feature this library is compiled
/// with.  By default, the type is string-like just like name.  If compiled with
/// the `json_payload` then a `serde_json::Value` is expected and  the library
/// acquires a dependency on the `serde_json` crate.
///
/// # Performance
/// A static string has the lowest overhead as no copies are necessary, roughly
/// equivalent performance to a regular trace.  A string that needs to be copied
/// first can make it ~1.7x slower than a regular trace.
///
/// When compiling with `json_payload`, this is ~2.1x slower than a string that
/// needs to be copied (or ~4.5x slower than a static string)
///
/// # Arguments
///
/// * `name` - A string that provides some meaningful name to this sample.
/// Usage of static strings is encouraged for best performance to avoid copies.
/// However, anything that can be converted into a Cow string can be passed as
/// an argument.
///
/// * `categories` - A static array of static strings that tags the samples in
/// some way.
///
/// # Examples
///
/// ```
/// xi_trace::trace_payload("something happened", &["rpc", "response"], "a note about this");
/// ```
///
/// With `json_payload` feature:
///
/// ```rust,ignore
/// xi_trace::trace_payload("my event", &["rpc", "response"], json!({"key": "value"}));
/// ```
#[inline]
pub fn trace_payload<S, C, P>(name: S, categories: C, payload: P)
where
    S: Into<StrCow>,
    C: Into<CategoriesT>,
    P: Into<TracePayloadT>,
{
    TRACE.instant_payload(name, categories, payload);
}

/// Creates a duration sample.  The sample is finalized (end_ns set) when the
/// returned value is dropped.  `trace_closure` may be prettier to read.
///
/// # Performance
/// See `trace_payload` for a more complete discussion.
///
/// # Arguments
///
/// * `name` - A string that provides some meaningful name to this sample.
/// Usage of static strings is encouraged for best performance to avoid copies.
/// However, anything that can be converted into a Cow string can be passed as
/// an argument.
///
/// * `categories` - A static array of static strings that tags the samples in
/// some way.
///
/// # Returns
/// A guard that when dropped will update the Sample with the timestamp & then
/// record it.
///
/// # Examples
///
/// ```
/// fn something_expensive() {
/// }
///
/// fn something_else_expensive() {
/// }
///
/// let trace_guard = xi_trace::trace_block("something_expensive", &["rpc", "request"]);
/// something_expensive();
/// std::mem::drop(trace_guard); // finalize explicitly if
///
/// {
///     let _guard = xi_trace::trace_block("something_else_expensive", &["rpc", "response"]);
///     something_else_expensive();
/// }
/// ```
#[inline]
pub fn trace_block<'a, S, C>(name: S, categories: C) -> SampleGuard<'a>
where
    S: Into<StrCow>,
    C: Into<CategoriesT>,
{
    TRACE.block(name, categories)
}

/// See `trace_block` for how the block works and `trace_payload` for a
/// discussion on payload.
#[inline]
pub fn trace_block_payload<'a, S, C, P>(name: S, categories: C, payload: P) -> SampleGuard<'a>
where
    S: Into<StrCow>,
    C: Into<CategoriesT>,
    P: Into<TracePayloadT>,
{
    TRACE.block_payload(name, categories, payload)
}

/// Creates a duration sample that measures how long the closure took to execute.
///
/// # Performance
/// See `trace_payload` for a more complete discussion.
///
/// # Arguments
///
/// * `name` - A string that provides some meaningful name to this sample.
/// Usage of static strings is encouraged for best performance to avoid copies.
/// However, anything that can be converted into a Cow string can be passed as
/// an argument.
///
/// * `categories` - A static array of static strings that tags the samples in
/// some way.
///
/// # Returns
/// The result of the closure.
///
/// # Examples
///
/// ```
/// fn something_expensive() -> u32 {
///     0
/// }
///
/// fn something_else_expensive(value: u32) {
/// }
///
/// let result = xi_trace::trace_closure("something_expensive", &["rpc", "request"], || {
///     something_expensive()
/// });
/// xi_trace::trace_closure("something_else_expensive", &["rpc", "response"], || {
///     something_else_expensive(result);
/// });
/// ```
#[inline]
pub fn trace_closure<S, C, F, R>(name: S, categories: C, closure: F) -> R
where
    S: Into<StrCow>,
    C: Into<CategoriesT>,
    F: FnOnce() -> R,
{
    TRACE.closure(name, categories, closure)
}

/// See `trace_closure` for how the closure works and `trace_payload` for a
/// discussion on payload.
#[inline]
pub fn trace_closure_payload<S, C, P, F, R>(name: S, categories: C, closure: F, payload: P) -> R
where
    S: Into<StrCow>,
    C: Into<CategoriesT>,
    P: Into<TracePayloadT>,
    F: FnOnce() -> R,
{
    TRACE.closure_payload(name, categories, closure, payload)
}

#[inline]
pub fn samples_len() -> usize {
    TRACE.get_samples_count()
}

/// Returns all the samples collected so far.  There is no guarantee that the
/// samples are ordered chronologically for several reasons:
///
/// 1. Samples that span sections of code may be inserted on end instead of
/// beginning.
/// 2. Performance optimizations might have per-thread buffers.  Keeping all
/// that sorted would be prohibitively expensive.
/// 3. You may not care about them always being sorted if you're merging samples
/// from multiple distributed sources (i.e. you want to sort the merged result
/// rather than just this processe's samples).
#[inline]
pub fn samples_cloned_unsorted() -> Vec<Sample> {
    TRACE.samples_cloned_unsorted()
}

/// Returns all the samples collected so far ordered chronologically by
/// creation.  Roughly corresponds to start_ns but instead there's a
/// monotonically increasing single global integer (when tracing) per creation
/// of Sample that determines order.
#[inline]
pub fn samples_cloned_sorted() -> Vec<Sample> {
    TRACE.samples_cloned_sorted()
}

/// Save tracing data to to supplied path, using the Trace Viewer format. Trace file can be opened
/// using the Chrome browser by visiting the URL `about:tracing`. If `sorted_chronologically` is
/// true then sort output traces chronologically by each trace's time of creation.
#[inline]
pub fn save<P: AsRef<Path>>(path: P, sort: bool) -> Result<(), chrome_trace_dump::Error> {
    TRACE.save(path, sort)
}

#[cfg(test)]
#[rustfmt::skip]
mod tests {
    use super::*;
    #[cfg(feature = "benchmarks")]
    use test::Bencher;
    #[cfg(feature = "benchmarks")]
    use test::black_box;

    #[cfg(not(feature = "json_payload"))]
    fn to_payload(value: &'static str) -> &'static str {
        value
    }

    #[cfg(feature = "json_payload")]
    fn to_payload(value: &'static str) -> TracePayloadT {
        json!({"test": value})
    }

    #[test]
    fn test_samples_pulse() {
        let trace = Trace::enabled(Config::with_limit_count(10));
        for _i in 0..50 {
            trace.instant("test_samples_pulse", &["test"]);
        }
    }

    #[test]
    fn test_samples_block() {
        let trace = Trace::enabled(Config::with_limit_count(10));
        for _i in 0..50 {
            let _ = trace.block("test_samples_block", &["test"]);
        }
    }

    #[test]
    fn test_samples_closure() {
        let trace = Trace::enabled(Config::with_limit_count(10));
        for _i in 0..50 {
            trace.closure("test_samples_closure", &["test"], || {});
        }
    }

    #[test]
    fn test_disable_drops_all_samples() {
        let trace = Trace::enabled(Config::with_limit_count(10));
        assert_eq!(trace.is_enabled(), true);
        trace.instant("1", &["test"]);
        trace.instant("2", &["test"]);
        trace.instant("3", &["test"]);
        trace.instant("4", &["test"]);
        trace.instant("5", &["test"]);
        assert_eq!(trace.get_samples_count(), 5);
        // 1 for exe name & 1 for the thread name
        assert_eq!(trace.samples_cloned_unsorted().len(), 7);
        trace.disable();
        assert_eq!(trace.get_samples_count(), 0);
    }

    #[test]
    fn test_get_samples() {
        let trace = Trace::enabled(Config::with_limit_count(20));
        assert_eq!(trace.samples_cloned_unsorted().len(), 0);

        assert_eq!(trace.is_enabled(), true);
        assert_eq!(trace.get_samples_limit(), 20);
        assert_eq!(trace.samples_cloned_unsorted().len(), 0);

        trace.closure_payload("x", &["test"], || (),
                              to_payload("test_get_samples"));
        assert_eq!(trace.get_samples_count(), 1);
        // +2 for exe & thread name.
        assert_eq!(trace.samples_cloned_unsorted().len(), 3);

        trace.closure_payload("y", &["test"], || {},
                              to_payload("test_get_samples"));
        assert_eq!(trace.samples_cloned_unsorted().len(), 4);

        trace.closure_payload("z", &["test"], || {},
                              to_payload("test_get_samples"));

        let snapshot = trace.samples_cloned_unsorted();
        assert_eq!(snapshot.len(), 5);

        assert_eq!(snapshot[0].name, "process_name");
        assert_eq!(snapshot[0].args.as_ref().unwrap().metadata_name.as_ref().is_some(), true);
        assert_eq!(snapshot[1].name, "thread_name");
        assert_eq!(snapshot[1].args.as_ref().unwrap().metadata_name.as_ref().is_some(), true);
        assert_eq!(snapshot[2].name, "x");
        assert_eq!(snapshot[3].name, "y");
        assert_eq!(snapshot[4].name, "z");
    }

    #[test]
    fn test_trace_disabled() {
        let trace = Trace::disabled();
        assert_eq!(trace.get_samples_limit(), 0);
        assert_eq!(trace.get_samples_count(), 0);

        {
            trace.instant("something", &[]);
            let _x = trace.block("something", &[]);
            trace.closure("something", &[], || ());
        }

        assert_eq!(trace.get_samples_count(), 0);
    }

    #[test]
    fn test_get_samples_nested_trace() {
        let trace = Trace::enabled(Config::with_limit_count(11));
        assert_eq!(trace.is_enabled(), true);
        assert_eq!(trace.get_samples_limit(), 11);

        // current recording mechanism should see:
        // a, b, y, z, c, x
        // even though the actual sampling order (from timestamp of
        // creation) is:
        // x, a, y, b, z, c
        // This might be an over-specified test as it will
        // probably change as the recording internals change.
        trace.closure_payload("x", &["test"], || {
            trace.instant_payload("a", &["test"], to_payload("test_get_samples_nested_trace"));
            trace.closure_payload("y", &["test"], || {
                trace.instant_payload("b", &["test"], to_payload("test_get_samples_nested_trace"));
            }, to_payload("test_get_samples_nested_trace"));
            let _ = trace.block_payload("z", &["test"], to_payload("test_get_samples_nested_trace"));
            trace.instant_payload("c", &["test"], to_payload("test_get_samples_nested_trace"));
        }, to_payload("test_get_samples_nested_trace"));

        let snapshot = trace.samples_cloned_unsorted();
        // +2 for exe & thread name
        assert_eq!(snapshot.len(), 9);

        assert_eq!(snapshot[0].name, "process_name");
        assert_eq!(snapshot[0].args.as_ref().unwrap().metadata_name.as_ref().is_some(), true);
        assert_eq!(snapshot[1].name, "thread_name");
        assert_eq!(snapshot[1].args.as_ref().unwrap().metadata_name.as_ref().is_some(), true);
        assert_eq!(snapshot[2].name, "a");
        assert_eq!(snapshot[3].name, "b");
        assert_eq!(snapshot[4].name, "y");
        assert_eq!(snapshot[5].name, "z");
        assert_eq!(snapshot[6].name, "z");
        assert_eq!(snapshot[7].name, "c");
        assert_eq!(snapshot[8].name, "x");
    }

    #[test]
    fn test_get_sorted_samples() {
        let trace = Trace::enabled(Config::with_limit_count(10));

        // current recording mechanism should see:
        // a, b, y, z, c, x
        // even though the actual sampling order (from timestamp of
        // creation) is:
        // x, a, y, b, z, c
        // This might be an over-specified test as it will
        // probably change as the recording internals change.

        // NOTE: 1 us sleeps are inserted as the first line of a closure to
        // ensure that when the samples are sorted by time they come out in a
        // stable order since the resolution of timestamps is 1us.
        // NOTE 2: from_micros is currently in unstable so using new
        trace.closure_payload("x", &["test"], || {
            std::thread::sleep(std::time::Duration::new(0, 1000));
            trace.instant_payload("a", &["test"], to_payload("test_get_sorted_samples"));
            trace.closure_payload("y", &["test"], || {
                std::thread::sleep(std::time::Duration::new(0, 1000));
                trace.instant_payload("b", &["test"], to_payload("test_get_sorted_samples"));
            }, to_payload("test_get_sorted_samples"));
            let _ = trace.block_payload("z", &["test"], to_payload("test_get_sorted_samples"));
            trace.instant("c", &["test"]);
        }, to_payload("test_get_sorted_samples"));

        let snapshot = trace.samples_cloned_sorted();
        // +2 for exe & thread name.
        assert_eq!(snapshot.len(), 9);

        assert_eq!(snapshot[0].name, "process_name");
        assert_eq!(snapshot[0].args.as_ref().unwrap().metadata_name.as_ref().is_some(), true);
        assert_eq!(snapshot[1].name, "thread_name");
        assert_eq!(snapshot[1].args.as_ref().unwrap().metadata_name.as_ref().is_some(), true);
        assert_eq!(snapshot[2].name, "x");
        assert_eq!(snapshot[3].name, "a");
        assert_eq!(snapshot[4].name, "y");
        assert_eq!(snapshot[5].name, "b");
        assert_eq!(snapshot[6].name, "z");
        assert_eq!(snapshot[7].name, "z");
        assert_eq!(snapshot[8].name, "c");
    }

    #[test]
    fn test_cross_process_samples() {
        let mut samples = vec![
            Sample::new_instant("local pid", &[], None),
            Sample::new_instant("remote pid", &[], None)];
        samples[0].pid = 1;
        samples[0].timestamp_us = 10;

        samples[1].pid = 2;
        samples[1].timestamp_us = 5;

        samples.sort();

        assert_eq!(samples[0].name, "remote pid");
        assert_eq!(samples[1].name, "local pid");
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_instant_disabled(b: &mut Bencher) {
        let trace = Trace::disabled();

        b.iter(|| black_box(trace.instant("nothing", &["benchmark"])));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_instant(b: &mut Bencher) {
        let trace = Trace::enabled(Config::default());
        b.iter(|| black_box(trace.instant("something", &["benchmark"])));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_instant_with_payload(b: &mut Bencher) {
        let trace = Trace::enabled(Config::default());
        b.iter(|| black_box(trace.instant_payload(
            "something", &["benchmark"],
            to_payload("some description of the trace"))));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_block_disabled(b: &mut Bencher) {
        let trace = Trace::disabled();
        b.iter(|| black_box(trace.block("something", &["benchmark"])));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_block(b: &mut Bencher) {
        let trace = Trace::enabled(Config::default());
        b.iter(|| black_box(trace.block("something", &["benchmark"])));
    }


    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_block_payload(b: &mut Bencher) {
        let trace = Trace::enabled(Config::default());
        b.iter(|| {
            black_box(|| {
                let _ = trace.block_payload(
                    "something", &["benchmark"],
                    to_payload("some payload for the block"));
            });
        });
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_closure_disabled(b: &mut Bencher) {
        let trace = Trace::disabled();

        b.iter(|| black_box(trace.closure("something", &["benchmark"], || {})));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_closure(b: &mut Bencher) {
        let trace = Trace::enabled(Config::default());
        b.iter(|| black_box(trace.closure("something", &["benchmark"], || {})));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_trace_closure_payload(b: &mut Bencher) {
        let trace = Trace::enabled(Config::default());
        b.iter(|| black_box(trace.closure_payload(
                    "something", &["benchmark"], || {},
                    to_payload("some description of the closure"))));
    }

    // this is the cost contributed by the timestamp to trace()
    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_single_timestamp(b: &mut Bencher) {
        b.iter(|| black_box(time::precise_time_ns()));
    }

    // this is the cost contributed by the timestamp to
    // trace_block()/trace_closure
    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_two_timestamps(b: &mut Bencher) {
        b.iter(|| {
            black_box(time::precise_time_ns());
            black_box(time::precise_time_ns());
        });
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_get_tid(b: &mut Bencher) {
        b.iter(|| black_box(sys_tid::current_tid()));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_get_pid(b: &mut Bencher) {
        b.iter(|| sys_pid::current_pid());
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::cmp::{self, Ordering};
use std::collections::vec_deque::{Drain, IntoIter, Iter, IterMut, VecDeque};
use std::hash::{Hash, Hasher};
use std::ops::{Index, IndexMut, RangeBounds};

/// Provides fixed size ring buffer that overwrites elements in FIFO order on
/// insertion when full.  API provided is similar to VecDeque & uses a VecDeque
/// internally. One distinction is that only append-like insertion is allowed.
/// This means that insert & push_front are not allowed.  The reasoning is that
/// there is ambiguity on how such functions should operate since it would be
/// pretty impossible to maintain a FIFO ordering.
///
/// All operations that would cause growth beyond the limit drop the appropriate
/// number of elements from the front.  For example, on a full buffer push_front
/// replaces the first element.
///
/// The removal of elements on operation that would cause excess beyond the
/// limit happens first to make sure the space is available in the underlying
/// VecDeque, thus guaranteeing O(1) operations always.
#[derive(Clone, Debug)]
pub struct FixedLifoDeque<T> {
    storage: VecDeque<T>,
    limit: usize,
}

impl<T> FixedLifoDeque<T> {
    /// Constructs a ring buffer that will reject all insertions as no-ops.
    /// This also construct the underlying VecDeque with_capacity(0) which
    /// in the current stdlib implementation allocates 2 Ts.
    #[inline]
    pub fn new() -> Self {
        FixedLifoDeque::with_limit(0)
    }

    /// Constructs a fixed size ring buffer with the given number of elements.
    /// Attempts to insert more than this number of elements will cause excess
    /// elements to first be evicted in FIFO order (i.e. from the front).
    pub fn with_limit(n: usize) -> Self {
        FixedLifoDeque { storage: VecDeque::with_capacity(n), limit: n }
    }

    /// This sets a new limit on the container.  Excess elements are dropped in
    /// FIFO order.  The new capacity is reset to the requested limit which will
    /// likely result in re-allocation + copies/clones even if the limit
    /// shrinks.
    pub fn reset_limit(&mut self, n: usize) {
        if n < self.limit {
            let overflow = self.limit - n;
            self.drop_excess_for_inserting(overflow);
        }
        self.limit = n;
        self.storage.reserve_exact(n);
        self.storage.shrink_to_fit();
        debug_assert!(self.storage.len() <= self.limit);
    }

    /// Returns the current limit this ring buffer is configured with.
    #[inline]
    pub fn limit(&self) -> usize {
        self.limit
    }

    #[inline]
    pub fn get(&self, index: usize) -> Option<&T> {
        self.storage.get(index)
    }

    #[inline]
    pub fn get_mut(&mut self, index: usize) -> Option<&mut T> {
        self.storage.get_mut(index)
    }

    #[inline]
    pub fn swap(&mut self, i: usize, j: usize) {
        self.storage.swap(i, j);
    }

    #[inline]
    pub fn capacity(&self) -> usize {
        self.limit
    }

    #[inline]
    pub fn iter(&self) -> Iter<T> {
        self.storage.iter()
    }

    #[inline]
    pub fn iter_mut(&mut self) -> IterMut<T> {
        self.storage.iter_mut()
    }

    /// Returns a tuple of 2 slices that represents the ring buffer. [0] is the
    /// beginning of the buffer to the physical end of the array or the last
    /// element (whichever comes first).  [1] is the continuation of [0] if the
    /// ring buffer has wrapped the contiguous storage.
    #[inline]
    pub fn as_slices(&self) -> (&[T], &[T]) {
        self.storage.as_slices()
    }

    #[inline]
    pub fn as_mut_slices(&mut self) -> (&mut [T], &mut [T]) {
        self.storage.as_mut_slices()
    }

    #[inline]
    pub fn len(&self) -> usize {
        self.storage.len()
    }

    #[inline]
    pub fn is_empty(&self) -> bool {
        self.storage.is_empty()
    }

    #[inline]
    pub fn drain<R>(&mut self, range: R) -> Drain<T>
    where
        R: RangeBounds<usize>,
    {
        self.storage.drain(range)
    }

    #[inline]
    pub fn clear(&mut self) {
        self.storage.clear();
    }

    #[inline]
    pub fn contains(&self, x: &T) -> bool
    where
        T: PartialEq<T>,
    {
        self.storage.contains(x)
    }

    #[inline]
    pub fn front(&self) -> Option<&T> {
        self.storage.front()
    }

    #[inline]
    pub fn front_mut(&mut self) -> Option<&mut T> {
        self.storage.front_mut()
    }

    #[inline]
    pub fn back(&self) -> Option<&T> {
        self.storage.back()
    }

    #[inline]
    pub fn back_mut(&mut self) -> Option<&mut T> {
        self.storage.back_mut()
    }

    #[inline]
    fn drop_excess_for_inserting(&mut self, n_to_be_inserted: usize) {
        if self.storage.len() + n_to_be_inserted > self.limit {
            let overflow =
                self.storage.len().min(self.storage.len() + n_to_be_inserted - self.limit);
            self.storage.drain(..overflow);
        }
    }

    /// Always an O(1) operation.  Memory is never reclaimed.
    #[inline]
    pub fn pop_front(&mut self) -> Option<T> {
        self.storage.pop_front()
    }

    /// Always an O(1) operation.  If the number of elements is at the limit,
    /// the element at the front is overwritten.
    ///
    /// Post condition: The number of elements is <= limit
    pub fn push_back(&mut self, value: T) {
        self.drop_excess_for_inserting(1);
        self.storage.push_back(value);
        // For when limit == 0
        self.drop_excess_for_inserting(0);
    }

    /// Always an O(1) operation.  Memory is never reclaimed.
    #[inline]
    pub fn pop_back(&mut self) -> Option<T> {
        self.storage.pop_back()
    }

    #[inline]
    pub fn swap_remove_back(&mut self, index: usize) -> Option<T> {
        self.storage.swap_remove_back(index)
    }

    #[inline]
    pub fn swap_remove_front(&mut self, index: usize) -> Option<T> {
        self.storage.swap_remove_front(index)
    }

    /// Always an O(1) operation.
    #[inline]
    pub fn remove(&mut self, index: usize) -> Option<T> {
        self.storage.remove(index)
    }

    pub fn split_off(&mut self, at: usize) -> FixedLifoDeque<T> {
        FixedLifoDeque { storage: self.storage.split_off(at), limit: self.limit }
    }

    /// Always an O(m) operation where m is the length of `other'.
    pub fn append(&mut self, other: &mut VecDeque<T>) {
        self.drop_excess_for_inserting(other.len());
        self.storage.append(other);
        // For when limit == 0
        self.drop_excess_for_inserting(0);
    }

    #[inline]
    pub fn retain<F>(&mut self, f: F)
    where
        F: FnMut(&T) -> bool,
    {
        self.storage.retain(f);
    }
}

impl<T: Clone> FixedLifoDeque<T> {
    /// Resizes a fixed queue.  This doesn't change the limit so the resize is
    /// capped to the limit.  Additionally, resizing drops the elements from the
    /// front unlike with a regular VecDeque.
    pub fn resize(&mut self, new_len: usize, value: T) {
        if new_len < self.len() {
            let to_drop = self.len() - new_len;
            self.storage.drain(..to_drop);
        } else {
            self.storage.resize(cmp::min(self.limit, new_len), value);
        }
    }
}

impl<A: PartialEq> PartialEq for FixedLifoDeque<A> {
    #[inline]
    fn eq(&self, other: &FixedLifoDeque<A>) -> bool {
        self.storage == other.storage
    }
}

impl<A: Eq> Eq for FixedLifoDeque<A> {}

impl<A: PartialOrd> PartialOrd for FixedLifoDeque<A> {
    #[inline]
    fn partial_cmp(&self, other: &FixedLifoDeque<A>) -> Option<Ordering> {
        self.storage.partial_cmp(&other.storage)
    }
}

impl<A: Ord> Ord for FixedLifoDeque<A> {
    #[inline]
    fn cmp(&self, other: &FixedLifoDeque<A>) -> Ordering {
        self.storage.cmp(&other.storage)
    }
}

impl<A: Hash> Hash for FixedLifoDeque<A> {
    #[inline]
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.storage.hash(state);
    }
}

impl<A> Index<usize> for FixedLifoDeque<A> {
    type Output = A;

    #[inline]
    fn index(&self, index: usize) -> &A {
        &self.storage[index]
    }
}

impl<A> IndexMut<usize> for FixedLifoDeque<A> {
    #[inline]
    fn index_mut(&mut self, index: usize) -> &mut A {
        &mut self.storage[index]
    }
}

impl<T> IntoIterator for FixedLifoDeque<T> {
    type Item = T;
    type IntoIter = IntoIter<T>;

    /// Consumes the list into a front-to-back iterator yielding elements by
    /// value.
    #[inline]
    fn into_iter(self) -> IntoIter<T> {
        self.storage.into_iter()
    }
}

impl<'a, T> IntoIterator for &'a FixedLifoDeque<T> {
    type Item = &'a T;
    type IntoIter = Iter<'a, T>;

    #[inline]
    fn into_iter(self) -> Iter<'a, T> {
        self.storage.iter()
    }
}

impl<'a, T> IntoIterator for &'a mut FixedLifoDeque<T> {
    type Item = &'a mut T;
    type IntoIter = IterMut<'a, T>;

    #[inline]
    fn into_iter(self) -> IterMut<'a, T> {
        self.storage.iter_mut()
    }
}

impl<A> Extend<A> for FixedLifoDeque<A> {
    fn extend<T: IntoIterator<Item = A>>(&mut self, iter: T) {
        for elt in iter {
            self.push_back(elt);
        }
    }
}

impl<'a, T: 'a + Copy> Extend<&'a T> for FixedLifoDeque<T> {
    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {
        self.extend(iter.into_iter().cloned());
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    #[cfg(feature = "benchmarks")]
    use test::Bencher;

    #[test]
    fn test_basic_insertions() {
        let mut tester = FixedLifoDeque::with_limit(3);
        assert_eq!(tester.len(), 0);
        assert_eq!(tester.capacity(), 3);
        assert_eq!(tester.front(), None);
        assert_eq!(tester.back(), None);

        tester.push_back(1);
        assert_eq!(tester.len(), 1);
        assert_eq!(tester.front(), Some(1).as_ref());
        assert_eq!(tester.back(), Some(1).as_ref());

        tester.push_back(2);
        assert_eq!(tester.len(), 2);
        assert_eq!(tester.front(), Some(1).as_ref());
        assert_eq!(tester.back(), Some(2).as_ref());

        tester.push_back(3);
        tester.push_back(4);
        assert_eq!(tester.len(), 3);
        assert_eq!(tester.front(), Some(2).as_ref());
        assert_eq!(tester.back(), Some(4).as_ref());
        assert_eq!(tester[0], 2);
        assert_eq!(tester[1], 3);
        assert_eq!(tester[2], 4);
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_push_back(b: &mut Bencher) {
        let mut q = FixedLifoDeque::with_limit(10);
        b.iter(|| q.push_back(5));
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_deletion_from_empty(b: &mut Bencher) {
        let mut q = FixedLifoDeque::<u32>::with_limit(10000);
        b.iter(|| q.pop_front());
    }

    #[cfg(feature = "benchmarks")]
    #[bench]
    fn bench_deletion_from_non_empty(b: &mut Bencher) {
        let mut q = FixedLifoDeque::with_limit(1000000);
        for i in 0..q.limit() {
            q.push_back(i);
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#![allow(
    clippy::if_same_then_else,
    clippy::needless_bool,
    clippy::needless_pass_by_value,
    clippy::ptr_arg
)]

#[cfg(all(test, feature = "benchmarks"))]
extern crate test;

use std::io::{Error as IOError, ErrorKind as IOErrorKind, Read, Write};

use super::Sample;

#[derive(Debug)]
pub enum Error {
    Io(IOError),
    Json(serde_json::Error),
    DecodingFormat(String),
}

impl From<IOError> for Error {
    fn from(e: IOError) -> Error {
        Error::Io(e)
    }
}

impl From<serde_json::Error> for Error {
    fn from(e: serde_json::Error) -> Error {
        Error::Json(e)
    }
}

impl From<String> for Error {
    fn from(e: String) -> Error {
        Error::DecodingFormat(e)
    }
}

impl Error {
    pub fn already_exists() -> Error {
        Error::Io(IOError::from(IOErrorKind::AlreadyExists))
    }
}

#[derive(Clone, Debug, Deserialize)]
#[serde(untagged)]
enum ChromeTraceArrayEntries {
    Array(Vec<Sample>),
}

/// This serializes the samples into the [Chrome trace event format](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwiJlZmDguXYAhUD4GMKHVmEDqIQFggpMAA&url=https%3A%2F%2Fdocs.google.com%2Fdocument%2Fd%2F1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU%2Fpreview&usg=AOvVaw0tBFlVbDVBikdzLqgrWK3g).
///
/// # Arguments
/// `samples` - Something that can be converted into an iterator of sample
/// references.
/// `format` - Which trace format to save the data in.  There are four total
/// formats described in the document.
/// `output` - Where to write the serialized result.
///
/// # Returns
/// A `Result<(), Error>` that indicates if serialization was successful or the
/// details of any error that occured.
///
/// # Examples
/// ```norun
/// let samples = xi_trace::samples_cloned_sorted();
/// let mut serialized = Vec::<u8>::new();
/// serialize(samples.iter(), serialized);
/// ```
pub fn serialize<W>(samples: &Vec<Sample>, output: W) -> Result<(), Error>
where
    W: Write,
{
    serde_json::to_writer(output, samples).map_err(Error::Json)
}

pub fn to_value(samples: &Vec<Sample>) -> Result<serde_json::Value, Error> {
    serde_json::to_value(samples).map_err(Error::Json)
}

pub fn decode(samples: serde_json::Value) -> Result<Vec<Sample>, Error> {
    serde_json::from_value(samples).map_err(Error::Json)
}

pub fn deserialize<R>(input: R) -> Result<Vec<Sample>, Error>
where
    R: Read,
{
    serde_json::from_reader(input).map_err(Error::Json)
}

#[cfg(test)]
mod tests {
    use super::*;
    #[cfg(feature = "json_payload")]
    use crate::TracePayloadT;
    #[cfg(feature = "benchmarks")]
    use test::Bencher;

    #[cfg(not(feature = "json_payload"))]
    fn to_payload(value: &'static str) -> &'static str {
        value
    }

    #[cfg(feature = "json_payload")]
    fn to_payload(value: &'static str) -> TracePayloadT {
        json!({ "test": value })
    }

    #[cfg(feature = "chrome_trace_event")]
    #[test]
    fn test_chrome_trace_serialization() {
        use super::super::*;

        let trace = Trace::enabled(Config::with_limit_count(10));
        trace.instant("sample1", &["test", "chrome"]);
        trace.instant_payload("sample2", &["test", "chrome"], to_payload("payload 2"));
        trace.instant_payload("sample3", &["test", "chrome"], to_payload("payload 3"));
        trace.closure_payload(
            "sample4",
            &["test", "chrome"],
            || {
                let _guard = trace.block("sample5", &["test,chrome"]);
            },
            to_payload("payload 4"),
        );

        let samples = trace.samples_cloned_unsorted();

        let mut serialized = Vec::<u8>::new();

        let result = serialize(&samples, &mut serialized);
        assert!(result.is_ok(), "{:?}", result);

        let decoded_result: Vec<serde_json::Value> = serde_json::from_slice(&serialized).unwrap();
        assert_eq!(decoded_result.len(), 8);
        assert_eq!(decoded_result[0]["name"].as_str().unwrap(), "process_name");
        assert_eq!(decoded_result[1]["name"].as_str().unwrap(), "thread_name");
        for i in 2..5 {
            assert_eq!(decoded_result[i]["name"].as_str().unwrap(), samples[i].name);
            assert_eq!(decoded_result[i]["cat"].as_str().unwrap(), "test,chrome");
            assert_eq!(decoded_result[i]["ph"].as_str().unwrap(), "i");
            assert_eq!(decoded_result[i]["ts"], samples[i].timestamp_us);
            let nth_sample = &samples[i];
            let nth_args = nth_sample.args.as_ref().unwrap();
            assert_eq!(decoded_result[i]["args"]["xi_payload"], json!(nth_args.payload.as_ref()));
        }
        assert_eq!(decoded_result[5]["ph"], "B");
        assert_eq!(decoded_result[6]["ph"], "E");
        assert_eq!(decoded_result[7]["ph"], "X");
    }

    #[cfg(feature = "chrome_trace_event")]
    #[test]
    fn test_chrome_trace_deserialization() {
        use super::super::*;

        let trace = Trace::enabled(Config::with_limit_count(10));
        trace.instant("sample1", &["test", "chrome"]);
        trace.instant_payload("sample2", &["test", "chrome"], to_payload("payload 2"));
        trace.instant_payload("sample3", &["test", "chrome"], to_payload("payload 3"));
        trace.closure_payload("sample4", &["test", "chrome"], || (), to_payload("payload 4"));

        let samples = trace.samples_cloned_unsorted();

        let mut serialized = Vec::<u8>::new();
        let result = serialize(&samples, &mut serialized);
        assert!(result.is_ok(), "{:?}", result);

        let deserialized_samples = deserialize(serialized.as_slice()).unwrap();
        assert_eq!(deserialized_samples, samples);
    }

    #[cfg(all(feature = "chrome_trace_event", feature = "benchmarks"))]
    #[bench]
    fn bench_chrome_trace_serialization_one_element(b: &mut Bencher) {
        use super::*;

        let mut serialized = Vec::<u8>::new();
        let samples = vec![super::Sample::new_instant("trace1", &["benchmark", "test"], None)];
        b.iter(|| {
            serialized.clear();
            serialize(&samples, &mut serialized).unwrap();
        });
    }

    #[cfg(all(feature = "chrome_trace_event", feature = "benchmarks"))]
    #[bench]
    fn bench_chrome_trace_serialization_multiple_elements(b: &mut Bencher) {
        use super::super::*;
        use super::*;

        let mut serialized = Vec::<u8>::new();
        let samples = vec![
            Sample::new_instant("trace1", &["benchmark", "test"], None),
            Sample::new_instant("trace2", &["benchmark"], None),
            Sample::new_duration("trace3", &["benchmark"], Some(to_payload("some payload")), 0, 0),
            Sample::new_instant("trace4", &["benchmark"], None),
        ];

        b.iter(|| {
            serialized.clear();
            serialize(&samples, &mut serialized).unwrap();
        });
    }
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#[cfg(all(target_family = "unix", not(target_os = "fuchsia")))]
#[inline]
pub fn current_pid() -> u64 {
    extern "C" {
        fn getpid() -> libc::pid_t;
    }

    unsafe { getpid() as u64 }
}

#[cfg(target_os = "fuchsia")]
pub fn current_pid() -> u64 {
    // TODO: implement for fuchsia (does getpid work?)
    0
}

#[cfg(target_family = "windows")]
#[inline]
pub fn current_pid() -> u64 {
    extern "C" {
        fn GetCurrentProcessId() -> libc::c_ulong;
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#[cfg(any(target_os = "macos", target_os = "ios"))]
#[inline]
pub fn current_tid() -> Result<u64, libc::c_int> {
    #[link(name = "pthread")]
    extern "C" {
        fn pthread_threadid_np(thread: libc::pthread_t, thread_id: *mut u64) -> libc::c_int;
    }

    unsafe {
        let mut tid = 0;
        let err = pthread_threadid_np(0, &mut tid);
        match err {
            0 => Ok(tid),
            _ => Err(err),
        }
    }
}

#[cfg(target_os = "fuchsia")]
#[inline]
pub fn current_tid() -> Result<u64, libc::c_int> {
    // TODO: fill in for fuchsia.  This is the native C API but maybe there are
    // rust-specific bindings already.
    /*
    extern {
        fn thrd_get_zx_handle(thread: thrd_t) -> zx_handle_t;
        fn thrd_current() -> thrd_t;
    }

    Ok(thrd_get_zx_handle(thrd_current()) as u64)
    */
    Ok(0)
}

#[cfg(any(target_os = "linux", target_os = "android"))]
#[inline]
pub fn current_tid() -> Result<u64, libc::c_int> {
    unsafe { Ok(libc::syscall(libc::SYS_gettid) as u64) }
}

// TODO: maybe use https://github.com/alexcrichton/cfg-if to simplify this?
// pthread-based fallback
#[cfg(all(
    target_family = "unix",
    not(any(
        target_os = "macos",
        target_os = "ios",
        target_os = "linux",
        target_os = "android",
        target_os = "fuchsia"
    ))
))]
pub fn current_tid() -> Result<u64, libc::c_int> {
    unsafe { Ok(libc::pthread_self() as u64) }
}

#[cfg(target_os = "windows")]
#[inline]
pub fn current_tid() -> Result<u64, libc::c_int> {
    extern "C" {
        fn GetCurrentThreadId() -> libc::c_ulong;
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#[macro_use]
extern crate log;
extern crate chrono;
extern crate fern;

extern crate dirs;

extern crate xi_core_lib;
extern crate xi_rpc;

use std::collections::HashMap;
use std::fs;
use std::io;
use std::path::{Path, PathBuf};
use std::process;

use xi_core_lib::XiCore;
use xi_rpc::RpcLoop;

const XI_LOG_DIR: &str = "xi-core";
const XI_LOG_FILE: &str = "xi-core.log";

fn get_logging_directory_path<P: AsRef<Path>>(directory: P) -> Result<PathBuf, io::Error> {
    match dirs::data_local_dir() {
        Some(mut log_dir) => {
            log_dir.push(directory);
            Ok(log_dir)
        }
        None => Err(io::Error::new(
            io::ErrorKind::NotFound,
            "No standard logging directory known for this platform",
        )),
    }
}

/// This function tries to create the parent directories for a file
///
/// It wraps around the `parent()` function of `Path` which returns an `Option<&Path>` and
/// `fs::create_dir_all` which returns an `io::Result<()>`.
///
/// This allows you to use `?`/`try!()` to create the dir and you recive the additional custom error for when `parent()`
/// returns nothing.
///
/// # Errors
/// This can return an `io::Error` if `fs::create_dir_all` fails or if `parent()` returns `None`.
/// See `Path`'s `parent()` function for more details.
/// # Examples
/// ```
/// use std::path::Path;
/// use std::ffi::OsStr;
///
/// let path_with_file = Path::new("/some/directory/then/file");
/// assert_eq!(Some(OsStr::new("file")), path_with_file.file_name());
/// assert_eq!(create_log_directory(path_with_file).is_ok(), true);
///
/// let path_with_other_file = Path::new("/other_file");
/// assert_eq!(Some(OsStr::new("other_file")), path_with_other_file.file_name());
/// assert_eq!(create_log_directory(path_with_file).is_ok(), true);
///
/// // Path that is just the root or prefix:
/// let path_without_file = Path::new("/");
/// assert_eq!(None, path_without_file.file_name());
/// assert_eq!(create_log_directory(path_without_file).is_ok(), false);
/// ```
fn create_log_directory(path_with_file: &Path) -> io::Result<()> {
    let log_dir = path_with_file.parent().ok_or_else(|| io::Error::new(
        io::ErrorKind::InvalidInput,
        format!(
            "Unable to get the parent of the following Path: {}, Your path should contain a file name",
            path_with_file.display(),
        ),
    ))?;
    fs::create_dir_all(log_dir)?;
    Ok(())
}

fn setup_logging(logging_path: Option<&Path>) -> Result<(), fern::InitError> {
    let level_filter = match std::env::var("XI_LOG") {
        Ok(level) => match level.to_lowercase().as_ref() {
            "trace" => log::LevelFilter::Trace,
            "debug" => log::LevelFilter::Debug,
            _ => log::LevelFilter::Info,
        },
        // Default to info
        Err(_) => log::LevelFilter::Info,
    };

    let mut fern_dispatch = fern::Dispatch::new()
        .format(|out, message, record| {
            out.finish(format_args!(
                "{}[{}][{}] {}",
                chrono::Local::now().format("[%Y-%m-%d][%H:%M:%S]"),
                record.target(),
                record.level(),
                message,
            ))
        })
        .level(level_filter)
        .chain(io::stderr());

    if let Some(logging_file_path) = logging_path {
        create_log_directory(logging_file_path)?;

        fern_dispatch = fern_dispatch.chain(fern::log_file(logging_file_path)?);
    };

    // Start fern
    fern_dispatch.apply()?;
    info!("Logging with fern is set up");

    // Log details of the logging_file_path result using fern/log
    // Either logging the path fern is outputting to or the error from obtaining the path
    match logging_path {
        Some(logging_file_path) => info!("Writing logs to: {}", logging_file_path.display()),
        None => warn!("No path was supplied for the log file. Not saving logs to disk, falling back to just stderr"),
    }
    Ok(())
}

fn generate_logging_path(logfile_config: LogfileConfig) -> Result<PathBuf, io::Error> {
    // Use the file name set in logfile_config or fallback to the default
    let logfile_file_name = match logfile_config.file {
        Some(file_name) => file_name,
        None => PathBuf::from(XI_LOG_FILE),
    };
    if logfile_file_name.eq(Path::new("")) {
        return Err(io::Error::new(io::ErrorKind::InvalidInput, "A blank file name was supplied"));
    };
    // Use the directory name set in logfile_config or fallback to the default
    let logfile_directory_name = match logfile_config.directory {
        Some(dir) => dir,
        None => PathBuf::from(XI_LOG_DIR),
    };

    let mut logging_directory_path = get_logging_directory_path(logfile_directory_name)?;

    // Add the file name & return the full path
    logging_directory_path.push(logfile_file_name);
    Ok(logging_directory_path)
}

fn get_flags() -> HashMap<String, Option<String>> {
    let mut flags: HashMap<String, Option<String>> = HashMap::new();

    let flag_prefix = "-";
    let mut args_iterator = std::env::args().peekable();
    while let Some(arg) = args_iterator.next() {
        if arg.starts_with(flag_prefix) {
            let key = arg.trim_start_matches(flag_prefix).to_string();

            // Check the next argument doesn't start with the flag prefix
            // map_or accounts for peek returning an Option
            let next_arg_not_a_flag: bool =
                args_iterator.peek().map_or(false, |val| !val.starts_with(flag_prefix));
            if next_arg_not_a_flag {
                flags.insert(key, args_iterator.next());
            }
        }
    }
    flags
}

struct EnvFlagConfig {
    env_name: &'static str,
    flag_name: &'static str,
}

/// Extracts a value from the flags and the env.
///
/// In this order: `String` from the flags, then `String` from the env, then `None`
fn extract_env_or_flag(
    flags: &HashMap<String, Option<String>>,
    conf: &EnvFlagConfig,
) -> Option<String> {
    flags.get(conf.flag_name).cloned().unwrap_or_else(|| std::env::var(conf.env_name).ok())
}

struct LogfileConfig {
    directory: Option<PathBuf>,
    file: Option<PathBuf>,
}

fn generate_logfile_config(flags: &HashMap<String, Option<String>>) -> LogfileConfig {
    // If the key is set, get the Option within
    let log_dir_env_flag = EnvFlagConfig { env_name: "XI_LOG_DIR", flag_name: "log-dir" };
    let log_file_env_flag = EnvFlagConfig { env_name: "XI_LOG_FILE", flag_name: "log-file" };
    let log_dir_flag_option = extract_env_or_flag(&flags, &log_dir_env_flag).map(PathBuf::from);

    let log_file_flag_option = extract_env_or_flag(&flags, &log_file_env_flag).map(PathBuf::from);

    LogfileConfig { directory: log_dir_flag_option, file: log_file_flag_option }
}

fn main() {
    let mut state = XiCore::new();
    let stdin = io::stdin();
    let stdout = io::stdout();
    let mut rpc_looper = RpcLoop::new(stdout);

    let flags = get_flags();

    let logfile_config = generate_logfile_config(&flags);

    let logging_path_result = generate_logging_path(logfile_config);

    let logging_path =
        logging_path_result.as_ref().map(|p: &PathBuf| -> &Path { p.as_path() }).ok();

    if let Err(e) = setup_logging(logging_path) {
        eprintln!("[ERROR] setup_logging returned error, logging not enabled: {:?}", e);
    }
    if let Err(e) = logging_path_result.as_ref() {
        warn!("Unable to generate the logging path to pass to set up: {}", e)
    }

    match rpc_looper.mainloop(|| stdin.lock(), &mut state) {
        Ok(_) => (),
        Err(err) => {
            error!("xi-core exited with error:\n{:?}", err);
            process::exit(1);
        }
    }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! The library base for implementing xi-editor plugins.
extern crate xi_core_lib as xi_core;
extern crate xi_rope;
extern crate xi_rpc;
extern crate xi_trace;
#[macro_use]
extern crate serde_json;
extern crate bytecount;
extern crate memchr;
extern crate rand;
extern crate serde;

#[macro_use]
extern crate log;

mod base_cache;
mod core_proxy;
mod dispatch;
mod state_cache;
mod view;

use std::io;
use std::path::Path;

use crate::xi_core::plugin_rpc::{GetDataResponse, TextUnit};
use crate::xi_core::{ConfigTable, LanguageId};
use serde_json::Value;
use xi_rope::interval::IntervalBounds;
use xi_rope::RopeDelta;
use xi_rpc::{ReadError, RpcLoop};

use self::dispatch::Dispatcher;

pub use crate::base_cache::ChunkCache;
pub use crate::core_proxy::CoreProxy;
pub use crate::state_cache::StateCache;
pub use crate::view::View;
pub use crate::xi_core::plugin_rpc::{Hover, Range};

/// Abstracts getting data from the peer. Mainly exists for mocking in tests.
pub trait DataSource {
    fn get_data(
        &self,
        start: usize,
        unit: TextUnit,
        max_size: usize,
        rev: u64,
    ) -> Result<GetDataResponse, Error>;
}

/// A generic interface for types that cache a remote document.
///
/// In general, users of this library should not need to implement this trait;
/// we provide two concrete Cache implementations, [`ChunkCache`] and
/// [`StateCache`]. If however a plugin's particular needs are not met by
/// those implementations, a user may choose to implement their own.
///
/// [`ChunkCache`]: ../base_cache/struct.ChunkCache.html
/// [`StateCache`]: ../state_cache/struct.StateCache.html
pub trait Cache {
    /// Create a new instance of this type; instances are created automatically
    /// as relevant views are added.
    fn new(buf_size: usize, rev: u64, num_lines: usize) -> Self;
    /// Returns the line at `line_num` (zero-indexed). Returns an `Err(_)` if
    /// there is a problem connecting to the peer, or if the requested line
    /// is out of bounds.
    ///
    /// The `source` argument is some type that implements [`DataSource`]; in
    /// the general case this is backed by the remote peer.
    ///
    /// [`DataSource`]: trait.DataSource.html
    fn get_line<DS: DataSource>(&mut self, source: &DS, line_num: usize) -> Result<&str, Error>;

    /// Returns the specified region of the buffer. Returns an `Err(_)` if
    /// there is a problem connecting to the peer, or if the requested line
    /// is out of bounds.
    ///
    /// The `source` argument is some type that implements [`DataSource`]; in
    /// the general case this is backed by the remote peer.
    ///
    /// [`DataSource`]: trait.DataSource.html
    fn get_region<DS, I>(&mut self, source: &DS, interval: I) -> Result<&str, Error>
    where
        DS: DataSource,
        I: IntervalBounds;

    /// Returns the entire contents of the remote document, fetching as needed.
    fn get_document<DS: DataSource>(&mut self, source: &DS) -> Result<String, Error>;

    /// Returns the offset of the line at `line_num`, zero-indexed, fetching
    /// data from `source` if needed.
    ///
    /// # Errors
    ///
    /// Returns an error if `line_num` is greater than the total number of lines
    /// in the document, or if there is a problem communicating with `source`.
    fn offset_of_line<DS: DataSource>(
        &mut self,
        source: &DS,
        line_num: usize,
    ) -> Result<usize, Error>;
    /// Returns the index of the line containing `offset`, fetching
    /// data from `source` if needed.
    ///
    /// # Errors
    ///
    /// Returns an error if `offset` is greater than the total length of
    /// the document, or if there is a problem communicating with `source`.
    fn line_of_offset<DS: DataSource>(
        &mut self,
        source: &DS,
        offset: usize,
    ) -> Result<usize, Error>;
    /// Updates the cache by applying this delta.
    fn update(&mut self, delta: Option<&RopeDelta>, buf_size: usize, num_lines: usize, rev: u64);
    /// Flushes any state held by this cache.
    fn clear(&mut self);
}

/// An interface for plugins.
///
/// Users of this library must implement this trait for some type.
pub trait Plugin {
    type Cache: Cache;

    /// Called when the Plugin is initialized. The plugin receives CoreProxy
    /// object that is a wrapper around the RPC Peer and can be used to call
    /// related methods on the Core in a type-safe manner.
    #[allow(unused_variables)]
    fn initialize(&mut self, core: CoreProxy) {}

    /// Called when an edit has occurred in the remote view. If the plugin wishes
    /// to add its own edit, it must do so using asynchronously via the edit notification.
    fn update(
        &mut self,
        view: &mut View<Self::Cache>,
        delta: Option<&RopeDelta>,
        edit_type: String,
        author: String,
    );
    /// Called when a buffer has been saved to disk. The buffer's previous
    /// path, if one existed, is passed as `old_path`.
    fn did_save(&mut self, view: &mut View<Self::Cache>, old_path: Option<&Path>);
    /// Called when a view has been closed. By the time this message is received,
    /// It is possible to send messages to this view. The plugin may wish to
    /// perform cleanup, however.
    fn did_close(&mut self, view: &View<Self::Cache>);
    /// Called when there is a new view that this buffer is interested in.
    /// This is called once per view, and is paired with a call to
    /// `Plugin::did_close` when the view is closed.
    fn new_view(&mut self, view: &mut View<Self::Cache>);

    /// Called when a config option has changed for this view. `changes`
    /// is a map of keys/values that have changed; previous values are available
    /// in the existing config, accessible through `view.get_config()`.
    fn config_changed(&mut self, view: &mut View<Self::Cache>, changes: &ConfigTable);

    /// Called when syntax language has changed for this view.
    /// New language is available in the `view`, and old language is available in `old_lang`.
    #[allow(unused_variables)]
    fn language_changed(&mut self, view: &mut View<Self::Cache>, old_lang: LanguageId) {}

    /// Called with a custom command.
    #[allow(unused_variables)]
    fn custom_command(&mut self, view: &mut View<Self::Cache>, method: &str, params: Value) {}

    /// Called when the runloop is idle, if the plugin has previously
    /// asked to be scheduled via `View::schedule_idle()`. Plugins that
    /// are doing things like full document analysis can use this mechanism
    /// to perform their work incrementally while remaining responsive.
    #[allow(unused_variables)]
    fn idle(&mut self, view: &mut View<Self::Cache>) {}

    /// Language Plugins specific methods

    #[allow(unused_variables)]
    fn get_hover(&mut self, view: &mut View<Self::Cache>, request_id: usize, position: usize) {}
}

#[derive(Debug)]
pub enum Error {
    RpcError(xi_rpc::Error),
    WrongReturnType,
    BadRequest,
    PeerDisconnect,
    // Just used in tests
    Other(String),
}

/// Run `plugin` until it exits, blocking the current thread.
pub fn mainloop<P: Plugin>(plugin: &mut P) -> Result<(), ReadError> {
    let stdin = io::stdin();
    let stdout = io::stdout();
    let mut rpc_looper = RpcLoop::new(stdout);
    let mut dispatcher = Dispatcher::new(plugin);

// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::collections::HashMap;
use std::path::PathBuf;

use serde_json::{self, Value};

use crate::core_proxy::CoreProxy;
use crate::xi_core::plugin_rpc::{HostNotification, HostRequest, PluginBufferInfo, PluginUpdate};
use crate::xi_core::{ConfigTable, LanguageId, PluginPid, ViewId};
use xi_rpc::{Handler as RpcHandler, RemoteError, RpcCtx};
use xi_trace::{self, trace, trace_block, trace_block_payload};

use super::{Plugin, View};

/// Convenience for unwrapping a view, when handling RPC notifications.
macro_rules! bail {
    ($opt:expr, $method:expr, $pid:expr, $view:expr) => {
        match $opt {
            Some(t) => t,
            None => {
                warn!("{:?} missing {:?} for {:?}", $pid, $view, $method);
                return;
            }
        }
    };
}

/// Convenience for unwrapping a view when handling RPC requests.
/// Prints an error if the view is missing, and returns an appropriate error.
macro_rules! bail_err {
    ($opt:expr, $method:expr, $pid:expr, $view:expr) => {
        match $opt {
            Some(t) => t,
            None => {
                warn!("{:?} missing {:?} for {:?}", $pid, $view, $method);
                return Err(RemoteError::custom(404, "missing view", None));
            }
        }
    };
}

/// Handles raw RPCs from core, updating state and forwarding calls
/// to the plugin,
pub struct Dispatcher<'a, P: 'a + Plugin> {
    //TODO: when we add multi-view, this should be an Arc+Mutex/Rc+RefCell
    views: HashMap<ViewId, View<P::Cache>>,
    pid: Option<PluginPid>,
    plugin: &'a mut P,
}

impl<'a, P: 'a + Plugin> Dispatcher<'a, P> {
    pub(crate) fn new(plugin: &'a mut P) -> Self {
        Dispatcher { views: HashMap::new(), pid: None, plugin }
    }

    fn do_initialize(
        &mut self,
        ctx: &RpcCtx,
        plugin_id: PluginPid,
        buffers: Vec<PluginBufferInfo>,
    ) {
        assert!(self.pid.is_none(), "initialize rpc received with existing pid");
        info!("Initializing plugin {:?}", plugin_id);
        self.pid = Some(plugin_id);

        let core_proxy = CoreProxy::new(self.pid.unwrap(), ctx);
        self.plugin.initialize(core_proxy);

        self.do_new_buffer(ctx, buffers);
    }

    fn do_did_save(&mut self, view_id: ViewId, path: PathBuf) {
        let v = bail!(self.views.get_mut(&view_id), "did_save", self.pid, view_id);
        let prev_path = v.path.take();
        v.path = Some(path);
        self.plugin.did_save(v, prev_path.as_deref());
    }

    fn do_config_changed(&mut self, view_id: ViewId, changes: &ConfigTable) {
        let v = bail!(self.views.get_mut(&view_id), "config_changed", self.pid, view_id);
        self.plugin.config_changed(v, &changes);
        for (key, value) in changes.iter() {
            v.config_table.insert(key.to_owned(), value.to_owned());
        }
        let conf = serde_json::from_value(Value::Object(v.config_table.clone()));
        v.config = conf.unwrap();
    }

    fn do_language_changed(&mut self, view_id: ViewId, new_lang: LanguageId) {
        let v = bail!(self.views.get_mut(&view_id), "language_changed", self.pid, view_id);
        let old_lang = v.language_id.clone();
        v.set_language(new_lang);
        self.plugin.language_changed(v, old_lang);
    }

    fn do_custom_command(&mut self, view_id: ViewId, method: &str, params: Value) {
        let v = bail!(self.views.get_mut(&view_id), method, self.pid, view_id);
        self.plugin.custom_command(v, method, params);
    }

    fn do_new_buffer(&mut self, ctx: &RpcCtx, buffers: Vec<PluginBufferInfo>) {
        let plugin_id = self.pid.unwrap();
        buffers
            .into_iter()
            .map(|info| View::new(ctx.get_peer().clone(), plugin_id, info))
            .for_each(|view| {
                let mut view = view;
                self.plugin.new_view(&mut view);
                self.views.insert(view.view_id, view);
            });
    }

    fn do_close(&mut self, view_id: ViewId) {
        {
            let v = bail!(self.views.get(&view_id), "close", self.pid, view_id);
            self.plugin.did_close(v);
        }
        self.views.remove(&view_id);
    }

    fn do_shutdown(&mut self) {
        info!("rust plugin lib does not shutdown");
        //TODO: handle shutdown
    }

    fn do_get_hover(&mut self, view_id: ViewId, request_id: usize, position: usize) {
        let v = bail!(self.views.get_mut(&view_id), "get_hover", self.pid, view_id);
        self.plugin.get_hover(v, request_id, position)
    }

    fn do_tracing_config(&mut self, enabled: bool) {
        if enabled {
            xi_trace::enable_tracing();
            info!("Enabling tracing in global plugin {:?}", self.pid);
            trace("enable tracing", &["plugin"]);
        } else {
            xi_trace::disable_tracing();
            info!("Disabling tracing in global plugin {:?}", self.pid);
            trace("enable tracing", &["plugin"]);
        }
    }

    fn do_update(&mut self, update: PluginUpdate) -> Result<Value, RemoteError> {
        let _t = trace_block("Dispatcher::do_update", &["plugin"]);
        let PluginUpdate {
            view_id,
            delta,
            new_len,
            new_line_count,
            rev,
            undo_group,
            edit_type,
            author,
        } = update;
        let v = bail_err!(self.views.get_mut(&view_id), "update", self.pid, view_id);
        v.update(delta.as_ref(), new_len, new_line_count, rev, undo_group);
        self.plugin.update(v, delta.as_ref(), edit_type, author);

        Ok(Value::from(1))
    }

    fn do_collect_trace(&self) -> Result<Value, RemoteError> {
        use xi_trace::chrome_trace_dump;

        let samples = xi_trace::samples_cloned_unsorted();
        chrome_trace_dump::to_value(&samples).map_err(|e| RemoteError::Custom {
            code: 0,
            message: format!("Could not serialize trace: {:?}", e),
            data: None,
        })
    }
}

impl<'a, P: Plugin> RpcHandler for Dispatcher<'a, P> {
    type Notification = HostNotification;
    type Request = HostRequest;

    fn handle_notification(&mut self, ctx: &RpcCtx, rpc: Self::Notification) {
        use self::HostNotification::*;
        let _t = trace_block("Dispatcher::handle_notif", &["plugin"]);
        match rpc {
            Initialize { plugin_id, buffer_info } => {
                self.do_initialize(ctx, plugin_id, buffer_info)
            }
            DidSave { view_id, path } => self.do_did_save(view_id, path),
            ConfigChanged { view_id, changes } => self.do_config_changed(view_id, &changes),
            NewBuffer { buffer_info } => self.do_new_buffer(ctx, buffer_info),
            DidClose { view_id } => self.do_close(view_id),
            Shutdown(..) => self.do_shutdown(),
            TracingConfig { enabled } => self.do_tracing_config(enabled),
            GetHover { view_id, request_id, position } => {
                self.do_get_hover(view_id, request_id, position)
            }
            LanguageChanged { view_id, new_lang } => self.do_language_changed(view_id, new_lang),
            CustomCommand { view_id, method, params } => {
                self.do_custom_command(view_id, &method, params)
            }
            Ping(..) => (),
        }
    }

    fn handle_request(&mut self, _ctx: &RpcCtx, rpc: Self::Request) -> Result<Value, RemoteError> {
        use self::HostRequest::*;
        let _t = trace_block("Dispatcher::handle_request", &["plugin"]);
        match rpc {
            Update(params) => self.do_update(params),
            CollectTrace(..) => self.do_collect_trace(),
        }
    }

    fn idle(&mut self, _ctx: &RpcCtx, token: usize) {
        let _t = trace_block_payload("Dispatcher::idle", &["plugin"], format!("token: {}", token));
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! The simplest cache. This should eventually offer line-oriented access
//! to the remote document, and can be used as a building block for more
//! complicated caching schemes.

use memchr::memchr;

use crate::xi_core::plugin_rpc::{GetDataResponse, TextUnit};
use xi_rope::interval::IntervalBounds;
use xi_rope::{DeltaElement, Interval, LinesMetric, Rope, RopeDelta};
use xi_trace::trace_block;

use super::{Cache, DataSource, Error};

#[cfg(not(test))]
const CHUNK_SIZE: usize = 1024 * 1024;

#[cfg(test)]
const CHUNK_SIZE: usize = 16;

/// A simple cache, holding a single contiguous chunk of the document.
#[derive(Debug, Clone, Default)]
pub struct ChunkCache {
    /// The position of this chunk relative to the tracked document.
    /// All offsets are guaranteed to be valid UTF-8 character boundaries.
    pub offset: usize,
    /// A chunk of the remote buffer.
    pub contents: String,
    /// The (zero-based) line number of the line containing the start of the chunk.
    pub first_line: usize,
    /// The byte offset of the start of the chunk from the start of `first_line`.
    /// If this chunk starts at a line break, this will be 0.
    pub first_line_offset: usize,
    /// A list of indexes of newlines in this chunk.
    pub line_offsets: Vec<usize>,
    /// The total size of the tracked document.
    pub buf_size: usize,
    pub num_lines: usize,
    pub rev: u64,
}

impl Cache for ChunkCache {
    fn new(buf_size: usize, rev: u64, num_lines: usize) -> Self {
        let mut new = Self::default();
        new.buf_size = buf_size;
        new.num_lines = num_lines;
        new.rev = rev;
        new
    }

    /// Returns the line at `line_num` (zero-indexed). Returns an `Err(_)` if
    /// there is a problem connecting to the peer, or if the requested line
    /// is out of bounds.
    ///
    /// The `source` argument is some type that implements [`DataSource`]; in
    /// the general case this is backed by the remote peer.
    ///
    /// # Errors
    ///
    /// Returns an error if `line_num` is greater than the total number of lines
    /// in the document, or if there is a problem communicating with `source`.
    ///
    /// [`DataSource`]: trait.DataSource.html
    fn get_line<DS>(&mut self, source: &DS, line_num: usize) -> Result<&str, Error>
    where
        DS: DataSource,
    {
        if line_num >= self.num_lines {
            return Err(Error::BadRequest);
        }

        // if chunk does not include the start of this line, fetch and reset everything
        if self.contents.is_empty()
            || line_num < self.first_line
            || (line_num == self.first_line && self.first_line_offset > 0)
            || (line_num > self.first_line + self.line_offsets.len())
        {
            let resp = source.get_data(line_num, TextUnit::Line, CHUNK_SIZE, self.rev)?;
            self.reset_chunk(resp);
        }

        // We now know that the start of this line is contained in self.contents.
        let mut start_off = self.cached_offset_of_line(line_num).unwrap() - self.offset;

        // Now we make sure we also contain the end of the line, fetching more
        // of the document as necessary.
        loop {
            if let Some(end_off) = self.cached_offset_of_line(line_num + 1) {
                return Ok(&self.contents[start_off..end_off - self.offset]);
            }
            // if we have a chunk and we're fetching more, discard unnecessary
            // portion of our chunk.
            if start_off != 0 {
                self.clear_up_to(start_off);
                start_off = 0;
            }

            let chunk_end = self.offset + self.contents.len();
            let resp = source.get_data(chunk_end, TextUnit::Utf8, CHUNK_SIZE, self.rev)?;
            self.append_chunk(&resp);
        }
    }

    fn get_region<DS, I>(&mut self, source: &DS, interval: I) -> Result<&str, Error>
    where
        DS: DataSource,
        I: IntervalBounds,
    {
        let Interval { start, end } = interval.into_interval(self.buf_size);
        if self.contents.is_empty()
            || start < self.offset
            || start >= self.offset + self.contents.len()
        {
            let resp = source.get_data(start, TextUnit::Utf8, CHUNK_SIZE, self.rev)?;
            self.reset_chunk(resp);
        }

        loop {
            let start_off = start - self.offset;
            let end_off = end - self.offset;
            if end_off <= self.contents.len() {
                return Ok(&self.contents[start_off..end_off]);
            }

            if start_off != 0 {
                self.clear_up_to(start_off);
            }

            let chunk_end = self.offset + self.contents.len();
            let resp = source.get_data(chunk_end, TextUnit::Utf8, CHUNK_SIZE, self.rev)?;
            self.append_chunk(&resp);
        }
    }

    // could reimplement this with get_region, but this doesn't bloat the cache.
    // Not clear that's a win, though, since if we're using this at all caching
    // is probably worth it?
    fn get_document<DS: DataSource>(&mut self, source: &DS) -> Result<String, Error> {
        let mut result = String::new();
        let mut cur_idx = 0;
        while cur_idx < self.buf_size {
            if self.contents.is_empty() || cur_idx != self.offset {
                let resp = source.get_data(cur_idx, TextUnit::Utf8, CHUNK_SIZE, self.rev)?;
                self.reset_chunk(resp);
            }
            result.push_str(&self.contents);
            cur_idx = self.offset + self.contents.len();
        }
        Ok(result)
    }

    fn offset_of_line<DS: DataSource>(
        &mut self,
        source: &DS,
        line_num: usize,
    ) -> Result<usize, Error> {
        if line_num > self.num_lines {
            return Err(Error::BadRequest);
        }
        match self.cached_offset_of_line(line_num) {
            Some(offset) => Ok(offset),
            None => {
                let resp = source.get_data(line_num, TextUnit::Line, CHUNK_SIZE, self.rev)?;
                self.reset_chunk(resp);
                self.offset_of_line(source, line_num)
            }
        }
    }

    fn line_of_offset<DS: DataSource>(
        &mut self,
        source: &DS,
        offset: usize,
    ) -> Result<usize, Error> {
        if offset > self.buf_size {
            return Err(Error::BadRequest);
        }
        if self.contents.is_empty()
            || offset < self.offset
            || offset > self.offset + self.contents.len()
        {
            let resp = source.get_data(offset, TextUnit::Utf8, CHUNK_SIZE, self.rev)?;
            self.reset_chunk(resp);
        }

        let rel_offset = offset - self.offset;
        let line_num = match self.line_offsets.binary_search(&rel_offset) {
            Ok(ix) => ix + self.first_line + 1,
            Err(ix) => ix + self.first_line,
        };
        Ok(line_num)
    }

    /// Updates the chunk to reflect changes in this delta.
    fn update(&mut self, delta: Option<&RopeDelta>, new_len: usize, num_lines: usize, rev: u64) {
        let _t = trace_block("ChunkCache::update", &["plugin"]);
        let is_empty = self.offset == 0 && self.contents.is_empty();
        let should_clear = match delta {
            Some(delta) if !is_empty => self.should_clear(delta),
            // if no contents, clearing is a noop
            Some(_) => true,
            // no delta means a very large edit
            None => true,
        };

        if should_clear {
            self.clear();
        } else {
            // only reached if delta exists
            self.update_chunk(delta.unwrap());
        }
        self.buf_size = new_len;
        self.num_lines = num_lines;
        self.rev = rev;
    }

    fn clear(&mut self) {
        self.contents.clear();
        self.offset = 0;
        self.line_offsets.clear();
        self.first_line = 0;
        self.first_line_offset = 0;
    }
}

impl ChunkCache {
    /// Returns the offset of the provided `line_num` if it can be determined
    /// without fetching data. The offset of line 0 is always 0, and there
    /// is an implicit line at the last offset in the buffer.
    fn cached_offset_of_line(&self, line_num: usize) -> Option<usize> {
        if line_num < self.first_line {
            return None;
        }

        let rel_line_num = line_num - self.first_line;

        if rel_line_num == 0 {
            return Some(self.offset - self.first_line_offset);
        }

        if rel_line_num <= self.line_offsets.len() {
            return Some(self.offset + self.line_offsets[rel_line_num - 1]);
        }

        // EOF
        if line_num == self.num_lines && self.offset + self.contents.len() == self.buf_size {
            return Some(self.offset + self.contents.len());
        }
        None
    }

    /// Clears anything in the cache up to `offset`, which is indexed relative
    /// to `self.contents`.
    ///
    /// # Panics
    ///
    /// Panics if `offset` is not a character boundary, or if `offset` is greater than
    /// the length of `self.content`.
    fn clear_up_to(&mut self, offset: usize) {
        if offset > self.contents.len() {
            panic!("offset greater than content length: {} > {}", offset, self.contents.len())
        }

        let new_contents = self.contents.split_off(offset);
        self.contents = new_contents;
        self.offset += offset;
        // first find out if offset is a line offset, and set first_line / first_line_offset
        let (new_line, new_line_off) = match self.line_offsets.binary_search(&offset) {
            Ok(idx) => (self.first_line + idx + 1, 0),
            Err(0) => (self.first_line, self.first_line_offset + offset),
            Err(idx) => (self.first_line + idx, offset - self.line_offsets[idx - 1]),
        };

        // then clear line_offsets up to and including offset
        self.line_offsets =
            self.line_offsets.iter().filter(|i| **i > offset).map(|i| i - offset).collect();

        self.first_line = new_line;
        self.first_line_offset = new_line_off;
    }

    /// Discard any existing cache, starting again with the new data.
    fn reset_chunk(&mut self, data: GetDataResponse) {
        self.contents = data.chunk;
        self.offset = data.offset;
        self.first_line = data.first_line;
        self.first_line_offset = data.first_line_offset;
        self.recalculate_line_offsets();
    }

    /// Append to the existing cache, leaving existing data in place.
    fn append_chunk(&mut self, data: &GetDataResponse) {
        self.contents.push_str(data.chunk.as_str());
        // this is doing extra work in the case where we're fetching a single
        // massive (multiple of CHUNK_SIZE) line, but unclear if it's worth optimizing
        self.recalculate_line_offsets();
    }

    fn recalculate_line_offsets(&mut self) {
        self.line_offsets.clear();
        newline_offsets(&self.contents, &mut self.line_offsets);
    }

    /// Determine whether we should update our state with this delta,
    /// or if we should clear it. In the update case, also patches up
    /// offsets.
    fn should_clear(&mut self, delta: &RopeDelta) -> bool {
        let (iv, _) = delta.summary();
        let start = iv.start();
        let end = iv.end();
        // we only apply the delta if it is a simple edit, which
        // begins inside or immediately following our chunk.
        // - If it begins _before_ our chunk, we are likely going to
        // want to fetch the edited region, which will reset our state;
        // - If it's a complex edit the logic is tricky, and this should
        // be rare enough we can afford to discard.
        // The one 'complex edit' we should probably be handling is
        // the replacement of a single range. This could be a new
        // convenience method on `Delta`?
        if start < self.offset || start > self.offset + self.contents.len() {
            true
        } else if delta.is_simple_delete() {
            // Don't go over cache boundary.
            let end = end.min(self.offset + self.contents.len());

            self.simple_delete(start, end);
            false
        } else if let Some(text) = delta.as_simple_insert() {
            assert_eq!(iv.size(), 0);
            self.simple_insert(text, start);
            false
        } else {
            true
        }
    }

    /// Patches up `self.line_offsets` in the simple insert case.
    fn simple_insert(&mut self, text: &Rope, ins_offset: usize) {
        let has_newline = text.measure::<LinesMetric>() > 0;
        let self_off = self.offset;
        assert!(ins_offset >= self_off);
        // regardless of if we are inserting newlines we adjust offsets
        self.line_offsets.iter_mut().for_each(|off| {
            if *off > ins_offset - self_off {
                *off += text.len()
            }
        });
        // calculate and insert new newlines if necessary
        // we could save some hassle and just rerun memchr on the chunk here?
        if has_newline {
            let mut new_offsets = Vec::new();
            newline_offsets(&String::from(text), &mut new_offsets);
            new_offsets.iter_mut().for_each(|off| *off += ins_offset - self_off);

            let split_idx = self
                .line_offsets
                .binary_search(&new_offsets[0])
                .err()
                .expect("new index cannot be occupied");

            self.line_offsets =
                [&self.line_offsets[..split_idx], &new_offsets, &self.line_offsets[split_idx..]]
                    .concat();
        }
    }

    /// Patches up `self.line_offsets` in the simple delete case.
    fn simple_delete(&mut self, start: usize, end: usize) {
        let del_size = end - start;
        let start = start - self.offset;
        let end = end - self.offset;
        let has_newline = memchr(b'\n', &self.contents.as_bytes()[start..end]).is_some();
        // a bit too fancy: only reallocate if we need to remove an item
        if has_newline {
            self.line_offsets = self
                .line_offsets
                .iter()
                .filter_map(|off| match *off {
                    x if x <= start => Some(x),
                    x if x > start && x <= end => None,
                    x if x > end => Some(x - del_size),
                    hmm => panic!("invariant violated {} {} {}?", start, end, hmm),
                })
                .collect();
        } else {
            self.line_offsets.iter_mut().for_each(|off| {
                if *off >= end {
                    *off -= del_size
                }
            });
        }
    }

    /// Updates `self.contents` with the given delta.
    fn update_chunk(&mut self, delta: &RopeDelta) {
        let chunk_start = self.offset;
        let chunk_end = chunk_start + self.contents.len();
        let mut new_state = String::with_capacity(self.contents.len());
        let mut prev_copy_end = 0;
        let mut del_before: usize = 0;
        let mut ins_before: usize = 0;

        for op in delta.els.as_slice() {
            match *op {
                DeltaElement::Copy(start, end) => {
                    if start < chunk_start {
                        del_before += start - prev_copy_end;
                        if end >= chunk_start {
                            let cp_end = (end - chunk_start).min(self.contents.len());
                            new_state.push_str(&self.contents[0..cp_end]);
                        }
                    } else if start <= chunk_end {
                        if prev_copy_end < chunk_start {
                            del_before += chunk_start - prev_copy_end;
                        }
                        let cp_start = start - chunk_start;
                        let cp_end = (end - chunk_start).min(self.contents.len());
                        new_state.push_str(&self.contents[cp_start..cp_end]);
                    }
                    prev_copy_end = end;
                }
                DeltaElement::Insert(ref s) => {
                    if prev_copy_end < chunk_start {
                        ins_before += s.len();
                    } else if prev_copy_end <= chunk_end {
                        let s: String = s.into();
                        new_state.push_str(&s);
                    }
                }
            }
        }
        self.offset += ins_before;
        self.offset -= del_before;
        self.contents = new_state;
    }
}

/// Calculates the offsets of newlines in `text`,
/// inserting the results into `storage`. The offsets are the offset
/// of the start of the line, not the line break character.
fn newline_offsets(text: &str, storage: &mut Vec<usize>) {
    let mut cur_idx = 0;
    while let Some(idx) = memchr(b'\n', &text.as_bytes()[cur_idx..]) {
        storage.push(cur_idx + idx + 1);
        cur_idx += idx + 1;
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::xi_core::plugin_rpc::GetDataResponse;
    use xi_rope::delta::Delta;
    use xi_rope::interval::Interval;
    use xi_rope::rope::{LinesMetric, Rope};

    struct MockDataSource(Rope);

    impl DataSource for MockDataSource {
        fn get_data(
            &self,
            start: usize,
            unit: TextUnit,
            _max_size: usize,
            _rev: u64,
        ) -> Result<GetDataResponse, Error> {
            let offset = unit
                .resolve_offset(&self.0, start)
                .ok_or(Error::Other("unable to resolve offset".into()))?;
            let first_line = self.0.line_of_offset(offset);
            let first_line_offset = offset - self.0.offset_of_line(first_line);
            let end_off = (offset + CHUNK_SIZE).min(self.0.len());

            // not the right error, but okay for this
            if offset > self.0.len() {
                Err(Error::Other("offset too big".into()))
            } else {
                let chunk = self.0.slice_to_cow(offset..end_off).into_owned();
                Ok(GetDataResponse { chunk, offset, first_line, first_line_offset })
            }
        }
    }

    #[test]
    fn simple_chunk() {
        let mut c = ChunkCache::default();
        c.buf_size = 2;
        c.contents = "oh".into();

        let d = Delta::simple_edit(Interval::new(0, 0), "yay".into(), c.contents.len());
        c.update(Some(&d), d.new_document_len(), 1, 1);
        assert_eq!(&c.contents, "yayoh");
        assert_eq!(c.offset, 0);

        let d = Delta::simple_edit(Interval::new(0, 0), "ahh".into(), c.contents.len());
        c.update(Some(&d), d.new_document_len(), 1, 2);

        assert_eq!(&c.contents, "ahhyayoh");
        assert_eq!(c.offset, 0);

        let d = Delta::simple_edit(Interval::new(2, 2), "_oops_".into(), c.contents.len());
        assert_eq!(d.els.len(), 3);
        c.update(Some(&d), d.new_document_len(), 1, 3);

        assert_eq!(&c.contents, "ah_oops_hyayoh");
        assert_eq!(c.offset, 0);

        let d = Delta::simple_edit(Interval::new(9, 9), "fin".into(), c.contents.len());
        c.update(Some(&d), d.new_document_len(), 1, 5);

        assert_eq!(&c.contents, "ah_oops_hfinyayoh");
        assert_eq!(c.offset, 0);
    }

    #[test]
    fn get_lines() {
        let remote_document = MockDataSource("this\nhas\nfour\nlines!".into());
        let mut c = ChunkCache::default();
        c.buf_size = remote_document.0.len();
        c.num_lines = remote_document.0.measure::<LinesMetric>() + 1;
        assert_eq!(c.num_lines, 4);
        assert_eq!(c.buf_size, 20);
        assert_eq!(c.line_offsets.len(), 0);
        assert_eq!(c.get_line(&remote_document, 0).ok(), Some("this\n"));
        assert_eq!(c.line_offsets.len(), 3);
        assert_eq!(c.offset, 0);
        assert_eq!(c.buf_size, 20);
        assert_eq!(c.contents.len(), 16);
        assert_eq!(c.get_line(&remote_document, 2).ok(), Some("four\n"));
        assert_eq!(c.cached_offset_of_line(3), Some(14));
        assert_eq!(c.cached_offset_of_line(4), None);
        assert_eq!(c.get_line(&remote_document, 3).ok(), Some("lines!"));
        assert!(c.get_line(&remote_document, 4).is_err());
    }

    #[test]
    fn get_region() {
        let remote_document = MockDataSource("but\nthis big fella\nhas\nFIVE\nlines!".into());
        let mut c = ChunkCache::default();
        c.buf_size = remote_document.0.len();
        c.num_lines = remote_document.0.measure::<LinesMetric>() + 1;
        assert_eq!(c.get_region(&remote_document, ..3).ok(), Some("but"));
        assert_eq!(c.get_region(&remote_document, 28..).ok(), Some("lines!"));
        assert!(c.offset > 0);
        assert_eq!(
            c.get_region(&remote_document, ..).ok(),
            Some("but\nthis big fella\nhas\nFIVE\nlines!")
        );
    }

    #[test]
    fn reset_chunk() {
        let data = GetDataResponse {
            chunk: "1\n2\n3\n4\n5\n6\n7".into(),
            offset: 0,
            first_line: 0,
            first_line_offset: 0,
        };
        let mut cache = ChunkCache::default();
        cache.reset_chunk(data);

        assert_eq!(cache.line_offsets.len(), 6);
        assert_eq!(cache.line_offsets, vec![2, 4, 6, 8, 10, 12]);

        let idx_1 = cache.cached_offset_of_line(1).unwrap();
        let idx_2 = cache.cached_offset_of_line(2).unwrap();
        assert_eq!(&cache.contents.as_str()[idx_1..idx_2], "2\n");
    }

    #[test]
    fn clear_up_to() {
        let mut c = ChunkCache::default();
        let data = GetDataResponse {
            chunk: "this\n has a newline at idx 4\nand at idx 28".into(),
            offset: 0,
            first_line: 0,
            first_line_offset: 0,
        };
        c.reset_chunk(data);
        assert_eq!(c.line_offsets, vec![5, 29]);
        c.clear_up_to(5);
        assert_eq!(c.offset, 5);
        assert_eq!(c.first_line, 1);
        assert_eq!(c.first_line_offset, 0);
        assert_eq!(c.line_offsets, vec![24]);

        c.clear_up_to(10);
        assert_eq!(c.offset, 15);
        assert_eq!(c.first_line, 1);
        assert_eq!(c.first_line_offset, 10);
        assert_eq!(c.line_offsets, vec![14]);
    }

    #[test]
    fn simple_insert() {
        let mut c = ChunkCache::default();
        c.contents = "some".into();
        c.buf_size = 4;
        let d =
            Delta::simple_edit(Interval::new(0, 0), "two\nline\nbreaks".into(), c.contents.len());
        assert!(d.as_simple_insert().is_some());
        assert!(!d.is_simple_delete());
        c.update(Some(&d), d.new_document_len(), 3, 1);
        assert_eq!(c.line_offsets, vec![4, 9]);

        let d = Delta::simple_edit(Interval::new(4, 4), "one\nmore".into(), c.contents.len());
        assert!(d.as_simple_insert().is_some());
        c.update(Some(&d), d.new_document_len(), 4, 2);
        assert_eq!(&c.contents, "two\none\nmoreline\nbreakssome");
        assert_eq!(c.line_offsets, vec![4, 8, 17]);
    }
    #[test]
    fn offset_of_line() {
        let source = MockDataSource("this\nhas\nfour\nlines!".into());
        let mut c = ChunkCache::default();
        c.buf_size = source.0.len();
        c.num_lines = source.0.measure::<LinesMetric>() + 1;
        assert_eq!(c.num_lines, 4);
        assert_eq!(c.cached_offset_of_line(0), Some(0));
        assert_eq!(c.offset_of_line(&source, 0).unwrap(), 0);
        assert_eq!(c.offset_of_line(&source, 1).unwrap(), 5);
        assert_eq!(c.offset_of_line(&source, 2).unwrap(), 9);
        assert_eq!(c.offset_of_line(&source, 3).unwrap(), 14);
    }

    #[test]
    fn cached_offset_of_line() {
        let data = GetDataResponse {
            chunk: "zer\none\ntwo\ntri".into(),
            offset: 0,
            first_line: 0,
            first_line_offset: 0,
        };
        // ensure that the manual num_lines we set below is the same we would
        // receive on the wire
        assert_eq!(Rope::from(&data.chunk).measure::<LinesMetric>() + 1, 4);
        let mut c = ChunkCache::default();
        c.buf_size = data.chunk.len();
        c.num_lines = 4;
        c.reset_chunk(data);
        assert_eq!(&c.contents, "zer\none\ntwo\ntri");
        assert_eq!(&c.line_offsets, &[4, 8, 12]);

        assert_eq!(c.cached_offset_of_line(0), Some(0));
        assert_eq!(c.cached_offset_of_line(1), Some(4));
        assert_eq!(c.cached_offset_of_line(2), Some(8));
        assert_eq!(c.cached_offset_of_line(3), Some(12));
        assert_eq!(c.cached_offset_of_line(4), Some(15));
        assert_eq!(c.cached_offset_of_line(5), None);

        // delete a newline, and see that line_offsets is correctly updated
        let delta = Delta::simple_edit(Interval::new(3, 4), "".into(), c.buf_size);
        assert!(delta.is_simple_delete());
        c.update(Some(&delta), delta.new_document_len(), 3, 1);
        assert_eq!(&c.contents, "zerone\ntwo\ntri");
        assert_eq!(&c.line_offsets, &[7, 11]);

        assert_eq!(c.cached_offset_of_line(0), Some(0));
        assert_eq!(c.cached_offset_of_line(1), Some(7));
        assert_eq!(c.cached_offset_of_line(2), Some(11));
        assert_eq!(c.cached_offset_of_line(3), Some(14));
        assert_eq!(c.cached_offset_of_line(4), None);
    }

    #[test]
    fn simple_delete() {
        let data = GetDataResponse {
            chunk: "zer\none\ntwo\ntri".into(),
            offset: 0,
            first_line: 0,
            first_line_offset: 0,
        };
        // ensure that the manual num_lines we set below is the same we would
        // receive on the wire
        assert_eq!(Rope::from(&data.chunk).measure::<LinesMetric>() + 1, 4);
        let mut c = ChunkCache::default();
        c.buf_size = data.chunk.len();
        c.num_lines = 4;
        c.reset_chunk(data);

        assert_eq!(&c.contents, "zer\none\ntwo\ntri");
        assert_eq!(&c.line_offsets, &[4, 8, 12]);

        let delta = Delta::simple_edit(Interval::new(3, 4), "".into(), c.buf_size);
        assert!(delta.is_simple_delete());
        let (iv, _) = delta.summary();
        let start = iv.start();
        let end = iv.end();
        assert_eq!((start, end), (3, 4));
        assert_eq!(c.offset, 0);
        c.simple_delete(start, end);

        assert_eq!(&c.line_offsets, &[7, 11]);
    }

    #[test]
    fn large_delete() {
        // Issue #1136 on github
        let large_str = "This string literal is larger than CHUNK_SIZE.";
        assert!(large_str.len() > CHUNK_SIZE);

        let data = GetDataResponse {
            // Emulate a cache that has only a part of the buffer.
            chunk: large_str.split_at(CHUNK_SIZE).0.into(),
            offset: 0,
            first_line: 0,
            first_line_offset: 0,
        };
        let mut c = ChunkCache::default();
        c.reset_chunk(data);

        // This delta deletes everything.
        let delta =
            Delta::simple_edit(Interval::new(0, large_str.len()), "".into(), large_str.len());
        assert!(delta.is_simple_delete());

        c.update(Some(&delta), delta.new_document_len(), 1, 1); // Should succeed
    }

    #[test]
    fn simple_edits_with_offset() {
        let mut source = MockDataSource("this\nhas\nfour\nlines!".into());
        let mut c = ChunkCache::default();
        c.buf_size = source.0.len();
        c.num_lines = source.0.measure::<LinesMetric>() + 1;
        // get line fetches from source, starting at this line
        assert_eq!(c.get_line(&source, 2).ok(), Some("four\n"));
        assert_eq!(c.offset, 9);
        assert_eq!(&c.contents, "four\nlines!");
        assert_eq!(c.offset_of_line(&source, 3).unwrap(), 14);
        let d = Delta::simple_edit(
            Interval::new(10, 10),
            "ive nice\ns".into(),
            c.contents.len() + c.offset,
        );
        c.update(Some(&d), d.new_document_len(), 5, 1);
        // keep our source up to date
        source.0 = "this\nhas\nfive nice\nsour\nlines!".into();

        assert_eq!(&c.contents, "five nice\nsour\nlines!");
        assert_eq!(c.offset, 9);
        assert_eq!(c.offset_of_line(&source, 3).unwrap(), 19);
        assert_eq!(c.offset_of_line(&source, 4).unwrap(), 24);
        // this isn't in the chunk, so should cause a fetch that brings in the line
        assert_eq!(c.offset_of_line(&source, 0).unwrap(), 0);
        assert_eq!(c.offset, 0);
        // during tests, we fetch the document in 16 byte chunks
        assert_eq!(&c.contents, "this\nhas\nfive ni"); // "ce\nsour\nlines!");
        assert_eq!(c.offset_of_line(&source, 1).unwrap(), 5);
        assert_eq!(c.offset_of_line(&source, 3).unwrap(), 19);
        assert_eq!(c.offset_of_line(&source, 4).unwrap(), 24);

        // reset and fetch the middle, so we have an offset:
        let _ = c.offset_of_line(&source, 0);
        c.clear_up_to(5);
        assert_eq!(&c.contents, &"this\nhas\nfive nice\nsour\nlines!"[5..CHUNK_SIZE]);
        assert_eq!(c.offset, 5);
        assert_eq!(c.first_line, 1);
        //assert_eq!(c.offset_of_line(&source, 2).unwrap(), 9);
        let d = Delta::simple_edit(Interval::new(6, 10), "".into(), c.contents.len() + c.offset);
        assert!(d.is_simple_delete());
        c.update(Some(&d), d.new_document_len(), 4, 1);
        source.0 = "this\nhive nice\nsour\nlines!".into();

        assert_eq!(c.offset, 5);
        assert_eq!(c.first_line, 1);
        assert_eq!(c.get_line(&source, 1).unwrap(), "hive nice\n");
        assert_eq!(c.offset_of_line(&source, 2).unwrap(), 15);
    }

    #[test]
    fn cache_offsets() {
        let mut c = ChunkCache::default();
        // "this\nstring\nis\nour\ntotal\nbuffer"
        c.contents = "ring\nis\nour\ntotal\nbuffer".into();
        c.buf_size = c.contents.len() + 7;
        c.offset = 7;
        c.first_line = 1;
        c.first_line_offset = 2;
        c.recalculate_line_offsets();

        assert_eq!(c.cached_offset_of_line(2), Some(12));
        assert_eq!(c.cached_offset_of_line(3), Some(15));
        assert_eq!(c.cached_offset_of_line(0), None);
        assert_eq!(c.cached_offset_of_line(1), Some(5));
    }

    #[test]
    fn get_big_line() {
        let test_str = "this\nhas one big line in the middle\nwow, multi-fetch!\nyay!";
        let source = MockDataSource(test_str.into());
        let mut c = ChunkCache::default();
        c.buf_size = source.0.len();
        c.num_lines = source.0.measure::<LinesMetric>() + 1;
        assert_eq!(c.num_lines, 4);
        assert_eq!(c.get_line(&source, 0).unwrap(), "this\n");
        assert_eq!(c.contents, test_str[..CHUNK_SIZE]);
        assert_eq!(c.get_line(&source, 1).unwrap(), "has one big line in the middle\n");
        // fetches are always in an interval of CHUNK_SIZE. because getting this line
        // requres multiple fetches, contents is truncated at the start of the line.
        assert_eq!(c.contents, test_str[5..CHUNK_SIZE * 3]);
        assert_eq!(c.get_line(&source, 3).unwrap(), "yay!");
        assert_eq!(c.first_line, 3);
    }

    // if get_line is passed a line (0-indexed) that == the total number of lines
    // (1-indexed) we should always be returning a ::BadRequest error.
    #[test]
    fn get_last_line() {
        let base_document = "\
            one\n\
            two\n
            three\n\
            four";
        let source = MockDataSource(base_document.into());
        let mut c = ChunkCache::default();
        let delta = Delta::simple_edit(Interval::new(0, 0), base_document.into(), 0);
        c.update(Some(&delta), base_document.len(), 4, 0);
        match c.get_line(&source, 4) {
            Err(Error::BadRequest) => (),
            other => assert!(false, "expected BadRequest, found {:?}", other),
        };
    }

    #[test]
    fn convert_lines_offsets() {
        let source = MockDataSource("this\nhas\nfour\nlines!".into());
        let mut c = ChunkCache::default();
        c.buf_size = source.0.len();
        c.num_lines = source.0.measure::<LinesMetric>() + 1;

        assert_eq!(c.line_of_offset(&source, 0).unwrap(), 0);
        assert_eq!(c.line_of_offset(&source, 1).unwrap(), 0);
        eprintln!("{:?} {} {}", c.line_offsets, c.offset, c.buf_size);
        assert_eq!(c.line_of_offset(&source, 4).unwrap(), 0);
        assert_eq!(c.line_of_offset(&source, 5).unwrap(), 1);
        assert_eq!(c.line_of_offset(&source, 8).unwrap(), 1);
        assert_eq!(c.line_of_offset(&source, 9).unwrap(), 2);
        assert_eq!(c.line_of_offset(&source, 13).unwrap(), 2);
        assert_eq!(c.line_of_offset(&source, 14).unwrap(), 3);
        assert_eq!(c.line_of_offset(&source, 18).unwrap(), 3);
        assert_eq!(c.line_of_offset(&source, 20).unwrap(), 3);
        assert!(c.line_of_offset(&source, 21).is_err());

        assert_eq!(c.offset_of_line(&source, 0).unwrap(), 0);
        assert_eq!(c.offset_of_line(&source, 1).unwrap(), 5);
        assert_eq!(c.offset_of_line(&source, 2).unwrap(), 9);
        assert_eq!(c.offset_of_line(&source, 3).unwrap(), 14);
        assert_eq!(c.offset_of_line(&source, 4).unwrap(), 20);
        assert!(c.offset_of_line(&source, 5).is_err());
    }

    #[test]
    fn get_line_regression() {
        let base_document = r#"fn main() {
    let one = "one";
    let two = "two";
}"#;

        let edited_document = r#"fn main() {
    let one = "one";
    let two = "two";}"#;

        let mut source = MockDataSource(base_document.into());
        let mut c = ChunkCache::default();
        let delta = Delta::simple_edit(Interval::new(0, 0), base_document.into(), 0);

        c.update(Some(&delta), base_document.len(), 4, 0);
        assert_eq!(c.get_line(&source, 0).unwrap(), "fn main() {\n");
        assert_eq!(c.get_line(&source, 1).unwrap(), "    let one = \"one\";\n");
        assert_eq!(c.get_line(&source, 2).unwrap(), "    let two = \"two\";\n");
        assert_eq!(c.get_line(&source, 3).unwrap(), "}");

        let delta = Delta::simple_edit(Interval::new(53, 54), "".into(), c.buf_size);
        c.update(Some(&delta), base_document.len() - 1, 3, 1);
        source.0 = edited_document.into();
        assert_eq!(c.get_line(&source, 0).unwrap(), "fn main() {\n");
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A more sophisticated cache that manages user state.

use rand::{thread_rng, Rng};

use xi_rope::interval::IntervalBounds;
use xi_rope::{LinesMetric, RopeDelta};
use xi_trace::trace_block;

use super::{Cache, DataSource, Error, View};
use crate::base_cache::ChunkCache;

const CACHE_SIZE: usize = 1024;

/// Number of probes for eviction logic.
const NUM_PROBES: usize = 5;

struct CacheEntry<S> {
    line_num: usize,
    offset: usize,
    user_state: Option<S>,
}

/// The caching state
#[derive(Default)]
pub struct StateCache<S> {
    pub(crate) buf_cache: ChunkCache,
    state_cache: Vec<CacheEntry<S>>,
    /// The frontier, represented as a sorted list of line numbers.
    frontier: Vec<usize>,
}

impl<S: Clone + Default> Cache for StateCache<S> {
    fn new(buf_size: usize, rev: u64, num_lines: usize) -> Self {
        StateCache {
            buf_cache: ChunkCache::new(buf_size, rev, num_lines),
            state_cache: Vec::new(),
            frontier: Vec::new(),
        }
    }

    fn get_line<DS: DataSource>(&mut self, source: &DS, line_num: usize) -> Result<&str, Error> {
        self.buf_cache.get_line(source, line_num)
    }

    fn get_region<DS, I>(&mut self, source: &DS, interval: I) -> Result<&str, Error>
    where
        DS: DataSource,
        I: IntervalBounds,
    {
        self.buf_cache.get_region(source, interval)
    }

    fn get_document<DS: DataSource>(&mut self, source: &DS) -> Result<String, Error> {
        self.buf_cache.get_document(source)
    }

    fn offset_of_line<DS: DataSource>(
        &mut self,
        source: &DS,
        line_num: usize,
    ) -> Result<usize, Error> {
        self.buf_cache.offset_of_line(source, line_num)
    }

    fn line_of_offset<DS: DataSource>(
        &mut self,
        source: &DS,
        offset: usize,
    ) -> Result<usize, Error> {
        self.buf_cache.line_of_offset(source, offset)
    }

    /// Updates the cache by applying this delta.
    fn update(&mut self, delta: Option<&RopeDelta>, buf_size: usize, num_lines: usize, rev: u64) {
        let _t = trace_block("StateCache::update", &["plugin"]);

        if let Some(ref delta) = delta {
            self.update_line_cache(delta);
        } else {
            // if there's no delta (very large edit) we blow away everything
            self.clear_to_start(0);
        }

        self.buf_cache.update(delta, buf_size, num_lines, rev);
    }

    /// Flushes any state held by this cache.
    fn clear(&mut self) {
        self.reset()
    }
}

impl<S: Clone + Default> StateCache<S> {
    /// Find an entry in the cache by line num. On return `Ok(i)` means entry
    /// at index `i` is an exact match, while `Err(i)` means the entry would be
    /// inserted at `i`.
    fn find_line(&self, line_num: usize) -> Result<usize, usize> {
        self.state_cache.binary_search_by(|probe| probe.line_num.cmp(&line_num))
    }

    /// Find an entry in the cache by offset. Similar to `find_line`.
    pub fn find_offset(&self, offset: usize) -> Result<usize, usize> {
        self.state_cache.binary_search_by(|probe| probe.offset.cmp(&offset))
    }

    /// Get the state from the nearest cache entry at or before given line number.
    /// Returns line number, offset, and user state.
    pub fn get_prev(&self, line_num: usize) -> (usize, usize, S) {
        if line_num > 0 {
            let mut ix = match self.find_line(line_num) {
                Ok(ix) => ix,
                Err(0) => return (0, 0, S::default()),
                Err(ix) => ix - 1,
            };
            loop {
                let item = &self.state_cache[ix];
                if let Some(ref s) = item.user_state {
                    return (item.line_num, item.offset, s.clone());
                }
                if ix == 0 {
                    break;
                }
                ix -= 1;
            }
        }
        (0, 0, S::default())
    }

    /// Get the state at the given line number, if it exists in the cache.
    pub fn get(&self, line_num: usize) -> Option<&S> {
        self.find_line(line_num).ok().and_then(|ix| self.state_cache[ix].user_state.as_ref())
    }

    /// Set the state at the given line number. Note: has no effect if line_num
    /// references the end of the partial line at EOF.
    pub fn set<DS>(&mut self, source: &DS, line_num: usize, s: S)
    where
        DS: DataSource,
    {
        if let Some(entry) = self.get_entry(source, line_num) {
            entry.user_state = Some(s);
        }
    }

    /// Get the cache entry at the given line number, creating it if necessary.
    /// Returns None if line_num > number of newlines in doc (ie if it references
    /// the end of the partial line at EOF).
    fn get_entry<DS>(&mut self, source: &DS, line_num: usize) -> Option<&mut CacheEntry<S>>
    where
        DS: DataSource,
    {
        match self.find_line(line_num) {
            Ok(ix) => Some(&mut self.state_cache[ix]),
            Err(_ix) => {
                if line_num == self.buf_cache.num_lines {
                    None
                } else {
                    let offset = self
                        .buf_cache
                        .offset_of_line(source, line_num)
                        .expect("get_entry should validate inputs");
                    let new_ix = self.insert_entry(line_num, offset, None);
                    Some(&mut self.state_cache[new_ix])
                }
            }
        }
    }

    /// Insert a new entry into the cache, returning its index.
    fn insert_entry(&mut self, line_num: usize, offset: usize, user_state: Option<S>) -> usize {
        if self.state_cache.len() >= CACHE_SIZE {
            self.evict();
        }
        match self.find_line(line_num) {
            Ok(_ix) => panic!("entry already exists"),
            Err(ix) => {
                self.state_cache.insert(ix, CacheEntry { line_num, offset, user_state });
                ix
            }
        }
    }

    /// Evict one cache entry.
    fn evict(&mut self) {
        let ix = self.choose_victim();
        self.state_cache.remove(ix);
    }

    fn choose_victim(&self) -> usize {
        let mut best = None;
        let mut rng = thread_rng();
        for _ in 0..NUM_PROBES {
            let ix = rng.gen_range(0, self.state_cache.len());
            let gap = self.compute_gap(ix);
            if best.map(|(last_gap, _)| gap < last_gap).unwrap_or(true) {
                best = Some((gap, ix));
            }
        }
        best.unwrap().1
    }

    /// Compute the gap that would result after deleting the given entry.
    fn compute_gap(&self, ix: usize) -> usize {
        let before = if ix == 0 { 0 } else { self.state_cache[ix - 1].offset };
        let after = if let Some(item) = self.state_cache.get(ix + 1) {
            item.offset
        } else {
            self.buf_cache.buf_size
        };
        assert!(after >= before, "{} < {} ix: {}", after, before, ix);
        after - before
    }

    /// Release all state _after_ the given offset.
    fn truncate_cache(&mut self, offset: usize) {
        let (line_num, ix) = match self.find_offset(offset) {
            Ok(ix) => (self.state_cache[ix].line_num, ix + 1),
            Err(ix) => (if ix == 0 { 0 } else { self.state_cache[ix - 1].line_num }, ix),
        };
        self.truncate_frontier(line_num);
        self.state_cache.truncate(ix);
    }

    pub(crate) fn truncate_frontier(&mut self, line_num: usize) {
        match self.frontier.binary_search(&line_num) {
            Ok(ix) => self.frontier.truncate(ix + 1),
            Err(ix) => {
                self.frontier.truncate(ix);
                self.frontier.push(line_num);
            }
        }
    }

    /// Updates the line cache to reflect this delta.
    fn update_line_cache(&mut self, delta: &RopeDelta) {
        let (iv, new_len) = delta.summary();
        if let Some(n) = delta.as_simple_insert() {
            assert_eq!(iv.size(), 0);
            assert_eq!(new_len, n.len());

            let newline_count = n.measure::<LinesMetric>();
            self.line_cache_simple_insert(iv.start(), new_len, newline_count);
        } else if delta.is_simple_delete() {
            assert_eq!(new_len, 0);
            self.line_cache_simple_delete(iv.start(), iv.end())
        } else {
            self.clear_to_start(iv.start());
        }
    }

    fn line_cache_simple_insert(&mut self, start: usize, new_len: usize, newline_num: usize) {
        let ix = match self.find_offset(start) {
            Ok(ix) => ix + 1,
            Err(ix) => ix,
        };

        for entry in &mut self.state_cache[ix..] {
            entry.line_num += newline_num;
            entry.offset += new_len;
        }
        self.patchup_frontier(ix, newline_num as isize);
    }

    fn line_cache_simple_delete(&mut self, start: usize, end: usize) {
        let off = self.buf_cache.offset;
        let chunk_end = off + self.buf_cache.contents.len();
        if start >= off && end <= chunk_end {
            let del_newline_num = count_newlines(&self.buf_cache.contents[start - off..end - off]);
            // delete all entries that overlap the deleted range
            let ix = match self.find_offset(start) {
                Ok(ix) => ix + 1,
                Err(ix) => ix,
            };
            while ix < self.state_cache.len() && self.state_cache[ix].offset <= end {
                self.state_cache.remove(ix);
            }
            for entry in &mut self.state_cache[ix..] {
                entry.line_num -= del_newline_num;
                entry.offset -= end - start;
            }
            self.patchup_frontier(ix, -(del_newline_num as isize));
        } else {
            // if this region isn't in our chunk we can't correctly adjust newlines
            self.clear_to_start(start);
        }
    }

    fn patchup_frontier(&mut self, cache_idx: usize, nl_count_delta: isize) {
        let line_num = match cache_idx {
            0 => 0,
            ix => self.state_cache[ix - 1].line_num,
        };
        let mut new_frontier = Vec::new();
        let mut need_push = true;
        for old_ln in &self.frontier {
            if *old_ln < line_num {
                new_frontier.push(*old_ln);
            } else if need_push {
                new_frontier.push(line_num);
                need_push = false;
                if let Some(ref entry) = self.state_cache.get(cache_idx) {
                    if *old_ln >= entry.line_num {
                        new_frontier.push(old_ln.wrapping_add(nl_count_delta as usize));
                    }
                }
            }
        }
        if need_push {
            new_frontier.push(line_num);
        }
        self.frontier = new_frontier;
    }

    /// Clears any cached text and anything in the state cache before `start`.
    fn clear_to_start(&mut self, start: usize) {
        self.truncate_cache(start);
    }

    /// Clear all state and reset frontier to start.
    pub fn reset(&mut self) {
        self.truncate_cache(0);
    }

    /// The frontier keeps track of work needing to be done. A typical
    /// user will call `get_frontier` to get a line number, do the work
    /// on that line, insert state for the next line, and then call either
    /// `update_frontier` or `close_frontier` depending on whether there
    /// is more work to be done at that location.
    pub fn get_frontier(&self) -> Option<usize> {
        self.frontier.first().cloned()
    }

    /// Updates the frontier. This can go backward, but most typically
    /// goes forward by 1 line (compared to the `get_frontier` result).
    pub fn update_frontier(&mut self, new_frontier: usize) {
        if self.frontier.get(1) == Some(&new_frontier) {
            self.frontier.remove(0);
        } else {
            self.frontier[0] = new_frontier;
        }
    }

    /// Closes the current frontier. This is the correct choice to handle
    /// EOF.
    pub fn close_frontier(&mut self) {
        self.frontier.remove(0);
    }
}

/// StateCache specific extensions on `View`
impl<S: Default + Clone> View<StateCache<S>> {
    pub fn get_frontier(&self) -> Option<usize> {
        self.cache.get_frontier()
    }

    pub fn get_prev(&self, line_num: usize) -> (usize, usize, S) {
        self.cache.get_prev(line_num)
    }

    pub fn get(&self, line_num: usize) -> Option<&S> {
        self.cache.get(line_num)
    }

    pub fn set(&mut self, line_num: usize, s: S) {
        let ctx = self.make_ctx();
        self.cache.set(&ctx, line_num, s)
    }

    pub fn update_frontier(&mut self, new_frontier: usize) {
        self.cache.update_frontier(new_frontier)
    }

    pub fn close_frontier(&mut self) {
        self.cache.close_frontier()
    }

    pub fn reset(&mut self) {
        self.cache.reset()
    }

    pub fn find_offset(&self, offset: usize) -> Result<usize, usize> {
        self.cache.find_offset(offset)
    }
}

fn count_newlines(s: &str) -> usize {
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use serde::Deserialize;
use serde_json::{self, Value};
use std::path::{Path, PathBuf};

use crate::xi_core::plugin_rpc::{
    GetDataResponse, PluginBufferInfo, PluginEdit, ScopeSpan, TextUnit,
};
use crate::xi_core::{BufferConfig, ConfigTable, LanguageId, PluginPid, ViewId};
use xi_core_lib::annotations::AnnotationType;
use xi_core_lib::plugin_rpc::DataSpan;
use xi_rope::interval::IntervalBounds;
use xi_rope::RopeDelta;
use xi_trace::trace_block;

use xi_rpc::RpcPeer;

use super::{Cache, DataSource, Error};

/// A type that acts as a proxy for a remote view. Provides access to
/// a document cache, and implements various methods for querying and modifying
/// view state.
pub struct View<C> {
    pub(crate) cache: C,
    pub(crate) peer: RpcPeer,
    pub(crate) path: Option<PathBuf>,
    pub(crate) config: BufferConfig,
    pub(crate) config_table: ConfigTable,
    plugin_id: PluginPid,
    // TODO: this is only public to avoid changing the syntect impl
    // this should go away with async edits
    pub rev: u64,
    pub undo_group: Option<usize>,
    buf_size: usize,
    pub(crate) view_id: ViewId,
    pub(crate) language_id: LanguageId,
}

impl<C: Cache> View<C> {
    pub(crate) fn new(peer: RpcPeer, plugin_id: PluginPid, info: PluginBufferInfo) -> Self {
        let PluginBufferInfo { views, rev, path, config, buf_size, nb_lines, syntax, .. } = info;

        assert_eq!(views.len(), 1, "assuming single view");
        let view_id = views.first().unwrap().to_owned();
        let path = path.map(PathBuf::from);
        View {
            cache: C::new(buf_size, rev, nb_lines),
            peer,
            config_table: config.clone(),
            config: serde_json::from_value(Value::Object(config)).unwrap(),
            path,
            plugin_id,
            view_id,
            rev,
            undo_group: None,
            buf_size,
            language_id: syntax,
        }
    }

    pub(crate) fn update(
        &mut self,
        delta: Option<&RopeDelta>,
        new_len: usize,
        new_num_lines: usize,
        rev: u64,
        undo_group: Option<usize>,
    ) {
        self.cache.update(delta, new_len, new_num_lines, rev);
        self.rev = rev;
        self.undo_group = undo_group;
        self.buf_size = new_len;
    }

    pub(crate) fn set_language(&mut self, new_language_id: LanguageId) {
        self.language_id = new_language_id;
    }

    //NOTE: (discuss in review) this feels bad, but because we're mutating cache,
    // which we own, we can't just pass in a reference to something else we own;
    // so we create this on each call. The `clone`is only cloning an `Arc`,
    // but we could maybe use a RefCell or something and make this cleaner.
    /// Returns a `FetchCtx`, a thin wrapper around an RpcPeer that implements
    /// the `DataSource` trait and can be used when updating a cache.
    pub(crate) fn make_ctx(&self) -> FetchCtx {
        FetchCtx { view_id: self.view_id, plugin_id: self.plugin_id, peer: self.peer.clone() }
    }

    /// Returns the length of the view's buffer, in bytes.
    pub fn get_buf_size(&self) -> usize {
        self.buf_size
    }

    pub fn get_path(&self) -> Option<&Path> {
        self.path.as_deref()
    }

    pub fn get_language_id(&self) -> &LanguageId {
        &self.language_id
    }

    pub fn get_config(&self) -> &BufferConfig {
        &self.config
    }

    pub fn get_cache(&mut self) -> &mut C {
        &mut self.cache
    }

    pub fn get_id(&self) -> ViewId {
        self.view_id
    }

    pub fn get_line(&mut self, line_num: usize) -> Result<&str, Error> {
        let ctx = self.make_ctx();
        self.cache.get_line(&ctx, line_num)
    }

    /// Returns a region of the view's buffer.
    pub fn get_region<I: IntervalBounds>(&mut self, interval: I) -> Result<&str, Error> {
        let ctx = self.make_ctx();
        self.cache.get_region(&ctx, interval)
    }

    pub fn get_document(&mut self) -> Result<String, Error> {
        let ctx = self.make_ctx();
        self.cache.get_document(&ctx)
    }

    pub fn offset_of_line(&mut self, line_num: usize) -> Result<usize, Error> {
        let ctx = self.make_ctx();
        self.cache.offset_of_line(&ctx, line_num)
    }

    pub fn line_of_offset(&mut self, offset: usize) -> Result<usize, Error> {
        let ctx = self.make_ctx();
        self.cache.line_of_offset(&ctx, offset)
    }

    pub fn add_scopes(&self, scopes: &[Vec<String>]) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "scopes": scopes,
        });
        self.peer.send_rpc_notification("add_scopes", &params);
    }

    pub fn edit(
        &self,
        delta: RopeDelta,
        priority: u64,
        after_cursor: bool,
        new_undo_group: bool,
        author: String,
    ) {
        let undo_group = if new_undo_group { None } else { self.undo_group };
        let edit = PluginEdit { rev: self.rev, delta, priority, after_cursor, undo_group, author };
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "edit": edit
        });
        self.peer.send_rpc_notification("edit", &params);
    }

    pub fn update_spans(&self, start: usize, len: usize, spans: &[ScopeSpan]) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "start": start,
            "len": len,
            "rev": self.rev,
            "spans": spans,
        });
        self.peer.send_rpc_notification("update_spans", &params);
    }

    pub fn update_annotations(
        &self,
        start: usize,
        len: usize,
        annotation_spans: &[DataSpan],
        annotation_type: &AnnotationType,
    ) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "start": start,
            "len": len,
            "rev": self.rev,
            "spans": annotation_spans,
            "annotation_type": annotation_type,
        });
        self.peer.send_rpc_notification("update_annotations", &params);
    }

    pub fn schedule_idle(&self) {
        let token: usize = self.view_id.into();
        self.peer.schedule_idle(token);
    }

    /// Returns `true` if an incoming RPC is pending. This is intended
    /// to reduce latency for bulk operations done in the background.
    pub fn request_is_pending(&self) -> bool {
        self.peer.request_is_pending()
    }

    pub fn add_status_item(&self, key: &str, value: &str, alignment: &str) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "key": key,
            "value": value,
            "alignment": alignment
        });
        self.peer.send_rpc_notification("add_status_item", &params);
    }

    pub fn update_status_item(&self, key: &str, value: &str) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "key": key,
            "value": value
        });
        self.peer.send_rpc_notification("update_status_item", &params);
    }

    pub fn remove_status_item(&self, key: &str) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "key": key
        });
        self.peer.send_rpc_notification("remove_status_item", &params);
    }
}

/// A simple wrapper type that acts as a `DataSource`.
pub struct FetchCtx {
    plugin_id: PluginPid,
    view_id: ViewId,
    peer: RpcPeer,
}

impl DataSource for FetchCtx {
    fn get_data(
        &self,
        start: usize,
        unit: TextUnit,
        max_size: usize,
        rev: u64,
    ) -> Result<GetDataResponse, Error> {
        let _t = trace_block("FetchCtx::get_data", &["plugin"]);
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": self.view_id,
            "start": start,
            "unit": unit,
            "max_size": max_size,
            "rev": rev,
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A proxy for the methods on Core
use crate::xi_core::plugin_rpc::Hover;
use crate::xi_core::plugins::PluginId;
use crate::xi_core::ViewId;
use xi_rpc::{RemoteError, RpcCtx, RpcPeer};

#[derive(Clone)]
pub struct CoreProxy {
    plugin_id: PluginId,
    peer: RpcPeer,
}

impl CoreProxy {
    pub fn new(plugin_id: PluginId, rpc_ctx: &RpcCtx) -> Self {
        CoreProxy { plugin_id, peer: rpc_ctx.get_peer().clone() }
    }

    pub fn add_status_item(&mut self, view_id: ViewId, key: &str, value: &str, alignment: &str) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": view_id,
            "key": key,
            "value": value,
            "alignment": alignment
        });

        self.peer.send_rpc_notification("add_status_item", &params)
    }

    pub fn update_status_item(&mut self, view_id: ViewId, key: &str, value: &str) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": view_id,
            "key": key,
            "value": value
        });

        self.peer.send_rpc_notification("update_status_item", &params)
    }

    pub fn remove_status_item(&mut self, view_id: ViewId, key: &str) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "view_id": view_id,
            "key": key
        });

        self.peer.send_rpc_notification("remove_status_item", &params)
    }

    pub fn display_hover(
        &mut self,
        view_id: ViewId,
        request_id: usize,
        result: &Result<Hover, RemoteError>,
    ) {
        let params = json!({
            "plugin_id": self.plugin_id,
            "request_id": request_id,
            "result": result,
            "view_id": view_id
        });

        self.peer.send_rpc_notification("show_hover", &params);
    }

// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Library export for benchmarking and testing purposes.
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Simple parser expression generator

use std::char::from_u32;
use std::ops;

pub trait Peg {
    fn p(&self, s: &[u8]) -> Option<usize>;
}

impl<F: Fn(&[u8]) -> Option<usize>> Peg for F {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        self(s)
    }
}

pub struct OneByte<F>(pub F);

impl<F: Fn(u8) -> bool> Peg for OneByte<F> {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        if s.is_empty() || !self.0(s[0]) {
            None
        } else {
            Some(1)
        }
    }
}

impl Peg for u8 {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        OneByte(|b| b == *self).p(s)
    }
}

pub struct OneChar<F>(pub F);

fn decode_utf8(s: &[u8]) -> Option<(char, usize)> {
    if s.is_empty() {
        return None;
    }
    let b = s[0];
    if b < 0x80 {
        return Some((b as char, 1));
    } else if b >= 0xc2 && b < 0xe0 && s.len() >= 2 {
        let b2 = s[1];
        if (b2 as i8) > -0x40 {
            return None;
        }
        let cp = (u32::from(b) << 6) + u32::from(b2) - 0x3080;
        return from_u32(cp).map(|ch| (ch, 2));
    } else if b >= 0xe0 && b < 0xf0 && s.len() >= 3 {
        let b2 = s[1];
        let b3 = s[2];
        if (b2 as i8) > -0x40 || (b3 as i8) > -0x40 {
            return None;
        }
        let cp = (u32::from(b) << 12) + (u32::from(b2) << 6) + u32::from(b3) - 0xe2080;
        if cp < 0x800 {
            return None;
        } // overlong encoding
        return from_u32(cp).map(|ch| (ch, 3));
    } else if b >= 0xf0 && b < 0xf5 && s.len() >= 4 {
        let b2 = s[1];
        let b3 = s[2];
        let b4 = s[3];
        if (b2 as i8) > -0x40 || (b3 as i8) > -0x40 || (b4 as i8) > -0x40 {
            return None;
        }
        let cp =
            (u32::from(b) << 18) + (u32::from(b2) << 12) + (u32::from(b3) << 6) + u32::from(b4)
                - 0x03c8_2080;
        if cp < 0x10000 {
            return None;
        } // overlong encoding
        return from_u32(cp).map(|ch| (ch, 4));
    }
    None
}

impl<F: Fn(char) -> bool> Peg for OneChar<F> {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        if let Some((ch, len)) = decode_utf8(s) {
            if self.0(ch) {
                return Some(len);
            }
        }
        None
    }
}

// split out into a separate function to help inlining heuristics; even so,
// prefer to use bytes even though they're not quite as ergonomic
fn char_helper(s: &[u8], c: char) -> Option<usize> {
    OneChar(|x| x == c).p(s)
}

impl Peg for char {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        let c = *self;
        if c <= '\x7f' {
            (c as u8).p(s)
        } else {
            char_helper(s, c)
        }
    }
}

// byte ranges, including inclusive variants

/// Use Inclusive(a..b) to indicate an inclusive range. When a...b syntax becomes
/// stable, we'll get rid of this and switch to that.
pub struct Inclusive<T>(pub T);

impl Peg for ops::Range<u8> {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        OneByte(|x| x >= self.start && x < self.end).p(s)
    }
}

impl Peg for Inclusive<ops::Range<u8>> {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        OneByte(|x| x >= self.0.start && x <= self.0.end).p(s)
    }
}

// Note: char ranges are also possible, but probably not commonly used, and inefficient

impl<'a> Peg for &'a [u8] {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        let len = self.len();
        if s.len() >= len && &s[..len] == *self {
            Some(len)
        } else {
            None
        }
    }
}

impl<'a> Peg for &'a str {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        self.as_bytes().p(s)
    }
}

impl<P1: Peg, P2: Peg> Peg for (P1, P2) {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        self.0.p(s).and_then(|len1| self.1.p(&s[len1..]).map(|len2| len1 + len2))
    }
}

impl<P1: Peg, P2: Peg, P3: Peg> Peg for (P1, P2, P3) {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        self.0.p(s).and_then(|len1| {
            self.1
                .p(&s[len1..])
                .and_then(|len2| self.2.p(&s[len1 + len2..]).map(|len3| len1 + len2 + len3))
        })
    }
}

macro_rules! impl_tuple {
    ( $( $p:ident $ix:ident ),* ) => {
        impl< $( $p : Peg ),* > Peg for ( $( $p ),* ) {
            #[inline(always)]
            fn p(&self, s: &[u8]) -> Option<usize> {
                let ( $( ref $ix ),* ) = *self;
                let mut i = 0;
                $(
                    if let Some(len) = $ix.p(&s[i..]) {
                        i += len;
                    } else {
                        return None;
                    }
                )*
                Some(i)
            }
        }
    }
}
impl_tuple!(P1 p1, P2 p2, P3 p3, P4 p4);

/// Choice from two heterogeneous alternatives.
pub struct Alt<P1, P2>(pub P1, pub P2);

impl<P1: Peg, P2: Peg> Peg for Alt<P1, P2> {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        self.0.p(s).or_else(|| self.1.p(s))
    }
}

/// Choice from three heterogeneous alternatives.
pub struct Alt3<P1, P2, P3>(pub P1, pub P2, pub P3);

impl<P1: Peg, P2: Peg, P3: Peg> Peg for Alt3<P1, P2, P3> {
    #[inline(always)]
    fn p(&self, s: &[u8]) -> Option<usize> {
        self.0.p(s).or_else(|| self.1.p(s).or_else(|| self.2.p(s)))
    }
}

/// Choice from a homogenous slice of parsers.
pub struct OneOf<'a, P: 'a>(pub &'a [P]);

impl<'a, P: Peg> Peg for OneOf<'a, P> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        for p in self.0.iter() {
            if let Some(len) = p.p(s) {
                return Some(len);
            }
        }
        None
    }
}

/// Repetition with a minimum and maximum (inclusive) bound
pub struct Repeat<P, R>(pub P, pub R);

impl<P: Peg> Peg for Repeat<P, usize> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        let Repeat(ref p, reps) = *self;
        let mut i = 0;
        let mut count = 0;
        while count < reps {
            if let Some(len) = p.p(&s[i..]) {
                i += len;
                count += 1;
            } else {
                break;
            }
        }
        Some(i)
    }
}

impl<P: Peg> Peg for Repeat<P, ops::Range<usize>> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        let Repeat(ref p, ops::Range { start, end }) = *self;
        let mut i = 0;
        let mut count = 0;
        while count + 1 < end {
            if let Some(len) = p.p(&s[i..]) {
                i += len;
                count += 1;
            } else {
                break;
            }
        }
        if count >= start {
            Some(i)
        } else {
            None
        }
    }
}

impl<P: Peg> Peg for Repeat<P, ops::RangeFrom<usize>> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        let Repeat(ref p, ops::RangeFrom { start }) = *self;
        let mut i = 0;
        let mut count = 0;
        while let Some(len) = p.p(&s[i..]) {
            i += len;
            count += 1;
        }
        if count >= start {
            Some(i)
        } else {
            None
        }
    }
}

impl<P: Peg> Peg for Repeat<P, ops::RangeFull> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        ZeroOrMore(Ref(&self.0)).p(s)
    }
}

impl<P: Peg> Peg for Repeat<P, ops::RangeTo<usize>> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        let Repeat(ref p, ops::RangeTo { end }) = *self;
        Repeat(Ref(p), 0..end).p(s)
    }
}

pub struct Optional<P>(pub P);

impl<P: Peg> Peg for Optional<P> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        self.0.p(s).or(Some(0))
    }
}

#[allow(dead_code)] // not used by rust lang, but used in tests
pub struct OneOrMore<P>(pub P);

impl<P: Peg> Peg for OneOrMore<P> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        Repeat(Ref(&self.0), 1..).p(s)
    }
}

pub struct ZeroOrMore<P>(pub P);

impl<P: Peg> Peg for ZeroOrMore<P> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        let mut i = 0;
        while let Some(len) = self.0.p(&s[i..]) {
            i += len;
        }
        Some(i)
    }
}

/// Fail to match if the arg matches, otherwise match empty.
pub struct FailIf<P>(pub P);

impl<P: Peg> Peg for FailIf<P> {
    #[inline]
    fn p(&self, s: &[u8]) -> Option<usize> {
        match self.0.p(s) {
            Some(_) => None,
            None => Some(0),
        }
    }
}

/// A wrapper to use whenever you have a reference to a Peg object
pub struct Ref<'a, P: 'a>(pub &'a P);

impl<'a, P: Peg> Peg for Ref<'a, P> {
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A language syntax coloring and indentation plugin for xi-editor.

extern crate xi_core_lib;
extern crate xi_plugin_lib;
extern crate xi_rope;
extern crate xi_trace;

use std::{collections::HashMap, env, path::Path};

use crate::language::{plaintext::PlaintextParser, rust::RustParser};
use crate::parser::Parser;
use crate::statestack::State;
use xi_core_lib::{plugins::rpc::ScopeSpan, ConfigTable, LanguageId, ViewId};
use xi_plugin_lib::{mainloop, Cache, Plugin, StateCache, View};
use xi_rope::RopeDelta;
use xi_trace::{trace, trace_block, trace_payload};

mod language;
mod parser;
mod peg;
mod statestack;

const LINES_PER_RPC: usize = 50;

type ScopeId = u32;

struct LangPlugin {
    view_states: HashMap<ViewId, ViewState>,
}

impl LangPlugin {
    fn new() -> LangPlugin {
        LangPlugin { view_states: HashMap::new() }
    }
}

impl Plugin for LangPlugin {
    type Cache = StateCache<State>;

    fn update(
        &mut self,
        view: &mut View<Self::Cache>,
        _delta: Option<&RopeDelta>,
        _edit_type: String,
        _author: String,
    ) {
        view.schedule_idle();
    }

    fn did_save(&mut self, view: &mut View<Self::Cache>, _old_path: Option<&Path>) {
        let view_id = view.get_id();
        if let Some(view_state) = self.view_states.get_mut(&view_id) {
            view_state.do_highlighting(view);
        }
    }

    fn did_close(&mut self, view: &View<Self::Cache>) {
        let view_id = view.get_id();
        self.view_states.remove(&view_id);
    }

    fn new_view(&mut self, view: &mut View<Self::Cache>) {
        let view_id = view.get_id();
        let mut view_state = ViewState::new();

        view_state.do_highlighting(view);
        self.view_states.insert(view_id, view_state);
    }

    fn config_changed(&mut self, _view: &mut View<Self::Cache>, _changes: &ConfigTable) {}

    fn language_changed(
        &mut self,
        view: &mut View<<Self as Plugin>::Cache>,
        _old_lang: LanguageId,
    ) {
        let view_id = view.get_id();
        if let Some(view_state) = self.view_states.get_mut(&view_id) {
            view_state.do_highlighting(view);
        }
    }

    fn idle(&mut self, view: &mut View<Self::Cache>) {
        let view_id = view.get_id();

        if let Some(view_state) = self.view_states.get_mut(&view_id) {
            for _ in 0..LINES_PER_RPC {
                if !view_state.highlight_one_line(view) {
                    view_state.flush_spans(view);
                    return;
                }

                if view.request_is_pending() {
                    trace("yielding for request", &["experimental-lang"]);
                    break;
                }
            }

            view_state.flush_spans(view);
            view.schedule_idle();
        }
    }
}

struct ViewState {
    current_language: LanguageId,
    parser: Box<dyn Parser>,
    offset: usize,
    initial_state: State,
    spans_start: usize,
    spans: Vec<ScopeSpan>,
    scope_offset: u32,
}

impl ViewState {
    fn new() -> ViewState {
        ViewState {
            current_language: LanguageId::from("Plain Text"),
            parser: Box::new(PlaintextParser::new()),
            offset: 0,
            initial_state: State::default(),
            spans_start: 0,
            spans: Vec::new(),
            scope_offset: 0,
        }
    }

    fn do_highlighting(&mut self, view: &mut View<StateCache<State>>) {
        self.offset = 0;
        self.spans_start = 0;
        self.initial_state = State::default();
        self.spans = Vec::new();
        view.get_cache().clear();

        if view.get_language_id() != &self.current_language {
            let parser: Box<dyn Parser> = match view.get_language_id().as_ref() {
                "Rust" => Box::new(RustParser::new()),
                "Plain Text" => Box::new(PlaintextParser::new()),
                language_id => {
                    trace_payload(
                        "unsupported language",
                        &["experimental-lang"],
                        format!("language id: {}", language_id),
                    );
                    Box::new(PlaintextParser::new())
                }
            };

            self.current_language = view.get_language_id().clone();
            self.parser = parser;
        }

        let scopes = self.parser.get_all_scopes();
        view.add_scopes(&scopes);

        if !self.parser.has_offset() {
            self.parser.set_scope_offset(self.scope_offset);
            self.scope_offset += scopes.len() as u32;
        }

        view.schedule_idle();
    }

    fn highlight_one_line(&mut self, view: &mut View<StateCache<State>>) -> bool {
        if let Some(line_num) = view.get_frontier() {
            let (line_num, offset, _state) = view.get_prev(line_num);

            if offset != self.offset {
                self.flush_spans(view);
                self.offset = offset;
                self.spans_start = offset;
            }

            let new_frontier = match view.get_line(line_num) {
                Ok("") => None,
                Ok(line) => {
                    let new_state = self.compute_syntax(line);
                    self.offset += line.len();

                    if line.as_bytes().last() == Some(&b'\n') {
                        Some((new_state, line_num + 1))
                    } else {
                        None
                    }
                }
                Err(_) => None,
            };

            let mut converged = false;
            if let Some((ref new_state, new_line_num)) = new_frontier {
                if let Some(old_state) = view.get(new_line_num) {
                    converged = old_state == new_state;
                }
            }

            if !converged {
                if let Some((new_state, new_line_num)) = new_frontier {
                    view.set(new_line_num, new_state);
                    view.update_frontier(new_line_num);
                    return true;
                }
            }

            view.close_frontier();
        }

        false
    }

    fn compute_syntax(&mut self, line: &str) -> State {
        let _guard = trace_block("ExperimentalLang::compute_syntax", &["experimental-lang"]);

        let mut i = 0;
        let mut state = self.initial_state;
        while i < line.len() {
            let (prevlen, s0, len, s1) = self.parser.parse(&line[i..], state);

            if prevlen > 0 {
                // TODO: maybe make an iterator to avoid this duplication
                let scope_id = self.parser.get_scope_id_for_state(self.initial_state);

                let start = self.offset - self.spans_start + i;
                let end = start + prevlen;

                let span = ScopeSpan { start, end, scope_id };
                self.spans.push(span);

                i += prevlen;
            }

            let scope_id = self.parser.get_scope_id_for_state(s0);

            let start = self.offset - self.spans_start + i;
            let end = start + len;

            let span = ScopeSpan { start, end, scope_id };
            self.spans.push(span);

            i += len;
            state = s1;
        }

        state
    }

    fn flush_spans(&mut self, view: &mut View<StateCache<State>>) {
        if self.spans_start != self.offset {
            trace_payload(
                "flushing spans",
                &["experimental-lang"],
                format!("flushing spans: {:?}", self.spans),
            );
            view.update_spans(self.spans_start, self.offset - self.spans_start, &self.spans);
            self.spans.clear();
        }

        self.spans_start = self.offset;
    }
}

fn main() {
    if let Some(ref s) = env::args().nth(1) {
        if s == "test" {
            language::rust::test();
            return;
        }
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use crate::statestack::State;
use crate::ScopeId;

/// Trait for abstracting over text parsing and [Scope] extraction
pub trait Parser {
    fn has_offset(&mut self) -> bool;
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::{collections::HashMap, hash::Hash};

/// An entire state stack is represented as a single integer.
#[derive(Default, Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct State(usize);

struct Entry<T> {
    tos: T,
    prev: State,
}

/// All states are interpreted in a context.
pub struct Context<T> {
    // oddly enough, this is 1-based, as state 0 doesn't have an entry.
    entries: Vec<Entry<T>>,

    next: HashMap<(State, T), State>,
}

impl<T: Clone + Hash + Eq> Context<T> {
    pub fn new() -> Context<T> {
        Context { entries: Vec::new(), next: HashMap::new() }
    }

    fn entry(&self, s: State) -> Option<&Entry<T>> {
        if s.0 == 0 {
            None
        } else {
            Some(&self.entries[s.0 - 1])
        }
    }

    /// The top of the stack for the given state.
    pub fn tos(&self, s: State) -> Option<T> {
        self.entry(s).map(|entry| entry.tos.clone())
    }

    pub fn pop(&self, s: State) -> Option<State> {
        self.entry(s).map(|entry| entry.prev)
    }

    pub fn push(&mut self, s: State, el: T) -> State {
        let entries = &mut self.entries;
        *self.next.entry((s, el.clone())).or_insert_with(|| {
            entries.push(Entry { tos: el, prev: s });
            State(entries.len())
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Rust language syntax analysis and highlighting.

use std::io::{stdin, Read};

use crate::parser::Parser;
use crate::peg::*;
use crate::statestack::{Context, State};
use crate::ScopeId;

/// See [this](https://github.com/sublimehq/Packages/blob/master/Rust/Rust.sublime-syntax)
/// for reference.
static ALL_SCOPES: &[&[&str]] = &[
    &["source.rust"],
    &["source.rust", "string.quoted.double.rust"],
    &["source.rust", "string.quoted.single.rust"],
    &["source.rust", "comment.line.double-slash.rust"],
    &["source.rust", "constant.character.escape.rust"],
    &["source.rust", "constant.numeric.decimal.rust"],
    &["source.rust", "invalid.illegal.rust"],
    &["source.rust", "keyword.operator.rust"],
    &["source.rust", "keyword.operator.arithmetic.rust"],
    &["source.rust", "entity.name.type.rust"],
];

#[derive(Clone, Debug, Hash, PartialEq, Eq)]
pub enum StateEl {
    Source,
    StrQuote,
    CharQuote,
    Comment,
    // One for each /*
    CharConst,
    NumericLiteral,
    Invalid,
    Keyword,
    Operator,
    PrimType,
    //RawStrHash,  // One for each hash in a raw string
    //Block,    // One for each {
    //Bracket,  // One for each [
    //Paren,    // One for each (
    // generics etc
}

impl StateEl {
    pub fn scope_id(&self) -> ScopeId {
        match self {
            StateEl::Source => 0,
            StateEl::StrQuote => 1,
            StateEl::CharQuote => 2,
            StateEl::Comment => 3,
            StateEl::CharConst => 4,
            StateEl::NumericLiteral => 5,
            StateEl::Invalid => 6,
            StateEl::Keyword => 7,
            StateEl::Operator => 8,
            StateEl::PrimType => 9,
        }
    }
}

// sorted for easy binary searching
const RUST_KEYWORDS: &[&[u8]] = &[
    b"Self",
    b"abstract",
    b"alignof",
    b"as",
    b"become",
    b"box",
    b"break",
    b"const",
    b"continue",
    b"crate",
    b"default",
    b"do",
    b"else",
    b"enum",
    b"extern",
    b"false",
    b"final",
    b"fn",
    b"for",
    b"if",
    b"impl",
    b"in",
    b"let",
    b"loop",
    b"macro",
    b"match",
    b"mod",
    b"move",
    b"mut",
    b"offsetof",
    b"override",
    b"priv",
    b"proc",
    b"pub",
    b"pure",
    b"ref",
    b"return",
    b"self",
    b"sizeof",
    b"static",
    b"struct",
    b"super",
    b"trait",
    b"true",
    b"type",
    b"typeof",
    b"union",
    b"unsafe",
    b"unsized",
    b"use",
    b"virtual",
    b"where",
    b"while",
    b"yield",
];

// sorted for easy binary searching
const RUST_PRIM_TYPES: &[&[u8]] = &[
    b"bool", b"char", b"f32", b"f64", b"i128", b"i16", b"i32", b"i64", b"i8", b"isize", b"str",
    b"u128", b"u16", b"u32", b"u64", b"u8", b"usize",
];

const RUST_OPERATORS: &[&[u8]] = &[
    b"!", b"%=", b"%", b"&=", b"&&", b"&", b"*=", b"*", b"+=", b"+", b"-=", b"-", b"/=", b"/",
    b"<<=", b"<<", b">>=", b">>", b"^=", b"^", b"|=", b"||", b"|", b"==", b"=", b"..", b"=>",
    b"<=", b"<", b">=", b">",
];

pub struct RustParser {
    scope_offset: Option<u32>,
    ctx: Context<StateEl>,
}

impl RustParser {
    pub fn new() -> RustParser {
        RustParser { scope_offset: None, ctx: Context::new() }
    }

    fn quoted_str(&mut self, t: &[u8], state: State) -> (usize, State, usize, State) {
        let mut i = 0;
        while i < t.len() {
            let b = t[i];
            if b == b'"' {
                return (0, state, i + 1, self.ctx.pop(state).unwrap());
            } else if b == b'\\' {
                if let Some(len) = escape.p(&t[i..]) {
                    return (i, self.ctx.push(state, StateEl::CharConst), len, state);
                } else if let Some(len) =
                    (FailIf(OneOf(b"\r\nbu")), OneChar(|_| true)).p(&t[i + 1..])
                {
                    return (i + 1, self.ctx.push(state, StateEl::Invalid), len, state);
                }
            }
            i += 1;
        }
        (0, state, i, state)
    }
}

impl Parser for RustParser {
    fn has_offset(&mut self) -> bool {
        self.scope_offset.is_some()
    }

    fn set_scope_offset(&mut self, offset: u32) {
        if !self.has_offset() {
            self.scope_offset = Some(offset)
        }
    }

    fn get_all_scopes(&self) -> Vec<Vec<String>> {
        ALL_SCOPES
            .iter()
            .map(|stack| stack.iter().map(|s| (*s).to_string()).collect::<Vec<_>>())
            .collect()
    }

    fn get_scope_id_for_state(&self, state: State) -> ScopeId {
        let offset = self.scope_offset.unwrap_or_default();

        if let Some(element) = self.ctx.tos(state) {
            element.scope_id() + offset
        } else {
            offset
        }
    }

    fn parse(&mut self, text: &str, mut state: State) -> (usize, State, usize, State) {
        let t = text.as_bytes();
        match self.ctx.tos(state) {
            Some(StateEl::Comment) => {
                for i in 0..t.len() {
                    if let Some(len) = "/*".p(&t[i..]) {
                        state = self.ctx.push(state, StateEl::Comment);
                        return (i, state, len, state);
                    } else if let Some(len) = "*/".p(&t[i..]) {
                        return (0, state, i + len, self.ctx.pop(state).unwrap());
                    }
                }
                return (0, state, t.len(), state);
            }
            Some(StateEl::StrQuote) => return self.quoted_str(t, state),
            _ => (),
        }
        let mut i = 0;
        while i < t.len() {
            let b = t[i];
            if let Some(len) = "/*".p(&t[i..]) {
                state = self.ctx.push(state, StateEl::Comment);
                return (i, state, len, state);
            } else if "//".p(&t[i..]).is_some() {
                return (i, self.ctx.push(state, StateEl::Comment), t.len(), state);
            } else if let Some(len) = numeric_literal.p(&t[i..]) {
                return (i, self.ctx.push(state, StateEl::NumericLiteral), len, state);
            } else if b == b'"' {
                state = self.ctx.push(state, StateEl::StrQuote);
                return (i, state, 1, state);
            } else if let Some(len) = char_literal.p(&t[i..]) {
                return (i, self.ctx.push(state, StateEl::CharQuote), len, state);
            } else if let Some(len) = OneOf(RUST_OPERATORS).p(&t[i..]) {
                return (i, self.ctx.push(state, StateEl::Operator), len, state);
            } else if let Some(len) = ident.p(&t[i..]) {
                if RUST_KEYWORDS.binary_search(&&t[i..i + len]).is_ok() {
                    return (i, self.ctx.push(state, StateEl::Keyword), len, state);
                } else if RUST_PRIM_TYPES.binary_search(&&t[i..i + len]).is_ok() {
                    return (i, self.ctx.push(state, StateEl::PrimType), len, state);
                } else {
                    i += len;
                    continue;
                }
            } else if let Some(len) = whitespace.p(&t[i..]) {
                return (i, self.ctx.push(state, StateEl::Source), len, state);
            }

            i += 1;
        }

        (0, self.ctx.push(state, StateEl::Source), t.len(), state)
    }
}

fn is_digit(c: u8) -> bool {
    c >= b'0' && c <= b'9'
}

fn is_hex_digit(c: u8) -> bool {
    (c >= b'0' && c <= b'9') || (c >= b'a' && c <= b'f') || (c >= b'A' && c <= b'F')
}

// Note: will have to rework this if we want to support non-ASCII identifiers
fn is_ident_start(c: u8) -> bool {
    (c >= b'A' && c <= b'Z') || (c >= b'a' && c <= b'z') || c == b'_'
}

fn is_ident_continue(c: u8) -> bool {
    is_ident_start(c) || is_digit(c)
}

fn ident(s: &[u8]) -> Option<usize> {
    (OneByte(is_ident_start), ZeroOrMore(OneByte(is_ident_continue))).p(s)
}

// sequence of decimal digits with optional separator
fn raw_numeric(s: &[u8]) -> Option<usize> {
    (OneByte(is_digit), ZeroOrMore(Alt(b'_', OneByte(is_digit)))).p(s)
}

fn int_suffix(s: &[u8]) -> Option<usize> {
    (Alt(b'u', b'i'), OneOf(&["8", "16", "32", "64", "128", "size"])).p(s)
}

// At least one P with any number of SEP mixed in. Note: this is also an example
// of composing combinators to make a new combinator.
struct OneOrMoreWithSep<P, SEP>(P, SEP);

impl<P: Peg, SEP: Peg> Peg for OneOrMoreWithSep<P, SEP> {
    fn p(&self, s: &[u8]) -> Option<usize> {
        let OneOrMoreWithSep(ref p, ref sep) = *self;
        (ZeroOrMore(Ref(sep)), Ref(p), ZeroOrMore(Alt(Ref(p), Ref(sep)))).p(s)
    }
}

fn positive_nondecimal(s: &[u8]) -> Option<usize> {
    (
        b'0',
        Alt3(
            (b'x', OneOrMoreWithSep(OneByte(is_hex_digit), b'_')),
            (b'o', OneOrMoreWithSep(Inclusive(b'0'..b'7'), b'_')),
            (b'b', OneOrMoreWithSep(Alt(b'0', b'1'), b'_')),
        ),
        Optional(int_suffix),
    )
        .p(s)
}

fn positive_decimal(s: &[u8]) -> Option<usize> {
    (
        raw_numeric,
        Alt(
            int_suffix,
            (
                Optional((b'.', FailIf(OneByte(is_ident_start)), Optional(raw_numeric))),
                Optional((Alt(b'e', b'E'), Optional(Alt(b'+', b'-')), raw_numeric)),
                Optional(Alt("f32", "f64")),
            ),
        ),
    )
        .p(s)
}

fn numeric_literal(s: &[u8]) -> Option<usize> {
    (Optional(b'-'), Alt(positive_nondecimal, positive_decimal)).p(s)
}

fn escape(s: &[u8]) -> Option<usize> {
    (
        b'\\',
        Alt3(
            OneOf(b"\\\'\"0nrt"),
            (b'x', Repeat(OneByte(is_hex_digit), 2)),
            ("u{", Repeat(OneByte(is_hex_digit), 1..7), b'}'),
        ),
    )
        .p(s)
}

fn char_literal(s: &[u8]) -> Option<usize> {
    (b'\'', Alt(OneChar(|c| c != '\\' && c != '\''), escape), b'\'').p(s)
}

// Parser for an arbitrary number of whitespace characters
// Reference: https://en.cppreference.com/w/cpp/string/byte/isspace
fn whitespace(s: &[u8]) -> Option<usize> {
    // 0x0B -> \v
    // 0x0C -> \f
    (OneOrMore(OneOf(&[b' ', b'\t', b'\n', b'\r', 0x0B, 0x0C]))).p(s)
}

// A simple stdio based harness for testing.
pub fn test() {
    let mut buf = String::new();
    let _ = stdin().read_to_string(&mut buf).unwrap();
    let mut c = RustParser::new();

    let mut state = State::default();
    for line in buf.lines() {
        let mut i = 0;
        while i < line.len() {
            let (prevlen, s0, len, s1) = c.parse(&line[i..], state);
            if prevlen > 0 {
                println!("{}: {:?}", &line[i..i + prevlen], state);
                i += prevlen;
            }
            println!("{}: {:?}", &line[i..i + len], s0);
            i += len;
            state = s1;
        }
    }
}

#[cfg(test)]
mod tests {
    use super::numeric_literal;

    #[test]
    fn numeric_literals() {
        assert_eq!(Some(1), numeric_literal(b"2.f64"));
        assert_eq!(Some(6), numeric_literal(b"2.0f64"));
        assert_eq!(Some(1), numeric_literal(b"2._f64"));
        assert_eq!(Some(1), numeric_literal(b"2._0f64"));
        assert_eq!(Some(5), numeric_literal(b"1_2__"));
        assert_eq!(Some(7), numeric_literal(b"1_2__u8"));
        assert_eq!(Some(9), numeric_literal(b"1_2__u128"));
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use crate::parser::Parser;
use crate::statestack::{Context, State};
use crate::ScopeId;

const PLAINTEXT_SOURCE_SCOPE: &[&str] = &["source.plaintext"];

pub struct PlaintextParser {
    scope_offset: Option<u32>,
    ctx: Context<()>,
}

impl PlaintextParser {
    pub fn new() -> PlaintextParser {
        PlaintextParser { scope_offset: None, ctx: Context::new() }
    }
}

impl Parser for PlaintextParser {
    fn has_offset(&mut self) -> bool {
        self.scope_offset.is_some()
    }

    fn set_scope_offset(&mut self, offset: u32) {
        if !self.has_offset() {
            self.scope_offset = Some(offset)
        }
    }

    fn get_all_scopes(&self) -> Vec<Vec<String>> {
        vec![PLAINTEXT_SOURCE_SCOPE.iter().map(|it| (*it).to_string()).collect()]
    }

    fn get_scope_id_for_state(&self, _state: State) -> ScopeId {
        self.scope_offset.unwrap_or_default()
    }

// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Benchmarks of PEG parsing libraries

#![feature(test)]

/// Run as:
/// ```
/// run nightly cargo bench --features "nom regex pom"
/// ```
use std::env;

extern crate xi_lang;

#[cfg(test)]
extern crate test;

#[cfg(feature = "pom")]
extern crate pom;

#[cfg(feature = "regex")]
extern crate regex;

#[cfg(feature = "nom")]
#[macro_use]
extern crate nom;

#[cfg(feature = "combine")]
extern crate combine;

const TEST_STR: &'static str = "1.2345e56";

#[cfg(all(test, feature = "pom"))]
mod pom_benches {
    use super::{test, TEST_STR};
    use pom::parser::{one_of, sym};
    use pom::{DataInput, Parser};
    use test::Bencher;

    fn pom_number() -> Parser<u8, usize> {
        let integer = one_of(b"123456789") - one_of(b"0123456789").repeat(0..) | sym(b'0');
        let frac = sym(b'.') + one_of(b"0123456789").repeat(1..);
        let exp = one_of(b"eE") + one_of(b"+-").opt() + one_of(b"0123456789").repeat(1..);
        let number = sym(b'-').opt() + integer + frac.opt() + exp.opt();
        number.pos()
    }

    #[bench]
    fn bench_pom(b: &mut Bencher) {
        let parser = pom_number();

        b.iter(|| {
            let mut buf = DataInput::new(test::black_box(TEST_STR.as_bytes()));
            parser.parse(&mut buf)
        })
    }
}

#[cfg(all(test, feature = "regex"))]
mod regex_benches {
    use super::{test, TEST_STR};
    use regex::Regex;
    use test::Bencher;

    #[bench]
    fn bench_regex(b: &mut Bencher) {
        let re = Regex::new(r"^(0|[1-9][0-9]*)(\.[0-9]+)?([eE]([+-])?[0-9]+)?").unwrap();
        b.iter(|| re.find(test::black_box(TEST_STR)))
    }
}

#[cfg(all(test, feature = "nom"))]
mod nom_benches {
    use super::{test, TEST_STR};
    use nom::digit;
    use test::Bencher;

    named!(digits<()>, fold_many1!(digit, (), |_, _| ()));

    named!(
        nom_num<()>,
        do_parse!(
            opt!(char!('-'))
                >> alt!(map!(char!('0'), |_| ()) | digits)
                >> opt!(do_parse!(char!('.') >> digits >> ()))
                >> opt!(do_parse!(
                    alt!(char!('e') | char!('E'))
                        >> opt!(alt!(char!('+') | char!('-')))
                        >> digits
                        >> ()
                ))
                >> ()
        )
    );

    #[cfg(feature = "nom")]
    #[bench]
    fn bench_nom(b: &mut Bencher) {
        b.iter(|| nom_num(test::black_box(TEST_STR.as_bytes())))
    }
}

#[cfg(all(test, feature = "combine"))]
mod combine_benches {
    use super::{is_digit, test, TEST_STR};
    use combine::range::take_while1;
    use combine::*;
    use test::Bencher;

    fn my_number(s: &[u8]) -> ParseResult<(), &[u8]> {
        (
            token(b'-').map(Some).or(value(None)),
            token(b'0').map(|_| &b"0"[..]).or(take_while1(is_digit)),
            optional((token(b'.'), take_while1(is_digit))),
            optional((
                token(b'e').or(token(b'E')),
                token(b'-').map(Some).or(token(b'+').map(Some)).or(value(None)),
                take_while1(is_digit),
            )),
        )
            .map(|_| ())
            .parse_stream(s)
    }

    #[bench]
    fn bench_combine(b: &mut Bencher) {
        assert_eq!(parser(my_number).parse(TEST_STR.as_bytes()), Ok(((), &b""[..])));
        b.iter(|| parser(my_number).parse(test::black_box(TEST_STR.as_bytes())))
    }
}

use xi_lang::peg::{Alt, OneByte, OneOrMore, Optional, Peg};

fn is_digit(c: u8) -> bool {
    c >= b'0' && c <= b'9'
}

fn my_number(s: &[u8]) -> Option<usize> {
    (
        Optional('-'),
        Alt('0', OneOrMore(OneByte(is_digit))),
        Optional(('.', OneOrMore(OneByte(is_digit)))),
        Optional((Alt('e', 'E'), Optional(Alt('-', '+')), OneOrMore(OneByte(is_digit)))),
    )
        .p(s)
}

fn main() {
    if let Some(s) = env::args().skip(1).next() {
        println!("my: {:?}", my_number(s.as_bytes()));
        /*
        let mut buf = DataInput::new(s.as_bytes());
        println!("pom: {:?}", pom_number().parse(&mut buf));
        let re = Regex::new(r"^(0|[1-9][0-9]*)(\.[0-9]+)?([eE]([+-])?[0-9]+)?").unwrap();
        println!("regex: {:?}", re.find(&s));
        println!("nom: {:?}", nom_num(s.as_bytes()));
        */
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use test::Bencher;

    #[bench]
    fn bench_my_peg(b: &mut Bencher) {
        b.iter(|| my_number(test::black_box(TEST_STR.as_bytes())))
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! A simple test program for evaluating the speed of cross-thread communications.
extern crate xi_rpc;

use std::sync::mpsc;
use std::thread;

/*
use xi_rpc::chan::Chan;

pub fn test_chan() {
    let n_iter = 1000000;
    let chan1 = Chan::new();
    let chan1s = chan1.clone();
    let chan2 = Chan::new();
    let chan2s = chan2.clone();
    let thread1 = thread::spawn(move|| {
        for _ in 0..n_iter {
            chan2s.try_send(chan1.recv());
        }
    });
    let thread2 = thread::spawn(move|| {
        for _ in 0..n_iter {
            chan1s.try_send(42);
            let _ = chan2.recv();
        }
    });
    let _ = thread1.join();
    let _ = thread2.join();
}
*/

pub fn test_mpsc() {
    let n_iter = 1000000;
    let (chan1s, chan1) = mpsc::channel();
    let (chan2s, chan2) = mpsc::channel();
    let thread1 = thread::spawn(move || {
        for _ in 0..n_iter {
            chan2s.send(chan1.recv()).unwrap();
        }
    });
    let thread2 = thread::spawn(move || {
        for _ in 0..n_iter {
            chan1s.send(42).unwrap();
            let _ = chan2.recv();
        }
    });
    let _ = thread1.join();
    let _ = thread2.join();
}

pub fn main() {
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Generic RPC handling (used for both front end and plugin communication).
//!
//! The RPC protocol is based on [JSON-RPC](http://www.jsonrpc.org/specification),
//! but with some modifications. Unlike JSON-RPC 2.0, requests and notifications
//! are allowed in both directions, rather than imposing client and server roles.
//! Further, the batch form is not supported.
//!
//! Because these changes make the protocol not fully compliant with the spec,
//! the `"jsonrpc"` member is omitted from request and response objects.
#![allow(clippy::boxed_local, clippy::or_fun_call)]

#[macro_use]
extern crate serde_json;
#[macro_use]
extern crate serde_derive;
extern crate crossbeam_utils;
extern crate serde;
extern crate xi_trace;

#[macro_use]
extern crate log;

mod error;
mod parse;

pub mod test_utils;

use std::cmp;
use std::collections::{BTreeMap, BinaryHeap, VecDeque};
use std::io::{self, BufRead, Write};
use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};
use std::sync::mpsc;
use std::sync::{Arc, Condvar, Mutex};
use std::thread;
use std::time::{Duration, Instant};

use serde::de::DeserializeOwned;
use serde_json::Value;

use xi_trace::{trace, trace_block, trace_block_payload, trace_payload};

pub use crate::error::{Error, ReadError, RemoteError};
use crate::parse::{Call, MessageReader, Response, RpcObject};

/// The maximum duration we will block on a reader before checking for an task.
const MAX_IDLE_WAIT: Duration = Duration::from_millis(5);

/// An interface to access the other side of the RPC channel. The main purpose
/// is to send RPC requests and notifications to the peer.
///
/// A single shared `RawPeer` exists for each `RpcLoop`; a reference can
/// be taken with `RpcLoop::get_peer()`.
///
/// In general, `RawPeer` shouldn't be used directly, but behind a pointer as
/// the `Peer` trait object.
pub struct RawPeer<W: Write + 'static>(Arc<RpcState<W>>);

/// The `Peer` trait represents the interface for the other side of the RPC
/// channel. It is intended to be used behind a pointer, a trait object.
pub trait Peer: Send + 'static {
    /// Used to implement `clone` in an object-safe way.
    /// For an explanation on this approach, see
    /// [this thread](https://users.rust-lang.org/t/solved-is-it-possible-to-clone-a-boxed-trait-object/1714/6).
    fn box_clone(&self) -> Box<dyn Peer>;
    /// Sends a notification (asynchronous RPC) to the peer.
    fn send_rpc_notification(&self, method: &str, params: &Value);
    /// Sends a request asynchronously, and the supplied callback will
    /// be called when the response arrives.
    ///
    /// `Callback` is an alias for `FnOnce(Result<Value, Error>)`; it must
    /// be boxed because trait objects cannot use generic paramaters.
    fn send_rpc_request_async(&self, method: &str, params: &Value, f: Box<dyn Callback>);
    /// Sends a request (synchronous RPC) to the peer, and waits for the result.
    fn send_rpc_request(&self, method: &str, params: &Value) -> Result<Value, Error>;
    /// Determines whether an incoming request (or notification) is
    /// pending. This is intended to reduce latency for bulk operations
    /// done in the background.
    fn request_is_pending(&self) -> bool;
    /// Adds a token to the idle queue. When the runloop is idle and the
    /// queue is not empty, the handler's `idle` fn will be called
    /// with the earliest added token.
    fn schedule_idle(&self, token: usize);
    /// Like `schedule_idle`, with the guarantee that the handler's `idle`
    /// fn will not be called _before_ the provided `Instant`.
    ///
    /// # Note
    ///
    /// This is not intended as a high-fidelity timer. Regular RPC messages
    /// will always take priority over an idle task.
    fn schedule_timer(&self, after: Instant, token: usize);
}

/// The `Peer` trait object.
pub type RpcPeer = Box<dyn Peer>;

pub struct RpcCtx {
    peer: RpcPeer,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
/// An RPC command.
///
/// This type is used as a placeholder in various places, and can be
/// used by clients as a catchall type for implementing `MethodHandler`.
pub struct RpcCall {
    pub method: String,
    pub params: Value,
}

/// A trait for types which can handle RPCs.
///
/// Types which implement `MethodHandler` are also responsible for implementing
/// `Parser`; `Parser` is provided when Self::Notification and Self::Request
/// can be used with serde::DeserializeOwned.
pub trait Handler {
    type Notification: DeserializeOwned;
    type Request: DeserializeOwned;
    fn handle_notification(&mut self, ctx: &RpcCtx, rpc: Self::Notification);
    fn handle_request(&mut self, ctx: &RpcCtx, rpc: Self::Request) -> Result<Value, RemoteError>;
    #[allow(unused_variables)]
    fn idle(&mut self, ctx: &RpcCtx, token: usize) {}
}

pub trait Callback: Send {
    fn call(self: Box<Self>, result: Result<Value, Error>);
}

impl<F: Send + FnOnce(Result<Value, Error>)> Callback for F {
    fn call(self: Box<F>, result: Result<Value, Error>) {
        (*self)(result)
    }
}

/// A helper type which shuts down the runloop if a panic occurs while
/// handling an RPC.
struct PanicGuard<'a, W: Write + 'static>(&'a RawPeer<W>);

impl<'a, W: Write + 'static> Drop for PanicGuard<'a, W> {
    fn drop(&mut self) {
        if thread::panicking() {
            error!("panic guard hit, closing runloop");
            self.0.disconnect();
        }
    }
}

trait IdleProc: Send {
    fn call(self: Box<Self>, token: usize);
}

impl<F: Send + FnOnce(usize)> IdleProc for F {
    fn call(self: Box<F>, token: usize) {
        (*self)(token)
    }
}

enum ResponseHandler {
    Chan(mpsc::Sender<Result<Value, Error>>),
    Callback(Box<dyn Callback>),
}

impl ResponseHandler {
    fn invoke(self, result: Result<Value, Error>) {
        match self {
            ResponseHandler::Chan(tx) => {
                let _ = tx.send(result);
            }
            ResponseHandler::Callback(f) => f.call(result),
        }
    }
}

#[derive(Debug, PartialEq, Eq)]
struct Timer {
    fire_after: Instant,
    token: usize,
}

struct RpcState<W: Write> {
    rx_queue: Mutex<VecDeque<Result<RpcObject, ReadError>>>,
    rx_cvar: Condvar,
    writer: Mutex<W>,
    id: AtomicUsize,
    pending: Mutex<BTreeMap<usize, ResponseHandler>>,
    idle_queue: Mutex<VecDeque<usize>>,
    timers: Mutex<BinaryHeap<Timer>>,
    needs_exit: AtomicBool,
    is_blocked: AtomicBool,
}

/// A structure holding the state of a main loop for handling RPC's.
pub struct RpcLoop<W: Write + 'static> {
    reader: MessageReader,
    peer: RawPeer<W>,
}

impl<W: Write + Send> RpcLoop<W> {
    /// Creates a new `RpcLoop` with the given output stream (which is used for
    /// sending requests and notifications, as well as responses).
    pub fn new(writer: W) -> Self {
        let rpc_peer = RawPeer(Arc::new(RpcState {
            rx_queue: Mutex::new(VecDeque::new()),
            rx_cvar: Condvar::new(),
            writer: Mutex::new(writer),
            id: AtomicUsize::new(0),
            pending: Mutex::new(BTreeMap::new()),
            idle_queue: Mutex::new(VecDeque::new()),
            timers: Mutex::new(BinaryHeap::new()),
            needs_exit: AtomicBool::new(false),
            is_blocked: AtomicBool::new(false),
        }));
        RpcLoop { reader: MessageReader::default(), peer: rpc_peer }
    }

    /// Gets a reference to the peer.
    pub fn get_raw_peer(&self) -> RawPeer<W> {
        self.peer.clone()
    }

    /// Starts the event loop, reading lines from the reader until EOF,
    /// or an error occurs.
    ///
    /// Returns `Ok()` in the EOF case, otherwise returns the
    /// underlying `ReadError`.
    ///
    /// # Note:
    /// The reader is supplied via a closure, as basically a workaround
    /// so that the reader doesn't have to be `Send`. Internally, the
    /// main loop starts a separate thread for I/O, and at startup that
    /// thread calls the given closure.
    ///
    /// Calls to the handler happen on the caller's thread.
    ///
    /// Calls to the handler are guaranteed to preserve the order as
    /// they appear on on the channel. At the moment, there is no way
    /// for there to be more than one incoming request to be outstanding.
    pub fn mainloop<R, RF, H>(&mut self, rf: RF, handler: &mut H) -> Result<(), ReadError>
    where
        R: BufRead,
        RF: Send + FnOnce() -> R,
        H: Handler,
    {
        let exit = crossbeam_utils::thread::scope(|scope| {
            let peer = self.get_raw_peer();
            peer.reset_needs_exit();

            let ctx = RpcCtx { peer: Box::new(peer.clone()) };
            scope.spawn(move |_| {
                let mut stream = rf();
                loop {
                    // The main thread cannot return while this thread is active;
                    // when the main thread wants to exit it sets this flag.
                    if self.peer.needs_exit() {
                        trace("read loop exit", &["rpc"]);
                        break;
                    }

                    let json = match self.reader.next(&mut stream) {
                        Ok(json) => json,
                        Err(err) => {
                            if self.peer.0.is_blocked.load(Ordering::Acquire) {
                                error!("failed to parse response json: {}", err);
                                self.peer.disconnect();
                            }
                            self.peer.put_rx(Err(err));
                            break;
                        }
                    };
                    if json.is_response() {
                        let id = json.get_id().unwrap();
                        let _resp =
                            trace_block_payload("read loop response", &["rpc"], format!("{}", id));
                        match json.into_response() {
                            Ok(resp) => {
                                let resp = resp.map_err(Error::from);
                                self.peer.handle_response(id, resp);
                            }
                            Err(msg) => {
                                error!("failed to parse response: {}", msg);
                                self.peer.handle_response(id, Err(Error::InvalidResponse));
                            }
                        }
                    } else {
                        self.peer.put_rx(Ok(json));
                    }
                }
            });

            loop {
                let _guard = PanicGuard(&peer);
                let read_result = next_read(&peer, handler, &ctx);
                let _trace = trace_block("main got msg", &["rpc"]);

                let json = match read_result {
                    Ok(json) => json,
                    Err(err) => {
                        trace_payload("main loop err", &["rpc"], err.to_string());
                        // finish idle work before disconnecting;
                        // this is mostly useful for integration tests.
                        if let Some(idle_token) = peer.try_get_idle() {
                            handler.idle(&ctx, idle_token);
                        }
                        peer.disconnect();
                        return err;
                    }
                };

                let method = json.get_method().map(String::from);
                match json.into_rpc::<H::Notification, H::Request>() {
                    Ok(Call::Request(id, cmd)) => {
                        let _t = trace_block_payload("handle request", &["rpc"], method.unwrap());
                        let result = handler.handle_request(&ctx, cmd);
                        peer.respond(result, id);
                    }
                    Ok(Call::Notification(cmd)) => {
                        let _t = trace_block_payload("handle notif", &["rpc"], method.unwrap());
                        handler.handle_notification(&ctx, cmd);
                    }
                    Ok(Call::InvalidRequest(id, err)) => peer.respond(Err(err), id),
                    Err(err) => {
                        trace_payload("read loop exit", &["rpc"], err.to_string());
                        peer.disconnect();
                        return ReadError::UnknownRequest(err);
                    }
                }
            }
        })
        .unwrap();

        if exit.is_disconnect() {
            Ok(())
        } else {
            Err(exit)
        }
    }
}

/// Returns the next read result, checking for idle work when no
/// result is available.
fn next_read<W, H>(peer: &RawPeer<W>, handler: &mut H, ctx: &RpcCtx) -> Result<RpcObject, ReadError>
where
    W: Write + Send,
    H: Handler,
{
    loop {
        if let Some(result) = peer.try_get_rx() {
            return result;
        }
        // handle timers before general idle work
        let time_to_next_timer = match peer.check_timers() {
            Some(Ok(token)) => {
                do_idle(handler, ctx, token);
                continue;
            }
            Some(Err(duration)) => Some(duration),
            None => None,
        };

        if let Some(idle_token) = peer.try_get_idle() {
            do_idle(handler, ctx, idle_token);
            continue;
        }

        // we don't want to block indefinitely if there's no current idle work,
        // because idle work could be scheduled from another thread.
        let idle_timeout = time_to_next_timer.unwrap_or(MAX_IDLE_WAIT).min(MAX_IDLE_WAIT);

        if let Some(result) = peer.get_rx_timeout(idle_timeout) {
            return result;
        }
    }
}

fn do_idle<H: Handler>(handler: &mut H, ctx: &RpcCtx, token: usize) {
    let _trace = trace_block_payload("do_idle", &["rpc"], format!("token: {}", token));
    handler.idle(ctx, token);
}

impl RpcCtx {
    pub fn get_peer(&self) -> &RpcPeer {
        &self.peer
    }

    /// Schedule the idle handler to be run when there are no requests pending.
    pub fn schedule_idle(&self, token: usize) {
        self.peer.schedule_idle(token)
    }
}

impl<W: Write + Send + 'static> Peer for RawPeer<W> {
    fn box_clone(&self) -> Box<dyn Peer> {
        Box::new((*self).clone())
    }

    fn send_rpc_notification(&self, method: &str, params: &Value) {
        let _trace = trace_block_payload("send notif", &["rpc"], method.to_owned());
        if let Err(e) = self.send(&json!({
            "method": method,
            "params": params,
        })) {
            error!("send error on send_rpc_notification method {}: {}", method, e);
        }
    }

    fn send_rpc_request_async(&self, method: &str, params: &Value, f: Box<dyn Callback>) {
        let _trace = trace_block_payload("send req async", &["rpc"], method.to_owned());
        self.send_rpc_request_common(method, params, ResponseHandler::Callback(f));
    }

    fn send_rpc_request(&self, method: &str, params: &Value) -> Result<Value, Error> {
        let _trace = trace_block_payload("send req sync", &["rpc"], method.to_owned());
        self.0.is_blocked.store(true, Ordering::Release);
        let (tx, rx) = mpsc::channel();
        self.send_rpc_request_common(method, params, ResponseHandler::Chan(tx));
        rx.recv().unwrap_or(Err(Error::PeerDisconnect))
    }

    fn request_is_pending(&self) -> bool {
        let queue = self.0.rx_queue.lock().unwrap();
        !queue.is_empty()
    }

    fn schedule_idle(&self, token: usize) {
        self.0.idle_queue.lock().unwrap().push_back(token);
    }

    fn schedule_timer(&self, after: Instant, token: usize) {
        self.0.timers.lock().unwrap().push(Timer { fire_after: after, token });
    }
}

impl<W: Write> RawPeer<W> {
    fn send(&self, v: &Value) -> Result<(), io::Error> {
        let _trace = trace_block("send", &["rpc"]);
        let mut s = serde_json::to_string(v).unwrap();
        s.push('\n');
        self.0.writer.lock().unwrap().write_all(s.as_bytes())
        // Technically, maybe we should flush here, but doesn't seem to be required.
    }

    fn respond(&self, result: Response, id: u64) {
        let mut response = json!({ "id": id });
        match result {
            Ok(result) => response["result"] = result,
            Err(error) => response["error"] = json!(error),
        };
        if let Err(e) = self.send(&response) {
            error!("error {} sending response to RPC {:?}", e, id);
        }
    }

    fn send_rpc_request_common(&self, method: &str, params: &Value, rh: ResponseHandler) {
        let id = self.0.id.fetch_add(1, Ordering::Relaxed);
        {
            let mut pending = self.0.pending.lock().unwrap();
            pending.insert(id, rh);
        }
        if let Err(e) = self.send(&json!({
            "id": id,
            "method": method,
            "params": params,
        })) {
            let mut pending = self.0.pending.lock().unwrap();
            if let Some(rh) = pending.remove(&id) {
                rh.invoke(Err(Error::Io(e)));
            }
        }
    }

    fn handle_response(&self, id: u64, resp: Result<Value, Error>) {
        let id = id as usize;
        let handler = {
            let mut pending = self.0.pending.lock().unwrap();
            pending.remove(&id)
        };
        match handler {
            Some(responsehandler) => responsehandler.invoke(resp),
            None => warn!("id {} not found in pending", id),
        }
    }

    /// Get a message from the receive queue if available.
    fn try_get_rx(&self) -> Option<Result<RpcObject, ReadError>> {
        let mut queue = self.0.rx_queue.lock().unwrap();
        queue.pop_front()
    }

    /// Get a message from the receive queue, waiting for at most `Duration`
    /// and returning `None` if no message is available.
    fn get_rx_timeout(&self, dur: Duration) -> Option<Result<RpcObject, ReadError>> {
        let mut queue = self.0.rx_queue.lock().unwrap();
        let result = self.0.rx_cvar.wait_timeout(queue, dur).unwrap();
        queue = result.0;
        queue.pop_front()
    }

    /// Adds a message to the receive queue. The message should only
    /// be `None` if the read thread is exiting.
    fn put_rx(&self, json: Result<RpcObject, ReadError>) {
        let mut queue = self.0.rx_queue.lock().unwrap();
        queue.push_back(json);
        self.0.rx_cvar.notify_one();
    }

    fn try_get_idle(&self) -> Option<usize> {
        self.0.idle_queue.lock().unwrap().pop_front()
    }

    /// Checks status of the most imminent timer. If that timer has expired,
    /// returns `Some(Ok(_))`, with the corresponding token.
    /// If a timer exists but has not expired, returns `Some(Err(_))`,
    /// with the error value being the `Duration` until the timer is ready.
    /// Returns `None` if no timers are registered.
    fn check_timers(&self) -> Option<Result<usize, Duration>> {
        let mut timers = self.0.timers.lock().unwrap();
        match timers.peek() {
            None => return None,
            Some(t) => {
                let now = Instant::now();
                if t.fire_after > now {
                    return Some(Err(t.fire_after - now));
                }
            }
        }
        Some(Ok(timers.pop().unwrap().token))
    }

    /// send disconnect error to pending requests.
    fn disconnect(&self) {
        let mut pending = self.0.pending.lock().unwrap();
        let ids = pending.keys().cloned().collect::<Vec<_>>();
        for id in &ids {
            let callback = pending.remove(id).unwrap();
            callback.invoke(Err(Error::PeerDisconnect));
        }
        self.0.needs_exit.store(true, Ordering::Relaxed);
    }

    /// Returns `true` if an error has occured in the main thread.
    fn needs_exit(&self) -> bool {
        self.0.needs_exit.load(Ordering::Relaxed)
    }

    fn reset_needs_exit(&self) {
        self.0.needs_exit.store(false, Ordering::SeqCst);
    }
}

impl Clone for Box<dyn Peer> {
    fn clone(&self) -> Box<dyn Peer> {
        self.box_clone()
    }
}

impl<W: Write> Clone for RawPeer<W> {
    fn clone(&self) -> Self {
        RawPeer(self.0.clone())
    }
}

//NOTE: for our timers to work with Rust's BinaryHeap we want to reverse
//the default comparison; smaller `Instant`'s are considered 'greater'.
impl Ord for Timer {
    fn cmp(&self, other: &Timer) -> cmp::Ordering {
        other.fire_after.cmp(&self.fire_after)
    }
}

impl PartialOrd for Timer {
    fn partial_cmp(&self, other: &Timer) -> Option<cmp::Ordering> {
        Some(self.cmp(other))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_notif() {
        let reader = MessageReader::default();
        let json = reader.parse(r#"{"method": "hi", "params": {"words": "plz"}}"#).unwrap();
        assert!(!json.is_response());
        let rpc = json.into_rpc::<Value, Value>().unwrap();
        match rpc {
            Call::Notification(_) => (),
            _ => panic!("parse failed"),
        }
    }

    #[test]
    fn test_parse_req() {
        let reader = MessageReader::default();
        let json =
            reader.parse(r#"{"id": 5, "method": "hi", "params": {"words": "plz"}}"#).unwrap();
        assert!(!json.is_response());
        let rpc = json.into_rpc::<Value, Value>().unwrap();
        match rpc {
            Call::Request(..) => (),
            _ => panic!("parse failed"),
        }
    }

    #[test]
    fn test_parse_bad_json() {
        // missing "" around params
        let reader = MessageReader::default();
        let json =
            reader.parse(r#"{"id": 5, "method": "hi", params: {"words": "plz"}}"#).err().unwrap();

        match json {
            ReadError::Json(..) => (),
            _ => panic!("parse failed"),
        }
        // not an object
        let json = reader.parse(r#"[5, "hi", {"arg": "val"}]"#).err().unwrap();

        match json {
            ReadError::NotObject => (),
            _ => panic!("parse failed"),
        }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Types and helpers used for testing.

use std::io::{self, Cursor, Write};
use std::sync::mpsc::{channel, Receiver, Sender};
use std::time::{Duration, Instant};

use serde_json::{self, Value};

use super::{Callback, Error, MessageReader, Peer, ReadError, Response, RpcObject};

/// Wraps an instance of `mpsc::Sender`, implementing `Write`.
///
/// This lets the tx side of an mpsc::channel serve as the destination
/// stream for an RPC loop.
pub struct DummyWriter(Sender<String>);

/// Wraps an instance of `mpsc::Receiver`, providing convenience methods
/// for parsing received messages.
pub struct DummyReader(MessageReader, Receiver<String>);

/// An Peer that doesn't do anything.
#[derive(Debug, Clone)]
pub struct DummyPeer;

/// Returns a `(DummyWriter, DummyReader)` pair.
pub fn test_channel() -> (DummyWriter, DummyReader) {
    let (tx, rx) = channel();
    (DummyWriter(tx), DummyReader(MessageReader::default(), rx))
}

/// Given a string type, returns a `Cursor<Vec<u8>>`, which implements
/// `BufRead`.
pub fn make_reader<S: AsRef<str>>(s: S) -> Cursor<Vec<u8>> {
    Cursor::new(s.as_ref().as_bytes().to_vec())
}

impl DummyReader {
    /// Attempts to read a message, returning `None` if the wait exceeds
    /// `timeout`.
    ///
    /// This method makes no assumptions about the contents of the
    /// message, and does no error handling.
    pub fn next_timeout(&mut self, timeout: Duration) -> Option<Result<RpcObject, ReadError>> {
        self.1.recv_timeout(timeout).ok().map(|s| self.0.parse(&s))
    }

    /// Reads and parses a response object.
    ///
    /// # Panics
    ///
    /// Panics if a non-response message is received, or if no message
    /// is received after a reasonable time.
    pub fn expect_response(&mut self) -> Response {
        let raw = self.next_timeout(Duration::from_secs(1)).expect("response should be received");
        let val = raw.as_ref().ok().map(|v| serde_json::to_string(&v.0));
        let resp = raw.map_err(|e| e.to_string()).and_then(|r| r.into_response());

        match resp {
            Err(msg) => panic!("Bad response: {:?}. {}", val, msg),
            Ok(resp) => resp,
        }
    }

    pub fn expect_object(&mut self) -> RpcObject {
        self.next_timeout(Duration::from_secs(1)).expect("expected object").unwrap()
    }

    pub fn expect_rpc(&mut self, method: &str) -> RpcObject {
        let obj = self
            .next_timeout(Duration::from_secs(1))
            .unwrap_or_else(|| panic!("expected rpc \"{}\"", method))
            .unwrap();
        assert_eq!(obj.get_method(), Some(method));
        obj
    }

    pub fn expect_nothing(&mut self) {
        if let Some(thing) = self.next_timeout(Duration::from_millis(500)) {
            panic!("unexpected something {:?}", thing);
        }
    }
}

impl Write for DummyWriter {
    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {
        let s = String::from_utf8(buf.to_vec()).unwrap();
        self.0
            .send(s)
            .map_err(|err| io::Error::new(io::ErrorKind::Other, format!("{:?}", err)))
            .map(|_| buf.len())
    }

    fn flush(&mut self) -> io::Result<()> {
        Ok(())
    }
}

impl Peer for DummyPeer {
    fn box_clone(&self) -> Box<dyn Peer> {
        Box::new(self.clone())
    }
    fn send_rpc_notification(&self, _method: &str, _params: &Value) {}
    fn send_rpc_request_async(&self, _method: &str, _params: &Value, f: Box<dyn Callback>) {
        f.call(Ok("dummy peer".into()))
    }
    fn send_rpc_request(&self, _method: &str, _params: &Value) -> Result<Value, Error> {
        Ok("dummy peer".into())
    }
    fn request_is_pending(&self) -> bool {
        false
    }
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use std::fmt;
use std::io;

use serde::de::{Deserialize, Deserializer};
use serde::ser::{Serialize, Serializer};
use serde_json::{Error as JsonError, Value};

/// The possible error outcomes when attempting to send a message.
#[derive(Debug)]
pub enum Error {
    /// An IO error occurred on the underlying communication channel.
    Io(io::Error),
    /// The peer returned an error.
    RemoteError(RemoteError),
    /// The peer closed the connection.
    PeerDisconnect,
    /// The peer sent a response containing the id, but was malformed.
    InvalidResponse,
}

/// The possible error outcomes when attempting to read a message.
#[derive(Debug)]
pub enum ReadError {
    /// An error occurred in the underlying stream
    Io(io::Error),
    /// The message was not valid JSON.
    Json(JsonError),
    /// The message was not a JSON object.
    NotObject,
    /// The the method and params were not recognized by the handler.
    UnknownRequest(JsonError),
    /// The peer closed the connection.
    Disconnect,
}

/// Errors that can be received from the other side of the RPC channel.
///
/// This type is intended to go over the wire. And by convention
/// should `Serialize` as a JSON object with "code", "message",
/// and optionally "data" fields.
///
/// The xi RPC protocol defines one error: `RemoteError::InvalidRequest`,
/// represented by error code `-32600`; however codes in the range
/// `-32700 ... -32000` (inclusive) are reserved for compatability with
/// the JSON-RPC spec.
///
/// # Examples
///
/// An invalid request:
///
/// ```
/// # extern crate xi_rpc;
/// # extern crate serde_json;
/// use xi_rpc::RemoteError;
/// use serde_json::Value;
///
/// let json = r#"{
///     "code": -32600,
///     "message": "Invalid request",
///     "data": "Additional details"
///     }"#;
///
/// let err = serde_json::from_str::<RemoteError>(&json).unwrap();
/// assert_eq!(err,
///            RemoteError::InvalidRequest(
///                Some(Value::String("Additional details".into()))));
/// ```
///
/// A custom error:
///
/// ```
/// # extern crate xi_rpc;
/// # extern crate serde_json;
/// use xi_rpc::RemoteError;
/// use serde_json::Value;
///
/// let json = r#"{
///     "code": 404,
///     "message": "Not Found"
///     }"#;
///
/// let err = serde_json::from_str::<RemoteError>(&json).unwrap();
/// assert_eq!(err, RemoteError::custom(404, "Not Found", None));
/// ```
#[derive(Debug, Clone, PartialEq)]
pub enum RemoteError {
    /// The JSON was valid, but was not a correctly formed request.
    ///
    /// This Error is used internally, and should not be returned by
    /// clients.
    InvalidRequest(Option<Value>),
    /// A custom error, defined by the client.
    Custom { code: i64, message: String, data: Option<Value> },
    /// An error that cannot be represented by an error object.
    ///
    /// This error is intended to accommodate clients that return arbitrary
    /// error values. It should not be used for new errors.
    Unknown(Value),
}

impl RemoteError {
    /// Creates a new custom error.
    pub fn custom<S, V>(code: i64, message: S, data: V) -> Self
    where
        S: AsRef<str>,
        V: Into<Option<Value>>,
    {
        let message = message.as_ref().into();
        let data = data.into();
        RemoteError::Custom { code, message, data }
    }
}

impl ReadError {
    /// Returns `true` iff this is the `ReadError::Disconnect` variant.
    pub fn is_disconnect(&self) -> bool {
        matches!(*self, ReadError::Disconnect)
    }
}

impl fmt::Display for ReadError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match *self {
            ReadError::Io(ref err) => write!(f, "I/O Error: {:?}", err),
            ReadError::Json(ref err) => write!(f, "JSON Error: {:?}", err),
            ReadError::NotObject => write!(f, "JSON message was not an object."),
            ReadError::UnknownRequest(ref err) => write!(f, "Unknown request: {:?}", err),
            ReadError::Disconnect => write!(f, "Peer closed the connection."),
        }
    }
}

impl From<JsonError> for ReadError {
    fn from(err: JsonError) -> ReadError {
        ReadError::Json(err)
    }
}

impl From<io::Error> for ReadError {
    fn from(err: io::Error) -> ReadError {
        ReadError::Io(err)
    }
}

impl From<JsonError> for RemoteError {
    fn from(err: JsonError) -> RemoteError {
        RemoteError::InvalidRequest(Some(json!(err.to_string())))
    }
}

impl From<RemoteError> for Error {
    fn from(err: RemoteError) -> Error {
        Error::RemoteError(err)
    }
}

#[derive(Deserialize, Serialize)]
struct ErrorHelper {
    code: i64,
    message: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    data: Option<Value>,
}

impl<'de> Deserialize<'de> for RemoteError {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let v = Value::deserialize(deserializer)?;
        let resp = match ErrorHelper::deserialize(&v) {
            Ok(resp) => resp,
            Err(_) => return Ok(RemoteError::Unknown(v)),
        };

        Ok(match resp.code {
            -32600 => RemoteError::InvalidRequest(resp.data),
            _ => RemoteError::Custom { code: resp.code, message: resp.message, data: resp.data },
        })
    }
}

impl Serialize for RemoteError {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let (code, message, data) = match *self {
            RemoteError::InvalidRequest(ref d) => (-32600, "Invalid request", d),
            RemoteError::Custom { code, ref message, ref data } => (code, message.as_ref(), data),
            RemoteError::Unknown(_) => panic!(
                "The 'Unknown' error variant is \
                 not intended for client use."
            ),
        };
        let message = message.to_owned();
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Parsing of raw JSON messages into RPC objects.

use std::io::BufRead;

use serde::de::DeserializeOwned;
use serde_json::{Error as JsonError, Value};

use crate::error::{ReadError, RemoteError};

/// A unique identifier attached to request RPCs.
type RequestId = u64;

/// An RPC response, received from the peer.
pub type Response = Result<Value, RemoteError>;

/// Reads and parses RPC messages from a stream, maintaining an
/// internal buffer.
#[derive(Debug, Default)]
pub struct MessageReader(String);

/// An internal type used during initial JSON parsing.
///
/// Wraps an arbitrary JSON object, which may be any valid or invalid
/// RPC message. This allows initial parsing and response handling to
/// occur on the read thread. If the message looks like a request, it
/// is passed to the main thread for handling.
#[derive(Debug, Clone)]
pub struct RpcObject(pub Value);

#[derive(Debug, Clone, PartialEq)]
/// An RPC call, which may be either a notification or a request.
pub enum Call<N, R> {
    /// An id and an RPC Request
    Request(RequestId, R),
    /// An RPC Notification
    Notification(N),
    /// A malformed request: the request contained an id, but could
    /// not be parsed. The client will receive an error.
    InvalidRequest(RequestId, RemoteError),
}

impl MessageReader {
    /// Attempts to read the next line from the stream and parse it as
    /// an RPC object.
    ///
    /// # Errors
    ///
    /// This function will return an error if there is an underlying
    /// I/O error, if the stream is closed, or if the message is not
    /// a valid JSON object.
    pub fn next<R: BufRead>(&mut self, reader: &mut R) -> Result<RpcObject, ReadError> {
        self.0.clear();
        let _ = reader.read_line(&mut self.0)?;
        if self.0.is_empty() {
            Err(ReadError::Disconnect)
        } else {
            self.parse(&self.0)
        }
    }

    /// Attempts to parse a &str as an RPC Object.
    ///
    /// This should not be called directly unless you are writing tests.
    #[doc(hidden)]
    pub fn parse(&self, s: &str) -> Result<RpcObject, ReadError> {
        let _trace = xi_trace::trace_block("parse", &["rpc"]);
        let val = serde_json::from_str::<Value>(&s)?;
        if !val.is_object() {
            Err(ReadError::NotObject)
        } else {
            Ok(val.into())
        }
    }
}

impl RpcObject {
    /// Returns the 'id' of the underlying object, if present.
    pub fn get_id(&self) -> Option<RequestId> {
        self.0.get("id").and_then(Value::as_u64)
    }

    /// Returns the 'method' field of the underlying object, if present.
    pub fn get_method(&self) -> Option<&str> {
        self.0.get("method").and_then(Value::as_str)
    }

    /// Returns `true` if this object looks like an RPC response;
    /// that is, if it has an 'id' field and does _not_ have a 'method'
    /// field.
    pub fn is_response(&self) -> bool {
        self.0.get("id").is_some() && self.0.get("method").is_none()
    }

    /// Attempts to convert the underlying `Value` into an RPC response
    /// object, and returns the result.
    ///
    /// The caller is expected to verify that the object is a response
    /// before calling this method.
    ///
    /// # Errors
    ///
    /// If the `Value` is not a well formed response object, this will
    /// return a `String` containing an error message. The caller should
    /// print this message and exit.
    pub fn into_response(mut self) -> Result<Response, String> {
        let _ = self.get_id().ok_or("Response requires 'id' field.".to_string())?;

        if self.0.get("result").is_some() == self.0.get("error").is_some() {
            return Err("RPC response must contain exactly one of\
                        'error' or 'result' fields."
                .into());
        }
        let result = self.0.as_object_mut().and_then(|obj| obj.remove("result"));

        match result {
            Some(r) => Ok(Ok(r)),
            None => {
                let error = self.0.as_object_mut().and_then(|obj| obj.remove("error")).unwrap();
                match serde_json::from_value::<RemoteError>(error) {
                    Ok(e) => Ok(Err(e)),
                    Err(e) => Err(format!("Error handling response: {:?}", e)),
                }
            }
        }
    }

    /// Attempts to convert the underlying `Value` into either an RPC
    /// notification or request.
    ///
    /// # Errors
    ///
    /// Returns a `serde_json::Error` if the `Value` cannot be converted
    /// to one of the expected types.
    pub fn into_rpc<N, R>(self) -> Result<Call<N, R>, JsonError>
    where
        N: DeserializeOwned,
        R: DeserializeOwned,
    {
        let id = self.get_id();
        match id {
            Some(id) => match serde_json::from_value::<R>(self.0) {
                Ok(resp) => Ok(Call::Request(id, resp)),
                Err(err) => Ok(Call::InvalidRequest(id, err.into())),
            },
            None => {
                let result = serde_json::from_value::<N>(self.0)?;
                Ok(Call::Notification(result))
            }
        }
    }
}

impl From<Value> for RpcObject {
    fn from(v: Value) -> RpcObject {
        RpcObject(v)
    }
}

#[cfg(test)]
mod tests {

    use super::*;
    use serde_json;

    #[derive(Serialize, Deserialize, Debug, PartialEq)]
    #[serde(rename_all = "snake_case")]
    #[serde(tag = "method", content = "params")]
    enum TestR {
        NewView { file_path: Option<String> },
        OldView { file_path: usize },
    }

    #[derive(Serialize, Deserialize, Debug, PartialEq)]
    #[serde(rename_all = "snake_case")]
    #[serde(tag = "method", content = "params")]
    enum TestN {
        CloseView { view_id: String },
        Save { view_id: String, file_path: String },
    }

    #[test]
    fn request_success() {
        let json = r#"{"id":0,"method":"new_view","params":{}}"#;
        let p: RpcObject = serde_json::from_str::<Value>(json).unwrap().into();
        assert!(!p.is_response());
        let req = p.into_rpc::<TestN, TestR>().unwrap();
        assert_eq!(req, Call::Request(0, TestR::NewView { file_path: None }));
    }

    #[test]
    fn request_failure() {
        // method does not exist
        let json = r#"{"id":0,"method":"new_truth","params":{}}"#;
        let p: RpcObject = serde_json::from_str::<Value>(json).unwrap().into();
        let req = p.into_rpc::<TestN, TestR>().unwrap();
        let is_ok = match req {
            Call::InvalidRequest(0, _) => true,
            _ => false,
        };
        if !is_ok {
            panic!("{:?}", req);
        }
    }

    #[test]
    fn notif_with_id() {
        // method is a notification, should not have ID
        let json = r#"{"id":0,"method":"close_view","params":{"view_id": "view-id-1"}}"#;
        let p: RpcObject = serde_json::from_str::<Value>(json).unwrap().into();
        let req = p.into_rpc::<TestN, TestR>().unwrap();
        let is_ok = match req {
            Call::InvalidRequest(0, _) => true,
            _ => false,
        };
        if !is_ok {
            panic!("{:?}", req);
        }
    }

    #[test]
    fn test_resp_err() {
        let json = r#"{"id":5,"error":{"code":420, "message":"chill out"}}"#;
        let p: RpcObject = serde_json::from_str::<Value>(json).unwrap().into();
        assert!(p.is_response());
        let resp = p.into_response().unwrap();
        assert_eq!(resp, Err(RemoteError::custom(420, "chill out", None)));
    }

    #[test]
    fn test_resp_result() {
        let json = r#"{"id":5,"result":"success!"}"#;
        let p: RpcObject = serde_json::from_str::<Value>(json).unwrap().into();
        assert!(p.is_response());
        let resp = p.into_response().unwrap();
        assert_eq!(resp, Ok(json!("success!")));
    }

    #[test]
    fn test_err() {
        let json = r#"{"code": -32600, "message": "Invalid Request"}"#;
        let e = serde_json::from_str::<RemoteError>(json).unwrap();
// Copyright 2017 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#[macro_use]
extern crate serde_json;
extern crate xi_rpc;

use std::io;
use std::time::Duration;

use serde_json::Value;
use xi_rpc::test_utils::{make_reader, test_channel};
use xi_rpc::{Handler, ReadError, RemoteError, RpcCall, RpcCtx, RpcLoop};

/// Handler that responds to requests with whatever params they sent.
pub struct EchoHandler;

#[allow(unused)]
impl Handler for EchoHandler {
    type Notification = RpcCall;
    type Request = RpcCall;
    fn handle_notification(&mut self, ctx: &RpcCtx, rpc: Self::Notification) {}
    fn handle_request(&mut self, ctx: &RpcCtx, rpc: Self::Request) -> Result<Value, RemoteError> {
        Ok(rpc.params)
    }
}

#[test]
fn test_recv_notif() {
    // we should not reply to a well formed notification
    let mut handler = EchoHandler;
    let (tx, mut rx) = test_channel();
    let mut rpc_looper = RpcLoop::new(tx);
    let r = make_reader(r#"{"method": "hullo", "params": {"words": "plz"}}"#);
    assert!(rpc_looper.mainloop(|| r, &mut handler).is_ok());
    let resp = rx.next_timeout(Duration::from_millis(100));
    assert!(resp.is_none());
}

#[test]
fn test_recv_resp() {
    // we should reply to a well formed request
    let mut handler = EchoHandler;
    let (tx, mut rx) = test_channel();
    let mut rpc_looper = RpcLoop::new(tx);
    let r = make_reader(r#"{"id": 1, "method": "hullo", "params": {"words": "plz"}}"#);
    assert!(rpc_looper.mainloop(|| r, &mut handler).is_ok());
    let resp = rx.expect_response().unwrap();
    assert_eq!(resp["words"], json!("plz"));
    // do it again
    let r = make_reader(r#"{"id": 0, "method": "hullo", "params": {"words": "yay"}}"#);
    assert!(rpc_looper.mainloop(|| r, &mut handler).is_ok());
    let resp = rx.expect_response().unwrap();
    assert_eq!(resp["words"], json!("yay"));
}

#[test]
fn test_recv_error() {
    // a malformed request containing an ID should receive an error
    let mut handler = EchoHandler;
    let (tx, mut rx) = test_channel();
    let mut rpc_looper = RpcLoop::new(tx);
    let r =
        make_reader(r#"{"id": 0, "method": "hullo","args": {"args": "should", "be": "params"}}"#);
    assert!(rpc_looper.mainloop(|| r, &mut handler).is_ok());
    let resp = rx.expect_response();
    assert!(resp.is_err(), "{:?}", resp);
}

#[test]
fn test_bad_json_err() {
    // malformed json should cause the runloop to return an error.
    let mut handler = EchoHandler;
    let mut rpc_looper = RpcLoop::new(io::sink());
    let r = make_reader(r#"this is not valid json"#);
    let exit = rpc_looper.mainloop(|| r, &mut handler);
    match exit {
        Err(ReadError::Json(_)) => (),
        Err(err) => panic!("Incorrect error: {:?}", err),
        Ok(()) => panic!("Expected an error"),
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Run line break test data.

// Run on:
// http://www.unicode.org/Public/UCD/latest/ucd/auxiliary/LineBreakTest.txt
// or use randomized data from tools/gen_rand_icu.cc (same format)
extern crate xi_unicode;

use xi_unicode::{LineBreakIterator, LineBreakLeafIter};

use std::fs::File;
use std::io::prelude::*;
use std::io::BufReader;

fn quote_str(s: &str) -> String {
    let mut result = String::new();
    for c in s.chars() {
        if c == '"' || c == '\\' {
            result.push('\\');
        }
        if ' ' <= c && c <= '~' {
            result.push(c);
        } else {
            result.push_str(&format!("\\u{{{:04x}}}", c as u32));
        }
    }
    result
}

fn check_breaks(s: &str, breaks: &[usize]) -> bool {
    let my_breaks = LineBreakIterator::new(s).map(|(bk, _hard)| bk).collect::<Vec<_>>();
    if my_breaks != breaks {
        println!("failed case: \"{}\"", quote_str(s));
        println!("expected {:?} actual {:?}", breaks, my_breaks);
        return false;
    }
    true
}

// Verify that starting iteration at a break is insensitive to look-behind.
fn check_lb(s: &str) -> bool {
    let breaks = LineBreakIterator::new(s).collect::<Vec<_>>();
    for i in 0..breaks.len() - 1 {
        let mut cursor = LineBreakLeafIter::new(s, breaks[i].0);
        for &bk in &breaks[i + 1..] {
            let mut next = cursor.next(s);
            if next.0 == s.len() {
                next = (s.len(), true);
            }
            if next != bk {
                println!("failed case: \"{}\"", quote_str(s));
                println!("expected {:?} actual {:?}", bk, next);
                return false;
            }
        }
    }
    true
}

fn run_test(filename: &str, lb: bool) -> std::io::Result<()> {
    let f = File::open(filename)?;
    let mut reader = BufReader::new(f);
    let mut pass = 0;
    let mut total = 0;
    loop {
        let mut line = String::new();
        if reader.read_line(&mut line)? == 0 {
            break;
        };
        let mut s = String::new();
        let mut breaks = Vec::new();
        for token in line.split_whitespace() {
            if token == "÷" {
                breaks.push(s.len());
            } else if token == "×" {
            } else if token == "#" {
                break;
            } else if let Ok(cp) = u32::from_str_radix(token, 16) {
                s.push(std::char::from_u32(cp).unwrap());
            }
        }
        total += 1;
        if lb {
            if check_lb(&s) {
                pass += 1;
            }
        } else {
            if check_breaks(&s, &breaks) {
                pass += 1;
            }
        }
    }
    println!("{}/{} pass", pass, total);
    Ok(())
}

fn main() {
    let mut args = std::env::args();
    let _ = args.next();
    let filename = args.next().unwrap();
    match args.next() {
        None => {
            let _ = run_test(&filename, false);
        }
        Some(ref s) if s == "--lookbehind" => {
            let _ = run_test(&filename, true);
        }
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Unicode utilities useful for text editing, including a line breaking iterator.
#![no_std]

extern crate alloc;

mod tables;

use core::cmp::Ordering;

use crate::tables::*;

/// The Unicode line breaking property of the given code point.
///
/// This is given as a numeric value which matches the ULineBreak
/// enum value from ICU.
pub fn linebreak_property(cp: char) -> u8 {
    let cp = cp as usize;
    if cp < 0x800 {
        LINEBREAK_1_2[cp]
    } else if cp < 0x10000 {
        let child = LINEBREAK_3_ROOT[cp >> 6];
        LINEBREAK_3_CHILD[(child as usize) * 0x40 + (cp & 0x3f)]
    } else {
        let mid = LINEBREAK_4_ROOT[cp >> 12];
        let leaf = LINEBREAK_4_MID[(mid as usize) * 0x40 + ((cp >> 6) & 0x3f)];
        LINEBREAK_4_LEAVES[(leaf as usize) * 0x40 + (cp & 0x3f)]
    }
}

/// The Unicode line breaking property of the given code point.
///
/// Look up the line breaking property for the first code point in the
/// string. Return the property as a numeric value, and also the utf-8
/// length of the codepoint, for convenience.
pub fn linebreak_property_str(s: &str, ix: usize) -> (u8, usize) {
    let b = s.as_bytes()[ix];
    if b < 0x80 {
        (LINEBREAK_1_2[b as usize], 1)
    } else if b < 0xe0 {
        // 2 byte UTF-8 sequences
        let cp = ((b as usize) << 6) + (s.as_bytes()[ix + 1] as usize) - 0x3080;
        (LINEBREAK_1_2[cp], 2)
    } else if b < 0xf0 {
        // 3 byte UTF-8 sequences
        let mid_ix = ((b as usize) << 6) + (s.as_bytes()[ix + 1] as usize) - 0x3880;
        let mid = LINEBREAK_3_ROOT[mid_ix];
        (LINEBREAK_3_CHILD[(mid as usize) * 0x40 + (s.as_bytes()[ix + 2] as usize) - 0x80], 3)
    } else {
        // 4 byte UTF-8 sequences
        let mid_ix = ((b as usize) << 6) + (s.as_bytes()[ix + 1] as usize) - 0x3c80;
        let mid = LINEBREAK_4_ROOT[mid_ix];
        let leaf_ix = ((mid as usize) << 6) + (s.as_bytes()[ix + 2] as usize) - 0x80;
        let leaf = LINEBREAK_4_MID[leaf_ix];
        (LINEBREAK_4_LEAVES[(leaf as usize) * 0x40 + (s.as_bytes()[ix + 3] as usize) - 0x80], 4)
    }
}

/// An iterator which produces line breaks according to the UAX 14 line
/// breaking algorithm. For each break, return a tuple consisting of the offset
/// within the source string and a bool indicating whether it's a hard break.
///
/// There is never a break at the beginning of the string (thus, the empty string
/// produces no breaks). For non-empty strings, there is always a break at the
/// end. It is indicated as a hard break when the string is terminated with a
/// newline or other Unicode explicit line-end character.
#[derive(Copy, Clone)]
pub struct LineBreakIterator<'a> {
    s: &'a str,
    ix: usize,
    state: u8,
}

impl<'a> Iterator for LineBreakIterator<'a> {
    type Item = (usize, bool);

    // return break pos and whether it's a hard break
    fn next(&mut self) -> Option<(usize, bool)> {
        loop {
            match self.ix.cmp(&self.s.len()) {
                Ordering::Greater => {
                    return None;
                }
                Ordering::Equal => {
                    // LB3, break at EOT
                    self.ix += 1;
                    let i = (self.state as usize) * N_LINEBREAK_CATEGORIES;
                    let new = LINEBREAK_STATE_MACHINE[i];
                    return Some((self.s.len(), new >= 0xc0));
                }
                Ordering::Less => {
                    let (lb, len) = linebreak_property_str(self.s, self.ix);
                    let i = (self.state as usize) * N_LINEBREAK_CATEGORIES + (lb as usize);
                    let new = LINEBREAK_STATE_MACHINE[i];
                    //println!("{:?}[{}], state {} + lb {} -> {}", &self.s[self.ix..], self.ix, self.state, lb, new);
                    let result = self.ix;
                    self.ix += len;
                    if (new as i8) < 0 {
                        // break found
                        self.state = new & 0x3f;
                        return Some((result, new >= 0xc0));
                    } else {
                        self.state = new;
                    }
                }
            }
        }
    }
}

impl<'a> LineBreakIterator<'a> {
    /// Create a new iterator for the given string slice.
    pub fn new(s: &str) -> LineBreakIterator {
        if s.is_empty() {
            LineBreakIterator {
                s,
                ix: 1, // LB2, don't break; sot takes priority for empty string
                state: 0,
            }
        } else {
            let (lb, len) = linebreak_property_str(s, 0);
            LineBreakIterator { s, ix: len, state: lb }
        }
    }
}

/// A struct useful for computing line breaks in a rope or other non-contiguous
/// string representation. This is a trickier problem than iterating in a string
/// for a few reasons, the trickiest of which is that in the general case,
/// line breaks require an indeterminate amount of look-behind.
///
/// This is something of an "expert-level" interface, and should only be used if
/// the caller is prepared to respect all the invariants. Otherwise, you might
/// get inconsistent breaks depending on start position and leaf boundaries.
#[derive(Copy, Clone)]
pub struct LineBreakLeafIter {
    ix: usize,
    state: u8,
}

impl Default for LineBreakLeafIter {
    // A default value. No guarantees on what happens when next() is called
    // on this. Intended to be useful for empty ropes.
    fn default() -> LineBreakLeafIter {
        LineBreakLeafIter { ix: 0, state: 0 }
    }
}

impl LineBreakLeafIter {
    /// Create a new line break iterator suitable for leaves in a rope.
    /// Precondition: ix is at a code point boundary within s.
    pub fn new(s: &str, ix: usize) -> LineBreakLeafIter {
        let (lb, len) = if ix == s.len() { (0, 0) } else { linebreak_property_str(s, ix) };
        LineBreakLeafIter { ix: ix + len, state: lb }
    }

    /// Return break pos and whether it's a hard break. Note: hard break
    /// indication may go away, this may not be useful in actual application.
    /// If end of leaf is found, return leaf's len. This does not indicate
    /// a break, as that requires at least one more codepoint of context.
    /// If it is a break, then subsequent next call will return an offset of 0.
    /// EOT is always a break, so in the EOT case it's up to the caller
    /// to figure that out.
    ///
    /// For consistent results, always supply same `s` until end of leaf is
    /// reached (and initially this should be the same as in the `new` call).
    pub fn next(&mut self, s: &str) -> (usize, bool) {
        loop {
            if self.ix == s.len() {
                self.ix = 0; // in preparation for next leaf
                return (s.len(), false);
            }
            let (lb, len) = linebreak_property_str(s, self.ix);
            let i = (self.state as usize) * N_LINEBREAK_CATEGORIES + (lb as usize);
            let new = LINEBREAK_STATE_MACHINE[i];
            //println!("\"{}\"[{}], state {} + lb {} -> {}", &s[self.ix..], self.ix, self.state, lb, new);
            let result = self.ix;
            self.ix += len;
            if (new as i8) < 0 {
                // break found
                self.state = new & 0x3f;
                return (result, new >= 0xc0);
            } else {
                self.state = new;
            }
        }
    }
}

fn is_in_asc_list<T: core::cmp::PartialOrd>(c: T, list: &[T], start: usize, end: usize) -> bool {
    if c == list[start] || c == list[end] {
        return true;
    }
    if end - start <= 1 {
        return false;
    }

    let mid = (start + end) / 2;

    if c >= list[mid] {
        is_in_asc_list(c, &list, mid, end)
    } else {
        is_in_asc_list(c, &list, start, mid)
    }
}

pub fn is_variation_selector(c: char) -> bool {
    (c >= '\u{FE00}' && c <= '\u{FE0F}') || (c >= '\u{E0100}' && c <= '\u{E01EF}')
}

pub trait EmojiExt {
    fn is_regional_indicator_symbol(self) -> bool;
    fn is_emoji_modifier(self) -> bool;
    fn is_emoji_combining_enclosing_keycap(self) -> bool;
    fn is_emoji(self) -> bool;
    fn is_emoji_modifier_base(self) -> bool;
    fn is_tag_spec_char(self) -> bool;
    fn is_emoji_cancel_tag(self) -> bool;
    fn is_zwj(self) -> bool;
}

impl EmojiExt for char {
    fn is_regional_indicator_symbol(self) -> bool {
        self >= '\u{1F1E6}' && self <= '\u{1F1FF}'
    }
    fn is_emoji_modifier(self) -> bool {
        self >= '\u{1F3FB}' && self <= '\u{1F3FF}'
    }
    fn is_emoji_combining_enclosing_keycap(self) -> bool {
        self == '\u{20E3}'
    }
    fn is_emoji(self) -> bool {
        is_in_asc_list(self, &EMOJI_TABLE, 0, EMOJI_TABLE.len() - 1)
    }
    fn is_emoji_modifier_base(self) -> bool {
        is_in_asc_list(self, &EMOJI_MODIFIER_BASE_TABLE, 0, EMOJI_MODIFIER_BASE_TABLE.len() - 1)
    }
    fn is_tag_spec_char(self) -> bool {
        '\u{E0020}' <= self && self <= '\u{E007E}'
    }
    fn is_emoji_cancel_tag(self) -> bool {
        self == '\u{E007F}'
    }
    fn is_zwj(self) -> bool {
        self == '\u{200D}'
    }
}

pub fn is_keycap_base(c: char) -> bool {
    ('0' <= c && c <= '9') || c == '#' || c == '*'
}

#[cfg(test)]
mod tests {
    use crate::linebreak_property;
    use crate::linebreak_property_str;
    use crate::LineBreakIterator;
    use alloc::vec;
    use alloc::vec::*;

    #[test]
    fn linebreak_prop() {
        assert_eq!(9, linebreak_property('\u{0001}'));
        assert_eq!(9, linebreak_property('\u{0003}'));
        assert_eq!(9, linebreak_property('\u{0004}'));
        assert_eq!(9, linebreak_property('\u{0008}'));
        assert_eq!(10, linebreak_property('\u{000D}'));
        assert_eq!(9, linebreak_property('\u{0010}'));
        assert_eq!(9, linebreak_property('\u{0015}'));
        assert_eq!(9, linebreak_property('\u{0018}'));
        assert_eq!(22, linebreak_property('\u{002B}'));
        assert_eq!(16, linebreak_property('\u{002C}'));
        assert_eq!(13, linebreak_property('\u{002D}'));
        assert_eq!(27, linebreak_property('\u{002F}'));
        assert_eq!(19, linebreak_property('\u{0030}'));
        assert_eq!(19, linebreak_property('\u{0038}'));
        assert_eq!(19, linebreak_property('\u{0039}'));
        assert_eq!(16, linebreak_property('\u{003B}'));
        assert_eq!(2, linebreak_property('\u{003E}'));
        assert_eq!(11, linebreak_property('\u{003F}'));
        assert_eq!(2, linebreak_property('\u{0040}'));
        assert_eq!(2, linebreak_property('\u{0055}'));
        assert_eq!(2, linebreak_property('\u{0056}'));
        assert_eq!(2, linebreak_property('\u{0058}'));
        assert_eq!(2, linebreak_property('\u{0059}'));
        assert_eq!(20, linebreak_property('\u{005B}'));
        assert_eq!(22, linebreak_property('\u{005C}'));
        assert_eq!(2, linebreak_property('\u{0062}'));
        assert_eq!(2, linebreak_property('\u{006C}'));
        assert_eq!(2, linebreak_property('\u{006D}'));
        assert_eq!(2, linebreak_property('\u{0071}'));
        assert_eq!(2, linebreak_property('\u{0074}'));
        assert_eq!(2, linebreak_property('\u{0075}'));
        assert_eq!(4, linebreak_property('\u{007C}'));
        assert_eq!(9, linebreak_property('\u{009D}'));
        assert_eq!(2, linebreak_property('\u{00D5}'));
        assert_eq!(2, linebreak_property('\u{00D8}'));
        assert_eq!(2, linebreak_property('\u{00E9}'));
        assert_eq!(2, linebreak_property('\u{0120}'));
        assert_eq!(2, linebreak_property('\u{0121}'));
        assert_eq!(2, linebreak_property('\u{015C}'));
        assert_eq!(2, linebreak_property('\u{016C}'));
        assert_eq!(2, linebreak_property('\u{017E}'));
        assert_eq!(2, linebreak_property('\u{01B0}'));
        assert_eq!(2, linebreak_property('\u{0223}'));
        assert_eq!(2, linebreak_property('\u{028D}'));
        assert_eq!(2, linebreak_property('\u{02BE}'));
        assert_eq!(1, linebreak_property('\u{02D0}'));
        assert_eq!(9, linebreak_property('\u{0337}'));
        assert_eq!(0, linebreak_property('\u{0380}'));
        assert_eq!(2, linebreak_property('\u{04AA}'));
        assert_eq!(2, linebreak_property('\u{04CE}'));
        assert_eq!(2, linebreak_property('\u{04F1}'));
        assert_eq!(2, linebreak_property('\u{0567}'));
        assert_eq!(2, linebreak_property('\u{0580}'));
        assert_eq!(9, linebreak_property('\u{05A1}'));
        assert_eq!(9, linebreak_property('\u{05B0}'));
        assert_eq!(38, linebreak_property('\u{05D4}'));
        assert_eq!(2, linebreak_property('\u{0643}'));
        assert_eq!(9, linebreak_property('\u{065D}'));
        assert_eq!(19, linebreak_property('\u{066C}'));
        assert_eq!(2, linebreak_property('\u{066E}'));
        assert_eq!(2, linebreak_property('\u{068A}'));
        assert_eq!(2, linebreak_property('\u{0776}'));
        assert_eq!(2, linebreak_property('\u{07A2}'));
        assert_eq!(0, linebreak_property('\u{07BB}'));
        assert_eq!(19, linebreak_property('\u{1091}'));
        assert_eq!(19, linebreak_property('\u{1B53}'));
        assert_eq!(2, linebreak_property('\u{1EEA}'));
        assert_eq!(42, linebreak_property('\u{200D}'));
        assert_eq!(14, linebreak_property('\u{30C7}'));
        assert_eq!(14, linebreak_property('\u{318B}'));
        assert_eq!(14, linebreak_property('\u{3488}'));
        assert_eq!(14, linebreak_property('\u{3B6E}'));
        assert_eq!(14, linebreak_property('\u{475B}'));
        assert_eq!(14, linebreak_property('\u{490B}'));
        assert_eq!(14, linebreak_property('\u{5080}'));
        assert_eq!(14, linebreak_property('\u{7846}'));
        assert_eq!(14, linebreak_property('\u{7F3A}'));
        assert_eq!(14, linebreak_property('\u{8B51}'));
        assert_eq!(14, linebreak_property('\u{920F}'));
        assert_eq!(14, linebreak_property('\u{9731}'));
        assert_eq!(14, linebreak_property('\u{9F3A}'));
        assert_eq!(2, linebreak_property('\u{ABD2}'));
        assert_eq!(19, linebreak_property('\u{ABF6}'));
        assert_eq!(32, linebreak_property('\u{B2EA}'));
        assert_eq!(32, linebreak_property('\u{B3F5}'));
        assert_eq!(32, linebreak_property('\u{B796}'));
        assert_eq!(32, linebreak_property('\u{B9E8}'));
        assert_eq!(32, linebreak_property('\u{BD42}'));
        assert_eq!(32, linebreak_property('\u{C714}'));
        assert_eq!(32, linebreak_property('\u{CC25}'));
        assert_eq!(0, linebreak_property('\u{EA59}'));
        assert_eq!(0, linebreak_property('\u{F6C8}'));
        assert_eq!(0, linebreak_property('\u{F83C}'));
        assert_eq!(2, linebreak_property('\u{FC6A}'));
        assert_eq!(0, linebreak_property('\u{15199}'));
        assert_eq!(0, linebreak_property('\u{163AC}'));
        assert_eq!(0, linebreak_property('\u{1EF65}'));
        assert_eq!(14, linebreak_property('\u{235A7}'));
        assert_eq!(14, linebreak_property('\u{2E483}'));
        assert_eq!(14, linebreak_property('\u{2FFFA}'));
        assert_eq!(14, linebreak_property('\u{3613E}'));
        assert_eq!(14, linebreak_property('\u{3799A}'));
        assert_eq!(0, linebreak_property('\u{4DD35}'));
        assert_eq!(0, linebreak_property('\u{5858D}'));
        assert_eq!(0, linebreak_property('\u{585C2}'));
        assert_eq!(0, linebreak_property('\u{6CF38}'));
        assert_eq!(0, linebreak_property('\u{7573F}'));
        assert_eq!(0, linebreak_property('\u{7AABF}'));
        assert_eq!(0, linebreak_property('\u{87762}'));
        assert_eq!(0, linebreak_property('\u{90297}'));
        assert_eq!(0, linebreak_property('\u{9D037}'));
        assert_eq!(0, linebreak_property('\u{A0E65}'));
        assert_eq!(0, linebreak_property('\u{B8E7F}'));
        assert_eq!(0, linebreak_property('\u{BBEA5}'));
        assert_eq!(0, linebreak_property('\u{BE28C}'));
        assert_eq!(0, linebreak_property('\u{C1B57}'));
        assert_eq!(0, linebreak_property('\u{C2011}'));
        assert_eq!(0, linebreak_property('\u{CBF32}'));
        assert_eq!(0, linebreak_property('\u{DD9BD}'));
        assert_eq!(0, linebreak_property('\u{DF4A6}'));
        assert_eq!(0, linebreak_property('\u{E923D}'));
        assert_eq!(0, linebreak_property('\u{E94DB}'));
        assert_eq!(0, linebreak_property('\u{F90AB}'));
        assert_eq!(0, linebreak_property('\u{100EF6}'));
        assert_eq!(0, linebreak_property('\u{106487}'));
        assert_eq!(0, linebreak_property('\u{1064B4}'));
    }

    #[test]
    fn linebreak_prop_str() {
        assert_eq!((9, 1), linebreak_property_str(&"\u{0004}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{0005}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{0008}", 0));
        assert_eq!((4, 1), linebreak_property_str(&"\u{0009}", 0));
        assert_eq!((17, 1), linebreak_property_str(&"\u{000A}", 0));
        assert_eq!((6, 1), linebreak_property_str(&"\u{000C}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{000E}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{0010}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{0013}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{0017}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{001C}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{001D}", 0));
        assert_eq!((9, 1), linebreak_property_str(&"\u{001F}", 0));
        assert_eq!((11, 1), linebreak_property_str(&"\u{0021}", 0));
        assert_eq!((23, 1), linebreak_property_str(&"\u{0027}", 0));
        assert_eq!((22, 1), linebreak_property_str(&"\u{002B}", 0));
        assert_eq!((13, 1), linebreak_property_str(&"\u{002D}", 0));
        assert_eq!((27, 1), linebreak_property_str(&"\u{002F}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{003C}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0043}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{004B}", 0));
        assert_eq!((36, 1), linebreak_property_str(&"\u{005D}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0060}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0065}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0066}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0068}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0069}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{006C}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{006D}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0077}", 0));
        assert_eq!((2, 1), linebreak_property_str(&"\u{0079}", 0));
        assert_eq!((4, 1), linebreak_property_str(&"\u{007C}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{008D}", 0));
        assert_eq!((1, 2), linebreak_property_str(&"\u{00D7}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{015C}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{01B5}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{0216}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{0234}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{026E}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{027C}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{02BB}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{0313}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{0343}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{034A}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{0358}", 0));
        assert_eq!((0, 2), linebreak_property_str(&"\u{0378}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{038C}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{03A4}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{03AC}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{041F}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{049A}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{04B4}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{04C6}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{0535}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{05B1}", 0));
        assert_eq!((0, 2), linebreak_property_str(&"\u{05FF}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{065D}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{067E}", 0));
        assert_eq!((19, 2), linebreak_property_str(&"\u{06F5}", 0));
        assert_eq!((19, 2), linebreak_property_str(&"\u{06F6}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{0735}", 0));
        assert_eq!((2, 2), linebreak_property_str(&"\u{074D}", 0));
        assert_eq!((9, 2), linebreak_property_str(&"\u{07A6}", 0));
        assert_eq!((0, 2), linebreak_property_str(&"\u{07B9}", 0));
        assert_eq!((2, 3), linebreak_property_str(&"\u{131F}", 0));
        assert_eq!((42, 3), linebreak_property_str(&"\u{200D}", 0));
        assert_eq!((2, 3), linebreak_property_str(&"\u{25DA}", 0));
        assert_eq!((2, 3), linebreak_property_str(&"\u{2C01}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{2EE5}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{4207}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{4824}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{491A}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{4C20}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{4D6A}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{50EB}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{521B}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{5979}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{5F9B}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{65AB}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{6B1F}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{7169}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{87CA}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{87FF}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{8A91}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{943A}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{9512}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{9D66}", 0));
        assert_eq!((9, 3), linebreak_property_str(&"\u{A928}", 0));
        assert_eq!((24, 3), linebreak_property_str(&"\u{AA7E}", 0));
        assert_eq!((2, 3), linebreak_property_str(&"\u{AAEA}", 0));
        assert_eq!((0, 3), linebreak_property_str(&"\u{AB66}", 0));
        assert_eq!((32, 3), linebreak_property_str(&"\u{B9FC}", 0));
        assert_eq!((32, 3), linebreak_property_str(&"\u{CD89}", 0));
        assert_eq!((32, 3), linebreak_property_str(&"\u{CDB2}", 0));
        assert_eq!((0, 3), linebreak_property_str(&"\u{F71D}", 0));
        assert_eq!((14, 3), linebreak_property_str(&"\u{F9DF}", 0));
        assert_eq!((2, 3), linebreak_property_str(&"\u{FEC3}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{13CC5}", 0));
        assert_eq!((2, 4), linebreak_property_str(&"\u{1D945}", 0));
        assert_eq!((40, 4), linebreak_property_str(&"\u{1F3C3}", 0));
        assert_eq!((41, 4), linebreak_property_str(&"\u{1F3FB}", 0));
        assert_eq!((14, 4), linebreak_property_str(&"\u{2BDCD}", 0));
        assert_eq!((14, 4), linebreak_property_str(&"\u{3898E}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{45C35}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{4EC30}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{58EE2}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{5E3E8}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{5FB7D}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{6A564}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{6C591}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{6CA82}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{83839}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{88F47}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{91CA0}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{95644}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{AC335}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{AE8BF}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{B282B}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{B4CFC}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{BBED0}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{CCC89}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{D40EB}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{D65F5}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{D8E0B}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{DF93A}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{E4E2C}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{F7935}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{F9DFF}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{1094B7}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{10C782}", 0));
        assert_eq!((0, 4), linebreak_property_str(&"\u{10E4D5}", 0));
    }

    #[test]
    fn lb_iter_simple() {
        assert_eq!(
            vec![(6, false), (11, false)],
            LineBreakIterator::new("hello world").collect::<Vec<_>>()
        );

        // LB7, LB18
        assert_eq!(
            vec![(3, false), (4, false)],
            LineBreakIterator::new("a  b").collect::<Vec<_>>()
        );

        // LB5
        assert_eq!(vec![(2, true), (3, false)], LineBreakIterator::new("a\nb").collect::<Vec<_>>());
        assert_eq!(
            vec![(2, true), (4, true)],
            LineBreakIterator::new("\r\n\r\n").collect::<Vec<_>>()
        );

        // LB8a
        assert_eq!(
            vec![(7, false)],
            LineBreakIterator::new("\u{200D}\u{1F3FB}").collect::<Vec<_>>()
        );

        // LB10 combining mark after space
        assert_eq!(
            vec![(2, false), (4, false)],
            LineBreakIterator::new("a \u{301}").collect::<Vec<_>>()
        );

        // LB15
        assert_eq!(vec![(3, false)], LineBreakIterator::new("\" [").collect::<Vec<_>>());

        // LB17
        assert_eq!(
            vec![(2, false), (10, false), (11, false)],
            LineBreakIterator::new("a \u{2014} \u{2014} c").collect::<Vec<_>>()
        );

        // LB18
        assert_eq!(
            vec![(2, false), (6, false), (7, false)],
            LineBreakIterator::new("a \"b\" c").collect::<Vec<_>>()
        );

        // LB21
        assert_eq!(vec![(2, false), (3, false)], LineBreakIterator::new("a-b").collect::<Vec<_>>());

        // LB21a
        assert_eq!(
            vec![(5, false)],
            LineBreakIterator::new("\u{05D0}-\u{05D0}").collect::<Vec<_>>()
        );

        // LB23a
        assert_eq!(vec![(6, false)], LineBreakIterator::new("$\u{1F3FB}%").collect::<Vec<_>>());

        // LB30b
        assert_eq!(
            vec![(8, false)],
            LineBreakIterator::new("\u{1F466}\u{1F3FB}").collect::<Vec<_>>()
        );

        // LB31
        assert_eq!(
            vec![(8, false), (16, false)],
            LineBreakIterator::new("\u{1F1E6}\u{1F1E6}\u{1F1E6}\u{1F1E6}").collect::<Vec<_>>()
        );
    }

    #[test]
    // The final break is hard only when there is an explicit separator.
    fn lb_iter_eot() {
        assert_eq!(vec![(4, false)], LineBreakIterator::new("abc ").collect::<Vec<_>>());

// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Raw trie data for linebreak property lookup.

// This file autogenerated from LineBreak-10.0.0.txt by mk_tables.py

#[rustfmt::skip]
pub const LINEBREAK_1_2: [u8; 2048] = [
    9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 17, 6, 6, 10, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 26, 11, 23, 2, 22, 21, 2, 23, 20, 36, 2, 22, 16, 13,
    16, 27, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 16, 16, 2, 2, 2, 11, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    20, 22, 36, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 20, 4, 8, 2, 9, 9, 9, 9, 9, 9, 29, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 12, 20, 21, 22,
    22, 22, 2, 1, 1, 2, 1, 23, 2, 4, 2, 2, 21, 22, 1, 1, 5, 2, 1, 1, 1, 1, 1,
    23, 1, 1, 1, 20, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,
    5, 1, 1, 1, 5, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 5, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 12, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 12,
    12, 12, 12, 12, 12, 12, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2,
    2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 16, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2,
    0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9,
    9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 0, 16, 4, 0, 0, 2, 2, 22, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 2, 9, 9, 2, 9, 9, 11, 9, 0, 0, 0, 0,
    0, 0, 0, 0, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,
    38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 0, 0, 0, 0, 0, 38, 38, 38, 2, 2,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 21, 21, 21, 16,
    16, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 9, 0, 11, 11, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 21, 19,
    19, 2, 2, 2, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 11, 2, 9, 9, 9, 9, 9, 9, 9, 2, 2, 9, 9, 9, 9, 9, 9, 2, 2, 9, 9,
    2, 9, 9, 9, 9, 2, 2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 9, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2,
    2, 2, 16, 11, 2, 0, 0, 0, 0, 0,
];

#[rustfmt::skip]
pub const LINEBREAK_3_ROOT: [u8; 1024] = [
    255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
    255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
    255, 255, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
    19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,
    38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 40, 40, 40, 40, 40, 40, 40, 40,
    40, 49, 50, 51, 52, 32, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65,
    66, 67, 68, 69, 70, 71, 72, 73, 40, 40, 40, 74, 40, 40, 40, 40, 75, 76, 77,
    78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 40, 40, 92, 93, 94,
    95, 96, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 40, 40, 40,
    40, 40, 40, 108, 109, 40, 40, 40, 40, 40, 110, 111, 112, 113, 114, 40, 115,
    116, 117, 118, 119, 120, 121, 122, 123, 124, 124, 124, 125, 126, 127, 128,
    129, 130, 124, 131, 132, 133, 134, 124, 135, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 40, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 136, 124, 124, 124, 124,
    124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 137, 138,
    40, 40, 40, 40, 139, 140, 141, 142, 40, 40, 143, 144, 145, 146, 147, 148,
    149, 150, 151, 152, 153, 154, 32, 155, 156, 157, 40, 158, 159, 160, 161,
    162, 163, 164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162,
    163, 164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163,
    164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163, 164,
    165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163, 164, 165,
    159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163, 164, 165, 159,
    160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160,
    161, 162, 163, 164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161,
    162, 163, 164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162,
    163, 164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163,
    164, 165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163, 164,
    165, 159, 160, 161, 162, 163, 164, 165, 159, 160, 161, 162, 163, 164, 165,
    159, 160, 161, 162, 163, 164, 166, 167, 168, 168, 168, 168, 168, 168, 168,
    168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168,
    168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 65, 65, 65, 65, 65, 65,
    65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,
    65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,
    65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,
    65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65,
    65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 124,
    124, 124, 124, 124, 124, 124, 124, 169, 170, 40, 171, 40, 40, 40, 40, 172,
    173, 174, 175, 176, 177, 40, 178, 179, 180, 181, 182,
];

#[rustfmt::skip]
pub const LINEBREAK_3_CHILD: [u8; 11712] = [
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9,
    9, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 9, 9, 9, 2, 9, 9, 9, 9, 9, 0, 0, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 0, 0, 2, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 2, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 9, 9, 4, 4, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2,
    0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 9, 2, 9,
    9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 0, 9, 9, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 9,
    0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 9, 9, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 19, 2, 2, 21, 21, 2, 2, 2, 2, 2, 21, 2, 22, 2, 2, 0, 0, 0, 9, 9, 9, 0,
    2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2,
    0, 2, 2, 0, 0, 9, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 0, 9, 9, 9, 0, 0,
    0, 9, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 2, 2, 2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 9, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,
    0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 9, 2, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9,
    0, 9, 9, 9, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 9,
    9, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 22, 0, 0, 0, 0, 0, 0, 0,
    2, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0,
    0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,
    2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 9, 2, 9, 9, 9, 9, 9, 9,
    9, 0, 0, 9, 9, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 2,
    2, 0, 2, 2, 2, 9, 9, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 2, 2,
    2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 2, 0, 2, 2, 2, 2, 2, 2, 0,
    0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2,
    0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,
    9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 0, 9, 9, 9, 9, 0, 0, 2, 0, 0, 0, 0, 0, 0,
    9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 22, 2, 0, 0, 0, 0, 0, 9, 9, 9, 9, 0, 2,
    2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 0, 0, 2, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 0, 0, 0,
    0, 0, 0, 0, 9, 9, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 9, 9, 0, 0, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 9, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 9, 2, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9,
    9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 9, 9,
    0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 2, 9, 9, 9, 9, 9, 9, 9,
    0, 9, 9, 9, 0, 9, 9, 9, 9, 2, 2, 0, 0, 0, 0, 2, 2, 2, 9, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 9, 9, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 21, 2, 2, 2, 2, 2, 2, 0, 0, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0,
    0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 0, 9, 0,
    9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 19, 0, 0, 9, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0, 0, 0,
    22, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 19, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24,
    24, 0, 24, 0, 0, 24, 24, 0, 24, 0, 0, 24, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24,
    0, 24, 24, 24, 24, 24, 24, 24, 0, 24, 24, 24, 0, 24, 0, 24, 0, 0, 24, 24, 0,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 24, 24, 24, 0, 0, 24,
    24, 24, 24, 24, 0, 24, 0, 24, 24, 24, 24, 24, 24, 0, 0, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 19, 0, 0, 24, 24, 24, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 5,
    5, 2, 5, 5, 12, 5, 5, 4, 12, 11, 11, 11, 11, 11, 12, 2, 11, 2, 2, 2, 9, 9,
    2, 2, 2, 2, 2, 2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 4, 9, 2, 9, 2, 9, 20, 8, 20, 8, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 4, 9, 9, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 4, 4, 2, 2, 2, 2, 2, 2,
    9, 2, 2, 2, 2, 2, 2, 0, 2, 2, 5, 5, 4, 5, 2, 2, 2, 2, 2, 12, 12, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 4, 4, 2, 2, 2, 2, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 24, 24, 24, 24, 24, 24, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 33, 33, 33, 33, 33, 33, 33, 33, 33,
    33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,
    33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,
    33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,
    33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,
    33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 35, 35, 35, 35, 35, 35, 35, 35,
    35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,
    35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,
    35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,
    35, 35, 35, 35, 35, 35, 35, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,
    2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,
    2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 9,
    9, 9, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 20, 8, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,
    0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 9, 9, 9,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 9, 9, 9, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 9, 9, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 4, 4, 18, 24, 4, 2, 4, 22, 24, 24, 0, 0, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    0, 0, 0, 0, 0, 0, 2, 2, 11, 11, 4, 4, 5, 2, 11, 11, 2, 9, 9, 9, 12, 0, 19,
    19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 9, 9, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 9, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 0, 0, 0, 0, 2, 0, 0, 0, 11, 11, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0, 24, 24, 24, 24, 24, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0, 0, 0, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 24, 0, 0, 0, 24, 24, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 0, 0, 2, 2, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0, 9, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 9, 9, 9, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 19, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 0, 0, 0, 4, 4, 4, 4, 4, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 0, 0, 0, 2, 2, 2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,
    2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 2, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 9, 2, 2, 2, 2, 9, 9, 9,
    2, 2, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,
    2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2,
    2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2,
    2, 2, 2, 5, 2, 0, 4, 4, 4, 4, 4, 4, 4, 12, 4, 4, 4, 28, 9, 42, 9, 9, 4, 12,
    4, 4, 3, 1, 1, 2, 23, 23, 20, 23, 23, 23, 20, 23, 1, 1, 2, 2, 15, 15, 15, 4,
    6, 6, 9, 9, 9, 9, 9, 12, 21, 21, 21, 21, 21, 21, 21, 21, 2, 23, 23, 1, 18,
    18, 2, 2, 2, 2, 2, 2, 16, 20, 8, 18, 18, 18, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 30, 2, 2, 2, 2, 0, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 20, 8, 1, 2, 1, 1, 1, 1, 2,
    2, 2, 2, 2, 2, 2, 2, 20, 8, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,
    0, 22, 22, 22, 22, 22, 22, 22, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,
    22, 22, 22, 22, 21, 22, 22, 22, 22, 21, 22, 22, 21, 22, 22, 22, 22, 22, 22,
    22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 21, 2, 1, 2, 2, 2, 21, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 1, 2, 2, 22, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,
    2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2,
    2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,
    2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2,
    1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 22, 22, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1,
    1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2,
    2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2,
    1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1,
    1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,
    2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 15, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 20, 8, 20, 8, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,
    14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 20, 8, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
    2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1,
    1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1,
    2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,
    1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 14, 14, 14, 14, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 14,
    14, 1, 1, 14, 2, 14, 14, 14, 40, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 2, 2, 2, 2, 1, 2, 1, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 14, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 1, 1, 1, 14, 2, 14, 14, 14, 1, 14,
    14, 1, 1, 1, 14, 14, 1, 1, 14, 1, 1, 14, 14, 14, 2, 1, 2, 2, 2, 2, 1, 1, 14,
    1, 1, 1, 1, 1, 1, 14, 14, 14, 14, 14, 1, 14, 14, 40, 14, 1, 1, 14, 14, 14,
    14, 14, 14, 14, 14, 2, 2, 2, 14, 14, 40, 40, 40, 40, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 23, 23, 23, 23, 23,
    23, 2, 11, 11, 14, 2, 2, 2, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 20, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 20, 8, 20, 8, 20, 8, 20,
    8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 20, 8, 20, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 20, 8, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 2, 2, 0, 0, 0, 0, 0, 11, 4, 4,
    4, 2, 11, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2,
    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,
    2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,
    2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2,
    2, 2, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,
    23, 23, 23, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 20, 4, 2, 2, 23, 23, 2, 2, 23, 23,
    20, 8, 20, 8, 20, 8, 20, 8, 4, 4, 4, 4, 11, 2, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2,
    3, 3, 4, 4, 4, 2, 4, 4, 20, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 0, 4, 8, 8, 14, 14, 18, 14,
    14, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 14, 14, 20, 8, 20, 8, 20, 8, 20, 8,
    18, 20, 8, 8, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 9, 9, 9, 9, 9, 9, 14,
    14, 14, 14, 14, 9, 14, 14, 14, 14, 14, 18, 18, 14, 14, 14, 0, 37, 14, 37,
    14, 37, 14, 37, 14, 37, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 37, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 37, 14, 37, 14, 37, 14, 14, 14, 14, 14, 14, 37, 14,
    14, 14, 14, 14, 14, 37, 37, 0, 0, 9, 9, 18, 18, 18, 18, 14, 18, 37, 14, 37,
    14, 37, 14, 37, 14, 37, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 37, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 37, 14, 37, 14, 37, 14, 14, 14, 14, 14, 14, 37, 14,
    14, 14, 14, 14, 14, 37, 37, 14, 14, 14, 14, 18, 37, 18, 18, 14, 0, 0, 0, 0,
    0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 0, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 0, 0, 0, 0, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 37, 37, 37,
    37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 1, 1, 1, 1, 1, 1, 1, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 18, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 11, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 2, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 2, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 2, 4, 4, 4, 4,
    4, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 2, 2, 2, 9, 2, 2, 2, 2, 9, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9,
    9, 9, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 21, 2, 0, 0, 0, 0, 0,
    0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 5, 5, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 19, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 0, 0, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 33, 33, 33, 33,
    33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,
    33, 33, 33, 33, 33, 33, 0, 0, 0, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 0, 2, 19, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 0, 0, 0, 0, 2, 2, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 24, 24, 24, 24,
    24, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 9, 2, 2, 2, 2, 2,
    2, 2, 2, 9, 9, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 2, 4, 4,
    4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 24,
    24, 24, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 4, 4, 2, 2, 2, 9, 9,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0,
    0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2,
    2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9,
    9, 9, 9, 9, 9, 4, 9, 9, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0,
    0, 0, 0, 0, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 31, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,
    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35,
    35, 35, 35, 35, 35, 35, 0, 0, 0, 0, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,
    34, 0, 0, 0, 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,
    25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,
    25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,
    25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 38, 9, 38, 38, 38, 38,
    38, 38, 38, 38, 38, 38, 2, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,
    38, 0, 38, 38, 38, 38, 38, 0, 38, 0, 38, 38, 0, 38, 38, 0, 38, 38, 38, 38,
    38, 38, 38, 38, 38, 38, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 8, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 21, 2, 0,
    0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 16, 8, 8, 16, 16, 11, 11,
    20, 8, 15, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    14, 14, 14, 14, 14, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8, 20, 8,
    14, 14, 20, 8, 14, 14, 14, 14, 14, 14, 14, 8, 14, 8, 0, 18, 18, 11, 11, 14,
    20, 8, 20, 8, 20, 8, 14, 14, 14, 14, 14, 14, 14, 14, 0, 14, 22, 21, 14, 0,
    0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 0, 0, 30, 0, 11, 14, 14, 22, 21, 14, 14, 20, 8, 14, 14, 8,
    14, 8, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 18, 18, 14, 14, 14, 11,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 20, 14, 8, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 20, 14, 8, 14, 20, 8, 8, 20, 8, 8, 18, 14, 37, 37, 37, 37, 37, 37,
    37, 37, 37, 37, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 18, 18, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 0, 0, 0, 14, 14, 14, 14, 14, 14, 0, 0, 14, 14, 14,
    14, 14, 14, 0, 0, 14, 14, 14, 14, 14, 14, 0, 0, 14, 14, 14, 0, 0, 0, 21, 22,
    14, 14, 14, 22, 22, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9,
    9, 9, 7, 1, 0, 0,
];

#[rustfmt::skip]
pub const LINEBREAK_4_ROOT: [u8; 272] = [
    255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,
    255, 0, 1, 2, 3, 4, 5, 6, 7, 8, 5, 5, 9, 5, 10, 11, 12, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 13, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 13,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 14, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5,
];

#[rustfmt::skip]
pub const LINEBREAK_4_MID: [u8; 960] = [
    0, 1, 2, 3, 4, 2, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 2, 2, 14, 15, 16, 17, 7,
    7, 2, 2, 2, 2, 18, 19, 7, 7, 20, 21, 22, 23, 24, 7, 25, 26, 27, 28, 29, 30,
    31, 32, 33, 7, 2, 34, 35, 36, 7, 7, 7, 7, 7, 37, 7, 7, 7, 7, 7, 7, 38, 39,
    40, 41, 42, 43, 44, 45, 46, 7, 47, 48, 49, 50, 7, 7, 51, 52, 53, 54, 7, 7,
    55, 56, 53, 57, 58, 59, 60, 7, 7, 7, 7, 7, 61, 62, 7, 7, 7, 7, 63, 64, 65,
    66, 7, 7, 7, 7, 67, 68, 69, 7, 70, 71, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 72, 7, 2, 73, 2, 2, 2, 74, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 75, 76, 2,
    2, 77, 2, 2, 78, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 2, 2, 2, 2, 2,
    79, 2, 80, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 66, 81, 7, 82,
    83, 84, 85, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 86, 87, 88, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 91, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 89, 89, 89, 89, 92, 93, 89, 89, 89, 89, 89, 94,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 95, 96, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 2, 2, 2, 97, 98, 99, 100, 101, 2, 102, 7, 7, 2, 103, 7, 7, 2, 104,
    105, 106, 107, 108, 2, 2, 2, 2, 109, 2, 2, 2, 2, 110, 2, 2, 2, 2, 2, 2, 2,
    2, 111, 112, 113, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 114, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 2, 2, 115, 2, 116, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 117, 118, 119, 120, 7, 7, 7, 7, 89, 89, 89, 89,
    121, 122, 123, 124, 89, 89, 89, 89, 89, 89, 125, 126, 89, 127, 128, 89, 129,
    130, 131, 132, 89, 133, 134, 135, 2, 136, 2, 137, 138, 139, 140, 89, 141,
    89, 89, 142, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 143, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89,
    89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 143, 144, 145, 7, 7,
    145, 145, 145, 146, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
];

#[rustfmt::skip]
pub const LINEBREAK_4_LEAVES: [u8; 9408] = [
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,
    0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 4,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2,
    2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,
    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 4, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 4, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,
    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 9, 9, 9, 9, 2, 2, 2,
    2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 9, 2, 2, 2, 2, 2,
    2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 0, 0, 0, 0,
    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 0, 0, 0, 0, 2, 2, 2, 2, 2, 4, 4, 4, 4,
    4, 4, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 4, 4, 4, 4, 4, 4,
    4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 4, 4, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    2, 2, 2, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,
    0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 9, 9, 9,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 2, 5, 2, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 4, 4, 2,
    4, 2, 9, 9, 9, 2, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 2, 5, 2, 4,
    4, 4, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 2, 4, 4, 2, 9, 0, 2, 2,
    2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0,
    0, 0, 0, 0, 9, 9, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,
    2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 9, 2, 9, 9, 9, 9, 9, 9, 9, 0, 0,
    9, 9, 0, 0, 9, 9, 9, 0, 0, 2, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 2, 2, 2,
    2, 2, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 2, 2, 2, 2, 4, 4, 4, 4, 2, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    0, 4, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 0, 0,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 4, 4, 11, 11, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4,
    4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 4,
    2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0,
    0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 24, 24, 24,
    24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 24, 24, 0, 0, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
    24, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 24, 24, 4, 4, 4, 24,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 2, 9, 9, 9, 9, 5, 2, 4, 4, 4, 4,
    5, 2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 4, 0, 5, 5, 5, 4, 4, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9,
    9, 2, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,
    0, 0, 5, 11, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9,
    9, 9, 2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,
    4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 20, 20, 20, 8, 8, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 2,
    2, 20, 8, 20, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 20, 8, 8, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 20, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 0, 0, 9, 9, 9, 9, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9,
    9, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 18, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 0, 0, 0,
    0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,
    0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 9, 9, 4, 9, 9, 9,
    9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 2,
    2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2,
    2, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,
    2, 9, 9, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0,
    2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,
    2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,
    0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,
    19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,
    19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    2, 2, 2, 2, 2, 2, 2, 2, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 2,
    2, 4, 4, 4, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9,
    9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9,
    9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,
    2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0,
    0, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 0, 0, 0, 0, 20, 20, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,
    2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2,
    0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0,
    2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 14, 14,
    14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 2, 14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 14, 14, 14, 14, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,
    39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 14, 14, 14, 14, 14,
    40, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 2, 2, 14, 14, 14, 14, 14, 2, 14, 14,
    14, 14, 14, 40, 40, 40, 14, 14, 40, 14, 14, 40, 40, 40, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 41, 41, 41, 41, 41, 14, 14, 40, 40, 14, 14, 40, 40, 40, 40, 40,
    40, 40, 40, 40, 40, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 40, 40, 40, 40, 14, 14, 14, 14, 40, 14, 40,
    40, 40, 40, 40, 40, 40, 40, 40, 14, 14, 14, 40, 14, 14, 14, 14, 40, 40, 40,
    14, 40, 40, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 2, 14, 2, 14, 2, 14, 14, 14, 14, 14, 40,
    14, 14, 14, 14, 2, 14, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 40, 40, 14, 14, 14, 14, 40, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 40, 14, 14, 14, 14, 40, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 40, 40, 40, 14, 14, 14, 40, 40, 40, 40, 40, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 23, 23, 23, 18, 18, 18, 2, 2, 2, 2, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 40, 40, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    40, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 40, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14,
    14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14,
    14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 40, 40, 40, 40, 40, 14, 40, 40, 14, 14,
    14, 14, 14, 14, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14, 40, 40, 40, 40, 40,
    40, 40, 40, 40, 40, 14, 14, 14, 40, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,
    40, 40, 40, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
    14, 14, 14, 14, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
    9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
];
// 51 unique states
pub const N_LINEBREAK_CATEGORIES: usize = 43;

#[rustfmt::skip]
pub const LINEBREAK_STATE_MACHINE: [u8; 3827] = [
    // state 0: XX
    0, 1, 2, 131, 4, 133, 6, 135, 8, 0, 10, 11, 12, 13, 142, 15, 16, 17, 18, 19,
    20, 21, 22, 23, 24, 25, 46, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36, 37,
    38, 167, 168, 169, 0,
    // state 1: AI
    0, 1, 2, 131, 4, 133, 6, 135, 8, 1, 10, 11, 12, 13, 142, 15, 16, 17, 18, 19,
    20, 21, 22, 23, 24, 25, 47, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36, 37,
    38, 167, 168, 169, 1,
    // state 2: AL
    0, 1, 2, 131, 4, 133, 6, 135, 8, 2, 10, 11, 12, 13, 142, 15, 16, 17, 18, 19,
    20, 21, 22, 23, 24, 25, 48, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36, 37,
    38, 167, 168, 169, 2,
    // state 3: B2
    128, 129, 130, 3, 4, 133, 6, 135, 8, 3, 10, 11, 12, 13, 142, 143, 16, 17,
    18, 147, 148, 149, 150, 23, 152, 153, 49, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 3,
    // state 4: BA
    128, 129, 130, 131, 4, 133, 6, 135, 8, 4, 10, 11, 140, 13, 142, 143, 16, 17,
    18, 147, 148, 149, 150, 23, 152, 153, 50, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 4,
    // state 5: BB
    0, 1, 2, 3, 4, 5, 6, 135, 8, 5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 51, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 5,
    // state 6: BK
    192, 193, 194, 195, 196, 197, 198, 199, 200, 194, 202, 203, 204, 205, 206,
    207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,
    222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 194,
    // state 7: CB
    128, 129, 130, 131, 132, 133, 6, 135, 8, 7, 10, 11, 12, 141, 142, 143, 16,
    17, 146, 147, 148, 149, 150, 23, 152, 153, 53, 27, 28, 29, 30, 159, 160,
    161, 162, 163, 36, 165, 166, 167, 168, 169, 7,
    // state 8: CL
    128, 129, 130, 131, 4, 133, 6, 135, 8, 8, 10, 11, 12, 13, 142, 143, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 54, 27, 28, 29, 30, 159, 160, 161, 162,
    163, 36, 37, 166, 167, 168, 169, 8,
    // state 9: CM
    0, 1, 2, 131, 4, 133, 6, 135, 8, 9, 10, 11, 12, 13, 142, 15, 16, 17, 18, 19,
    20, 21, 22, 23, 24, 25, 55, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36, 37,
    38, 167, 168, 169, 9,
    // state 10: CR
    192, 193, 194, 195, 196, 197, 198, 199, 200, 194, 202, 203, 204, 205, 206,
    207, 208, 17, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,
    222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 194,
    // state 11: EX
    128, 129, 130, 131, 4, 133, 6, 135, 8, 11, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 149, 150, 23, 152, 153, 57, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 11,
    // state 12: GL
    0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 58, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 12,
    // state 13: HY
    128, 129, 130, 131, 4, 133, 6, 135, 8, 13, 10, 11, 140, 13, 142, 143, 16,
    17, 18, 19, 148, 149, 150, 23, 152, 153, 59, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 13,
    // state 14: ID
    128, 129, 130, 131, 4, 133, 6, 135, 8, 14, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 60, 27, 28, 29, 30, 159, 160, 161, 162,
    163, 36, 37, 166, 167, 168, 169, 14,
    // state 15: IN
    128, 129, 130, 131, 4, 133, 6, 135, 8, 15, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 149, 150, 23, 152, 153, 61, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 15,
    // state 16: IS
    0, 1, 2, 131, 4, 133, 6, 135, 8, 16, 10, 11, 12, 13, 142, 143, 16, 17, 18,
    19, 148, 149, 150, 23, 24, 25, 62, 27, 28, 29, 30, 159, 160, 161, 162, 163,
    36, 37, 38, 167, 168, 169, 16,
    // state 17: LF
    192, 193, 194, 195, 196, 197, 198, 199, 200, 194, 202, 203, 204, 205, 206,
    207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,
    222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 194,
    // state 18: NS
    128, 129, 130, 131, 4, 133, 6, 135, 8, 18, 10, 11, 12, 13, 142, 143, 16, 17,
    18, 147, 148, 149, 150, 23, 152, 153, 64, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 18,
    // state 19: NU
    0, 1, 2, 131, 4, 133, 6, 135, 8, 19, 10, 11, 12, 13, 142, 15, 16, 17, 18,
    19, 20, 21, 22, 23, 24, 25, 65, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36,
    37, 38, 167, 168, 169, 19,
    // state 20: OP
    0, 1, 2, 3, 4, 5, 6, 7, 8, 20, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 66, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 20,
    // state 21: PO
    0, 1, 2, 131, 4, 133, 6, 135, 8, 21, 10, 11, 12, 13, 142, 143, 16, 17, 18,
    19, 20, 149, 150, 23, 24, 25, 67, 27, 28, 29, 30, 159, 160, 161, 162, 163,
    36, 37, 38, 167, 168, 169, 21,
    // state 22: PR
    0, 1, 2, 131, 4, 133, 6, 135, 8, 22, 10, 11, 12, 13, 14, 143, 16, 17, 18,
    19, 20, 149, 150, 23, 24, 25, 68, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,
    37, 38, 167, 40, 41, 22,
    // state 23: QU
    0, 1, 2, 3, 4, 5, 6, 7, 8, 23, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 69, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 23,
    // state 24: SA
    0, 1, 2, 131, 4, 133, 6, 135, 8, 24, 10, 11, 12, 13, 142, 15, 16, 17, 18,
    19, 20, 21, 22, 23, 24, 25, 70, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36,
    37, 38, 167, 168, 169, 24,
    // state 25: SG
    0, 1, 2, 131, 4, 133, 6, 135, 8, 25, 10, 11, 12, 13, 142, 15, 16, 17, 18,
    19, 20, 21, 22, 23, 24, 25, 71, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36,
    37, 38, 167, 168, 169, 25,
    // state 26: SP
    128, 129, 130, 131, 132, 133, 6, 135, 8, 130, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 72, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 130,
    // state 27: SY
    128, 129, 130, 131, 4, 133, 6, 135, 8, 27, 10, 11, 12, 13, 142, 143, 16, 17,
    18, 19, 148, 149, 150, 23, 152, 153, 73, 27, 28, 29, 30, 159, 160, 161, 162,
    163, 36, 37, 38, 167, 168, 169, 27,
    // state 28: ZW
    128, 129, 130, 131, 132, 133, 6, 135, 136, 130, 10, 139, 140, 141, 142, 143,
    144, 17, 146, 147, 148, 149, 150, 151, 152, 153, 74, 155, 28, 29, 158, 159,
    160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 130,
    // state 29: NL
    192, 193, 194, 195, 196, 197, 198, 199, 200, 194, 202, 203, 204, 205, 206,
    207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,
    222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 194,
    // state 30: WJ
    0, 1, 2, 3, 4, 5, 6, 7, 8, 30, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 76, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 30,
    // state 31: H2
    128, 129, 130, 131, 4, 133, 6, 135, 8, 31, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 77, 27, 28, 29, 30, 159, 160, 161, 34,
    35, 36, 37, 166, 167, 168, 169, 31,
    // state 32: H3
    128, 129, 130, 131, 4, 133, 6, 135, 8, 32, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 78, 27, 28, 29, 30, 159, 160, 161, 34,
    163, 36, 37, 166, 167, 168, 169, 32,
    // state 33: JL
    128, 129, 130, 131, 4, 133, 6, 135, 8, 33, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 79, 27, 28, 29, 30, 31, 32, 33, 162,
    35, 36, 37, 166, 167, 168, 169, 33,
    // state 34: JT
    128, 129, 130, 131, 4, 133, 6, 135, 8, 34, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 80, 27, 28, 29, 30, 159, 160, 161, 34,
    163, 36, 37, 166, 167, 168, 169, 34,
    // state 35: JV
    128, 129, 130, 131, 4, 133, 6, 135, 8, 35, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 81, 27, 28, 29, 30, 159, 160, 161, 34,
    35, 36, 37, 166, 167, 168, 169, 35,
    // state 36: CP
    0, 1, 2, 131, 4, 133, 6, 135, 8, 36, 10, 11, 12, 13, 142, 143, 16, 17, 18,
    19, 148, 21, 22, 23, 24, 25, 82, 27, 28, 29, 30, 159, 160, 161, 162, 163,
    36, 37, 38, 167, 168, 169, 36,
    // state 37: CJ
    128, 129, 130, 131, 4, 133, 6, 135, 8, 37, 10, 11, 12, 13, 142, 143, 16, 17,
    18, 147, 148, 149, 150, 23, 152, 153, 83, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 37,
    // state 38: HL
    0, 1, 2, 131, 44, 133, 6, 135, 8, 38, 10, 11, 12, 43, 142, 15, 16, 17, 18,
    19, 20, 21, 22, 23, 24, 25, 84, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36,
    37, 38, 167, 168, 169, 38,
    // state 39: RI
    128, 129, 130, 131, 4, 133, 6, 135, 8, 39, 10, 11, 12, 13, 142, 143, 16, 17,
    18, 147, 148, 149, 150, 23, 152, 153, 85, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 45, 168, 169, 39,
    // state 40: EB
    128, 129, 130, 131, 4, 133, 6, 135, 8, 40, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 86, 27, 28, 29, 30, 159, 160, 161, 162,
    163, 36, 37, 166, 167, 168, 41, 40,
    // state 41: EM
    128, 129, 130, 131, 4, 133, 6, 135, 8, 41, 10, 11, 12, 13, 142, 15, 16, 17,
    18, 147, 148, 21, 150, 23, 152, 153, 87, 27, 28, 29, 30, 159, 160, 161, 162,
    163, 36, 37, 166, 167, 168, 169, 41,
    // state 42: ZWJ
    0, 1, 2, 131, 4, 133, 6, 135, 8, 2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
    20, 21, 22, 23, 24, 25, 88, 27, 28, 29, 30, 159, 160, 161, 162, 163, 36, 37,
    38, 167, 40, 41, 2,
    // state 43: HL+HY
    0, 1, 2, 3, 4, 5, 6, 135, 8, 43, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 43, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 43,
    // state 44: HL+BA
    0, 1, 2, 3, 4, 5, 6, 135, 8, 44, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 44, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 44,
    // state 45: RI+RI
    128, 129, 130, 131, 4, 133, 6, 135, 8, 45, 10, 11, 140, 13, 142, 143, 16,
    17, 18, 147, 148, 149, 150, 23, 152, 153, 45, 27, 28, 29, 30, 159, 160, 161,
    162, 163, 36, 37, 166, 167, 168, 169, 45,
    // state 46: SP+ XX
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 47: SP+ AI
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 48: SP+ AL
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 49: SP+ B2
    128, 129, 130, 3, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143, 16,
    17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159, 160,
    161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 50: SP+ BA
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 51: SP+ BB
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 52: SP+ BK
    128, 129, 130, 131, 132, 133, 6, 135, 8, 130, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 130,
    // state 53: SP+ CB
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 54: SP+ CL
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 18, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159, 160,
    161, 162, 163, 36, 37, 166, 167, 168, 169, 170,
    // state 55: SP+ CM
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 56: SP+ CR
    128, 129, 130, 131, 132, 133, 6, 135, 8, 130, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 130,
    // state 57: SP+ EX
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 58: SP+ GL
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 59: SP+ HY
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 60: SP+ ID
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 61: SP+ IN
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 62: SP+ IS
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 63: SP+ LF
    128, 129, 130, 131, 132, 133, 6, 135, 8, 130, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 130,
    // state 64: SP+ NS
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 65: SP+ NU
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 66: SP+ OP
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,
    40, 41, 42,
    // state 67: SP+ PO
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 68: SP+ PR
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 69: SP+ QU
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 20, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159, 160,
    161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 70: SP+ SA
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 71: SP+ SG
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 72: SP+ SP
    128, 129, 130, 131, 132, 133, 6, 135, 8, 130, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 130,
    // state 73: SP+ SY
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 74: SP+ ZW
    128, 129, 130, 131, 132, 133, 6, 135, 136, 130, 10, 139, 140, 141, 142, 143,
    144, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 155, 28, 29, 158, 159,
    160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 130,
    // state 75: SP+ NL
    128, 129, 130, 131, 132, 133, 6, 135, 8, 130, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 130,
    // state 76: SP+ WJ
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 77: SP+ H2
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 78: SP+ H3
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 79: SP+ JL
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 80: SP+ JT
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 81: SP+ JV
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 82: SP+ CP
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 18, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159, 160,
    161, 162, 163, 36, 37, 166, 167, 168, 169, 170,
    // state 83: SP+ CJ
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 84: SP+ HL
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 85: SP+ RI
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 86: SP+ EB
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 87: SP+ EM
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
    // state 88: SP+ ZWJ
    128, 129, 130, 131, 132, 133, 6, 135, 8, 137, 10, 11, 140, 141, 142, 143,
    16, 17, 146, 147, 148, 149, 150, 151, 152, 153, 26, 27, 28, 29, 30, 159,
    160, 161, 162, 163, 36, 165, 166, 167, 168, 169, 170,
];

#[rustfmt::skip]
// Copyright 2016 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
#![feature(test)]

extern crate test;

#[cfg(test)]
mod bench {
    use std::cmp::max;
    use test::{black_box, Bencher};
    use xi_unicode::linebreak_property;
    use xi_unicode::linebreak_property_str;
    use xi_unicode::LineBreakIterator;

    fn linebreak_property_chars(s: &str) -> u8 {
        linebreak_property(black_box(s).chars().next().unwrap())
    }

    // compute the maximum numeric value of the lb, a model for iterating a string
    fn max_lb_chars(s: &str) -> u8 {
        let mut result = 0;
        for c in s.chars() {
            result = max(result, linebreak_property(c))
        }
        result
    }

    fn max_lb(s: &str) -> u8 {
        let mut result = 0;
        let mut ix = 0;
        while ix < s.len() {
            let (lb, len) = linebreak_property_str(s, ix);
            result = max(result, lb);
            ix += len;
        }
        result
    }

    #[bench]
    fn linebreak_lo(b: &mut Bencher) {
        b.iter(|| linebreak_property(black_box('\u{0042}')));
    }

    #[bench]
    fn linebreak_lo2(b: &mut Bencher) {
        b.iter(|| linebreak_property(black_box('\u{0644}')));
    }

    #[bench]
    fn linebreak_med(b: &mut Bencher) {
        b.iter(|| linebreak_property(black_box('\u{200D}')));
    }

    #[bench]
    fn linebreak_hi(b: &mut Bencher) {
        b.iter(|| linebreak_property(black_box('\u{1F680}')));
    }

    #[bench]
    fn linebreak_str_lo(b: &mut Bencher) {
        b.iter(|| linebreak_property_str("\\u{0042}", 0));
    }

    #[bench]
    fn linebreak_str_lo2(b: &mut Bencher) {
        b.iter(|| linebreak_property_str("\\u{0644}", 0));
    }

    #[bench]
    fn linebreak_str_med(b: &mut Bencher) {
        b.iter(|| linebreak_property_str("\\u{200D}", 0));
    }

    #[bench]
    fn linebreak_str_hi(b: &mut Bencher) {
        b.iter(|| linebreak_property_str("\u{1F680}", 0));
    }

    #[bench]
    fn linebreak_chars_lo2(b: &mut Bencher) {
        b.iter(|| linebreak_property_chars("\\u{0644}"));
    }

    #[bench]
    fn linebreak_chars_hi(b: &mut Bencher) {
        b.iter(|| linebreak_property_chars("\\u{1F680}"));
    }

    #[bench]
    fn max_lb_chars_hi(b: &mut Bencher) {
        b.iter(|| max_lb_chars("\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}"));
    }

    #[bench]
    fn max_lb_hi(b: &mut Bencher) {
        b.iter(|| max_lb("\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}\\u{1F680}"));
    }

    #[bench]
    fn max_lb_lo(b: &mut Bencher) {
        b.iter(|| max_lb("AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"));
    }

    #[bench]
    fn max_lb_chars_lo(b: &mut Bencher) {
        b.iter(|| max_lb_chars("AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"));
    }

    #[bench]
    fn lb_iter(b: &mut Bencher) {
        // 73 ASCII characters
        let s = "Now is the time for all good persons to come to the aid of their country.";
        b.iter(|| LineBreakIterator::new(s).count())
    }
// Copyright 2018 The xi-editor Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
extern crate xi_unicode;

use std::fs::File;
use std::io::BufReader;
use std::io::Read;

use xi_unicode::LineBreakIterator;

const TEST_FILE: &'static str = "tests/LineBreakTest.txt";

#[test]
fn line_break_test() {
    let file = File::open(TEST_FILE).expect("unable to open test file.");

    let mut reader = BufReader::new(file);
    let mut buffer = String::new();

    reader.read_to_string(&mut buffer).expect("failed to read test file.");

    let mut failed_tests = Vec::new();

    for full_test in buffer.lines().filter(|s| !s.starts_with('#')) {
        let test = full_test.split('#').next().unwrap().trim();

        let (string, breaks) = parse_test(test);
        let xi_lb = LineBreakIterator::new(&string).map(|(idx, _)| idx).collect::<Vec<_>>();

        if xi_lb != breaks {
            failed_tests.push((full_test.to_string(), breaks, xi_lb));
        }
    }

    if !failed_tests.is_empty() {
        println!("\nFailed {} line break tests.", failed_tests.len());

        for fail in failed_tests {
            println!("Failed Test:    {}", fail.0);
            println!("Unicode Breaks: {:?}", fail.1);
            println!("Xi Breaks:      {:?}\n", fail.2);
        }

        panic!("failed line break test.");
    }
}

// A typical test looks like: "× 0023 × 0308 × 0020 ÷ 0023 ÷"
fn parse_test(test: &str) -> (String, Vec<usize>) {
    use std::char;

    let mut parts = test.split(' ');
    let mut idx = 0usize;

    let mut string = String::new();
    let mut breaks = Vec::new();

    loop {
        let next = parts.next();
        if next.is_none() {
            break;
        }

        if next != Some("×") && next != Some("÷") {
            panic!("syntax error");
        }

        if next == Some("÷") {
            breaks.push(idx);
        }

        if let Some(hex) = parts.next() {
            let num = u32::from_str_radix(hex, 16).expect("syntax error");
            let ch = char::from_u32(num).expect("invalid codepoint");
            string.push(ch);
            idx += ch.len_utf8();
        } else {
            break;
        }
use ocaml::caml;
use std::time::{SystemTime, UNIX_EPOCH};

trait OCamlTransferableStruct {}

struct InterlanguageStruct {
    id: u128,
    value: u32,
}
impl InterlanguageStruct {
    fn new(value: u32) -> Self {
        let id = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_nanos();
        Self { id, value }
    }
}
impl Drop for InterlanguageStruct {
    fn drop(&mut self) {
        println!(
            "{}: drop() received value {}",
            self.id.to_string(),
            self.value.to_string(),
        );
    }
}
impl OCamlTransferableStruct for InterlanguageStruct {}

extern "C" fn generic_finalization_routine<T>(arg: ocaml::core::Value)
where
    T: OCamlTransferableStruct,
{
    println!("Running finalizer (dropping Box)");
    unmarshall_private::<T>(ocaml::Value::new(arg));
}

fn marshall<T>(x: T) -> ocaml::Value
where
    T: OCamlTransferableStruct,
{
    let x = Box::new(Some(x));
    let raw_ptr = Box::leak(x);
    ocaml::Value::alloc_custom(raw_ptr, generic_finalization_routine::<T>)
}

fn unmarshall_private<T>(arg: ocaml::Value) -> Box<Option<T>>
where
    T: OCamlTransferableStruct,
{
    unsafe {
        let raw_ptr = *(arg.custom_ptr_val_mut::<*mut Option<T>>());
        Box::from_raw(raw_ptr)
    }
}

fn unmarshall<T, F>(arg: ocaml::Value, mut f: F)
where
    T: OCamlTransferableStruct,
    F: FnMut(&mut Option<T>),
{
    let mut x = unmarshall_private(arg);
    f(x.as_mut());
    Box::leak(x);
}

fn create_the_struct() -> InterlanguageStruct {
    let x = InterlanguageStruct::new(3);
    println!(
        "{}: create_the_struct() set value to {}",
        x.id.to_string(),
        x.value.to_string(),
    );
    x
}

fn use_the_struct(x: &mut Option<InterlanguageStruct>) {
    if let Some(ref mut x) = x {
        let new_value = 5;
        println!(
            "{}: use_the_struct() received value {}; changing it to {}",
            x.id.to_string(),
            x.value.to_string(),
            new_value.to_string(),
        );
        x.value = new_value;
    } else {
        println!("unknown: use_the_struct() received a struct that was already dropped");
    }
}

fn drop_the_struct(x: &mut Option<InterlanguageStruct>) {
    if let Some(x) = x {
        println!("{}: drop_the_struct() called", x.id.to_string());
    } else {
        println!("unknown: drop_the_struct() called on a struct that was already dropped");
    }
    // to take ownership of the struct while in use (and thus be able to drop it):
    *x = None;
}

caml!(create_the_struct_ocaml() {
    marshall(create_the_struct())
});

caml!(use_the_struct_ocaml(arg) {
    unmarshall(arg, use_the_struct);
    ocaml::Value::unit()
});

use ocaml::caml;

caml!(rust_crash() {
    let _four = format!("{}", 4);
    ocaml::Value::unit()
});

caml!(rust_no_crash() {
    let _also_four = format!("{}", 4.to_string());
    ocaml::Value::unit()
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.;

extern crate clap;

use std::fs;
use std::path::PathBuf;

use clap::{App, Arg};
use facts_rust::facts_parser::*;
use oxidized::relative_path::*;

fn main() {
    let args = App::new("Facts JSON test (Rust)")
        .arg(
            Arg::with_name("file-path")
                .long("file-path")
                .multiple(true)
                .min_values(1)
                .required(true),
        )
        .arg(
            Arg::with_name("parse-only")
                .long("parse-only")
                .help("Parse Facts but don't convert them to JSON"),
        )
        .get_matches();

    for file_path in args.values_of("file-path").unwrap() {
        parse(file_path.to_owned(), args.is_present("parse-only"));
    }
}

fn parse(file_path: String, parse_only: bool) {
    let path = RelativePath::make(Prefix::Dummy, PathBuf::from(file_path.clone()));
    let opts = ExtractAsJsonOpts {
        php5_compat_mode: true,
        hhvm_compat_mode: true,
        allow_new_attribute_syntax: false,
        enable_xhp_class_modifier: false,
        disable_xhp_element_mangling: false,
        filename: path,
    };

    let content = fs::read(&file_path).expect("failed to read file");
    if parse_only {
        println!("{}", from_text(&content, opts).is_some());
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use std::cell::RefCell;
use std::collections::{BTreeMap, BTreeSet};

use ocamlrep::{FromOcamlRep, ToOcamlRep};
use ocamlrep_derive::{FromOcamlRep, ToOcamlRep};

fn val<T: FromOcamlRep + ToOcamlRep>(value: T) -> usize {
    let arena = Box::leak(Box::new(ocamlrep::Arena::new()));
    let value = arena.add(&value);
    // Round-trip back to T to exercise from_ocamlrep.
    let value = T::from_ocamlrep(value).unwrap();
    let value = arena.add(&value);
    value.to_bits()
}

#[no_mangle]
pub unsafe extern "C" fn convert_to_ocamlrep(value: usize) -> usize {
    match ocamlrep::slab::OwnedSlab::from_ocaml(value) {
        Some(slab) => slab.leak().to_bits(),
        None => value,
    }
}

#[no_mangle]
pub extern "C" fn realloc_in_ocaml_heap(value: usize) -> usize {
    let slab = unsafe { ocamlrep::slab::OwnedSlab::from_ocaml(value) };
    match slab {
        None => value,
        Some(slab) => {
            let pool = unsafe { ocamlrep_ocamlpool::Pool::new() };
            slab.value().clone_with_allocator(&pool).to_bits()
        }
    }
}

// Primitive Tests

#[no_mangle]
pub extern "C" fn get_a(_unit: usize) -> usize {
    val('a')
}

#[no_mangle]
pub extern "C" fn get_five(_unit: usize) -> usize {
    val(5)
}

#[no_mangle]
pub extern "C" fn get_true(_unit: usize) -> usize {
    val(true)
}

#[no_mangle]
pub extern "C" fn get_false(_unit: usize) -> usize {
    val(false)
}

// Option Tests

#[no_mangle]
pub extern "C" fn get_none(_unit: usize) -> usize {
    val(None::<isize>)
}

#[no_mangle]
pub extern "C" fn get_some_five(_unit: usize) -> usize {
    val(Some(5))
}

#[no_mangle]
pub extern "C" fn get_some_none(_unit: usize) -> usize {
    val(Some(None::<isize>))
}

#[no_mangle]
pub extern "C" fn get_some_some_five(_unit: usize) -> usize {
    val(Some(Some(5)))
}

// Ref tests

#[no_mangle]
pub extern "C" fn get_int_ref(_unit: usize) -> usize {
    val(RefCell::new(5))
}

#[no_mangle]
pub extern "C" fn get_int_option_ref(_unit: usize) -> usize {
    val(RefCell::new(Some(5)))
}

// Unsized type tests

#[no_mangle]
pub extern "C" fn get_str(_unit: usize) -> usize {
    let arena = Box::leak(Box::new(ocamlrep::Arena::new()));
    arena.add("static str").to_bits()
}

#[no_mangle]
pub extern "C" fn get_byte_slice(_unit: usize) -> usize {
    let arena = Box::leak(Box::new(ocamlrep::Arena::new()));
    arena.add(&b"byte\x00\xFFslice"[..]).to_bits()
}

#[no_mangle]
pub extern "C" fn get_int_opt_slice(_unit: usize) -> usize {
    let arena = Box::leak(Box::new(ocamlrep::Arena::new()));
    let vec = vec![None, Some(2), Some(3)];
    let slice = &vec[..];
    arena.add(slice).to_bits()
}

// List Tests

#[no_mangle]
pub extern "C" fn get_empty_list(_unit: usize) -> usize {
    val(Vec::<isize>::new())
}

#[no_mangle]
pub extern "C" fn get_five_list(_unit: usize) -> usize {
    val(vec![5])
}

#[no_mangle]
pub extern "C" fn get_one_two_three_list(_unit: usize) -> usize {
    val(vec![1, 2, 3])
}

#[no_mangle]
pub extern "C" fn get_float_list(_unit: usize) -> usize {
    val(vec![1.0, 2.0, 3.0])
}

// Struct tests

#[derive(FromOcamlRep, ToOcamlRep)]
struct Foo {
    a: isize,
    b: bool,
}

#[derive(FromOcamlRep, ToOcamlRep)]
struct Bar {
    c: Foo,
    d: Option<Vec<Option<isize>>>,
}

#[no_mangle]
pub extern "C" fn get_foo(_unit: usize) -> usize {
    val(Foo { a: 25, b: true })
}

#[no_mangle]
pub extern "C" fn get_bar(_unit: usize) -> usize {
    val(Bar {
        c: Foo { a: 42, b: false },
        d: Some(vec![Some(88), None, Some(66)]),
    })
}

// String Tests

#[no_mangle]
pub extern "C" fn get_empty_string(_unit: usize) -> usize {
    val(String::from(""))
}

#[no_mangle]
pub extern "C" fn get_a_string(_unit: usize) -> usize {
    val(String::from("a"))
}

#[no_mangle]
pub extern "C" fn get_ab_string(_unit: usize) -> usize {
    val(String::from("ab"))
}

#[no_mangle]
pub extern "C" fn get_abcde_string(_unit: usize) -> usize {
    val(String::from("abcde"))
}

#[no_mangle]
pub extern "C" fn get_abcdefg_string(_unit: usize) -> usize {
    val(String::from("abcdefg"))
}

#[no_mangle]
pub extern "C" fn get_abcdefgh_string(_unit: usize) -> usize {
    val(String::from("abcdefgh"))
}

#[no_mangle]
pub extern "C" fn get_zero_float(_unit: usize) -> usize {
    val(0.0 as f64)
}

#[no_mangle]
pub extern "C" fn get_one_two_float(_unit: usize) -> usize {
    val(1.2 as f64)
}

// Variant tests

#[derive(FromOcamlRep, ToOcamlRep)]
enum Fruit {
    Apple,
    Orange(isize),
    Pear { num: isize },
    Kiwi,
}

#[no_mangle]
pub extern "C" fn get_apple(_unit: usize) -> usize {
    val(Fruit::Apple)
}

#[no_mangle]
pub extern "C" fn get_orange(_unit: usize) -> usize {
    val(Fruit::Orange(39))
}

#[no_mangle]
pub extern "C" fn get_pear(_unit: usize) -> usize {
    val(Fruit::Pear { num: 76 })
}

#[no_mangle]
pub extern "C" fn get_kiwi(_unit: usize) -> usize {
    val(Fruit::Kiwi)
}

// Map tests

#[no_mangle]
pub extern "C" fn get_empty_smap(_unit: usize) -> usize {
    let map: BTreeMap<String, isize> = BTreeMap::new();
    val(map)
}

#[no_mangle]
pub extern "C" fn get_int_smap_singleton(_unit: usize) -> usize {
    let mut map = BTreeMap::new();
    map.insert(String::from("a"), 1);
    val(map)
}

#[no_mangle]
pub extern "C" fn get_int_smap(_unit: usize) -> usize {
    let mut map = BTreeMap::new();
    map.insert(String::from("a"), 1);
    map.insert(String::from("b"), 2);
    map.insert(String::from("c"), 3);
    val(map)
}

// Set tests

#[no_mangle]
pub extern "C" fn get_empty_sset(_unit: usize) -> usize {
    let set: BTreeSet<String> = BTreeSet::new();
    val(set)
}

#[no_mangle]
pub extern "C" fn get_sset_singleton(_unit: usize) -> usize {
    let mut set = BTreeSet::new();
    set.insert(String::from("a"));
    val(set)
}

#[no_mangle]
pub extern "C" fn get_sset(_unit: usize) -> usize {
    let mut set = BTreeSet::new();
    set.insert(String::from("a"));
    set.insert(String::from("b"));
    set.insert(String::from("c"));
    val(set)
}

#[no_mangle]
pub extern "C" fn roundtrip_int64(value: usize) -> usize {
    let i = unsafe { ocamlrep_caml_builtins::Int64::from_ocaml(value).unwrap() };
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

#![cfg(test)]

use std::fmt::Debug;

use bumpalo::Bump;

use ocamlrep::{FromOcamlRepIn, ToOcamlRep};
use ocamlrep_derive::{FromOcamlRepIn, ToOcamlRep};

fn test_round_trip<'a, T>(bump: &'a Bump, rust_value: T)
where
    T: FromOcamlRepIn<'a> + ToOcamlRep + Debug + PartialEq,
{
    let arena = ocamlrep::Arena::new();
    let ocaml_value = arena.add(&rust_value);
    assert_eq!(T::from_ocamlrep_in(ocaml_value, bump), Ok(rust_value));
}

#[test]
fn convert_primitives() {
    let bump = &Bump::new();

    test_round_trip(bump, ());
    test_round_trip(bump, 1isize);
    test_round_trip(bump, 2usize);
    test_round_trip(bump, 3i64);
    test_round_trip(bump, 4u64);
    test_round_trip(bump, 5i32);
    test_round_trip(bump, 6u32);
    test_round_trip(bump, true);
    test_round_trip(bump, false);
    test_round_trip(bump, 'a');
    test_round_trip(bump, 7.7f64);
}

#[test]
fn convert_std_types() {
    let bump = &Bump::new();

    test_round_trip(bump, None::<usize>);
    test_round_trip(bump, Some(&*bump.alloc(5usize)));
    test_round_trip(bump, Ok::<&str, &str>("okay"));
    test_round_trip(bump, Err::<&str, &str>("error"));
}

#[derive(Debug, FromOcamlRepIn, ToOcamlRep, PartialEq)]
struct Foo<'a> {
    bar: &'a usize,
    baz: usize,
}

#[test]
fn convert_struct_with_ref() {
    let bump = &Bump::new();
    test_round_trip(
        bump,
        Foo {
            bar: bump.alloc(3),
            baz: 4,
        },
    );
}

#[derive(Debug, FromOcamlRepIn, ToOcamlRep, PartialEq)]
enum Fruit<'a> {
    Apple,
    Orange(&'a str),
    Pear { is_tasty: bool },
    Kiwi,
    Peach(&'a (isize, bool)),
}

#[test]
fn convert_str_variant() {
    test_round_trip(&Bump::new(), Fruit::Orange("mandarin"));
}

#[test]
fn convert_boxed_tuple_variant() {
    let bump = &Bump::new();
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use ocamlrep_derive::{FromOcamlRep, ToOcamlRep};

#[cfg(test)]
use ocamlrep::{Allocator, Arena, FromError::*, FromOcamlRep, OpaqueValue, Value};

#[test]
fn expected_block_but_got_int() {
    let value = Value::int(42);
    let err = <(isize, isize)>::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, ExpectedBlock(42));
}

#[test]
fn expected_int_but_got_block() {
    let arena = Arena::new();
    let value = arena.block_with_size_and_tag(1, 0).build();
    // SAFETY: The value was allocated by an `Arena`.
    let value = unsafe { Arena::make_transparent(value) };
    let err = isize::from_ocamlrep(value).err().unwrap();
    match err {
        ExpectedImmediate(..) => {}
        _ => panic!("unexpected error: {}", err.to_string()),
    }
}

#[test]
fn wrong_tag_for_none() {
    let value = Value::int(1);
    let err = <Option<isize>>::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, NullaryVariantTagOutOfRange { max: 0, actual: 1 });
}

#[test]
fn wrong_tag_for_some() {
    let arena = Arena::new();
    let value = arena.block_with_size_and_tag(1, 1).build();
    // SAFETY: The value was allocated by an `Arena`.
    let value = unsafe { Arena::make_transparent(value) };
    let err = <Option<isize>>::from_ocamlrep(value).err().unwrap();
    assert_eq!(
        err,
        ExpectedBlockTag {
            expected: 0,
            actual: 1
        }
    );
}

#[test]
fn out_of_bool_range() {
    let value = Value::int(42);
    let err = bool::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, ExpectedBool(42));
}

#[test]
fn out_of_char_range() {
    let value = Value::int(-1);
    let err = char::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, ExpectedChar(-1));
}

#[derive(FromOcamlRep, ToOcamlRep)]
struct Foo {
    a: isize,
    b: bool,
}

#[test]
fn bad_struct_field() {
    let arena = Arena::new();
    let value = {
        let mut foo = arena.block_with_size_and_tag(2, 0);
        arena.set_field(&mut foo, 0, OpaqueValue::int(0));
        arena.set_field(&mut foo, 1, OpaqueValue::int(42));
        // SAFETY: `foo` was allocated by an `Arena`.
        unsafe { Arena::make_transparent(foo.build()) }
    };
    let err = Foo::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, ErrorInField(1, Box::new(ExpectedBool(42))));
}

#[derive(FromOcamlRep, ToOcamlRep)]
struct Bar {
    c: Foo,
    d: Option<Vec<Option<isize>>>,
}

#[test]
fn bad_nested_struct_field() {
    let arena = Arena::new();

    let foo = {
        let mut foo = arena.block_with_size_and_tag(2, 0);
        arena.set_field(&mut foo, 0, OpaqueValue::int(0));
        arena.set_field(&mut foo, 1, OpaqueValue::int(42));
        foo.build()
    };

    let bar = {
        let mut bar = arena.block_with_size_and_tag(2, 0);
        arena.set_field(&mut bar, 0, foo);
        arena.set_field(&mut bar, 1, OpaqueValue::int(0));
        // SAFETY: `bar` was allocated by an `Arena`.
        unsafe { Arena::make_transparent(bar.build()) }
    };

    let err = Bar::from_ocamlrep(bar).err().unwrap();
    assert_eq!(
        err,
        ErrorInField(0, Box::new(ErrorInField(1, Box::new(ExpectedBool(42)))))
    );
}

#[derive(FromOcamlRep, ToOcamlRep)]
struct UnitStruct;

#[test]
fn expected_unit_struct_but_got_nonzero() {
    let value = Value::int(42);
    let err = UnitStruct::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, ExpectedUnit(42));
}

#[test]
fn expected_unit_struct_but_got_block() {
    let arena = Arena::new();
    let value = arena.block_with_size_and_tag(1, 0).build();
    // SAFETY: The value was allocated by an `Arena`.
    let value = unsafe { Arena::make_transparent(value) };
    let err = UnitStruct::from_ocamlrep(value).err().unwrap();
    match err {
        ExpectedImmediate(..) => {}
        _ => panic!("unexpected error: {}", err.to_string()),
    }
}

#[derive(FromOcamlRep, ToOcamlRep)]
struct WrapperStruct(bool);

#[test]
fn bad_value_in_wrapper_struct() {
    let value = Value::int(42);
    let err = WrapperStruct::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, ExpectedBool(42))
}

#[derive(Debug, PartialEq, FromOcamlRep, ToOcamlRep)]
enum Fruit {
    Apple,
    Orange(bool),
    Pear { is_tasty: bool },
    Kiwi,
    Peach(Box<(isize, bool)>),
}

#[test]
fn nullary_variant_tag_out_of_range() {
    let value = Value::int(42);
    let err = Fruit::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, NullaryVariantTagOutOfRange { max: 1, actual: 42 });
}

#[test]
fn block_variant_tag_out_of_range() {
    let arena = Arena::new();
    let value = arena.block_with_size_and_tag(1, 42).build();
    // SAFETY: The value was allocated by an `Arena`.
    let value = unsafe { Arena::make_transparent(value) };
    let err = Fruit::from_ocamlrep(value).err().unwrap();
    assert_eq!(err, BlockTagOutOfRange { max: 2, actual: 42 });
}

#[test]
fn wrong_block_variant_size() {
    let arena = Arena::new();
    let value = arena.block_with_size_and_tag(42, 0).build();
    // SAFETY: The value was allocated by an `Arena`.
    let value = unsafe { Arena::make_transparent(value) };
    let err = Fruit::from_ocamlrep(value).err().unwrap();
    assert_eq!(
        err,
        WrongBlockSize {
            expected: 1,
            actual: 42
        }
    );
}

#[test]
fn bad_tuple_variant_value() {
    let arena = Arena::new();
    let orange = {
        let mut orange = arena.block_with_size_and_tag(1, 0);
        arena.set_field(&mut orange, 0, OpaqueValue::int(42));
        // SAFETY: `orange` was allocated by an `Arena`.
        unsafe { Arena::make_transparent(orange.build()) }
    };
    let err = Fruit::from_ocamlrep(orange).err().unwrap();
    assert_eq!(err, ErrorInField(0, Box::new(ExpectedBool(42))));
}

#[test]
fn bad_struct_variant_value() {
    let arena = Arena::new();
    let pear = {
        let mut pear = arena.block_with_size_and_tag(1, 1);
        arena.set_field(&mut pear, 0, OpaqueValue::int(42));
        // SAFETY: `pear` was allocated by an `Arena`.
        unsafe { Arena::make_transparent(pear.build()) }
    };
    let err = Fruit::from_ocamlrep(pear).err().unwrap();
    assert_eq!(err, ErrorInField(0, Box::new(ExpectedBool(42))));
}

#[test]
fn good_boxed_tuple_variant() {
    let arena = Arena::new();
    let peach = {
        let mut peach = arena.block_with_size_and_tag(2, 2);
        arena.set_field(&mut peach, 0, OpaqueValue::int(42));
        arena.set_field(&mut peach, 1, OpaqueValue::int(1));
        // SAFETY: `peach` was allocated by an `Arena`.
        unsafe { Arena::make_transparent(peach.build()) }
    };
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

#![cfg(test)]

use ocamlrep::{Allocator, Arena, FromOcamlRep, ToOcamlRep};

#[test]
fn mutated_reference() {
    // If we didn't clear the arena's caches after invoking `add_root`, then the
    // arena would memoize the first conversion, and return the OCaml
    // representation of the integer 1 for every conversion of x_ref.
    let arena = Arena::new();
    let x_mut: &mut i32 = &mut 1;
    let x_ref: &i32 = x_mut;
    let ocaml_1 = arena.add_root(&x_ref);
    *x_mut = 2;
    let x_ref: &i32 = x_mut;
    let ocaml_2 = arena.add_root(&x_ref);
    assert_eq!(ocaml_1.as_int(), Some(1));
    assert_eq!(ocaml_2.as_int(), Some(2));
}

#[test]
fn mutated_reference_with_add() {
    // The implementation of `ToOcamlRep` for `&T` uses `Allocator::memoize`,
    // but allocators should not memoize outside of an invocation of `add_root`,
    // else this test case would fail.
    let arena = Arena::new();
    let x_mut: &mut i32 = &mut 1;
    let x_ref: &i32 = x_mut;
    let ocaml_1 = arena.add(&x_ref);
    *x_mut = 2;
    let x_ref: &i32 = x_mut;
    let ocaml_2 = arena.add(&x_ref);
    assert_eq!(ocaml_1.as_int(), Some(1));
    assert_eq!(ocaml_2.as_int(), Some(2));
}

#[test]
fn shared_str() {
    // Without `add_root`, converting this tuple would convert the string
    // "hello" to its OCaml representation and copy it into the ocamlrep::Arena
    // twice.
    let arena = Arena::new();
    let s = "hello";
    let ocaml_tuple = arena.add_root(&(s, s));
    let ocaml_block = ocaml_tuple.as_block().unwrap();

    assert_eq!(
        ocaml_block[0].as_str(),
        Some(std::borrow::Cow::Borrowed("hello"))
    );
    assert_eq!(
        ocaml_block[1].as_str(),
        Some(std::borrow::Cow::Borrowed("hello"))
    );

    // The string pointer in the first field is physically equal to the string
    // pointer in the second field.
    assert_eq!(ocaml_block[0].to_bits(), ocaml_block[1].to_bits());
}

#[test]
fn shared_slice() {
    // Without `add_root`, converting this tuple would convert the list to its
    // OCaml representation and copy it into the ocamlrep::Arena twice.
    let arena = Arena::new();
    let s = &[1usize, 2, 3][..];
    let ocaml_tuple = arena.add_root(&(s, s));

    assert_eq!(
        <(Vec<usize>, Vec<usize>)>::from_ocamlrep(ocaml_tuple),
        Ok((vec![1, 2, 3], vec![1, 2, 3]))
    );

    // The list pointer in the first field is physically equal to the list
    // pointer in the second field.
    let ocaml_block = ocaml_tuple.as_block().unwrap();
    assert_eq!(ocaml_block[0].to_bits(), ocaml_block[1].to_bits());
}

#[test]
fn overlapping_substrs() {
    // Without `Allocator::memoized_slice`, a naive implementation of
    // `ToOcamlRep` for slices might use `Allocator::memoized`, failing to take
    // the slice length into consideration.
    // Then we'd incorrectly produce the tuple ("hello", "hello").
    let arena = Arena::new();
    let s1 = "hello";
    let s2 = &s1[..4];
    let ocaml_tuple = arena.add_root(&(s1, s2));

    assert_eq!(
        <(String, String)>::from_ocamlrep(ocaml_tuple),
        Ok((String::from("hello"), String::from("hell")))
    );
}

#[test]
fn overlapping_subslices() {
    // Without `Allocator::memoized_slice`, a naive implementation of
    // `ToOcamlRep` for slices might use `Allocator::memoized`, failing to take
    // the slice length into consideration.
    // Then we'd incorrectly produce the tuple ([1,2,3], [1,2,3]).
    let arena = Arena::new();
    let s1 = &[1usize, 2, 3][..];
    let s2 = &s1[..2];
    let ocaml_tuple = arena.add_root(&(s1, s2));

    assert_eq!(
        <(Vec<usize>, Vec<usize>)>::from_ocamlrep(ocaml_tuple),
        Ok((vec![1, 2, 3], vec![1, 2]))
    );
}

#[derive(Debug, PartialEq)]
#[repr(transparent)]
struct U32Pair(u64);

impl U32Pair {
    fn new(fst: u32, snd: u32) -> Self {
        let fst = fst as u64;
        let snd = snd as u64;
        Self(fst << 32 | snd)
    }
    fn fst(&self) -> u32 {
        (self.0 >> 32) as u32
    }
    fn snd(&self) -> u32 {
        self.0 as u32
    }
    fn inner(&self) -> &u64 {
        &self.0
    }
}
impl ToOcamlRep for U32Pair {
    fn to_ocamlrep<'a, A: Allocator>(&self, alloc: &'a A) -> ocamlrep::OpaqueValue<'a> {
        alloc.add(&(self.fst(), self.snd()))
    }
}
impl FromOcamlRep for U32Pair {
    fn from_ocamlrep(value: ocamlrep::Value<'_>) -> Result<Self, ocamlrep::FromError> {
        let (fst, snd) = <(u32, u32)>::from_ocamlrep(value)?;
        Ok(Self::new(fst, snd))
    }
}

#[test]
fn differently_typed_views_of_same_data() {
    // `Allocator::memoized` is keyed solely off of address and size in bytes.
    // If we have two views of the same bytes, but the views have two different
    // OCaml representations, then `Allocator::add_root` will produce an OCaml
    // value with an unexpected type.
    //
    // Here, `pair_as_int` gets converted first, and memoized. Since its address
    // and size are the same as `pair`, the allocator uses the same memoized
    // OCaml value for both. But the implementations of `ToOcamlRep` and
    // `FromOcamlRep` for U32Pair specify that the OCaml representation is a
    // tuple, not an immediate integer, so we encounter an error when trying to
    // convert the OCaml value to `(u64, U32Pair)`.
    let arena = Arena::new();
    let pair = &U32Pair::new(1, 2);
    let pair_as_int = pair.inner();
    let value = (pair_as_int, pair);

    use ocamlrep::FromError::*;
    assert_eq!(
        <(u64, U32Pair)>::from_ocamlrep(arena.add_root(&value)),
        Err(ErrorInField(1, Box::new(ExpectedBlock(1 << 32 | 2))))
    );

    // Using arena.add instead produces a correct result.
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.
use ocamlrep_custom::caml_serialize_default_impls;
use ocamlrep_custom::{CamlSerialize, Custom};
use ocamlrep_ocamlpool::ocaml_ffi;

use std::cell::RefCell;
use std::convert::TryInto;
use std::io::Write;
use std::rc::Rc;

struct DropTest(Rc<RefCell<bool>>);

impl CamlSerialize for DropTest {
    caml_serialize_default_impls!();
}

struct DropTestCell(Rc<RefCell<bool>>);

impl CamlSerialize for DropTestCell {
    caml_serialize_default_impls!();
}

impl DropTest {
    pub fn new() -> Self {
        Self(Rc::new(RefCell::new(false)))
    }

    pub fn cell(&self) -> Rc<RefCell<bool>> {
        self.0.clone()
    }
}

impl Drop for DropTest {
    fn drop(&mut self) {
        *self.0.borrow_mut() = true;
    }
}

ocaml_ffi! {
  fn test_custom_drop_test_new() -> Custom<DropTest> {
    Custom::from(DropTest::new())
  }

  fn test_custom_drop_test_custom_ref_count(x: Custom<DropTest>) -> usize {
    let w = Rc::downgrade(x.inner());
    drop(x);
    w.strong_count()
  }

  fn test_custom_drop_test_get_cell(x: Custom<DropTest>) -> Custom<DropTestCell> {
    Custom::from(DropTestCell(x.cell()))
  }

  fn test_custom_drop_test_cell_is_dropped(x: Custom<DropTestCell>) -> bool {
    *x.0.borrow()
  }
}

struct BoxedInt(isize);

impl CamlSerialize for BoxedInt {
    caml_serialize_default_impls!();

    fn serialize(&self) -> Vec<u8> {
        let mut buffer = Vec::new();
        buffer.write_all(&self.0.to_be_bytes()).unwrap();
        buffer
    }

    fn deserialize(buffer: &[u8]) -> Self {
        let i = isize::from_be_bytes(buffer[0..std::mem::size_of::<isize>()].try_into().unwrap());
        BoxedInt(i)
    }
}

ocaml_ffi! {
  fn test_custom_boxed_int_register() {
    // Safety: called from OCaml in a single-threaded context.
    unsafe {
      BoxedInt::register();
    }
  }

  fn test_custom_boxed_int_new(x: isize) -> Custom<BoxedInt> {
    Custom::from(BoxedInt(x))
  }

// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

mod common;
mod gen_by_ref_decl_visitor;
mod gen_enum_helper;
mod gen_visitor;
mod quote_helper;

use anyhow::{anyhow, Result};
use common::*;
use md5::{Digest, Md5};
use std::{fs, fs::File, io::prelude::*, path::PathBuf, process::Command};
use structopt::StructOpt;

#[derive(Debug, StructOpt)]
#[structopt(no_version)] // don't consult CARGO_PKG_VERSION (buck doesn't set it)
struct Opts {
    /// Command to regenerate the output. This text will be included in generated file headers.
    #[structopt(long)]
    regen_cmd: Option<String>,

    /// Path to a Rust formatter binary, which will be used on the generated output.
    #[structopt(long)]
    rustfmt: Option<String>,

    /// The codegen task to run.
    #[structopt(subcommand)]
    subcommand: Subcommand,
}

#[derive(Debug, StructOpt)]
enum Subcommand {
    /// Generate convenient factory functions and predicates for enum types.
    EnumHelpers(gen_enum_helper::Args),
    /// Generate Visitor and VisitorMut traits.
    Visitor(gen_visitor::Args),
    /// Generate a Visitor trait for by-reference types.
    ByRefDeclVisitor(gen_by_ref_decl_visitor::Args),
}

fn main() -> Result<()> {
    let opts = Opts::from_args();

    let formatter = opts.rustfmt.as_deref();
    eprintln!("Rust formatter set to {:?}", formatter);

    let regencmd = opts.regen_cmd.as_deref();
    eprintln!("Re-generate cmd set to {:?}", regencmd);

    let files = match opts.subcommand {
        Subcommand::EnumHelpers(args) => gen_enum_helper::run(&args)?,
        Subcommand::Visitor(args) => gen_visitor::run(&args)?,
        Subcommand::ByRefDeclVisitor(args) => gen_by_ref_decl_visitor::run(&args)?,
    };

    let output_files = files
        .into_iter()
        .map(|f| write_file(f, regencmd))
        .collect::<Result<Vec<_>>>()?;

    if let Err(e) = output_files
        .iter()
        .map(|o| format(formatter, o))
        .collect::<Result<Vec<_>>>()
    {
        eprintln!("formatter failed:\n  {:#?}", e);
    }

    if let Err(e) = output_files
        .iter()
        .map(|o| sign(o))
        .collect::<Result<Vec<_>>>()
    {
        eprintln!("signer failed:\n  {:#?}", e);
    }
    Ok(())
}

fn write_file(output: (PathBuf, String), regencmd: Option<&str>) -> Result<PathBuf> {
    let mut file = File::create(&output.0)?;
    let content = insert_header(&output.1[..], regencmd.unwrap_or(""))?;
    file.write_all(content.as_bytes())?;
    Ok(output.0)
}

fn format(formatter: Option<&str>, file: &PathBuf) -> Result<()> {
    match formatter {
        Some(formatter) => {
            let output = Command::new(formatter).arg(file).output()?;
            if !output.status.success() {
                eprintln!("formatter failed:\n  {:#?}", output);
            }
        }
        _ => eprintln!("Skip: formatter not found"),
    }
    Ok(())
}

fn sign(file: &PathBuf) -> Result<()> {
    // avoid putting the obvious literal in this source file, as that makes the
    // file as generated
    let token_tag = format!("@{}", "generated");
    let token = "<<SignedSource::*O*zOeWoEQle#+L!plEphiEmie@IsG>>";
    let expected = format!("{} {}", token_tag, token);

    let contents = fs::read_to_string(file).expect("signing failed: could not read file");
    if !contents.contains(&expected) {
        return Err(anyhow!("signing failed: input does not contain marker"));
    }

    let mut digest = Md5::new();
    digest.input(&contents);
    let md5 = hex::encode(digest.result());

    let new_contents =
        contents.replace(&expected, &format!("{} SignedSource<<{}>>", token_tag, md5));
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.
use super::{gen_helper, syn_helper::*};
use anyhow::{anyhow, Result};
use proc_macro2::TokenStream;
use quote::format_ident;
use std::{
    collections::{HashMap, HashSet, VecDeque},
    path::Path,
};
use syn::*;

pub struct Context<'a> {
    /// type declerations, no visit function will be generated for
    /// any type *not* in this map.
    pub defs: HashMap<String, &'a Item>,
    /// modules contain the `defs`.
    pub mods: HashSet<String>,
    /// root is a type from `defs`, a visit function will be generated
    /// if a type is in `defs` and transitively depended by `root`.
    pub root: &'a str,
    /// a set of types transitively depended by `root`.
    types: Vec<String>,
    /// a list of type parameters in the root type
    pub root_ty_params: Vec<String>,
    /// the name of `Context` type in `Visitor`
    pub context: String,
    /// the type param name for `Error`, which is used in `Result<(), Error>`
    pub error_ty_param: String,

    pub node_lifetime: String,
}
impl<'a> Context<'a> {
    pub fn new(files: &'a [(syn::File, &'a Path)], root: &'a str) -> Result<Self> {
        let mut defs = HashMap::new();
        let mut mods = HashSet::new();
        for (f, fp) in files {
            eprintln!("Processing {:?}", fp);
            for i in f.items.iter() {
                if let Ok(name) = get_ty_def_name(i) {
                    if let Some(old) = defs.insert(name, i) {
                        return Err(anyhow!("Type {:?} already exists, file {:?}", old, f));
                    }
                }
            }
            // assuming file name is the module name
            mods.insert(fp.file_stem().and_then(|fs| fs.to_str()).unwrap().into());
        }
        let root_item = defs
            .get(root)
            .ok_or_else(|| anyhow!("Root {} not found", root))?;
        let root_ty_params = get_ty_params(root_item)?;
        let types = Self::get_all_tys(&defs, root)?;
        Ok(Self {
            mods,
            defs,
            root,
            root_ty_params,
            types,
            context: "Context".into(),
            error_ty_param: "Error".into(),
            node_lifetime: "node".into(),
        })
    }

    pub fn context_ident(&self) -> Ident {
        format_ident!("{}", self.context)
    }

    pub fn error_ident(&self) -> Ident {
        format_ident!("{}", self.error_ty_param)
    }

    pub fn node_lifetime_ident(&self) -> Ident {
        format_ident!("{}", self.node_lifetime)
    }

    pub fn node_lifetime_ident_with_quote(&self) -> TokenStream {
        let l = self.node_lifetime_ident();
        gen_helper::make_lifetime(&l)
    }

    pub fn is_root_ty_param(&self, ty_param: &str) -> bool {
        self.root_ty_params.iter().any(|t| t == ty_param)
    }

    pub fn root_ty_params_raw(&'a self) -> impl Iterator<Item = &'a String> {
        self.root_ty_params.iter()
    }

    pub fn root_ty_params_(&'a self) -> impl Iterator<Item = Ident> + 'a {
        self.root_ty_params_raw().map(|t| format_ident!("{}", t))
    }

    pub fn root_ty_params_with_context_raw(&'a self) -> impl Iterator<Item = &'a String> {
        vec![&self.context, &self.error_ty_param]
            .into_iter()
            .chain(self.root_ty_params.iter())
    }

    pub fn root_ty_params_with_context(&'a self) -> impl Iterator<Item = Ident> + 'a {
        self.root_ty_params_with_context_raw()
            .map(|t| format_ident!("{}", t))
    }

    pub fn modules(&'a self) -> impl Iterator<Item = impl AsRef<str> + 'a> {
        self.mods.iter()
    }

    pub fn non_alias_types(&'a self) -> impl Iterator<Item = impl AsRef<str> + 'a> {
        self.types
            .iter()
            .filter(move |ty| self.defs.get(*ty).map_or(false, |def| !is_alias(*def)))
    }

    fn get_ty_names_<'b>(defs: &'b HashMap<String, &'b Item>) -> HashSet<&'b str> {
        defs.keys().map(|s| s.as_str()).collect()
    }

    fn get_all_tys(defs: &HashMap<String, &Item>, root: &'a str) -> Result<Vec<String>> {
        let defined_types = Self::get_ty_names_(defs);
        let mut visited = HashSet::<String>::new();
        let mut q = VecDeque::new();
        q.push_back(root.into());
        while let Some(ty) = q.pop_front() {
            let item = defs
                .get(&ty)
                .ok_or_else(|| anyhow!("Type {} not found", ty))?;
            visited.insert(get_ty_def_name(&item)?);
            let deps = get_dep_tys(&defined_types, item)?;
            for d in deps.into_iter() {
                if !visited.contains(&d) {
                    q.push_back(d);
                }
            }
        }
        let mut types: Vec<String> = visited.into_iter().collect();
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use proc_macro2::{Ident, Punct, Spacing, TokenStream};
use quote::quote;

pub use crate::common::gen_helpers::gen_module_uses;

pub fn gen_ty_params(tys: impl Iterator<Item = syn::Ident>) -> TokenStream {
    let ty_idents = tys.map(|ty| quote! { P::#ty, }).collect::<Vec<_>>();
    if ty_idents.is_empty() {
        quote! {}
    } else {
        quote! {<#(#ty_idents)*>}
    }
}

pub fn gen_ty_params_with_self(tys: impl Iterator<Item = syn::Ident>) -> TokenStream {
    let ty_idents = tys
        .map(|ty| quote! { <Self::P as Params>::#ty, })
        .collect::<Vec<_>>();
    if ty_idents.is_empty() {
        quote! {}
    } else {
        quote! {<#(#ty_idents)*>}
    }
}

pub fn single_quote() -> Punct {
    Punct::new('\'', Spacing::Joint)
}

// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use anyhow::{anyhow, Result};
use quote::format_ident;
use syn::*;

pub use crate::common::syn_helpers::{get_dep_tys, get_ty_def_name};

pub fn is_alias(i: &Item) -> bool {
    match i {
        Item::Type(_) => true,
        _ => false,
    }
}

pub fn get_ty_params(i: &Item) -> Result<Vec<String>> {
    use Item::*;
    match i {
        Enum(ItemEnum { generics, .. })
        | Struct(ItemStruct { generics, .. })
        | Type(ItemType { generics, .. }) => Ok(TypeParamCollector::on_generics(generics)),
        _ => Err(anyhow!("Not supported {:?}", i)),
    }
}

pub fn get_ty_param_idents(i: &Item) -> Result<impl Iterator<Item = Ident>> {
    Ok(get_ty_params(i)?
        .into_iter()
        .map(|t| format_ident!("{}", t)))
}

pub fn get_field_and_type_from_named<'a>(
    FieldsNamed { named, .. }: &'a FieldsNamed,
) -> Vec<(String, &'a Type)> {
    named
        .iter()
        .map(|f| (f.ident.as_ref().unwrap().to_string(), &f.ty))
        .collect()
}

pub fn get_field_and_type_from_unnamed(
    FieldsUnnamed { unnamed, .. }: &FieldsUnnamed,
) -> impl Iterator<Item = (usize, &Type)> {
    itertools::enumerate(unnamed.into_iter().map(|f| &f.ty))
}

struct TypeParamCollector(Vec<String>);

impl TypeParamCollector {
    pub fn on_generics(g: &Generics) -> Vec<String> {
        let mut collector = Self(vec![]);
        visit::visit_generics(&mut collector, g);
        collector.0
    }
}

impl<'ast> visit::Visit<'ast> for TypeParamCollector {
    fn visit_type_param(&mut self, node: &'ast TypeParam) {
        self.0.push(node.ident.to_string())
    }
}

pub fn try_get_types_from_box_tuple(
    FieldsUnnamed { unnamed, .. }: &FieldsUnnamed,
) -> Option<impl Iterator<Item = (usize, &Type)>> {
    let fields = unnamed.into_iter().collect::<Vec<_>>();
    if fields.len() == 1 {
        if let Type::Path(TypePath { path, .. }) = &fields[0].ty {
            if let Some(path_seg) = path.segments.first() {
                if path_seg.ident == "Box" {
                    if let syn::PathArguments::AngleBracketed(args) = &path_seg.arguments {
                        if let Some(GenericArgument::Type(Type::Tuple(syn::TypeTuple {
                            elems,
                            ..
                        }))) = args.args.first()
                        {
                            return Some(itertools::enumerate(elems.iter()));
                        }
                    }
                }
            }
        }
    }
    None
}

pub fn try_simple_type(ty: &Type) -> Option<String> {
    if let Type::Path(TypePath { path, .. }) = ty {
        if path.segments.len() == 1 {
            let ty = path.segments.first().unwrap();
            if ty.arguments.is_empty() {
                return Some(ty.ident.to_string());
            }
        }
    }
    None
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.
use super::{
    context::Context, generator::Generator, node_impl_generator::*, node_trait_generator::*,
    type_params_generator::*, visitor_trait_generator::*,
};
use anyhow::Result;
use std::{
    fs::File,
    io::Read,
    path::{Path, PathBuf},
};
use structopt::StructOpt;

#[derive(Debug, StructOpt)]
pub struct Args {
    /// Rust files containing the types for which codegen will be performed.
    /// All types reachable from the given root type must be defined in one of
    /// the files provided as `--input` or `--extern-input`.
    #[structopt(short, long, parse(from_os_str))]
    input: Vec<PathBuf>,

    /// The root type of the AST. All types reachable from this type will be
    /// visited by the generated visitor.
    #[structopt(short, long)]
    root: String,

    /// The directory to which generated files will be written.
    #[structopt(short, long, parse(from_os_str))]
    output: PathBuf,
}

pub fn run(args: &Args) -> Result<Vec<(PathBuf, String)>> {
    let inputs = &args.input;
    let output_dir = &args.output;
    let root = &args.root;
    let files = inputs
        .iter()
        .map(|file| -> Result<(syn::File, &Path)> {
            let file_path = Path::new(file);
            let mut file = File::open(file)?;
            let mut src = String::new();
            file.read_to_string(&mut src)?;
            Ok((syn::parse_file(&src)?, file_path))
        })
        .collect::<Result<Vec<_>>>()?;

    let ctx = Context::new(files.as_slice(), root)?;

    let generators: Vec<Box<dyn Generator>> = vec![
        Box::new(TypeParamGenerator),
        Box::new(RefNodeTrait),
        Box::new(MutNodeTrait),
        Box::new(RefNodeImpl),
        Box::new(MutNodeImpl),
        Box::new(RefVisitorTrait),
        Box::new(MutVisitorTrait),
    ];

    Ok(generators
        .into_iter()
        .map(|g| {
            let code = g.gen(&ctx)?;
            let filepath = output_dir.join(g.filename());
            Ok((filepath, format!("{}", code)))
        })
        .collect::<Result<Vec<_>>>()?)
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::context::Context;
use crate::common::*;
use proc_macro2::TokenStream;

#[macro_export]
macro_rules! impl_generator {
    ($ty:ty, $base:ident) => {
        impl Generator for $ty {
            fn filename(&self) -> String {
                <Self as $base>::filename()
            }

            fn gen(&self, ctx: &Context) -> Result<TokenStream> {
                <Self as $base>::gen(ctx)
            }
        }
    };
}

// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::{context::Context, generator::Generator};
use crate::common::*;
use proc_macro2::TokenStream;
use quote::quote;

pub struct TypeParamGenerator;

impl Generator for TypeParamGenerator {
    fn filename(&self) -> String {
        "type_params.rs".into()
    }

    fn gen(&self, ctx: &Context) -> Result<TokenStream> {
        let ty_params = ctx.root_ty_params_with_context();
        Ok(quote! {
            pub trait Params {
                #(type #ty_params;)*
            }
        })
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

mod context;
mod gen_helper;
mod node_impl_generator;
mod node_trait_generator;
mod run;
mod syn_helper;
mod type_params_generator;
mod visitor_trait_generator;

// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::{context::Context, gen_helper, generator::Generator};
use crate::{common::*, impl_generator};
use proc_macro2::{Ident, TokenStream};
use quote::{format_ident, quote};

trait NodeTrait {
    fn filename() -> String;
    fn trait_name() -> syn::Ident;
    fn receiver(lifttime: &Ident) -> TokenStream;
    fn visitor() -> syn::Ident;
    fn use_visitor() -> TokenStream;

    fn gen(ctx: &Context) -> Result<TokenStream> {
        let trait_name = Self::trait_name();
        let node_lifetime = ctx.node_lifetime_ident();
        let receiver = Self::receiver(&node_lifetime);
        let node_lifetime = gen_helper::make_lifetime(&node_lifetime);
        let visitor = Self::visitor();
        let use_visitor = Self::use_visitor();
        let context = ctx.context_ident();
        let error = ctx.error_ident();
        Ok(quote! {
            #![allow(unused_variables)]
            #use_visitor
            use super::type_params::Params;

            pub trait #trait_name<P: Params> {
                fn accept<#node_lifetime>(
                    #receiver,
                    ctx: &mut P::#context,
                    v: &mut dyn #visitor<#node_lifetime, P = P>,
                ) -> Result<(), P::#error> {
                    self.recurse(ctx, v)
                }

                fn recurse<#node_lifetime>(
                    #receiver,
                    ctx: &mut P::#context,
                    v: &mut dyn #visitor<#node_lifetime, P = P>,
                ) -> Result<(), P::#error> {
                    Ok(())
                }
            }
        })
    }
}

pub struct RefNodeTrait;
impl NodeTrait for RefNodeTrait {
    fn filename() -> String {
        "node.rs".into()
    }

    fn trait_name() -> syn::Ident {
        format_ident!("Node")
    }

    fn receiver(lifetime: &Ident) -> TokenStream {
        let l = gen_helper::make_lifetime(lifetime);
        quote! {&#l self}
    }

    fn visitor() -> syn::Ident {
        format_ident!("Visitor")
    }

    fn use_visitor() -> TokenStream {
        quote! { use super::visitor::Visitor; }
    }
}
impl_generator!(RefNodeTrait, NodeTrait);

pub struct MutNodeTrait;
impl NodeTrait for MutNodeTrait {
    fn filename() -> String {
        "node_mut.rs".into()
    }

    fn trait_name() -> syn::Ident {
        format_ident!("NodeMut")
    }

    fn receiver(lifetime: &Ident) -> TokenStream {
        let l = gen_helper::make_lifetime(lifetime);
        quote! {&#l mut self}
    }

    fn visitor() -> syn::Ident {
        format_ident!("VisitorMut")
    }

    fn use_visitor() -> TokenStream {
        quote! { use super::visitor_mut::VisitorMut; }
    }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::{
    context::Context, gen_helper::*, generator::Generator, syn_helper::*, visitor_trait_generator,
};
use crate::impl_generator;
use anyhow::{anyhow, Result};
use proc_macro2::{Ident, TokenStream};
use quote::{format_ident, quote};

pub trait NodeImpl {
    fn filename() -> String;
    fn node_trait_name() -> syn::Ident;
    fn self_ref_kind(lifetime: Option<&Ident>) -> TokenStream;
    fn visitor_trait_name() -> syn::Ident;
    fn use_node() -> TokenStream;
    fn use_visitor() -> TokenStream;

    fn gen(ctx: &Context) -> Result<TokenStream> {
        let impls = ctx
            .non_alias_types()
            .map(|ty| {
                let ty = ty.as_ref();
                let item = ctx
                    .defs
                    .get(ty)
                    .ok_or_else(|| anyhow!("Type {} not found", ty))?;
                Self::gen_node_impl(ctx, ty, item)
            })
            .collect::<Result<Vec<_>>>()?;
        let use_node = Self::use_node();
        let use_visitor = Self::use_visitor();
        let uses = gen_module_uses(ctx.modules());
        Ok(quote! {
            #![allow(unused_variables)]

            #use_node
            #use_visitor
            #uses
            use super::type_params::Params;

            #(#impls)*
        })
    }

    fn gen_node_impl(ctx: &Context, ty_name: &str, ty_def: &syn::Item) -> Result<TokenStream> {
        let recurse_body = Self::gen_recurse_body(ctx, ty_name, ty_def)?;
        let visit_fn = visitor_trait_generator::gen_visit_fn_name(ty_name);
        let ty_name = format_ident!("{}", ty_name);
        let ty_params = gen_ty_params(get_ty_param_idents(ty_def)?);
        let node_trait_name = Self::node_trait_name();
        let node_lifetime = ctx.node_lifetime_ident();
        let self_ref_kind = Self::self_ref_kind(Some(&node_lifetime));
        let node_lifetime = make_lifetime(&node_lifetime);
        let visitor_trait_name = Self::visitor_trait_name();
        let context = ctx.context_ident();
        let error = ctx.error_ident();

        Ok(quote! {
            impl<P: Params> #node_trait_name<P> for #ty_name#ty_params {
                fn accept<#node_lifetime>(
                    #self_ref_kind self,
                    c: &mut P::#context,
                    v: &mut dyn #visitor_trait_name<#node_lifetime, P = P>
                ) -> Result<(), P::#error> {
                    v.#visit_fn(c, self)
                }

                fn recurse<#node_lifetime>(
                    #self_ref_kind self,
                    c: &mut P::#context,
                    v: &mut dyn #visitor_trait_name<#node_lifetime, P = P>
                ) -> Result<(), P::#error> {
                    #recurse_body
                }
            }
        })
    }

    fn try_simple_ty_param(ctx: &Context, ty: &syn::Type) -> Option<String> {
        try_simple_type(ty).filter(|t| ctx.is_root_ty_param(t))
    }

    fn try_gen_simple_ty_param_visit_call(
        ctx: &Context,
        ty: &syn::Type,
        accessor: TokenStream,
    ) -> Option<TokenStream> {
        let ref_kind = Self::self_ref_kind(None);
        try_simple_type(ty)
            .filter(|t| ctx.is_root_ty_param(t))
            .map(|ty| {
                let fn_name = visitor_trait_generator::gen_visit_fn_name(ty);
                quote! {v.#fn_name( c, #ref_kind #accessor )?;}
            })
    }

    fn gen_recurse_body(ctx: &Context, ty_name: &str, ty: &syn::Item) -> Result<TokenStream> {
        use syn::{Item::*, *};
        match ty {
            Struct(ItemStruct { fields, .. }) => match fields {
                Fields::Named(fields) => {
                    let fields = get_field_and_type_from_named(fields);
                    let calls = fields.iter().map(|(name, ty)| {
                        let accessor = format_ident!("{}", name);
                        Self::try_gen_simple_ty_param_visit_call(ctx, ty, quote! { self.#accessor})
                            .unwrap_or(quote! {self.#accessor.accept(c, v)?;})
                    });
                    Ok(quote! {
                        #(#calls)*
                        Ok(())
                    })
                }
                Fields::Unnamed(fields) => {
                    let fields = get_field_and_type_from_unnamed(fields);
                    let calls = fields.map(|(i, ty)| {
                        let accessor = Index::from(i);
                        Self::try_gen_simple_ty_param_visit_call(ctx, ty, quote! { self.#accessor})
                            .unwrap_or(quote! {self.#accessor.accept(c, v)?;})
                    });
                    Ok(quote! {
                        #(#calls)*
                        Ok(())
                    })
                }
                Fields::Unit => Ok(quote! {}),
            },
            Enum(ItemEnum { variants, .. }) => {
                let mut arms: Vec<TokenStream> = vec![];
                for Variant {
                    ident: variant_name,
                    fields,
                    ..
                } in variants.iter()
                {
                    let ty_name = format_ident!("{}", ty_name);
                    match fields {
                        Fields::Named(_fields) => {
                            return Err(anyhow!(
                                "Enum with named fields not supported yet. Enum {:?}",
                                ty_name
                            ));
                        }
                        Fields::Unnamed(fields) => {
                            let mut pattern = vec![];
                            let mut calls = vec![];
                            if let Some(tys) = try_get_types_from_box_tuple(fields) {
                                let v = format_ident!("a");
                                pattern.push(quote! {#v});
                                calls.extend(tys.map(|(i, ty)| {
                                    let accessor = &Index::from(i);
                                    Self::try_gen_simple_ty_param_visit_call(
                                        ctx,
                                        ty,
                                        quote! { #v.#accessor },
                                    )
                                    .unwrap_or(quote! {#v.#accessor.accept(c, v)?;})
                                }));
                            } else {
                                let fields =
                                    get_field_and_type_from_unnamed(fields).collect::<Vec<_>>();
                                for (i, ty) in fields.iter() {
                                    let v = format_ident!("a{}", *i);
                                    pattern.push(quote! {#v,});
                                    calls.push(
                                        Self::try_gen_simple_ty_param_visit_call(
                                            ctx,
                                            ty,
                                            quote! { #v },
                                        )
                                        .unwrap_or(quote! { #v.accept(c, v)?; }),
                                    );
                                }
                            }
                            arms.push(quote! {
                                #ty_name::#variant_name(#(# pattern)*) => {
                                    #(#calls)*
                                    Ok(())
                                }
                            });
                        }
                        Fields::Unit => arms.push(quote! {
                            #ty_name::#variant_name => { {Ok(())} }
                        }),
                    }
                }
                match arms.as_slice() {
                    [] => Ok(quote! {}),
                    _ => Ok(quote! {
                        match self {
                            #(#arms)*
                        }
                    }),
                }
            }
            _ => Ok(quote! {}),
        }
    }
}

pub struct RefNodeImpl;
impl NodeImpl for RefNodeImpl {
    fn filename() -> String {
        "node_impl_gen.rs".into()
    }
    fn node_trait_name() -> syn::Ident {
        format_ident!("Node")
    }
    fn self_ref_kind(lifetime: Option<&Ident>) -> TokenStream {
        match lifetime {
            Some(l) => {
                let l = make_lifetime(l);
                quote! {&#l}
            }
            None => quote! {&},
        }
    }
    fn visitor_trait_name() -> syn::Ident {
        format_ident!("Visitor")
    }
    fn use_node() -> TokenStream {
        quote! { use super::node::Node; }
    }
    fn use_visitor() -> TokenStream {
        quote! { use super::visitor::Visitor; }
    }
}
impl_generator!(RefNodeImpl, NodeImpl);

pub struct MutNodeImpl;
impl NodeImpl for MutNodeImpl {
    fn filename() -> String {
        "node_mut_impl_gen.rs".into()
    }
    fn node_trait_name() -> syn::Ident {
        format_ident!("NodeMut")
    }
    fn self_ref_kind(lifetime: Option<&Ident>) -> TokenStream {
        match lifetime {
            Some(l) => {
                let l = make_lifetime(l);
                quote! {&#l mut}
            }
            None => quote! {&mut},
        }
    }
    fn visitor_trait_name() -> syn::Ident {
        format_ident!("VisitorMut")
    }
    fn use_node() -> TokenStream {
        quote! { use super::node_mut::NodeMut; }
    }
    fn use_visitor() -> TokenStream {
        quote! { use super::visitor_mut::VisitorMut; }
    }
}
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::{context::Context, gen_helper::*, generator::Generator, syn_helper::*};
use crate::{common::*, impl_generator};
use anyhow::{anyhow, Result};
use proc_macro2::TokenStream;
use quote::{format_ident, quote};

pub trait VisitorTrait {
    fn filename() -> String;
    fn trait_name() -> syn::Ident;
    fn node_ref_kind(lifetime: &TokenStream) -> TokenStream;
    fn use_node() -> TokenStream;
    fn node_trait_name() -> syn::Ident;

    fn gen(ctx: &Context) -> Result<TokenStream> {
        let use_node = Self::use_node();
        let trait_name = Self::trait_name();
        let node_dispatcher_function = Self::gen_node_dispatcher_function(ctx)?;
        let visit_functions = Self::gen_visit_functions(ctx)?;
        let visit_ty_params = Self::gen_visit_ty_params(ctx)?;
        let uses = gen_module_uses(ctx.modules());

        let lifetime = ctx.node_lifetime_ident();
        let lifetime = make_lifetime(&lifetime);

        Ok(quote! {
            #![allow(unused_variables)]

            #uses
            #use_node
            use super::type_params::Params;

            #node_dispatcher_function

            pub trait #trait_name<#lifetime> {
                type P: Params;

                fn object(&mut self) -> &mut dyn #trait_name<#lifetime, P = Self::P>;

                #(#visit_ty_params)*

                #(#visit_functions)*
            }
        })
    }

    fn gen_visit_ty_params(ctx: &Context) -> Result<Vec<TokenStream>> {
        let lifetime = ctx.node_lifetime_ident();
        let lifetime = make_lifetime(&lifetime);
        let ref_kind = Self::node_ref_kind(&lifetime);
        let context = ctx.context_ident();
        let error = ctx.error_ident();
        Ok(ctx
            .root_ty_params_()
            .map(|ty| {
                let name = gen_visit_fn_name(ty.to_string());
                quote! {
                    fn #name(&mut self, c: &mut <Self::P as Params>::#context, p: #ref_kind <Self::P as Params>::#ty) ->  Result<(), <Self::P as Params>::#error> {
                        Ok(())
                    }
                }
            })
            .collect())
    }

    fn gen_visit_functions(ctx: &Context) -> Result<Vec<TokenStream>> {
        let lifetime = ctx.node_lifetime_ident_with_quote();
        let ref_kind = Self::node_ref_kind(&lifetime);
        let context = ctx.context_ident();
        let error = ctx.error_ident();
        let mut visit_fn = vec![];
        for ty in ctx.non_alias_types() {
            let ty = ty.as_ref();
            let def = ctx
                .defs
                .get(ty)
                .ok_or_else(|| anyhow!("Type {} not found", ty))?;
            let ty_params = get_ty_param_idents(def)?;
            let ty_args = gen_ty_params_with_self(ty_params);
            let name = gen_visit_fn_name(ty);
            let ty = format_ident!("{}", ty);
            visit_fn.push(quote! {
                fn #name(&mut self, c: &mut <Self::P as Params>::#context, p: #ref_kind #ty#ty_args) -> Result<(), <Self::P as Params>::#error> {
                    p.recurse(c, self.object())
                }
            });
        }
        Ok(visit_fn)
    }

    fn gen_node_dispatcher_function(ctx: &Context) -> Result<TokenStream> {
        let visitor_trait_name = Self::trait_name();
        let context = ctx.context_ident();
        let error = ctx.error_ident();
        let lifetime = ctx.node_lifetime_ident_with_quote();
        let node_ref_kind = Self::node_ref_kind(&lifetime);
        let node_trait_name = Self::node_trait_name();
        Ok(quote! {
            pub fn visit<#lifetime, P: Params>(
                v: &mut impl #visitor_trait_name<#lifetime, P = P>,
                c: &mut P::#context,
                p: #node_ref_kind impl #node_trait_name<P>,
            ) -> Result<(), P::#error> {
                p.accept(c, v)
            }
        })
    }
}

pub fn gen_visit_fn_name(ty: impl AsRef<str>) -> syn::Ident {
    format_ident!("visit_{}", to_snake(ty.as_ref()))
}

pub struct RefVisitorTrait;
impl VisitorTrait for RefVisitorTrait {
    fn filename() -> String {
        "visitor.rs".into()
    }

    fn trait_name() -> syn::Ident {
        format_ident!("Visitor")
    }

    fn node_ref_kind(lifetime: &TokenStream) -> TokenStream {
        quote! { &#lifetime }
    }

    fn use_node() -> TokenStream {
        quote! { use super::node::Node; }
    }

    fn node_trait_name() -> syn::Ident {
        format_ident!("Node")
    }
}
impl_generator!(RefVisitorTrait, VisitorTrait);

pub struct MutVisitorTrait;
impl VisitorTrait for MutVisitorTrait {
    fn filename() -> String {
        "visitor_mut.rs".into()
    }

    fn trait_name() -> syn::Ident {
        format_ident!("VisitorMut")
    }

    fn node_ref_kind(lifetime: &TokenStream) -> TokenStream {
        quote! { &#lifetime mut }
    }

    fn use_node() -> TokenStream {
        quote! { use super::node_mut::NodeMut; }
    }

// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use std::fmt::Write;

pub use anyhow::Result;

pub fn to_snake(s: &str) -> String {
    let mut r = String::new();
    let chars: Vec<char> = s.chars().collect();
    for i in 0..chars.len() {
        if chars[i].is_ascii_uppercase() {
            if i != 0
                && chars[i - 1].is_ascii_lowercase()
                && (i + 1 == chars.len() || chars[i + 1].is_ascii_lowercase())
            {
                r.push('_');
            }
            r.push(chars[i].to_ascii_lowercase());
        } else {
            r.push(chars[i])
        }
    }
    r
}

pub fn insert_header(s: &str, command: &str) -> Result<String> {
    let mut content = String::new();
    write!(
        &mut content,
        "
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the \"hack\" directory of this source tree.
//
// @{} <<SignedSource::*O*zOeWoEQle#+L!plEphiEmie@IsG>>
//
// To regenerate this file, run:
//   {}

{}
",
        "generated", command, s
    )?;
    Ok(content)
}

pub mod gen_helpers {
    use proc_macro2::TokenStream;
    use quote::{format_ident, quote};

    pub fn gen_module_uses(ms: impl Iterator<Item = impl AsRef<str>>) -> TokenStream {
        let mods = ms.map(|m| format_ident!("{}", m.as_ref()));
        quote! {
            use crate::{#(#mods::*,)*};
        }
    }
}

pub mod syn_helpers {
    use std::collections::HashSet;

    use anyhow::{anyhow, Result};
    use syn::*;

    pub fn get_ty_def_name(i: &Item) -> Result<String> {
        use Item::*;
        match i {
            Enum(ItemEnum { ident, .. })
            | Struct(ItemStruct { ident, .. })
            | Type(ItemType { ident, .. }) => Ok(ident.to_string()),
            _ => Err(anyhow!("Not supported {:?}", i)),
        }
    }

    pub fn get_dep_tys(defined_types: &HashSet<&str>, i: &Item) -> Result<Vec<String>> {
        use Item::*;
        match i {
            Enum(ItemEnum { variants, .. }) => Ok(variants
                .iter()
                .fold(HashSet::<String>::new(), |mut a, v| {
                    for ty in LeafTyCollector::on_fields(Some(defined_types), &v.fields) {
                        a.insert(ty);
                    }
                    a
                })
                .into_iter()
                .collect()),
            Type(ItemType { ty, .. }) => {
                Ok(LeafTyCollector::on_type(Some(defined_types), ty.as_ref()).collect())
            }
            Struct(ItemStruct { fields, .. }) => {
                Ok(LeafTyCollector::on_fields(Some(defined_types), fields).collect())
            }
            _ => Err(anyhow!("Not supported {:?}", i)),
        }
    }

    struct LeafTyCollector {
        discovered_types: HashSet<String>,
    }

    impl LeafTyCollector {
        pub fn new() -> Self {
            Self {
                discovered_types: HashSet::new(),
            }
        }

        pub fn on_type<'a>(
            filter: Option<&'a HashSet<&'a str>>,
            ty: &Type,
        ) -> impl Iterator<Item = String> + 'a {
            let mut collector = Self::new();
            visit::visit_type(&mut collector, ty);
            collector
                .discovered_types
                .into_iter()
                .filter(move |s| filter.map_or(true, |f| f.contains(s.as_str())))
        }

        pub fn on_fields<'a>(
            filter: Option<&'a HashSet<&'a str>>,
            fields: &Fields,
        ) -> impl Iterator<Item = String> + 'a {
            let mut collector = Self::new();
            visit::visit_fields(&mut collector, fields);
            collector
                .discovered_types
                .into_iter()
                .filter(move |s| filter.map_or(true, |f| f.contains(s.as_str())))
        }
    }

    impl<'ast> visit::Visit<'ast> for LeafTyCollector {
        fn visit_path_segment(&mut self, node: &'ast PathSegment) {
            let ty = node.ident.to_string();
            self.discovered_types.insert(ty);
            visit::visit_path_segment(self, node);
        }
    }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use std::collections::{BTreeMap, BTreeSet, HashMap, HashSet, VecDeque};
use std::path::Path;

use anyhow::{anyhow, Result};
use synstructure::Structure;

use crate::common::syn_helpers;

pub struct Context {
    pub defs: BTreeMap<String, syn::DeriveInput>,
    pub mods: BTreeSet<String>,
}

impl Context {
    pub fn new(
        files: &[(&Path, Vec<syn::Item>)],
        extern_files: &[(&Path, Vec<syn::Item>)],
        root: &str,
    ) -> Result<Self> {
        let mut defs = HashMap::new();
        let mut mods = BTreeSet::new();
        for (filename, items) in files {
            eprintln!("Processing {:?}", filename);
            for item in items.iter() {
                if let Ok(name) = syn_helpers::get_ty_def_name(item) {
                    if defs.contains_key(&name) {
                        return Err(anyhow!("Type {} already exists, file {:?}", name, filename));
                    }
                    defs.insert(name, item);
                }
            }
            // assuming file name is the module name
            mods.insert(
                filename
                    .file_stem()
                    .and_then(|stem| stem.to_str())
                    .unwrap()
                    .into(),
            );
        }
        // The "extern" files provide the definitions of types which were
        // imported from the oxidized crate to the oxidized_by_ref crate via
        // an extern_types.txt file.
        for (filename, items) in extern_files {
            eprintln!("Processing extern file {:?}", filename);
            for item in items.iter() {
                if let Ok(name) = syn_helpers::get_ty_def_name(item) {
                    // Don't overwrite a definition if one is already there--we
                    // only need to fill in the ones which are missing (because
                    // they were re-exported from oxidized).
                    defs.entry(name).or_insert(item);
                }
            }
        }
        let reachable = Self::get_all_tys(&defs, root)?;
        let defs = defs
            .into_iter()
            .filter(|(ty_name, _)| reachable.contains(ty_name.as_str()))
            .filter_map(|(ty_name, item)| {
                use syn::Item::*;
                match item {
                    Struct(item_struct) => Some((ty_name, item_struct.clone().into())),
                    Enum(item_enum) => Some((ty_name, item_enum.clone().into())),
                    _ => None,
                }
            })
            .collect();
        Ok(Self { defs, mods })
    }

    pub fn modules(&self) -> impl Iterator<Item = &str> {
        self.mods.iter().map(|s| s.as_ref())
    }

    pub fn types(&self) -> impl Iterator<Item = &syn::DeriveInput> {
        self.defs.values()
    }

    pub fn type_structures(&self) -> impl Iterator<Item = Structure<'_>> {
        self.types().map(Structure::new)
    }

    fn get_all_tys(defs: &HashMap<String, &syn::Item>, root: &str) -> Result<HashSet<String>> {
        let defined_types = defs.keys().map(|s| s.as_str()).collect();
        let mut visited = HashSet::<String>::new();
        let mut q = VecDeque::new();
        q.push_back(root.into());
        while let Some(ty) = q.pop_front() {
            let item = defs
                .get(&ty)
                .ok_or_else(|| anyhow!("Type {} not found", ty))?;
            visited.insert(ty);
            let deps = syn_helpers::get_dep_tys(&defined_types, item)?;
            for d in deps.into_iter() {
                if !visited.contains(&d) {
                    q.push_back(d);
                }
            }
        }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

mod context;
mod node_impl_generator;
mod visitor_trait_generator;

use std::path::{Path, PathBuf};

use anyhow::Result;
use structopt::StructOpt;

use context::Context;

#[derive(Debug, StructOpt)]
pub struct Args {
    /// Rust files containing the types for which codegen will be performed.
    /// All types reachable from the given root type must be defined in one of
    /// the files provided as `--input` or `--extern-input`.
    #[structopt(short, long, parse(from_os_str))]
    input: Vec<PathBuf>,

    /// Rust files containing the types for which codegen will be performed.
    /// All types reachable from the given root type must be defined in on of
    /// the files provided as `--input` or `--extern-input`.
    #[structopt(short, long, parse(from_os_str))]
    extern_input: Vec<PathBuf>,

    /// The root type of the AST. All types reachable from this type will be
    /// visited by the generated visitor.
    #[structopt(short, long)]
    root: String,

    /// The directory to which generated files will be written.
    #[structopt(short, long, parse(from_os_str))]
    output: PathBuf,
}

pub fn run(args: &Args) -> Result<Vec<(PathBuf, String)>> {
    let files = parse_all(&args.input)?;
    let extern_files = parse_all(&args.extern_input)?;

    let ctx = Context::new(files.as_slice(), extern_files.as_slice(), &args.root)?;

    let results = vec![
        ("node_impl_gen.rs", node_impl_generator::gen(&ctx)),
        ("visitor.rs", visitor_trait_generator::gen(&ctx)),
    ];
    Ok(results
        .iter()
        .map(|(filename, source)| (args.output.join(filename), source.to_string()))
        .collect())
}

fn parse_all<'a>(files: &'a [PathBuf]) -> Result<Vec<(&'a Path, Vec<syn::Item>)>> {
    files
        .iter()
        .map(|filename| -> Result<(&Path, Vec<syn::Item>)> {
            let src = std::fs::read_to_string(&filename)?;
            let file = syn::parse_file(&src)?;
            Ok((&filename, file.items.into_iter().collect()))
        })
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use proc_macro2::TokenStream;
use quote::quote;

use crate::common::gen_helpers;

use super::context::Context;
use super::visitor_trait_generator;

pub fn gen(ctx: &Context) -> TokenStream {
    let uses = gen_helpers::gen_module_uses(ctx.modules());
    let impls = ctx.type_structures().map(gen_node_impl).collect::<Vec<_>>();

    quote! {
        #![allow(unused_variables)]
        #![allow(unused_braces)]

        use super::node::Node;
        use super::visitor::Visitor;
        #uses

        #(#impls)*
    }
}

fn gen_node_impl(s: synstructure::Structure<'_>) -> TokenStream {
    let ty_name = &s.ast().ident;
    let (_, ty_generics, _) = s.ast().generics.split_for_impl();
    let visit_fn = visitor_trait_generator::gen_visit_fn_name(ty_name.to_string());
    let recurse_body = s.each(|bi| quote! { #bi.accept(v) });

    // Sanity check: ensure that all types have at most one lifetime with name `'a`.
    let lifetimes = s.ast().generics.lifetimes().collect::<Vec<_>>();
    assert!(lifetimes.len() <= 1);
    if let Some(lifetime) = lifetimes.first() {
        assert_eq!("a", lifetime.lifetime.ident.to_string());
    }

    quote! {
        impl<'a> Node<'a> for #ty_name #ty_generics {
            fn accept(&'a self, v: &mut dyn Visitor<'a>) {
                v.#visit_fn(self)
            }

            fn recurse(&'a self, v: &mut dyn Visitor<'a>) {
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use proc_macro2::TokenStream;
use quote::{format_ident, quote};

use crate::common::{gen_helpers, to_snake};

use super::context::Context;

pub fn gen(ctx: &Context) -> TokenStream {
    let uses = gen_helpers::gen_module_uses(ctx.modules());
    let visit_functions = ctx.types().map(gen_visit_function).collect::<Vec<_>>();

    quote! {
        #![allow(unused_variables)]

        #uses
        use super::node::Node;

        pub trait Visitor<'a> {
            fn object(&mut self) -> &mut dyn Visitor<'a>;

            #(#visit_functions)*
        }
    }
}

fn gen_visit_function(ast: &syn::DeriveInput) -> TokenStream {
    let ty = &ast.ident;
    let name = gen_visit_fn_name(ty.to_string());
    let (_, ty_generics, _) = ast.generics.split_for_impl();
    quote! {
        fn #name(&mut self, p: &'a #ty #ty_generics) {
            p.recurse(self.object())
        }
    }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use proc_macro2::TokenStream;
use quote::{quote, ToTokens};
use syn::*;

pub enum RefKind {
    Ref,
    RefMut,
    Owned,
}

impl RefKind {
    pub fn mk_value(
        &self,
        var: &impl ToTokens,
        is_box: bool,
        tuple_accessor: Option<usize>,
    ) -> TokenStream {
        let accessor = tuple_accessor.map(Index::from);
        match (self, is_box, accessor) {
            (_, false, _) => quote! { #var },

            (RefKind::Ref, true, None) => quote! { &#var },
            (RefKind::Ref, true, Some(i)) => quote! { &#var.#i },

            (RefKind::RefMut, true, None) => quote! { #var.as_mut() },
            (RefKind::RefMut, true, Some(i)) => quote! { &mut #var.#i },

            (RefKind::Owned, true, None) => quote! { *#var },
            (RefKind::Owned, true, Some(i)) => quote! { (*#var).#i },
        }
    }

    pub fn mk_ty(&self, ty: &impl ToTokens) -> proc_macro2::TokenStream {
        match self {
            RefKind::Ref => quote! { &#ty },
            RefKind::RefMut => quote! { &mut #ty },
            RefKind::Owned => quote! { #ty },
        }
    }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

mod ref_kind;

use crate::{common::*, quote_helper::*};

use anyhow::{anyhow, Result};
use proc_macro2::TokenStream;
use quote::{format_ident, quote};
use ref_kind::RefKind;
use std::{
    fmt::Write,
    fs::File,
    io::Read,
    path::{Path, PathBuf},
};
use structopt::StructOpt;
use syn::*;

#[derive(Debug, StructOpt)]
pub struct Args {
    /// Rust files containing the enum types for which codegen will be performed.
    #[structopt(short, long)]
    input: Vec<String>,

    /// The directory to which generated files will be written.
    #[structopt(short, long, parse(from_os_str))]
    output: PathBuf,
}

pub fn run(args: &Args) -> Result<Vec<(PathBuf, String)>> {
    let inputs = &args.input;
    let output_dir = &args.output;
    let mut result = vec![];
    let mut mods = vec![];
    for input in inputs {
        let (file, uses) = parse_input_arg(input);
        eprintln!("Process: {}", file);
        eprintln!("Uses: {:?}", uses);
        let mut output_filename = Path::new(file)
            .file_stem()
            .ok_or_else(|| anyhow!("Unable to get file stem"))?
            .to_os_string();
        output_filename.push("_impl_gen");
        mods.push(output_filename.clone().into_string().unwrap());
        output_filename.push(".rs");
        let output_file = output_dir.join(Path::new(&output_filename));
        let mut file = File::open(file)?;
        let mut src = String::new();
        file.read_to_string(&mut src)?;
        let file = syn::parse_file(&src)?;
        let output = mk_file(&file, uses);
        let mut output_content = String::new();
        write!(&mut output_content, "{}", output)?;
        eprintln!("Output: {:?}", output_file);
        result.push((output_file, output_content));
    }

    let mut mod_filename = output_dir.to_path_buf();
    mod_filename.push("mod.rs");
    let mod_content = mk_mod_file(mods)?;
    result.push((mod_filename, mod_content));
    Ok(result)
}

fn mk_mod_file(mods: Vec<String>) -> Result<String> {
    let mods = mods.into_iter().map(|m| format_ident!("{}", m));
    let content = quote! {
      #(pub mod #mods;)*
    };
    let mut result = String::new();
    write!(&mut result, "{}", content)?;
    Ok(result)
}

fn parse_input_arg<'a>(file_with_uses: &'a str) -> (&'a str, Vec<&'a str>) {
    let mut data = file_with_uses.split("|");
    (data.next().unwrap(), data.collect::<Vec<_>>())
}

fn mk_file(file: &syn::File, uses: Vec<&str>) -> TokenStream {
    let uses = uses
        .into_iter()
        .map(|u| syn::parse_str::<UseTree>(u).unwrap());
    let enums = get_enums(&file);
    let content = enums.into_iter().map(mk_impl);
    quote! {
        #(use #uses;)*
        #(#content)*
    }
}

fn mk_impl(e: &ItemEnum) -> TokenStream {
    let name = &e.ident;
    let is_singleton = e.variants.len() < 2;
    let generics = &e.generics;
    let constrs = e.variants.iter().map(|v| mk_constr(name, v));
    let is_functions = e
        .variants
        .iter()
        .map(|v| mk_is_function(name, v, is_singleton));
    let as_ref_functions = e
        .variants
        .iter()
        .map(|v| mk_as_function("", name, v, RefKind::Ref, is_singleton));

    let as_mut_functions = e
        .variants
        .iter()
        .map(|v| mk_as_function("_mut", name, v, RefKind::RefMut, is_singleton));

    let as_into_functions = e
        .variants
        .iter()
        .map(|v| mk_as_function("_into", name, v, RefKind::Owned, is_singleton));

    quote! {
        impl#generics #name#generics {
            #(#constrs)*
            #(#is_functions)*
            #(#as_ref_functions)*
            #(#as_mut_functions)*
            #(#as_into_functions)*
        }
    }
}

fn mk_as_function(
    fn_name_suffix: &str,
    enum_name: &Ident,
    v: &Variant,
    ref_kind: RefKind,
    is_singleton: bool,
) -> TokenStream {
    let name = &v.ident;
    let fn_name = format_ident!("as_{}{}", &to_snake(&name.to_string()), fn_name_suffix);
    match &v.fields {
        Fields::Unit => quote! {},
        Fields::Unnamed(FieldsUnnamed { unnamed, .. }) => {
            let mut i = 0;
            let mut field_match: Vec<TokenStream> = vec![];
            let mut results: Vec<TokenStream> = vec![];
            let mut return_tys: Vec<TokenStream> = vec![];
            for field in unnamed {
                let matched = format_ident!("p{}", i.to_string());
                field_match.push(quote! { #matched, });
                let tys = unbox(&field.ty);
                if tys.is_empty() {
                    results.push(ref_kind.mk_value(&matched, false, None));
                    return_tys.push(ref_kind.mk_ty(&field.ty));
                } else if tys.len() == 1 {
                    results.push(ref_kind.mk_value(&matched, true, None));
                    return_tys.push(ref_kind.mk_ty(&tys[0]));
                } else {
                    let mut j = 0;
                    for ty in tys {
                        results.push(ref_kind.mk_value(&matched, true, Some(j)));
                        return_tys.push(ref_kind.mk_ty(ty));
                        j += 1;
                    }
                }
                i += 1;
            }
            let sep = <Token![,]>::default();
            let return_tys = if return_tys.len() > 1 {
                with_paren(join(return_tys.iter(), sep))
            } else {
                join(return_tys.iter(), sep)
            };
            let results = if results.len() > 1 {
                with_paren(join(results.iter(), sep))
            } else {
                join(results.iter(), sep)
            };
            let self_ = ref_kind.mk_ty(&format_ident!("self"));
            let else_ = if is_singleton {
                quote! {}
            } else {
                quote! { _ => None, }
            };
            quote! {
                pub fn #fn_name(#self_) -> Option<#return_tys> {
                    match self {
                        #enum_name::#name(#(#field_match)*) => Some(#results),
                        #else_
                    }
                }
            }
        }
        Fields::Named(_) => {
            eprintln!("Warning: not support named field: {:?}", &v.ident);
            quote! {}
        }
    }
}

fn mk_is_function(enum_name: &Ident, v: &Variant, is_singleton: bool) -> TokenStream {
    let name = &v.ident;
    let field_match = if let Fields::Unit = &v.fields {
        quote! {}
    } else {
        quote! { (..) }
    };
    let body = if is_singleton {
        quote! { true }
    } else {
        quote! {
            match self {
                #enum_name::#name#field_match => true,
                _ => false,
            }
        }
    };
    let fn_name = format_ident!("is_{}", &to_snake(&name.to_string()));
    quote! {
        pub fn #fn_name(&self) -> bool { #body }
    }
}

fn mk_constr(enum_name: &Ident, v: &Variant) -> TokenStream {
    let name = &v.ident;
    let fn_name = format_ident!("mk_{}", &to_snake(&name.to_string()));
    match &v.fields {
        Fields::Unit => quote! {
            pub fn #fn_name () -> Self {
                #enum_name::#name
            }
        },
        Fields::Unnamed(FieldsUnnamed { unnamed, .. }) => {
            let mut i = 0;
            let mut params: Vec<TokenStream> = vec![];
            let mut args: Vec<TokenStream> = vec![];
            for f in unnamed {
                let ty = &f.ty;
                let boxed_tys = unbox(ty);
                if boxed_tys.is_empty() {
                    let param = format_ident!("p{}", i.to_string());
                    params.push(quote! {#param : #ty, });
                    args.push(quote! {#param ,});
                    i += 1;
                } else if boxed_tys.len() == 1 {
                    let param = format_ident!("p{}", i.to_string());
                    let ty = boxed_tys[0];
                    params.push(quote! {#param : #ty, });
                    args.push(quote! {Box::new(#param) ,});
                    i += 1;
                } else {
                    let mut tuple_items: Vec<TokenStream> = vec![];
                    for ty in boxed_tys.iter() {
                        let param = format_ident!("p{}", i.to_string());
                        params.push(quote! {#param : #ty, });
                        tuple_items.push(quote! {#param, });
                        i += 1;
                    }
                    args.push(quote! {Box::new(( #(#tuple_items)* )) ,});
                }
            }
            quote! {
                pub fn #fn_name (#(#params)*) -> Self {
                    #enum_name::#name(#(#args)*)
                }
            }
        }
        Fields::Named(_) => {
            eprintln!("Warning: not support named field: {:?}", &v.ident);
            quote! {}
        }
    }
}

fn get_enums(file: &syn::File) -> Vec<&ItemEnum> {
    let mut r = vec![];
    for i in file.items.iter() {
        if let Item::Enum(e) = i {
            r.push(e);
        }
    }
    r
}

fn unbox(ty: &Type) -> Vec<&Type> {
    if let Type::Path(TypePath { path, .. }) = ty {
        if let Some(path_seg) = path.segments.first() {
            if path_seg.ident == "Box" {
                if let syn::PathArguments::AngleBracketed(args) = &path_seg.arguments {
                    match args.args.first() {
                        Some(GenericArgument::Type(Type::Tuple(syn::TypeTuple {
                            elems, ..
                        }))) => {
                            return elems.iter().collect::<Vec<_>>();
                        }
                        Some(GenericArgument::Type(ty)) => {
                            return vec![ty];
                        }
                        _ => {
                            eprintln!("Warnning: box missing type argument");
                            return vec![ty];
                        }
                    }
                }
            }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use proc_macro2::TokenStream;
use quote::{quote, ToTokens};

pub fn join(mut tokens: impl Iterator<Item = impl ToTokens>, sep: impl ToTokens) -> TokenStream {
    let mut acc: Vec<TokenStream> = vec![];
    if let Some(t) = tokens.next() {
        acc.push(quote! {#t});
    }
    for t in tokens {
        acc.push(quote! {#sep #t});
    }
    quote! { #(#acc)* }
}

// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.
#![deny(clippy::mut_from_ref)]

use bumpalo::Bump;

pub trait Arena {
    #[allow(clippy::mut_from_ref)]
    fn alloc<T: TrivialDrop>(&self, val: T) -> &mut T;
}

impl Arena for Bump {
    #[allow(clippy::mut_from_ref)]
    #[inline(always)]
    fn alloc<T: TrivialDrop>(&self, val: T) -> &mut T {
        self.alloc(val)
    }
}

/// Marker trait for types whose implementation of `Drop` is a no-op.
///
/// Used to denote types which can be moved into an arena (which does not drop
/// its contents) without leaking memory.
///
/// Must not be implemented for any type which owns heap memory or otherwise
/// needs to run cleanup in its `Drop` implementation (e.g., `Box`, `Vec`,
/// `std::fs::File`, etc.), or any type containing a field with such a
/// nontrivial `Drop` implementation.
pub trait TrivialDrop {}

impl TrivialDrop for () {}

impl TrivialDrop for bool {}

impl TrivialDrop for usize {}
impl TrivialDrop for u8 {}
impl TrivialDrop for u16 {}
impl TrivialDrop for u32 {}
impl TrivialDrop for u64 {}
impl TrivialDrop for u128 {}

impl TrivialDrop for isize {}
impl TrivialDrop for i8 {}
impl TrivialDrop for i16 {}
impl TrivialDrop for i32 {}
impl TrivialDrop for i64 {}
impl TrivialDrop for i128 {}

impl TrivialDrop for f32 {}
impl TrivialDrop for f64 {}

impl TrivialDrop for str {}
impl TrivialDrop for &str {}

impl<T: TrivialDrop> TrivialDrop for [T] {}
impl<T> TrivialDrop for &[T] {}

impl<T: Sized> TrivialDrop for &T {}

impl<T: TrivialDrop> TrivialDrop for Option<T> {}

impl<T: TrivialDrop, E: TrivialDrop> TrivialDrop for Result<T, E> {}

impl<T0, T1> TrivialDrop for (T0, T1)
where
    T0: TrivialDrop,
    T1: TrivialDrop,
{
}

impl<T0, T1, T2> TrivialDrop for (T0, T1, T2)
where
    T0: TrivialDrop,
    T1: TrivialDrop,
    T2: TrivialDrop,
{
}

impl<T0, T1, T2, T3> TrivialDrop for (T0, T1, T2, T3)
where
    T0: TrivialDrop,
    T1: TrivialDrop,
    T2: TrivialDrop,
    T3: TrivialDrop,
{
}

impl<T0, T1, T2, T3, T4> TrivialDrop for (T0, T1, T2, T3, T4)
where
    T0: TrivialDrop,
    T1: TrivialDrop,
    T2: TrivialDrop,
    T3: TrivialDrop,
    T4: TrivialDrop,
{
}

impl<T0, T1, T2, T3, T4, T5> TrivialDrop for (T0, T1, T2, T3, T4, T5)
where
    T0: TrivialDrop,
    T1: TrivialDrop,
    T2: TrivialDrop,
    T3: TrivialDrop,
    T4: TrivialDrop,
    T5: TrivialDrop,
{
}

impl<T0, T1, T2, T3, T4, T5, T6> TrivialDrop for (T0, T1, T2, T3, T4, T5, T6)
where
    T0: TrivialDrop,
    T1: TrivialDrop,
    T2: TrivialDrop,
    T3: TrivialDrop,
    T4: TrivialDrop,
    T5: TrivialDrop,
    T6: TrivialDrop,
{
}

impl<T0, T1, T2, T3, T4, T5, T6, T7> TrivialDrop for (T0, T1, T2, T3, T4, T5, T6, T7)
where
    T0: TrivialDrop,
    T1: TrivialDrop,
    T2: TrivialDrop,
    T3: TrivialDrop,
    T4: TrivialDrop,
    T5: TrivialDrop,
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use core_utils_rust as core_utils;
use namespaces_rust as namespaces;
use naming_special_names_rust as sn;
use std::collections::HashSet;

use oxidized::{
    aast_visitor::{AstParams, NodeMut, VisitorMut},
    ast::*,
    namespace_env,
};

fn is_special_identifier(name: &str) -> bool {
    use lazy_static::lazy_static;

    lazy_static! {
        static ref SPECIAL_IDENTIFIERS: HashSet<&'static str> = vec![
            sn::members::M_CLASS,
            sn::classes::PARENT,
            sn::classes::SELF,
            sn::classes::STATIC,
            sn::special_idents::THIS,
            sn::special_idents::DOLLAR_DOLLAR,
            sn::typehints::WILDCARD,
        ]
        .into_iter()
        .collect();
    }

    SPECIAL_IDENTIFIERS.contains(&name)
}

#[derive(Clone)]
struct Env {
    // TODO(hrust) I wanted to make namespace and type_params str's references but couldn't
    // find a way to specify that the lifetimes of these outlived the node I was taking them from
    namespace: ocamlrep::rc::RcOc<namespace_env::Env>,
    type_params: HashSet<String>,
}

impl Env {
    fn make(namespace: ocamlrep::rc::RcOc<namespace_env::Env>) -> Self {
        Self {
            namespace,
            type_params: HashSet::new(),
        }
    }

    // TODO: While elaboration for codegen and typing is similar, there are currently a
    // couple differences between the two and are toggled by this flag (XHP).
    // It would be nice to eventually eliminate the discrepancies between the two.
    pub fn in_codegen(&self) -> bool {
        self.namespace.is_codegen
    }

    fn extend_tparams(&mut self, tparaml: &[Tparam]) {
        for tparam in tparaml {
            self.type_params.insert(tparam.name.1.clone());
        }
    }

    fn elaborate_type_name(&self, id: &mut Id) {
        let name = &id.1;
        if self.type_params.contains::<str>(name)
            || is_special_identifier(name)
            || name.starts_with("$")
        {
            return;
        } else {
            id.1 =
                namespaces::elaborate_id(&self.namespace, namespaces::ElaborateKind::Class, id).1;
        }
    }

    fn handle_special_calls(&self, call: &mut Expr_) {
        match call {
            Expr_::Call(c) => {
                let (func, args) = (&c.0, &mut c.2);
                match func {
                    Expr(_, Expr_::Id(id))
                        if id.1 == sn::autoimported_functions::FUN_ && args.len() == 1 =>
                    {
                        match &args[0] {
                            Expr(p, Expr_::String(fn_name)) => {
                                let fn_name = core_utils::add_ns_bstr(&fn_name);
                                args[0] =
                                    Expr(p.clone(), Expr_::String(fn_name.into_owned().into()));
                            }
                            _ => {}
                        }
                    }
                    Expr(_, Expr_::Id(id))
                        if (id.1 == sn::autoimported_functions::METH_CALLER
                            || id.1 == sn::autoimported_functions::CLASS_METH)
                            && args.len() == 2
                            && !self.in_codegen() =>
                    {
                        match &args[0] {
                            Expr(p, Expr_::String(cl_name)) => {
                                let cl_name = core_utils::add_ns_bstr(&cl_name);
                                args[0] =
                                    Expr(p.clone(), Expr_::String(cl_name.into_owned().into()));
                            }
                            _ => {}
                        }
                    }
                    _ => {}
                }
            }
            _ => {}
        }
    }
}

fn is_reserved_type_hint(name: &str) -> bool {
    let base_name = core_utils::strip_ns(name);
    return sn::typehints::is_reserved_type_hint(&base_name) || sn::rx::is_reactive_typehint(name);
}

struct ElaborateNamespacesVisitor {}

impl<'ast> VisitorMut<'ast> for ElaborateNamespacesVisitor {
    type P = AstParams<Env, ()>;

    fn object(&mut self) -> &mut dyn VisitorMut<'ast, P = Self::P> {
        self
    }

    // Namespaces were already precomputed by ElaborateDefs
    // The following functions just set the namespace env correctly
    fn visit_class_(&mut self, env: &mut Env, cd: &mut Class_) -> Result<(), ()> {
        let mut env = env.clone();
        env.namespace = cd.namespace.clone();
        env.extend_tparams(&cd.tparams);
        cd.recurse(&mut env, self.object())
    }

    fn visit_typedef(&mut self, env: &mut Env, td: &mut Typedef) -> Result<(), ()> {
        let mut env = env.clone();
        env.namespace = td.namespace.clone();
        env.extend_tparams(&td.tparams);
        td.recurse(&mut env, self.object())
    }

    fn visit_def(&mut self, env: &mut Env, def: &mut Def) -> Result<(), ()> {
        match &def {
            // need to handle it ourselves, because in visit_fun_ is
            // called both for toplevel functions and lambdas
            Def::Fun(f) => {
                let mut env = env.clone();
                env.namespace = f.namespace.clone();
                env.extend_tparams(&f.tparams);
                def.recurse(&mut env, self.object())
            }
            Def::SetNamespaceEnv(nsenv) => Ok(env.namespace = (**nsenv).clone()),
            _ => def.recurse(env, self.object()),
        }
    }

    fn visit_method_(&mut self, env: &mut Env, m: &mut Method_) -> Result<(), ()> {
        let mut env = env.clone();
        env.extend_tparams(&m.tparams);
        m.recurse(&mut env, self.object())
    }

    fn visit_gconst(&mut self, env: &mut Env, gc: &mut Gconst) -> Result<(), ()> {
        let mut env = env.clone();
        env.namespace = gc.namespace.clone();
        gc.recurse(&mut env, self.object())
    }

    fn visit_file_attribute(&mut self, env: &mut Env, fa: &mut FileAttribute) -> Result<(), ()> {
        let mut env = env.clone();
        env.namespace = fa.namespace.clone();
        fa.recurse(&mut env, self.object())
    }

    fn visit_record_def(&mut self, env: &mut Env, rd: &mut RecordDef) -> Result<(), ()> {
        rd.name =
            namespaces::elaborate_id(&env.namespace, namespaces::ElaborateKind::Record, &rd.name);
        match &mut rd.extends {
            Some(Hint(_, h_)) => {
                let h = h_.as_mut();
                match h {
                    Hint_::Happly(sid, _hl) => {
                        let new_name = namespaces::elaborate_id(
                            &env.namespace,
                            namespaces::ElaborateKind::Record,
                            &sid,
                        );
                        *sid = new_name;
                    }
                    _ => {}
                }
            }
            _ => {}
        }
        rd.recurse(env, self.object())
    }

    // I don't think we need to visit blocks because we got rid of let bindings :)

    fn visit_catch(&mut self, env: &mut Env, catch: &mut Catch) -> Result<(), ()> {
        let exception_sid = &mut catch.0;
        env.elaborate_type_name(exception_sid);
        catch.recurse(env, self.object())
    }

    // I don't think we need to visit stmts because we got rid of let bindings :)

    // Lfun and Efun as Expr_:: nodes so update the env in visit_expr_

    // Actually rewrites the names
    fn visit_expr_(&mut self, env: &mut Env, e: &mut Expr_) -> Result<(), ()> {
        // Sets env for lambdas
        match e {
            Expr_::Call(c) => {
                let (func, targs, args, uargs) = (&mut c.0, &mut c.1, &mut c.2, &mut c.3);

                // Recurse first due to borrow order
                targs.accept(env, self.object())?;
                args.accept(env, self.object())?;
                uargs.accept(env, self.object())?;

                if let Some(sid) = func.1.as_id_mut() {
                    if !sn::special_functions::is_special_function(&sid.1) {
                        sid.1 = namespaces::elaborate_id(
                            &env.namespace,
                            namespaces::ElaborateKind::Fun,
                            sid,
                        )
                        .1;
                        env.handle_special_calls(e);
                    }
                } else {
                    func.accept(env, self.object())?;
                }
            }
            Expr_::FunctionPointer(fp) => {
                let (fpid, targs) = (&mut fp.0, &mut fp.1);
                if let Some(sid) = fpid.as_fpid_mut() {
                    sid.1 = namespaces::elaborate_id(
                        &env.namespace,
                        namespaces::ElaborateKind::Fun,
                        sid,
                    )
                    .1;
                } else if let Some(cc) = fpid.as_fpclass_const_mut() {
                    let type_ = cc.0;
                    if let Some(e) = type_.1.as_ciexpr_mut() {
                        if let Some(sid) = e.1.as_id_mut() {
                            env.elaborate_type_name(sid);
                        } else {
                            e.accept(env, self.object())?;
                        }
                    }
                } else {
                    fpid.accept(env, self.object())?;
                }
                targs.accept(env, self.object())?;
            }
            Expr_::ObjGet(og) => {
                let (obj, expr, nullsafe) = (&mut og.0, &mut og.1, &mut og.2);
                if let Expr_::Id(..) = expr.1 {
                } else {
                    expr.accept(env, self.object())?;
                }

                obj.accept(env, self.object())?;
                nullsafe.accept(env, self.object())?;
            }
            Expr_::Id(sid) if !((sid.1 == "NAN" || sid.1 == "INF") && env.in_codegen()) => {
                sid.1 =
                    namespaces::elaborate_id(&env.namespace, namespaces::ElaborateKind::Const, sid)
                        .1;
            }
            Expr_::New(n) => {
                let (class_id, targs, args, unpacked_el) = (&mut n.0, &mut n.1, &mut n.2, &mut n.3);
                if let Some(e) = class_id.1.as_ciexpr_mut() {
                    if let Some(sid) = e.1.as_id_mut() {
                        env.elaborate_type_name(sid);
                    } else {
                        e.accept(env, self.object())?;
                    }
                } else {
                    class_id.accept(env, self.object())?;
                }
                targs.accept(env, self.object())?;
                args.accept(env, self.object())?;
                unpacked_el.accept(env, self.object())?;
            }
            Expr_::Record(r) => {
                let record_name = &mut r.0;
                env.elaborate_type_name(record_name);
            }
            Expr_::ClassConst(cc) => {
                let type_ = &mut cc.0;
                if let Some(e) = type_.1.as_ciexpr_mut() {
                    if let Some(sid) = e.1.as_id_mut() {
                        env.elaborate_type_name(sid);
                    } else {
                        e.accept(env, self.object())?;
                    }
                } else {
                    type_.accept(env, self.object())?;
                }
            }
            Expr_::ClassGet(cg) => {
                let (class_id, class_get_expr) = (&mut cg.0, &mut cg.1);
                if let Some(e) = class_id.1.as_ciexpr_mut() {
                    if let Some(sid) = e.1.as_id_mut() {
                        env.elaborate_type_name(sid);
                    } else {
                        e.accept(env, self.object())?;
                    }
                } else {
                    class_id.accept(env, self.object())?;
                }
                class_get_expr.accept(env, self.object())?;
            }
            Expr_::Xml(x) => {
                let (xml_id, attributes, el) = (&mut x.0, &mut x.1, &mut x.2);
                /* if XHP element mangling is disabled, namespaces are supported */
                if !env.in_codegen() || env.namespace.disable_xhp_element_mangling {
                    env.elaborate_type_name(xml_id);
                }
                attributes.recurse(env, self.object())?;
                el.recurse(env, self.object())?;
            }
            _ => e.recurse(env, self.object())?,
        }
        Ok(())
    }

    fn visit_hint_(&mut self, env: &mut Env, hint: &mut Hint_) -> Result<(), ()> {
        fn is_rx(x: &str) -> bool {
            x == sn::rx::RX || x == sn::rx::RX_LOCAL || x == sn::rx::RX_SHALLOW || x == sn::rx::PURE
        }
        fn is_xhp_screwup(x: &str) -> bool {
            x == "Xhp" || x == ":Xhp" || x == "XHP"
        }
        match hint {
            Hint_::Happly(sid, _) if is_xhp_screwup(&sid.1) => {}
            Hint_::Happly(sid, hints) if is_rx(&sid.1) && hints.len() == 1 => match *hints[0].1 {
                Hint_::Hfun(_) => {}
                _ => {
                    env.elaborate_type_name(sid);
                }
            },
            Hint_::Happly(sid, _) if is_rx(&sid.1) => {
                env.elaborate_type_name(sid);
            }
            Hint_::Happly(sid, _) if is_reserved_type_hint(&sid.1) && !env.in_codegen() => {}
            Hint_::Happly(sid, _) => {
                env.elaborate_type_name(sid);
            }
            _ => {}
        }
        hint.recurse(env, self.object())
    }

    fn visit_shape_field_name(
        &mut self,
        env: &mut Env,
        sfn: &mut ShapeFieldName,
    ) -> Result<(), ()> {
        match sfn {
            ShapeFieldName::SFclassConst(id, _) => {
                env.elaborate_type_name(id);
            }
            _ => {}
        }
        sfn.recurse(env, self.object())
    }

    fn visit_user_attribute(&mut self, env: &mut Env, ua: &mut UserAttribute) -> Result<(), ()> {
        if !sn::user_attributes::is_reserved(&ua.name.1) {
            env.elaborate_type_name(&mut ua.name);
        }
        ua.recurse(env, self.object())
    }

    fn visit_insteadof_alias(
        &mut self,
        env: &mut Env,
        alias: &mut InsteadofAlias,
    ) -> Result<(), ()> {
        let (replacement_sid, orig_sids) = (&mut alias.0, &mut alias.2);
        env.elaborate_type_name(replacement_sid);
        for sid in orig_sids.iter_mut() {
            env.elaborate_type_name(sid);
        }
        alias.recurse(env, self.object())
    }

    fn visit_use_as_alias(&mut self, env: &mut Env, alias: &mut UseAsAlias) -> Result<(), ()> {
        let sid_option = &mut alias.0;
        Ok(match sid_option {
            Some(sid) => {
                env.elaborate_type_name(sid);
            }
            _ => {}
        })
    }

    fn visit_xhp_child(&mut self, env: &mut Env, child: &mut XhpChild) -> Result<(), ()> {
        match child {
            XhpChild::ChildName(sid)
                if !env.in_codegen()
                    && !sn::xhp::is_reserved(&sid.1)
                    && !sn::xhp::is_xhp_category(&sid.1) =>
            {
                env.elaborate_type_name(sid);
            }
            _ => {}
        }
        child.recurse(env, self.object())
    }
}

pub fn elaborate_program(e: ocamlrep::rc::RcOc<namespace_env::Env>, defs: &mut Program) {
    let mut env = Env::make(e);
    let mut visitor = ElaborateNamespacesVisitor {};
    for mut def in defs.into_iter() {
        visitor.visit_def(&mut env, &mut def).unwrap();
    }
/*
 * Copyright (c) 2015, Facebook, Inc.
 * All rights reserved.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the "hack" directory of this source tree.
 *
 */

/** Module consisting of the special names known to the typechecker */

pub mod classes {
    pub const PARENT: &str = "parent";

    pub const STATIC: &str = "static";

    pub const SELF: &str = "self";

    pub const UNKNOWN: &str = "\\*Unknown*";

    /* Used for dynamic classnames, e.g. new $foo(); */

    pub const AWAITABLE: &str = "\\HH\\Awaitable";

    pub const GENERATOR: &str = "\\Generator";

    pub const ASYNC_GENERATOR: &str = "\\HH\\AsyncGenerator";

    pub const HH_FORMAT_STRING: &str = "\\HH\\FormatString";

    pub fn is_format_string(x: &str) -> bool {
        match x {
            HH_FORMAT_STRING => true,
            _ => false,
        }
    }

    pub const HH_BUILTIN_ENUM: &str = "\\HH\\BuiltinEnum";

    pub const HH_BUILTIN_ENUM_CLASS: &str = "\\HH\\BuiltinEnumClass";

    pub const THROWABLE: &str = "\\Throwable";

    pub const STD_CLASS: &str = "\\stdClass";

    pub const DATE_TIME: &str = "\\DateTime";

    pub const DATE_TIME_IMMUTABLE: &str = "\\DateTimeImmutable";

    pub const ASYNC_ITERATOR: &str = "\\HH\\AsyncIterator";

    pub const ASYNC_KEYED_ITERATOR: &str = "\\HH\\AsyncKeyedIterator";

    pub const STRINGISH: &str = "\\Stringish";

    pub const XHP_CHILD: &str = "\\XHPChild";

    pub const IMEMOIZE_PARAM: &str = "\\HH\\IMemoizeParam";

    pub const CLASS_NAME: &str = "\\HH\\classname";

    pub const TYPE_NAME: &str = "\\HH\\typename";

    pub const IDISPOSABLE: &str = "\\IDisposable";

    pub const IASYNC_DISPOSABLE: &str = "\\IAsyncDisposable";

    pub const MEMBER_OF: &str = "\\HH\\MemberOf";
}

pub mod collections {
    /* concrete classes */
    pub const VECTOR: &str = "\\HH\\Vector";

    pub const IMM_VECTOR: &str = "\\HH\\ImmVector";

    pub const SET: &str = "\\HH\\Set";

    pub const IMM_SET: &str = "\\HH\\ImmSet";

    pub const MAP: &str = "\\HH\\Map";

    pub const IMM_MAP: &str = "\\HH\\ImmMap";

    pub const PAIR: &str = "\\HH\\Pair";

    /* interfaces */
    pub const CONTAINER: &str = "\\HH\\Container";

    pub const KEYED_CONTAINER: &str = "\\HH\\KeyedContainer";

    pub const TRAVERSABLE: &str = "\\HH\\Traversable";

    pub const KEYED_TRAVERSABLE: &str = "\\HH\\KeyedTraversable";

    pub const COLLECTION: &str = "\\Collection";

    pub const CONST_VECTOR: &str = "\\ConstVector";

    pub const CONST_MAP: &str = "\\ConstMap";

    pub const CONST_COLLECTION: &str = "\\ConstCollection";

    pub const DICT: &str = "\\HH\\dict";

    pub const VEC: &str = "\\HH\\vec";

    pub const KEYSET: &str = "\\HH\\keyset";
}

pub mod members {
    use lazy_static::lazy_static;
    use std::collections::HashMap;
    use std::collections::HashSet;

    pub const M_CLASS: &str = "class";

    pub const __CONSTRUCT: &str = "__construct";

    pub const __DESTRUCT: &str = "__destruct";

    pub const __CALL: &str = "__call";

    pub const __CALL_STATIC: &str = "__callStatic";

    pub const __CLONE: &str = "__clone";

    pub const __DEBUG_INFO: &str = "__debugInfo";

    pub const __DISPOSE: &str = "__dispose";

    pub const __DISPOSE_ASYNC: &str = "__disposeAsync";

    pub const __GET: &str = "__get";

    pub const __INVOKE: &str = "__invoke";

    pub const __ISSET: &str = "__isset";

    pub const __SET: &str = "__set";

    pub const __SET_STATE: &str = "__set_state";

    pub const __SLEEP: &str = "__sleep";

    pub const __TO_STRING: &str = "__toString";

    pub const __UNSET: &str = "__unset";

    pub const __WAKEUP: &str = "__wakeup";

    lazy_static! {
        static ref AS_SET: HashSet<&'static str> = vec![
            __CONSTRUCT,
            __DESTRUCT,
            __CALL,
            __CALL_STATIC,
            __CLONE,
            __DEBUG_INFO,
            __DISPOSE,
            __DISPOSE_ASYNC,
            __GET,
            __INVOKE,
            __ISSET,
            __SET,
            __SET_STATE,
            __SLEEP,
            __TO_STRING,
            __UNSET,
            __WAKEUP
        ]
        .into_iter()
        .collect();
        pub static ref AS_LOWERCASE_SET: HashSet<String> = {
            AS_SET
                .iter()
                .fold(HashSet::<String>::new(), |mut set, special_name| {
                    set.insert(special_name.to_ascii_lowercase());
                    set
                })
        };
        pub static ref UNSUPPORTED_MAP: HashMap<String, &'static str> = {
            vec![__CALL, __CALL_STATIC, __GET, __ISSET, __SET, __UNSET]
                .iter()
                .fold(
                    HashMap::<String, &'static str>::new(),
                    |mut set, special_name| {
                        set.insert(special_name.to_ascii_lowercase(), special_name);
                        set
                    },
                )
        };
    }

    /* Any data- or aria- attribute is always valid, even if it is not declared
     * for a given XHP element */
    pub fn is_special_xhp_attribute(s: &str) -> bool {
        s.len() >= 6
            && match &s[..6] {
                ":data-" | ":aria-" => true,
                _ => false,
            }
    }
}

pub mod user_attributes {
    use lazy_static::lazy_static;
    use std::collections::HashSet;

    pub const OVERRIDE: &str = "__Override";

    pub const CONSISTENT_CONSTRUCT: &str = "__ConsistentConstruct";

    pub const CONST: &str = "__Const";

    pub const DEPRECATED: &str = "__Deprecated";

    pub const ENTRY_POINT: &str = "__EntryPoint";

    pub const MEMOIZE: &str = "__Memoize";

    pub const MEMOIZE_LSB: &str = "__MemoizeLSB";

    pub const PHP_STD_LIB: &str = "__PHPStdLib";

    pub const HIPHOP_SPECIFIC: &str = "__HipHopSpecific";

    pub const ACCEPT_DISPOSABLE: &str = "__AcceptDisposable";

    pub const RETURN_DISPOSABLE: &str = "__ReturnDisposable";

    pub const PURE: &str = "__Pure";

    pub const CIPP: &str = "__Cipp";

    pub const CIPP_LOCAL: &str = "__CippLocal";

    pub const CIPP_GLOBAL: &str = "__CippGlobal";

    pub const CIPP_RX: &str = "__CippRx";

    pub const REACTIVE: &str = "__Rx";

    pub const LOCAL_REACTIVE: &str = "__RxLocal";

    pub const SHALLOW_REACTIVE: &str = "__RxShallow";

    pub const MUTABLE: &str = "__Mutable";

    pub const MUTABLE_RETURN: &str = "__MutableReturn";

    pub const ONLY_RX_IF_IMPL: &str = "__OnlyRxIfImpl";

    pub const LSB: &str = "__LSB";

    pub const AT_MOST_RX_AS_FUNC: &str = "__AtMostRxAsFunc";

    pub const AT_MOST_RX_AS_ARGS: &str = "__AtMostRxAsArgs";

    pub const SEALED: &str = "__Sealed";

    pub const RETURNS_VOID_TO_RX: &str = "__ReturnsVoidToRx";

    pub const MAYBE_MUTABLE: &str = "__MaybeMutable";

    pub const LATE_INIT: &str = "__LateInit";

    pub const OWNED_MUTABLE: &str = "__OwnedMutable";

    pub const NON_RX: &str = "__NonRx";

    pub const NEWABLE: &str = "__Newable";

    pub const ENFORCEABLE: &str = "__Enforceable";

    pub const EXPLICIT: &str = "__Explicit";

    pub const SOFT: &str = "__Soft";

    pub const WARN: &str = "__Warn";

    pub const MOCK_CLASS: &str = "__MockClass";

    pub const PROVENANCE_SKIP_FRAME: &str = "__ProvenanceSkipFrame";

    pub const DYNAMICALLY_CALLABLE: &str = "__DynamicallyCallable";

    pub const DYNAMICALLY_CONSTRUCTIBLE: &str = "__DynamicallyConstructible";

    pub const REIFIABLE: &str = "__Reifiable";

    pub const NEVER_INLINE: &str = "__NEVER_INLINE";

    pub const ENABLE_UNSTABLE_FEATURES: &str = "__EnableUnstableFeatures";

    pub const ENUM_CLASS: &str = "__EnumClass";

    pub const ATOM: &str = "__Atom";

    pub const POLICIED: &str = "__Policied";

    pub const INFERFLOWS: &str = "__InferFlows";

    pub const EXTERNAL: &str = "__External";

    lazy_static! {
        static ref AS_SET: HashSet<&'static str> = vec![
            OVERRIDE,
            CONSISTENT_CONSTRUCT,
            CONST,
            DEPRECATED,
            ENTRY_POINT,
            MEMOIZE,
            MEMOIZE_LSB,
            PHP_STD_LIB,
            HIPHOP_SPECIFIC,
            ACCEPT_DISPOSABLE,
            RETURN_DISPOSABLE,
            PURE,
            CIPP,
            CIPP_LOCAL,
            CIPP_GLOBAL,
            CIPP_RX,
            REACTIVE,
            LOCAL_REACTIVE,
            MUTABLE,
            MUTABLE_RETURN,
            SHALLOW_REACTIVE,
            ONLY_RX_IF_IMPL,
            LSB,
            SEALED,
            RETURNS_VOID_TO_RX,
            MAYBE_MUTABLE,
            LATE_INIT,
            AT_MOST_RX_AS_FUNC,
            AT_MOST_RX_AS_ARGS,
            OWNED_MUTABLE,
            NON_RX,
            NEWABLE,
            ENFORCEABLE,
            EXPLICIT,
            SOFT,
            WARN,
            MOCK_CLASS,
            PROVENANCE_SKIP_FRAME,
            DYNAMICALLY_CALLABLE,
            DYNAMICALLY_CONSTRUCTIBLE,
            REIFIABLE,
            NEVER_INLINE,
            ENABLE_UNSTABLE_FEATURES,
            ENUM_CLASS,
            ATOM,
            POLICIED,
            INFERFLOWS,
            EXTERNAL,
        ]
        .into_iter()
        .collect();
    }

    pub fn is_memoized(name: &str) -> bool {
        name == MEMOIZE || name == MEMOIZE_LSB
    }

    // TODO(hrust) these should probably be added to the above map/fields, too

    pub fn is_native(name: &str) -> bool {
        name == "__Native"
    }

    pub fn is_foldable(name: &str) -> bool {
        name == "__IsFoldable"
    }

    pub fn is_meth_caller(name: &str) -> bool {
        name == "__MethCaller"
    }

    pub fn is_reserved(name: &str) -> bool {
        name.starts_with("__")
    }

    pub fn is_soft(name: &str) -> bool {
        name == SOFT
    }
}

pub mod attribute_kinds {
    use lazy_static::lazy_static;
    use std::collections::HashMap;

    pub const CLS: &str = "\\HH\\ClassAttribute";

    pub const ENUM: &str = "\\HH\\EnumAttribute";

    pub const TYPE_ALIAS: &str = "\\HH\\TypeAliasAttribute";

    pub const FN: &str = "\\HH\\FunctionAttribute";

    pub const MTHD: &str = "\\HH\\MethodAttribute";

    pub const INST_PROPERTY: &str = "\\HH\\InstancePropertyAttribute";

    pub const STATIC_PROPERTY: &str = "\\HH\\StaticPropertyAttribute";

    pub const PARAMETER: &str = "\\HH\\ParameterAttribute";

    pub const TYPE_PARAM: &str = "\\HH\\TypeParameterAttribute";

    pub const FILE: &str = "\\HH\\FileAttribute";

    pub const TYPE_CONST: &str = "\\HH\\TypeConstantAttribute";

    pub const LAMBDA: &str = "\\HH\\LambdaAttribute";

    pub static PLAIN_ENGLISH: &[(&str, &str)] = &[
        (CLS, "a class"),
        (ENUM, "an enum"),
        (TYPE_ALIAS, "a typealias"),
        (FN, "a function"),
        (MTHD, "a method"),
        (INST_PROPERTY, "an instance property"),
        (STATIC_PROPERTY, "a static property"),
        (PARAMETER, "a parameter"),
        (TYPE_PARAM, "a type parameter"),
        (FILE, "a file"),
        (TYPE_CONST, "a type constant"),
        (LAMBDA, "a lambda expression"),
    ];

    lazy_static! {
        pub static ref PLAIN_ENGLISH_MAP: HashMap<&'static str, &'static str> =
            PLAIN_ENGLISH.iter().copied().collect();
    }
}

/* Tested before \\-prepending name-canonicalization */
pub mod special_functions {
    use lazy_static::lazy_static;

    pub const TUPLE: &str = "tuple"; /* pseudo-function */

    pub const ECHO: &str = "echo"; /* pseudo-function */

    pub const HHAS_ADATA: &str = "__hhas_adata";

    pub fn is_special_function(x: &str) -> bool {
        lazy_static! {
            static ref ALL_SPECIAL_FUNCTIONS: Vec<&'static str> =
                vec![TUPLE, ECHO, HHAS_ADATA,].into_iter().collect();
        }
        ALL_SPECIAL_FUNCTIONS.contains(&x)
    }
}

pub mod autoimported_functions {
    pub const INVARIANT: &str = "\\HH\\invariant";

    pub const INVARIANT_VIOLATION: &str = "\\HH\\invariant_violation";

    pub const FUN_: &str = "\\HH\\fun";

    pub const INST_METH: &str = "\\HH\\inst_meth";

    pub const CLASS_METH: &str = "\\HH\\class_meth";

    pub const METH_CALLER: &str = "\\HH\\meth_caller";
}

pub mod special_idents {
    pub const THIS: &str = "$this";

    pub const PLACEHOLDER: &str = "$_";

    pub const DOLLAR_DOLLAR: &str = "$$";

    /* Intentionally using an invalid variable name to ensure it's translated */
    pub const TMP_VAR_PREFIX: &str = "__tmp$";

    pub fn is_tmp_var(name: &str) -> bool {
        name.len() > 6 && &name.as_bytes()[..6] == TMP_VAR_PREFIX.as_bytes()
    }

    pub fn assert_tmp_var(name: &str) {
        assert!(is_tmp_var(name))
    }
}

pub mod pseudo_functions {
    use lazy_static::lazy_static;
    use std::collections::HashSet;

    pub const ISSET: &str = "\\isset";

    pub const UNSET: &str = "\\unset";

    pub const HH_SHOW: &str = "\\hh_show";

    pub const HH_SHOW_ENV: &str = "\\hh_show_env";

    pub const HH_LOG_LEVEL: &str = "\\hh_log_level";

    pub const HH_FORCE_SOLVE: &str = "\\hh_force_solve";

    pub const HH_LOOP_FOREVER: &str = "\\hh_loop_forever";

    pub const ECHO: &str = "\\echo";

    pub const ECHO_NO_NS: &str = "echo";

    pub const EMPTY: &str = "\\empty";

    pub const EXIT: &str = "\\exit";

    pub const DIE: &str = "\\die";

    pub static ALL_PSEUDO_FUNCTIONS: &[&str] = &[
        ISSET,
        UNSET,
        HH_SHOW,
        HH_SHOW_ENV,
        HH_LOG_LEVEL,
        HH_FORCE_SOLVE,
        HH_LOOP_FOREVER,
        ECHO,
        EMPTY,
        EXIT,
        DIE,
    ];

    lazy_static! {
        static ref PSEUDO_SET: HashSet<&'static str> =
            ALL_PSEUDO_FUNCTIONS.iter().copied().collect();
    }

    pub fn is_pseudo_function(x: &str) -> bool {
        PSEUDO_SET.contains(x)
    }
}

pub mod std_lib_functions {
    pub const IS_ARRAY: &str = "\\is_array";

    pub const IS_NULL: &str = "\\is_null";

    pub const GET_CLASS: &str = "\\get_class";

    pub const ARRAY_FILTER: &str = "\\array_filter";

    pub const ARRAY_MAP: &str = "\\array_map";

    pub const CALL_USER_FUNC: &str = "\\call_user_func";

    pub const TYPE_STRUCTURE: &str = "\\HH\\type_structure";

    pub const ARRAY_MARK_LEGACY: &str = "\\HH\\array_mark_legacy";

    pub const ARRAY_UNMARK_LEGACY: &str = "\\HH\\array_unmark_legacy";
}

pub mod typehints {
    use lazy_static::lazy_static;
    use std::collections::HashSet;

    pub const NULL: &str = "null";

    pub const VOID: &str = "void";

    pub const RESOURCE: &str = "resource";

    pub const NUM: &str = "num";

    pub const ARRAYKEY: &str = "arraykey";

    pub const NORETURN: &str = "noreturn";

    pub const MIXED: &str = "mixed";

    pub const NONNULL: &str = "nonnull";

    pub const THIS: &str = "this";

    pub const DYNAMIC: &str = "dynamic";

    pub const NOTHING: &str = "nothing";

    pub const INT: &str = "int";

    pub const BOOL: &str = "bool";

    pub const FLOAT: &str = "float";

    pub const STRING: &str = "string";

    pub const DARRAY: &str = "darray";

    pub const VARRAY: &str = "varray";

    pub const VARRAY_OR_DARRAY: &str = "varray_or_darray";

    pub const CALLABLE: &str = "callable";

    pub const OBJECT_CAST: &str = "object";

    pub const WILDCARD: &str = "_";

    pub fn is_reserved_type_hint(x: &str) -> bool {
        lazy_static! {
            static ref RESERVED_TYPEHINTS: HashSet<&'static str> = vec![
                NULL,
                VOID,
                RESOURCE,
                NUM,
                ARRAYKEY,
                NORETURN,
                MIXED,
                NONNULL,
                THIS,
                DYNAMIC,
                NOTHING,
                INT,
                BOOL,
                FLOAT,
                STRING,
                DARRAY,
                VARRAY,
                VARRAY_OR_DARRAY,
                CALLABLE,
                WILDCARD,
            ]
            .into_iter()
            .collect();
        }

        RESERVED_TYPEHINTS.contains(x)
    }

    lazy_static! {
        static ref RESERVED_GLOBAL_NAMES: HashSet<&'static str> =
            vec![CALLABLE, crate::classes::SELF, crate::classes::PARENT]
                .into_iter()
                .collect();
    }

    pub fn is_reserved_global_name(x: &str) -> bool {
        RESERVED_GLOBAL_NAMES.contains(x)
    }

    lazy_static! {
        static ref RESERVED_HH_NAMES: HashSet<&'static str> = vec![
            VOID, NORETURN, INT, BOOL, FLOAT, NUM, STRING, RESOURCE, MIXED, ARRAYKEY, DYNAMIC,
            WILDCARD, NULL, NONNULL, NOTHING, THIS
        ]
        .into_iter()
        .collect();
    }

    pub fn is_reserved_hh_name(x: &str) -> bool {
        RESERVED_HH_NAMES.contains(x)
    }

    // This function checks if this is a namespace of the "(not HH)\\(...)*\\(reserved_name)"
    pub fn is_namespace_with_reserved_hh_name(x: &str) -> bool {
        // This splits the string into its namespaces
        fn unqualify(x: &str) -> (Vec<&str>, &str) {
            let mut as_list = x.split('\\').collect::<Vec<&str>>();
            // Retain if not empty
            as_list.retain(|&split| match split {
                "" => false,
                _ => true,
            });
            let last_split = match as_list.pop() {
                None => "",
                Some(x) => x,
            };

            (as_list, last_split)
        }

        // This returns a bool whether or not the list is just the string "HH"
        fn is_hh(qualifier: &[&str]) -> bool {
            match qualifier.len() {
                1 => qualifier[0] == "HH",
                _ => false,
            }
        }
        let (qualifier, name) = unqualify(x);
        !is_hh(&qualifier) && !qualifier.is_empty() && is_reserved_hh_name(name)
    }
}

pub mod literal {
    pub const TRUE: &str = "true";
    pub const FALSE: &str = "false";
    pub const NULL: &str = "null";
}

pub mod pseudo_consts {
    use lazy_static::lazy_static;
    use std::collections::HashSet;

    pub const G__LINE__: &str = "\\__LINE__";

    pub const G__CLASS__: &str = "\\__CLASS__";

    pub const G__TRAIT__: &str = "\\__TRAIT__";

    pub const G__FILE__: &str = "\\__FILE__";

    pub const G__DIR__: &str = "\\__DIR__";

    pub const G__FUNCTION__: &str = "\\__FUNCTION__";

    pub const G__METHOD__: &str = "\\__METHOD__";

    pub const G__NAMESPACE__: &str = "\\__NAMESPACE__";

    pub const G__COMPILER_FRONTEND__: &str = "\\__COMPILER_FRONTEND__";

    pub const G__FUNCTION_CREDENTIAL__: &str = "\\__FUNCTION_CREDENTIAL__";

    pub const DIE: &str = "\\die";

    pub const EXIT: &str = "\\exit";

    pub static ALL_PSEUDO_CONSTS: &[&str] = &[
        G__LINE__,
        G__CLASS__,
        G__TRAIT__,
        G__FILE__,
        G__DIR__,
        G__FUNCTION__,
        G__METHOD__,
        G__NAMESPACE__,
        G__COMPILER_FRONTEND__,
        G__FUNCTION_CREDENTIAL__,
        DIE,
        EXIT,
    ];

    lazy_static! {
        static ref PSEUDO_SET: HashSet<&'static str> = ALL_PSEUDO_CONSTS.iter().copied().collect();
    }

    pub fn is_pseudo_const(x: &str) -> bool {
        PSEUDO_SET.contains(x)
    }
}

pub mod fb {
    pub const ENUM: &str = "\\Enum";

    pub const IDX: &str = "\\HH\\idx";

    pub const TYPE_STRUCTURE: &str = "\\HH\\TypeStructure";

    pub const INCORRECT_TYPE: &str = "\\HH\\INCORRECT_TYPE";

    pub const INCORRECT_TYPE_NO_NS: &str = "HH\\INCORRECT_TYPE";
}

pub mod hh {
    pub const CONTAINS: &str = "\\HH\\Lib\\C\\contains";

    pub const CONTAINS_KEY: &str = "\\HH\\Lib\\C\\contains_key";
}

pub mod rx {
    pub const FREEZE: &str = "\\HH\\Rx\\freeze";

    pub const MUTABLE_: &str = "\\HH\\Rx\\mutable";

    pub const TRAVERSABLE: &str = "\\HH\\Rx\\Traversable";

    pub const IS_ENABLED: &str = "\\HH\\Rx\\IS_ENABLED";

    pub const KEYED_TRAVERSABLE: &str = "\\HH\\Rx\\KeyedTraversable";

    pub const ASYNC_ITERATOR: &str = "\\HH\\Rx\\AsyncIterator";

    pub const MOVE: &str = "\\HH\\Rx\\move";

    pub const PURE: &str = "Pure";

    pub const CIPP: &str = "Cipp";

    pub const CIPP_LOCAL: &str = "CippLocal";

    pub const CIPP_GLOBAL: &str = "CippGlobal";

    pub const CIPP_RX: &str = "CippRx";

    pub const RX: &str = "Rx";

    pub const RX_LOCAL: &str = "RxLocal";

    pub const RX_SHALLOW: &str = "RxShallow";

    pub const MUTABLE: &str = "Mutable";

    pub const MAYBE_MUTABLE: &str = "MaybeMutable";

    pub const OWNED_MUTABLE: &str = "OwnedMutable";

    pub fn is_reactive_typehint(x: &str) -> bool {
        use lazy_static::lazy_static;
        use std::collections::HashSet;

        lazy_static! {
            static ref REACTIVE_TYPEHINTS: HashSet<&'static str> = vec![
                PURE,
                CIPP,
                CIPP_LOCAL,
                CIPP_GLOBAL,
                CIPP_RX,
                RX,
                RX_LOCAL,
                RX_SHALLOW,
                MUTABLE,
                MAYBE_MUTABLE,
                OWNED_MUTABLE,
            ]
            .into_iter()
            .collect();
        }

        REACTIVE_TYPEHINTS.contains(x)
    }
}

pub mod coeffects {
    pub const DEFAULTS: &str = "defaults";

    pub const RX_LOCAL: &str = "rx_local";

    pub const RX_SHALLOW: &str = "rx_shallow";

    pub const RX: &str = "rx";

    pub const WRITE_PROPS: &str = "write_props";

    pub const POLICIED_LOCAL: &str = "policied_local";

    pub const POLICIED_SHALLOW: &str = "policied_shallow";

    pub const POLICIED: &str = "policied";

    pub const POLICIED_OF_LOCAL: &str = "policied_of_local";

    pub const POLICIED_OF_SHALLOW: &str = "policied_of_shallow";

    pub const POLICIED_OF: &str = "policied_of";

    pub const PURE: &str = "pure";
}

pub mod shapes {
    pub const SHAPES: &str = "\\HH\\Shapes";

    pub const IDX: &str = "idx";

    pub const AT: &str = "at";

    pub const KEY_EXISTS: &str = "keyExists";

    pub const REMOVE_KEY: &str = "removeKey";

    pub const TO_ARRAY: &str = "toArray";

    pub const TO_DICT: &str = "toDict";
}

pub mod superglobals {
    use lazy_static::lazy_static;
    use std::collections::HashSet;
    pub const GLOBALS: &str = "$GLOBALS";

    pub static SUPERGLOBALS: &[&str] = &[
        "$_SERVER",
        "$_GET",
        "$_POST",
        "$_FILES",
        "$_COOKIE",
        "$_REQUEST",
        "$_ENV",
    ];

    lazy_static! {
        static ref SUPERGLOBALS_SET: HashSet<&'static str> = SUPERGLOBALS.iter().copied().collect();
    }
    pub fn is_superglobal(x: &str) -> bool {
        SUPERGLOBALS_SET.contains(x)
    }
    pub fn is_any_global(x: &str) -> bool {
        is_superglobal(x) || x == GLOBALS
    }
}

pub mod xhp {
    pub const PCDATA: &str = "pcdata";
    pub const ANY: &str = "any";
    pub const EMPTY: &str = "empty";
    pub fn is_reserved(x: &str) -> bool {
        x == PCDATA || x == ANY || x == EMPTY
    }
    pub fn is_xhp_category(x: &str) -> bool {
        x.starts_with('%')
    }
}

pub mod regex {
    pub const T_PATTERN: &str = "\\HH\\Lib\\Regex\\Pattern";
}

pub mod emitter_special_functions {
    pub const EVAL: &str = "\\eval";
    pub const SET_FRAME_METADATA: &str = "\\HH\\set_frame_metadata";
    pub const SYSTEMLIB_REIFIED_GENERICS: &str = "\\__systemlib_reified_generics";
}

pub mod math {
    pub const NAN: &str = "NAN";
    pub const INF: &str = "INF";
    pub const NEG_INF: &str = "-INF";
}

#[cfg(test)]
mod test {
    use crate::members::is_special_xhp_attribute;
    use crate::members::AS_LOWERCASE_SET;
    use crate::members::UNSUPPORTED_MAP;
    use crate::special_idents::is_tmp_var;
    use crate::typehints::is_namespace_with_reserved_hh_name;

    #[test]
    fn test_special_idents_is_tmp_var() {
        assert!(!is_tmp_var("_tmp$Blah"));
        assert!(!is_tmp_var("__tmp$"));
        assert!(!is_tmp_var("О БОЖЕ"));

        assert!(is_tmp_var("__tmp$Blah"));
    }

    #[test]
    fn test_members_as_lowercase_set() {
        assert!(AS_LOWERCASE_SET.contains("__tostring"));
        assert!(!AS_LOWERCASE_SET.contains("__toString"));
    }

    #[test]
    fn test_members_unsupported_map() {
        assert_eq!(UNSUPPORTED_MAP.get("__callstatic"), Some(&"__callStatic"));
        assert!(!UNSUPPORTED_MAP.contains_key("__callStatic"));
    }

    #[test]
    fn test_members_is_special_xhp_attribute() {
        assert!(is_special_xhp_attribute(":data-blahblah"));
        assert!(is_special_xhp_attribute(":aria-blahblah"));

        assert!(!is_special_xhp_attribute(":arla-blahblah"));
        assert!(!is_special_xhp_attribute(":aria"));
    }

    #[test]
    fn test_typehint_is_namespace_with_reserved_hh_name() {
        assert!(!is_namespace_with_reserved_hh_name("HH\\void"));
        assert!(!is_namespace_with_reserved_hh_name("void"));
        assert!(!is_namespace_with_reserved_hh_name("ReturnType\\Lloyd"));
        assert!(!is_namespace_with_reserved_hh_name("Lloyd"));
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use crate::source_text::SourceText;
use line_break_map::LineBreakMap;
use oxidized::pos::Pos;
use std::rc::Rc;

#[derive(Debug)]
pub struct IndexedSourceTextImpl<'a> {
    pub source_text: SourceText<'a>,
    offset_map: LineBreakMap,
}

#[derive(Clone, Debug)]
pub struct IndexedSourceText<'a>(Rc<IndexedSourceTextImpl<'a>>);

impl<'a> IndexedSourceText<'a> {
    pub fn new(source_text: SourceText<'a>) -> Self {
        let text = source_text.text();
        Self(Rc::new(IndexedSourceTextImpl {
            source_text,
            offset_map: LineBreakMap::new(text),
        }))
    }

    pub fn source_text(&self) -> &SourceText<'a> {
        &self.0.source_text
    }

    pub fn offset_to_position(&self, offset: isize) -> (isize, isize) {
        self.0.offset_map.offset_to_position(offset)
    }

    pub fn relative_pos(&self, start_offset: usize, end_offset: usize) -> Pos {
        let pos_start = self.0.offset_map.offset_to_file_pos_triple(start_offset);
        let pos_end = self.0.offset_map.offset_to_file_pos_triple(end_offset);
        Pos::from_lnum_bol_cnum(self.0.source_text.file_path_rc(), pos_start, pos_end)
    }

    pub fn offset_to_file_pos_triple(&self, offset: usize) -> (usize, usize, usize) {
        self.0.offset_map.offset_to_file_pos_triple(offset)
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

mod operator_generated;

use ocamlrep_derive::{FromOcamlRep, ToOcamlRep};
use parser_core_types::{parser_env::ParserEnv, token_kind::TokenKind};

pub use crate::operator_generated::*;

#[derive(PartialEq, FromOcamlRep, ToOcamlRep)]
pub enum Assoc {
    LeftAssociative,
    RightAssociative,
    NotAssociative,
}

use self::Operator::*;

impl Operator {
    // NOTE: ParserEnv is not used in operator::precedence(). The function rust_precedence_helper (defined in rust_parser_ffi.rs)
    // assumes that ParserEnv is not used. If operator::precedence() starts using ParserEnv, the helper and the callsites in OCaml
    // must be updated.
    pub fn precedence(&self, _: &ParserEnv) -> usize {
        // TODO: eval
        // TODO: Comma
        // TODO: elseif
        // TODO: else
        // TODO: endif
        // TODO: variable operator $
        match self {
            IncludeOperator | IncludeOnceOperator | RequireOperator | RequireOnceOperator => 1,
            PrintOperator => 5,
            AssignmentOperator
            | AdditionAssignmentOperator
            | SubtractionAssignmentOperator
            | MultiplicationAssignmentOperator
            | DivisionAssignmentOperator
            | ExponentiationAssignmentOperator
            | RemainderAssignmentOperator
            | ConcatenationAssignmentOperator
            | AndAssignmentOperator
            | OrAssignmentOperator
            | ExclusiveOrAssignmentOperator
            | LeftShiftAssignmentOperator
            | RightShiftAssignmentOperator
            | CoalesceAssignmentOperator => 6,
            PipeOperator => 7,
            ConditionalQuestionOperator
            | ConditionalColonOperator
            | DegenerateConditionalOperator => 8,
            CoalesceOperator => 9,
            LogicalOrOperator => 10,
            LogicalAndOperator => 11,
            OrOperator => 12,
            ExclusiveOrOperator => 13,
            AndOperator => 14,
            EqualOperator
            | StrictEqualOperator
            | PhpNotEqualOperator
            | NotEqualOperator
            | StrictNotEqualOperator => 15,
            SpaceshipOperator
            | LessThanOperator
            | LessThanOrEqualOperator
            | GreaterThanOperator
            | GreaterThanOrEqualOperator => 16,
            LeftShiftOperator | RightShiftOperator => 17,
            AdditionOperator | SubtractionOperator | ConcatenationOperator => 18,
            MultiplicationOperator | DivisionOperator | RemainderOperator => 19,
            LogicalNotOperator | NotOperator | UnaryPlusOperator | UnaryMinusOperator => 20,
            InstanceofOperator | IsOperator | AsOperator | NullableAsOperator => 21,
            CastOperator
            | ErrorControlOperator
            | PrefixIncrementOperator
            | PrefixDecrementOperator
            | ExponentOperator => 22,
            PostfixIncrementOperator
            | PostfixDecrementOperator
            | AwaitOperator
            | ReadonlyOperator => 23,
            CloneOperator => 24,
            // value 25 is reserved for assignment that appear in expressions
            FunctionCallOperator => 26,
            NewOperator => 27,
            MemberSelectionOperator | NullSafeMemberSelectionOperator => 28,
            IndexingOperator => 29,
            ScopeResolutionOperator => 30,
            DollarOperator => 31,
        }
    }

    pub fn precedence_for_assignment_in_expressions() -> usize {
        25
    }

    // NOTE: ParserEnv is not used in operator::associativity(). The function rust_associativity_helper (defined in rust_parser_ffi.rs)
    // assumes that ParserEnv is not used. If operator::associativity() starts using ParserEnv, the function and the callsites in OCaml
    // must be updated.
    pub fn associativity(&self, _: &ParserEnv) -> Assoc {
        match self {
            | EqualOperator | StrictEqualOperator | NotEqualOperator | PhpNotEqualOperator
            | StrictNotEqualOperator | LessThanOperator | LessThanOrEqualOperator
            | GreaterThanOperator | GreaterThanOrEqualOperator | InstanceofOperator
            | NewOperator | CloneOperator | SpaceshipOperator => Assoc::NotAssociative,
            | DegenerateConditionalOperator
            | PipeOperator | ConditionalQuestionOperator | ConditionalColonOperator
            | LogicalOrOperator | ExclusiveOrOperator | LogicalAndOperator
            | OrOperator | AndOperator | LeftShiftOperator | RightShiftOperator
            | AdditionOperator | SubtractionOperator | ConcatenationOperator
            | MultiplicationOperator | DivisionOperator | RemainderOperator
            | MemberSelectionOperator | NullSafeMemberSelectionOperator
            | ScopeResolutionOperator | FunctionCallOperator | IndexingOperator
            | IncludeOperator | IncludeOnceOperator | RequireOperator
            | RequireOnceOperator | IsOperator | AsOperator | NullableAsOperator
                // eval
                // Comma
                // elseif
                // else
                // endif
                => Assoc::LeftAssociative,
            | CoalesceOperator | CoalesceAssignmentOperator | LogicalNotOperator | NotOperator | CastOperator
            | DollarOperator | UnaryPlusOperator | UnaryMinusOperator  // TODO: Correct?
            | ErrorControlOperator // TODO: Correct?
            | PostfixIncrementOperator | PostfixDecrementOperator
            | PrefixIncrementOperator | PrefixDecrementOperator | ExponentOperator
            | AssignmentOperator | AdditionAssignmentOperator
            | SubtractionAssignmentOperator | MultiplicationAssignmentOperator
            | DivisionAssignmentOperator | ExponentiationAssignmentOperator
            | ConcatenationAssignmentOperator
            | RemainderAssignmentOperator | AndAssignmentOperator
            | OrAssignmentOperator | ExclusiveOrAssignmentOperator
            | LeftShiftAssignmentOperator | RightShiftAssignmentOperator
            | PrintOperator | AwaitOperator | ReadonlyOperator => Assoc::RightAssociative,
        }
    }

    pub fn prefix_unary_from_token(token: TokenKind) -> Operator {
        match token {
            TokenKind::Await => AwaitOperator,
            TokenKind::Exclamation => LogicalNotOperator,
            TokenKind::Tilde => NotOperator,
            TokenKind::PlusPlus => PrefixIncrementOperator,
            TokenKind::MinusMinus => PrefixDecrementOperator,
            TokenKind::Dollar => DollarOperator,
            TokenKind::Plus => UnaryPlusOperator,
            TokenKind::Minus => UnaryMinusOperator,
            TokenKind::At => ErrorControlOperator,
            TokenKind::New => NewOperator,
            TokenKind::Clone => CloneOperator,
            TokenKind::Include => IncludeOperator,
            TokenKind::Include_once => IncludeOnceOperator,
            TokenKind::Require => RequireOperator,
            TokenKind::Require_once => RequireOnceOperator,
            TokenKind::Print => PrintOperator,
            TokenKind::Readonly => ReadonlyOperator,
            _ => panic!("not a unary operator"),
        }
    }

    // Is this a token that can appear after an expression?
    pub fn is_trailing_operator_token(token: TokenKind) -> bool {
        match token {
            TokenKind::PlusPlus
            | TokenKind::MinusMinus
            | TokenKind::LeftParen
            | TokenKind::LeftBracket
            | TokenKind::LeftBrace
            | TokenKind::Plus
            | TokenKind::Minus
            | TokenKind::Ampersand
            | TokenKind::BarGreaterThan
            | TokenKind::Question
            | TokenKind::QuestionQuestion
            | TokenKind::QuestionQuestionEqual
            | TokenKind::QuestionColon
            | TokenKind::BarBar
            | TokenKind::Carat
            | TokenKind::AmpersandAmpersand
            | TokenKind::Bar
            | TokenKind::EqualEqual
            | TokenKind::EqualEqualEqual
            | TokenKind::ExclamationEqual
            | TokenKind::ExclamationEqualEqual
            | TokenKind::LessThanEqualGreaterThan
            | TokenKind::LessThan
            | TokenKind::LessThanEqual
            | TokenKind::GreaterThan
            | TokenKind::GreaterThanEqual
            | TokenKind::LessThanLessThan
            | TokenKind::GreaterThanGreaterThan
            | TokenKind::Dot
            | TokenKind::Star
            | TokenKind::Slash
            | TokenKind::Percent
            | TokenKind::Instanceof
            | TokenKind::Is
            | TokenKind::As
            | TokenKind::QuestionAs
            | TokenKind::StarStar
            | TokenKind::Equal
            | TokenKind::PlusEqual
            | TokenKind::MinusEqual
            | TokenKind::StarEqual
            | TokenKind::SlashEqual
            | TokenKind::StarStarEqual
            | TokenKind::DotEqual
            | TokenKind::PercentEqual
            | TokenKind::AmpersandEqual
            | TokenKind::BarEqual
            | TokenKind::CaratEqual
            | TokenKind::LessThanLessThanEqual
            | TokenKind::GreaterThanGreaterThanEqual
            | TokenKind::MinusGreaterThan
            | TokenKind::QuestionMinusGreaterThan
            | TokenKind::ColonColon => true,
            _ => false,
        }
    }

    pub fn trailing_from_token(token: TokenKind) -> Operator {
        match token {
            TokenKind::BarGreaterThan => PipeOperator,
            TokenKind::Question => ConditionalQuestionOperator,
            TokenKind::Colon => ConditionalColonOperator,
            TokenKind::QuestionQuestion => CoalesceOperator,
            TokenKind::QuestionQuestionEqual => CoalesceAssignmentOperator,
            TokenKind::QuestionColon => DegenerateConditionalOperator,
            TokenKind::BarBar => LogicalOrOperator,
            TokenKind::Carat => ExclusiveOrOperator,
            TokenKind::AmpersandAmpersand => LogicalAndOperator,
            TokenKind::Bar => OrOperator,
            TokenKind::Ampersand => AndOperator,
            TokenKind::EqualEqual => EqualOperator,
            TokenKind::EqualEqualEqual => StrictEqualOperator,
            TokenKind::ExclamationEqual => NotEqualOperator,
            TokenKind::ExclamationEqualEqual => StrictNotEqualOperator,
            TokenKind::LessThan => LessThanOperator,
            TokenKind::LessThanEqualGreaterThan => SpaceshipOperator,
            TokenKind::LessThanEqual => LessThanOrEqualOperator,
            TokenKind::GreaterThan => GreaterThanOperator,
            TokenKind::GreaterThanEqual => GreaterThanOrEqualOperator,
            TokenKind::LessThanLessThan => LeftShiftOperator,
            TokenKind::GreaterThanGreaterThan => RightShiftOperator,
            TokenKind::Plus => AdditionOperator,
            TokenKind::Minus => SubtractionOperator,
            TokenKind::Dot => ConcatenationOperator,
            TokenKind::Star => MultiplicationOperator,
            TokenKind::Slash => DivisionOperator,
            TokenKind::Percent => RemainderOperator,
            TokenKind::Instanceof => InstanceofOperator,
            TokenKind::Is => IsOperator,
            TokenKind::As => AsOperator,
            TokenKind::QuestionAs => NullableAsOperator,
            TokenKind::StarStar => ExponentOperator,
            TokenKind::Equal => AssignmentOperator,
            TokenKind::PlusEqual => AdditionAssignmentOperator,
            TokenKind::MinusEqual => SubtractionAssignmentOperator,
            TokenKind::StarEqual => MultiplicationAssignmentOperator,
            TokenKind::SlashEqual => DivisionAssignmentOperator,
            TokenKind::StarStarEqual => ExponentiationAssignmentOperator,
            TokenKind::DotEqual => ConcatenationAssignmentOperator,
            TokenKind::PercentEqual => RemainderAssignmentOperator,
            TokenKind::AmpersandEqual => AndAssignmentOperator,
            TokenKind::BarEqual => OrAssignmentOperator,
            TokenKind::CaratEqual => ExclusiveOrAssignmentOperator,
            TokenKind::LessThanLessThanEqual => LeftShiftAssignmentOperator,
            TokenKind::GreaterThanGreaterThanEqual => RightShiftAssignmentOperator,
            TokenKind::MinusGreaterThan => MemberSelectionOperator,
            TokenKind::QuestionMinusGreaterThan => NullSafeMemberSelectionOperator,
            TokenKind::ColonColon => ScopeResolutionOperator,
            TokenKind::PlusPlus => PostfixIncrementOperator,
            TokenKind::MinusMinus => PostfixDecrementOperator,
            TokenKind::LeftParen => FunctionCallOperator,
            TokenKind::LeftBracket => IndexingOperator,
            TokenKind::LeftBrace => IndexingOperator,
            _ => panic!("not a trailing operator"),
        }
    }

    pub fn is_binary_operator_token(token: TokenKind) -> bool {
        match token {
            TokenKind::Plus
            | TokenKind::Minus
            | TokenKind::Ampersand
            | TokenKind::BarGreaterThan
            | TokenKind::QuestionQuestion
            | TokenKind::QuestionQuestionEqual
            | TokenKind::QuestionColon
            | TokenKind::BarBar
            | TokenKind::Carat
            | TokenKind::AmpersandAmpersand
            | TokenKind::Bar
            | TokenKind::EqualEqual
            | TokenKind::EqualEqualEqual
            | TokenKind::ExclamationEqual
            | TokenKind::ExclamationEqualEqual
            | TokenKind::LessThanEqualGreaterThan
            | TokenKind::LessThan
            | TokenKind::LessThanEqual
            | TokenKind::GreaterThan
            | TokenKind::GreaterThanEqual
            | TokenKind::LessThanLessThan
            | TokenKind::GreaterThanGreaterThan
            | TokenKind::Dot
            | TokenKind::Star
            | TokenKind::Slash
            | TokenKind::Percent
            | TokenKind::StarStar
            | TokenKind::Equal
            | TokenKind::PlusEqual
            | TokenKind::MinusEqual
            | TokenKind::StarEqual
            | TokenKind::SlashEqual
            | TokenKind::DotEqual
            | TokenKind::PercentEqual
            | TokenKind::AmpersandEqual
            | TokenKind::BarEqual
            | TokenKind::CaratEqual
            | TokenKind::LessThanLessThanEqual
            | TokenKind::GreaterThanGreaterThanEqual
            | TokenKind::MinusGreaterThan
            | TokenKind::QuestionMinusGreaterThan => true,
            _ => false,
        }
    }

    pub fn is_assignment(&self) -> bool {
        match self {
            AssignmentOperator
            | AdditionAssignmentOperator
            | SubtractionAssignmentOperator
            | MultiplicationAssignmentOperator
            | DivisionAssignmentOperator
            | ExponentiationAssignmentOperator
            | ConcatenationAssignmentOperator
            | RemainderAssignmentOperator
            | AndAssignmentOperator
            | OrAssignmentOperator
            | ExclusiveOrAssignmentOperator
            | LeftShiftAssignmentOperator
            | RightShiftAssignmentOperator
            | CoalesceAssignmentOperator => true,
            _ => false,
        }
    }

    pub fn is_comparison(&self) -> bool {
        match self {
            EqualOperator
            | StrictEqualOperator
            | NotEqualOperator
            | PhpNotEqualOperator
            | StrictNotEqualOperator
            | LessThanOperator
            | LessThanOrEqualOperator
            | GreaterThanOperator
            | GreaterThanOrEqualOperator
            | SpaceshipOperator => true,
            _ => false,
        }
    }
/**
 * Copyright (c) 2016, Facebook, Inc.
 * All rights reserved.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the "hack" directory of this source tree. An additional
 * directory.
 *
 **
 *
 * THIS FILE IS @generated; DO NOT EDIT IT
 * To regenerate this file, run
 *
 *   buck run //hphp/hack/src:generate_full_fidelity
 *
 **
 *
 */
use super::{
    has_arena::HasArena,
    syntax::*, syntax_variant_generated::*,
};
use crate::{
    lexable_token::LexableToken,
    syntax::{SyntaxType, SyntaxValueType},
};

impl<'a, C, T, V> SyntaxType<C> for Syntax<'a, T, V>
where
    T: LexableToken + Copy,
    V: SyntaxValueType<T>,
    C: HasArena<'a>,
{
    fn make_end_of_file(ctx: &C, token: Self) -> Self {
        let syntax = SyntaxVariant::EndOfFile(ctx.get_arena().alloc(EndOfFileChildren {
            token,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_script(ctx: &C, declarations: Self) -> Self {
        let syntax = SyntaxVariant::Script(ctx.get_arena().alloc(ScriptChildren {
            declarations,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_qualified_name(ctx: &C, parts: Self) -> Self {
        let syntax = SyntaxVariant::QualifiedName(ctx.get_arena().alloc(QualifiedNameChildren {
            parts,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_simple_type_specifier(ctx: &C, specifier: Self) -> Self {
        let syntax = SyntaxVariant::SimpleTypeSpecifier(ctx.get_arena().alloc(SimpleTypeSpecifierChildren {
            specifier,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_literal_expression(ctx: &C, expression: Self) -> Self {
        let syntax = SyntaxVariant::LiteralExpression(ctx.get_arena().alloc(LiteralExpressionChildren {
            expression,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_prefixed_string_expression(ctx: &C, name: Self, str: Self) -> Self {
        let syntax = SyntaxVariant::PrefixedStringExpression(ctx.get_arena().alloc(PrefixedStringExpressionChildren {
            name,
            str,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_prefixed_code_expression(ctx: &C, prefix: Self, left_backtick: Self, expression: Self, right_backtick: Self) -> Self {
        let syntax = SyntaxVariant::PrefixedCodeExpression(ctx.get_arena().alloc(PrefixedCodeExpressionChildren {
            prefix,
            left_backtick,
            expression,
            right_backtick,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_variable_expression(ctx: &C, expression: Self) -> Self {
        let syntax = SyntaxVariant::VariableExpression(ctx.get_arena().alloc(VariableExpressionChildren {
            expression,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_pipe_variable_expression(ctx: &C, expression: Self) -> Self {
        let syntax = SyntaxVariant::PipeVariableExpression(ctx.get_arena().alloc(PipeVariableExpressionChildren {
            expression,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_file_attribute_specification(ctx: &C, left_double_angle: Self, keyword: Self, colon: Self, attributes: Self, right_double_angle: Self) -> Self {
        let syntax = SyntaxVariant::FileAttributeSpecification(ctx.get_arena().alloc(FileAttributeSpecificationChildren {
            left_double_angle,
            keyword,
            colon,
            attributes,
            right_double_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_enum_declaration(ctx: &C, attribute_spec: Self, keyword: Self, name: Self, colon: Self, base: Self, type_: Self, left_brace: Self, use_clauses: Self, enumerators: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::EnumDeclaration(ctx.get_arena().alloc(EnumDeclarationChildren {
            attribute_spec,
            keyword,
            name,
            colon,
            base,
            type_,
            left_brace,
            use_clauses,
            enumerators,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_enum_use(ctx: &C, keyword: Self, names: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::EnumUse(ctx.get_arena().alloc(EnumUseChildren {
            keyword,
            names,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_enumerator(ctx: &C, name: Self, equal: Self, value: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::Enumerator(ctx.get_arena().alloc(EnumeratorChildren {
            name,
            equal,
            value,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_enum_class_declaration(ctx: &C, attribute_spec: Self, enum_keyword: Self, class_keyword: Self, name: Self, colon: Self, base: Self, extends: Self, extends_list: Self, left_brace: Self, elements: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::EnumClassDeclaration(ctx.get_arena().alloc(EnumClassDeclarationChildren {
            attribute_spec,
            enum_keyword,
            class_keyword,
            name,
            colon,
            base,
            extends,
            extends_list,
            left_brace,
            elements,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_enum_class_enumerator(ctx: &C, type_: Self, name: Self, equal: Self, initial_value: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::EnumClassEnumerator(ctx.get_arena().alloc(EnumClassEnumeratorChildren {
            type_,
            name,
            equal,
            initial_value,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_record_declaration(ctx: &C, attribute_spec: Self, modifier: Self, keyword: Self, name: Self, extends_keyword: Self, extends_opt: Self, left_brace: Self, fields: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::RecordDeclaration(ctx.get_arena().alloc(RecordDeclarationChildren {
            attribute_spec,
            modifier,
            keyword,
            name,
            extends_keyword,
            extends_opt,
            left_brace,
            fields,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_record_field(ctx: &C, type_: Self, name: Self, init: Self, semi: Self) -> Self {
        let syntax = SyntaxVariant::RecordField(ctx.get_arena().alloc(RecordFieldChildren {
            type_,
            name,
            init,
            semi,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_alias_declaration(ctx: &C, attribute_spec: Self, keyword: Self, name: Self, generic_parameter: Self, constraint: Self, equal: Self, type_: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::AliasDeclaration(ctx.get_arena().alloc(AliasDeclarationChildren {
            attribute_spec,
            keyword,
            name,
            generic_parameter,
            constraint,
            equal,
            type_,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_property_declaration(ctx: &C, attribute_spec: Self, modifiers: Self, type_: Self, declarators: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::PropertyDeclaration(ctx.get_arena().alloc(PropertyDeclarationChildren {
            attribute_spec,
            modifiers,
            type_,
            declarators,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_property_declarator(ctx: &C, name: Self, initializer: Self) -> Self {
        let syntax = SyntaxVariant::PropertyDeclarator(ctx.get_arena().alloc(PropertyDeclaratorChildren {
            name,
            initializer,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_namespace_declaration(ctx: &C, header: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::NamespaceDeclaration(ctx.get_arena().alloc(NamespaceDeclarationChildren {
            header,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_namespace_declaration_header(ctx: &C, keyword: Self, name: Self) -> Self {
        let syntax = SyntaxVariant::NamespaceDeclarationHeader(ctx.get_arena().alloc(NamespaceDeclarationHeaderChildren {
            keyword,
            name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_namespace_body(ctx: &C, left_brace: Self, declarations: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::NamespaceBody(ctx.get_arena().alloc(NamespaceBodyChildren {
            left_brace,
            declarations,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_namespace_empty_body(ctx: &C, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::NamespaceEmptyBody(ctx.get_arena().alloc(NamespaceEmptyBodyChildren {
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_namespace_use_declaration(ctx: &C, keyword: Self, kind: Self, clauses: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::NamespaceUseDeclaration(ctx.get_arena().alloc(NamespaceUseDeclarationChildren {
            keyword,
            kind,
            clauses,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_namespace_group_use_declaration(ctx: &C, keyword: Self, kind: Self, prefix: Self, left_brace: Self, clauses: Self, right_brace: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::NamespaceGroupUseDeclaration(ctx.get_arena().alloc(NamespaceGroupUseDeclarationChildren {
            keyword,
            kind,
            prefix,
            left_brace,
            clauses,
            right_brace,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_namespace_use_clause(ctx: &C, clause_kind: Self, name: Self, as_: Self, alias: Self) -> Self {
        let syntax = SyntaxVariant::NamespaceUseClause(ctx.get_arena().alloc(NamespaceUseClauseChildren {
            clause_kind,
            name,
            as_,
            alias,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_function_declaration(ctx: &C, attribute_spec: Self, declaration_header: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::FunctionDeclaration(ctx.get_arena().alloc(FunctionDeclarationChildren {
            attribute_spec,
            declaration_header,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_function_declaration_header(ctx: &C, modifiers: Self, keyword: Self, name: Self, type_parameter_list: Self, left_paren: Self, parameter_list: Self, right_paren: Self, contexts: Self, colon: Self, readonly_return: Self, type_: Self, where_clause: Self) -> Self {
        let syntax = SyntaxVariant::FunctionDeclarationHeader(ctx.get_arena().alloc(FunctionDeclarationHeaderChildren {
            modifiers,
            keyword,
            name,
            type_parameter_list,
            left_paren,
            parameter_list,
            right_paren,
            contexts,
            colon,
            readonly_return,
            type_,
            where_clause,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_contexts(ctx: &C, left_bracket: Self, types: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::Contexts(ctx.get_arena().alloc(ContextsChildren {
            left_bracket,
            types,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_where_clause(ctx: &C, keyword: Self, constraints: Self) -> Self {
        let syntax = SyntaxVariant::WhereClause(ctx.get_arena().alloc(WhereClauseChildren {
            keyword,
            constraints,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_where_constraint(ctx: &C, left_type: Self, operator: Self, right_type: Self) -> Self {
        let syntax = SyntaxVariant::WhereConstraint(ctx.get_arena().alloc(WhereConstraintChildren {
            left_type,
            operator,
            right_type,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_methodish_declaration(ctx: &C, attribute: Self, function_decl_header: Self, function_body: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::MethodishDeclaration(ctx.get_arena().alloc(MethodishDeclarationChildren {
            attribute,
            function_decl_header,
            function_body,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_methodish_trait_resolution(ctx: &C, attribute: Self, function_decl_header: Self, equal: Self, name: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::MethodishTraitResolution(ctx.get_arena().alloc(MethodishTraitResolutionChildren {
            attribute,
            function_decl_header,
            equal,
            name,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_classish_declaration(ctx: &C, attribute: Self, modifiers: Self, xhp: Self, keyword: Self, name: Self, type_parameters: Self, extends_keyword: Self, extends_list: Self, implements_keyword: Self, implements_list: Self, where_clause: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::ClassishDeclaration(ctx.get_arena().alloc(ClassishDeclarationChildren {
            attribute,
            modifiers,
            xhp,
            keyword,
            name,
            type_parameters,
            extends_keyword,
            extends_list,
            implements_keyword,
            implements_list,
            where_clause,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_classish_body(ctx: &C, left_brace: Self, elements: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::ClassishBody(ctx.get_arena().alloc(ClassishBodyChildren {
            left_brace,
            elements,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_trait_use_precedence_item(ctx: &C, name: Self, keyword: Self, removed_names: Self) -> Self {
        let syntax = SyntaxVariant::TraitUsePrecedenceItem(ctx.get_arena().alloc(TraitUsePrecedenceItemChildren {
            name,
            keyword,
            removed_names,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_trait_use_alias_item(ctx: &C, aliasing_name: Self, keyword: Self, modifiers: Self, aliased_name: Self) -> Self {
        let syntax = SyntaxVariant::TraitUseAliasItem(ctx.get_arena().alloc(TraitUseAliasItemChildren {
            aliasing_name,
            keyword,
            modifiers,
            aliased_name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_trait_use_conflict_resolution(ctx: &C, keyword: Self, names: Self, left_brace: Self, clauses: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::TraitUseConflictResolution(ctx.get_arena().alloc(TraitUseConflictResolutionChildren {
            keyword,
            names,
            left_brace,
            clauses,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_trait_use(ctx: &C, keyword: Self, names: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::TraitUse(ctx.get_arena().alloc(TraitUseChildren {
            keyword,
            names,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_require_clause(ctx: &C, keyword: Self, kind: Self, name: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::RequireClause(ctx.get_arena().alloc(RequireClauseChildren {
            keyword,
            kind,
            name,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_const_declaration(ctx: &C, modifiers: Self, keyword: Self, type_specifier: Self, declarators: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::ConstDeclaration(ctx.get_arena().alloc(ConstDeclarationChildren {
            modifiers,
            keyword,
            type_specifier,
            declarators,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_constant_declarator(ctx: &C, name: Self, initializer: Self) -> Self {
        let syntax = SyntaxVariant::ConstantDeclarator(ctx.get_arena().alloc(ConstantDeclaratorChildren {
            name,
            initializer,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_type_const_declaration(ctx: &C, attribute_spec: Self, modifiers: Self, keyword: Self, type_keyword: Self, name: Self, type_parameters: Self, type_constraint: Self, equal: Self, type_specifier: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::TypeConstDeclaration(ctx.get_arena().alloc(TypeConstDeclarationChildren {
            attribute_spec,
            modifiers,
            keyword,
            type_keyword,
            name,
            type_parameters,
            type_constraint,
            equal,
            type_specifier,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_context_const_declaration(ctx: &C, modifiers: Self, const_keyword: Self, ctx_keyword: Self, name: Self, type_parameters: Self, constraint: Self, equal: Self, ctx_list: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::ContextConstDeclaration(ctx.get_arena().alloc(ContextConstDeclarationChildren {
            modifiers,
            const_keyword,
            ctx_keyword,
            name,
            type_parameters,
            constraint,
            equal,
            ctx_list,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_decorated_expression(ctx: &C, decorator: Self, expression: Self) -> Self {
        let syntax = SyntaxVariant::DecoratedExpression(ctx.get_arena().alloc(DecoratedExpressionChildren {
            decorator,
            expression,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_parameter_declaration(ctx: &C, attribute: Self, visibility: Self, call_convention: Self, readonly: Self, type_: Self, name: Self, default_value: Self) -> Self {
        let syntax = SyntaxVariant::ParameterDeclaration(ctx.get_arena().alloc(ParameterDeclarationChildren {
            attribute,
            visibility,
            call_convention,
            readonly,
            type_,
            name,
            default_value,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_variadic_parameter(ctx: &C, call_convention: Self, type_: Self, ellipsis: Self) -> Self {
        let syntax = SyntaxVariant::VariadicParameter(ctx.get_arena().alloc(VariadicParameterChildren {
            call_convention,
            type_,
            ellipsis,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_old_attribute_specification(ctx: &C, left_double_angle: Self, attributes: Self, right_double_angle: Self) -> Self {
        let syntax = SyntaxVariant::OldAttributeSpecification(ctx.get_arena().alloc(OldAttributeSpecificationChildren {
            left_double_angle,
            attributes,
            right_double_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_attribute_specification(ctx: &C, attributes: Self) -> Self {
        let syntax = SyntaxVariant::AttributeSpecification(ctx.get_arena().alloc(AttributeSpecificationChildren {
            attributes,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_attribute(ctx: &C, at: Self, attribute_name: Self) -> Self {
        let syntax = SyntaxVariant::Attribute(ctx.get_arena().alloc(AttributeChildren {
            at,
            attribute_name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_inclusion_expression(ctx: &C, require: Self, filename: Self) -> Self {
        let syntax = SyntaxVariant::InclusionExpression(ctx.get_arena().alloc(InclusionExpressionChildren {
            require,
            filename,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_inclusion_directive(ctx: &C, expression: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::InclusionDirective(ctx.get_arena().alloc(InclusionDirectiveChildren {
            expression,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_compound_statement(ctx: &C, left_brace: Self, statements: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::CompoundStatement(ctx.get_arena().alloc(CompoundStatementChildren {
            left_brace,
            statements,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_expression_statement(ctx: &C, expression: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::ExpressionStatement(ctx.get_arena().alloc(ExpressionStatementChildren {
            expression,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_markup_section(ctx: &C, hashbang: Self, suffix: Self) -> Self {
        let syntax = SyntaxVariant::MarkupSection(ctx.get_arena().alloc(MarkupSectionChildren {
            hashbang,
            suffix,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_markup_suffix(ctx: &C, less_than_question: Self, name: Self) -> Self {
        let syntax = SyntaxVariant::MarkupSuffix(ctx.get_arena().alloc(MarkupSuffixChildren {
            less_than_question,
            name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_unset_statement(ctx: &C, keyword: Self, left_paren: Self, variables: Self, right_paren: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::UnsetStatement(ctx.get_arena().alloc(UnsetStatementChildren {
            keyword,
            left_paren,
            variables,
            right_paren,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_using_statement_block_scoped(ctx: &C, await_keyword: Self, using_keyword: Self, left_paren: Self, expressions: Self, right_paren: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::UsingStatementBlockScoped(ctx.get_arena().alloc(UsingStatementBlockScopedChildren {
            await_keyword,
            using_keyword,
            left_paren,
            expressions,
            right_paren,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_using_statement_function_scoped(ctx: &C, await_keyword: Self, using_keyword: Self, expression: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::UsingStatementFunctionScoped(ctx.get_arena().alloc(UsingStatementFunctionScopedChildren {
            await_keyword,
            using_keyword,
            expression,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_while_statement(ctx: &C, keyword: Self, left_paren: Self, condition: Self, right_paren: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::WhileStatement(ctx.get_arena().alloc(WhileStatementChildren {
            keyword,
            left_paren,
            condition,
            right_paren,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_if_statement(ctx: &C, keyword: Self, left_paren: Self, condition: Self, right_paren: Self, statement: Self, elseif_clauses: Self, else_clause: Self) -> Self {
        let syntax = SyntaxVariant::IfStatement(ctx.get_arena().alloc(IfStatementChildren {
            keyword,
            left_paren,
            condition,
            right_paren,
            statement,
            elseif_clauses,
            else_clause,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_elseif_clause(ctx: &C, keyword: Self, left_paren: Self, condition: Self, right_paren: Self, statement: Self) -> Self {
        let syntax = SyntaxVariant::ElseifClause(ctx.get_arena().alloc(ElseifClauseChildren {
            keyword,
            left_paren,
            condition,
            right_paren,
            statement,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_else_clause(ctx: &C, keyword: Self, statement: Self) -> Self {
        let syntax = SyntaxVariant::ElseClause(ctx.get_arena().alloc(ElseClauseChildren {
            keyword,
            statement,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_try_statement(ctx: &C, keyword: Self, compound_statement: Self, catch_clauses: Self, finally_clause: Self) -> Self {
        let syntax = SyntaxVariant::TryStatement(ctx.get_arena().alloc(TryStatementChildren {
            keyword,
            compound_statement,
            catch_clauses,
            finally_clause,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_catch_clause(ctx: &C, keyword: Self, left_paren: Self, type_: Self, variable: Self, right_paren: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::CatchClause(ctx.get_arena().alloc(CatchClauseChildren {
            keyword,
            left_paren,
            type_,
            variable,
            right_paren,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_finally_clause(ctx: &C, keyword: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::FinallyClause(ctx.get_arena().alloc(FinallyClauseChildren {
            keyword,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_do_statement(ctx: &C, keyword: Self, body: Self, while_keyword: Self, left_paren: Self, condition: Self, right_paren: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::DoStatement(ctx.get_arena().alloc(DoStatementChildren {
            keyword,
            body,
            while_keyword,
            left_paren,
            condition,
            right_paren,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_for_statement(ctx: &C, keyword: Self, left_paren: Self, initializer: Self, first_semicolon: Self, control: Self, second_semicolon: Self, end_of_loop: Self, right_paren: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::ForStatement(ctx.get_arena().alloc(ForStatementChildren {
            keyword,
            left_paren,
            initializer,
            first_semicolon,
            control,
            second_semicolon,
            end_of_loop,
            right_paren,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_foreach_statement(ctx: &C, keyword: Self, left_paren: Self, collection: Self, await_keyword: Self, as_: Self, key: Self, arrow: Self, value: Self, right_paren: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::ForeachStatement(ctx.get_arena().alloc(ForeachStatementChildren {
            keyword,
            left_paren,
            collection,
            await_keyword,
            as_,
            key,
            arrow,
            value,
            right_paren,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_switch_statement(ctx: &C, keyword: Self, left_paren: Self, expression: Self, right_paren: Self, left_brace: Self, sections: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::SwitchStatement(ctx.get_arena().alloc(SwitchStatementChildren {
            keyword,
            left_paren,
            expression,
            right_paren,
            left_brace,
            sections,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_switch_section(ctx: &C, labels: Self, statements: Self, fallthrough: Self) -> Self {
        let syntax = SyntaxVariant::SwitchSection(ctx.get_arena().alloc(SwitchSectionChildren {
            labels,
            statements,
            fallthrough,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_switch_fallthrough(ctx: &C, keyword: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::SwitchFallthrough(ctx.get_arena().alloc(SwitchFallthroughChildren {
            keyword,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_case_label(ctx: &C, keyword: Self, expression: Self, colon: Self) -> Self {
        let syntax = SyntaxVariant::CaseLabel(ctx.get_arena().alloc(CaseLabelChildren {
            keyword,
            expression,
            colon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_default_label(ctx: &C, keyword: Self, colon: Self) -> Self {
        let syntax = SyntaxVariant::DefaultLabel(ctx.get_arena().alloc(DefaultLabelChildren {
            keyword,
            colon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_return_statement(ctx: &C, keyword: Self, expression: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::ReturnStatement(ctx.get_arena().alloc(ReturnStatementChildren {
            keyword,
            expression,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_yield_break_statement(ctx: &C, keyword: Self, break_: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::YieldBreakStatement(ctx.get_arena().alloc(YieldBreakStatementChildren {
            keyword,
            break_,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_throw_statement(ctx: &C, keyword: Self, expression: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::ThrowStatement(ctx.get_arena().alloc(ThrowStatementChildren {
            keyword,
            expression,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_break_statement(ctx: &C, keyword: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::BreakStatement(ctx.get_arena().alloc(BreakStatementChildren {
            keyword,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_continue_statement(ctx: &C, keyword: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::ContinueStatement(ctx.get_arena().alloc(ContinueStatementChildren {
            keyword,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_echo_statement(ctx: &C, keyword: Self, expressions: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::EchoStatement(ctx.get_arena().alloc(EchoStatementChildren {
            keyword,
            expressions,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_concurrent_statement(ctx: &C, keyword: Self, statement: Self) -> Self {
        let syntax = SyntaxVariant::ConcurrentStatement(ctx.get_arena().alloc(ConcurrentStatementChildren {
            keyword,
            statement,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_simple_initializer(ctx: &C, equal: Self, value: Self) -> Self {
        let syntax = SyntaxVariant::SimpleInitializer(ctx.get_arena().alloc(SimpleInitializerChildren {
            equal,
            value,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_anonymous_class(ctx: &C, class_keyword: Self, left_paren: Self, argument_list: Self, right_paren: Self, extends_keyword: Self, extends_list: Self, implements_keyword: Self, implements_list: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::AnonymousClass(ctx.get_arena().alloc(AnonymousClassChildren {
            class_keyword,
            left_paren,
            argument_list,
            right_paren,
            extends_keyword,
            extends_list,
            implements_keyword,
            implements_list,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_anonymous_function(ctx: &C, attribute_spec: Self, static_keyword: Self, async_keyword: Self, function_keyword: Self, left_paren: Self, parameters: Self, right_paren: Self, ctx_list: Self, colon: Self, readonly_return: Self, type_: Self, use_: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::AnonymousFunction(ctx.get_arena().alloc(AnonymousFunctionChildren {
            attribute_spec,
            static_keyword,
            async_keyword,
            function_keyword,
            left_paren,
            parameters,
            right_paren,
            ctx_list,
            colon,
            readonly_return,
            type_,
            use_,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_anonymous_function_use_clause(ctx: &C, keyword: Self, left_paren: Self, variables: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::AnonymousFunctionUseClause(ctx.get_arena().alloc(AnonymousFunctionUseClauseChildren {
            keyword,
            left_paren,
            variables,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_lambda_expression(ctx: &C, attribute_spec: Self, async_: Self, signature: Self, arrow: Self, body: Self) -> Self {
        let syntax = SyntaxVariant::LambdaExpression(ctx.get_arena().alloc(LambdaExpressionChildren {
            attribute_spec,
            async_,
            signature,
            arrow,
            body,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_lambda_signature(ctx: &C, left_paren: Self, parameters: Self, right_paren: Self, contexts: Self, colon: Self, readonly_return: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::LambdaSignature(ctx.get_arena().alloc(LambdaSignatureChildren {
            left_paren,
            parameters,
            right_paren,
            contexts,
            colon,
            readonly_return,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_cast_expression(ctx: &C, left_paren: Self, type_: Self, right_paren: Self, operand: Self) -> Self {
        let syntax = SyntaxVariant::CastExpression(ctx.get_arena().alloc(CastExpressionChildren {
            left_paren,
            type_,
            right_paren,
            operand,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_scope_resolution_expression(ctx: &C, qualifier: Self, operator: Self, name: Self) -> Self {
        let syntax = SyntaxVariant::ScopeResolutionExpression(ctx.get_arena().alloc(ScopeResolutionExpressionChildren {
            qualifier,
            operator,
            name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_member_selection_expression(ctx: &C, object: Self, operator: Self, name: Self) -> Self {
        let syntax = SyntaxVariant::MemberSelectionExpression(ctx.get_arena().alloc(MemberSelectionExpressionChildren {
            object,
            operator,
            name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_safe_member_selection_expression(ctx: &C, object: Self, operator: Self, name: Self) -> Self {
        let syntax = SyntaxVariant::SafeMemberSelectionExpression(ctx.get_arena().alloc(SafeMemberSelectionExpressionChildren {
            object,
            operator,
            name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_embedded_member_selection_expression(ctx: &C, object: Self, operator: Self, name: Self) -> Self {
        let syntax = SyntaxVariant::EmbeddedMemberSelectionExpression(ctx.get_arena().alloc(EmbeddedMemberSelectionExpressionChildren {
            object,
            operator,
            name,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_yield_expression(ctx: &C, keyword: Self, operand: Self) -> Self {
        let syntax = SyntaxVariant::YieldExpression(ctx.get_arena().alloc(YieldExpressionChildren {
            keyword,
            operand,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_prefix_unary_expression(ctx: &C, operator: Self, operand: Self) -> Self {
        let syntax = SyntaxVariant::PrefixUnaryExpression(ctx.get_arena().alloc(PrefixUnaryExpressionChildren {
            operator,
            operand,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_postfix_unary_expression(ctx: &C, operand: Self, operator: Self) -> Self {
        let syntax = SyntaxVariant::PostfixUnaryExpression(ctx.get_arena().alloc(PostfixUnaryExpressionChildren {
            operand,
            operator,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_binary_expression(ctx: &C, left_operand: Self, operator: Self, right_operand: Self) -> Self {
        let syntax = SyntaxVariant::BinaryExpression(ctx.get_arena().alloc(BinaryExpressionChildren {
            left_operand,
            operator,
            right_operand,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_is_expression(ctx: &C, left_operand: Self, operator: Self, right_operand: Self) -> Self {
        let syntax = SyntaxVariant::IsExpression(ctx.get_arena().alloc(IsExpressionChildren {
            left_operand,
            operator,
            right_operand,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_as_expression(ctx: &C, left_operand: Self, operator: Self, right_operand: Self) -> Self {
        let syntax = SyntaxVariant::AsExpression(ctx.get_arena().alloc(AsExpressionChildren {
            left_operand,
            operator,
            right_operand,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_nullable_as_expression(ctx: &C, left_operand: Self, operator: Self, right_operand: Self) -> Self {
        let syntax = SyntaxVariant::NullableAsExpression(ctx.get_arena().alloc(NullableAsExpressionChildren {
            left_operand,
            operator,
            right_operand,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_conditional_expression(ctx: &C, test: Self, question: Self, consequence: Self, colon: Self, alternative: Self) -> Self {
        let syntax = SyntaxVariant::ConditionalExpression(ctx.get_arena().alloc(ConditionalExpressionChildren {
            test,
            question,
            consequence,
            colon,
            alternative,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_eval_expression(ctx: &C, keyword: Self, left_paren: Self, argument: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::EvalExpression(ctx.get_arena().alloc(EvalExpressionChildren {
            keyword,
            left_paren,
            argument,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_define_expression(ctx: &C, keyword: Self, left_paren: Self, argument_list: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::DefineExpression(ctx.get_arena().alloc(DefineExpressionChildren {
            keyword,
            left_paren,
            argument_list,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_isset_expression(ctx: &C, keyword: Self, left_paren: Self, argument_list: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::IssetExpression(ctx.get_arena().alloc(IssetExpressionChildren {
            keyword,
            left_paren,
            argument_list,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_function_call_expression(ctx: &C, receiver: Self, type_args: Self, left_paren: Self, argument_list: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::FunctionCallExpression(ctx.get_arena().alloc(FunctionCallExpressionChildren {
            receiver,
            type_args,
            left_paren,
            argument_list,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_function_pointer_expression(ctx: &C, receiver: Self, type_args: Self) -> Self {
        let syntax = SyntaxVariant::FunctionPointerExpression(ctx.get_arena().alloc(FunctionPointerExpressionChildren {
            receiver,
            type_args,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_parenthesized_expression(ctx: &C, left_paren: Self, expression: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::ParenthesizedExpression(ctx.get_arena().alloc(ParenthesizedExpressionChildren {
            left_paren,
            expression,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_braced_expression(ctx: &C, left_brace: Self, expression: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::BracedExpression(ctx.get_arena().alloc(BracedExpressionChildren {
            left_brace,
            expression,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_et_splice_expression(ctx: &C, dollar: Self, left_brace: Self, expression: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::ETSpliceExpression(ctx.get_arena().alloc(ETSpliceExpressionChildren {
            dollar,
            left_brace,
            expression,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_embedded_braced_expression(ctx: &C, left_brace: Self, expression: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::EmbeddedBracedExpression(ctx.get_arena().alloc(EmbeddedBracedExpressionChildren {
            left_brace,
            expression,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_list_expression(ctx: &C, keyword: Self, left_paren: Self, members: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::ListExpression(ctx.get_arena().alloc(ListExpressionChildren {
            keyword,
            left_paren,
            members,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_collection_literal_expression(ctx: &C, name: Self, left_brace: Self, initializers: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::CollectionLiteralExpression(ctx.get_arena().alloc(CollectionLiteralExpressionChildren {
            name,
            left_brace,
            initializers,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_object_creation_expression(ctx: &C, new_keyword: Self, object: Self) -> Self {
        let syntax = SyntaxVariant::ObjectCreationExpression(ctx.get_arena().alloc(ObjectCreationExpressionChildren {
            new_keyword,
            object,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_constructor_call(ctx: &C, type_: Self, left_paren: Self, argument_list: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::ConstructorCall(ctx.get_arena().alloc(ConstructorCallChildren {
            type_,
            left_paren,
            argument_list,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_record_creation_expression(ctx: &C, type_: Self, left_bracket: Self, members: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::RecordCreationExpression(ctx.get_arena().alloc(RecordCreationExpressionChildren {
            type_,
            left_bracket,
            members,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_darray_intrinsic_expression(ctx: &C, keyword: Self, explicit_type: Self, left_bracket: Self, members: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::DarrayIntrinsicExpression(ctx.get_arena().alloc(DarrayIntrinsicExpressionChildren {
            keyword,
            explicit_type,
            left_bracket,
            members,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_dictionary_intrinsic_expression(ctx: &C, keyword: Self, explicit_type: Self, left_bracket: Self, members: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::DictionaryIntrinsicExpression(ctx.get_arena().alloc(DictionaryIntrinsicExpressionChildren {
            keyword,
            explicit_type,
            left_bracket,
            members,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_keyset_intrinsic_expression(ctx: &C, keyword: Self, explicit_type: Self, left_bracket: Self, members: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::KeysetIntrinsicExpression(ctx.get_arena().alloc(KeysetIntrinsicExpressionChildren {
            keyword,
            explicit_type,
            left_bracket,
            members,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_varray_intrinsic_expression(ctx: &C, keyword: Self, explicit_type: Self, left_bracket: Self, members: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::VarrayIntrinsicExpression(ctx.get_arena().alloc(VarrayIntrinsicExpressionChildren {
            keyword,
            explicit_type,
            left_bracket,
            members,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_vector_intrinsic_expression(ctx: &C, keyword: Self, explicit_type: Self, left_bracket: Self, members: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::VectorIntrinsicExpression(ctx.get_arena().alloc(VectorIntrinsicExpressionChildren {
            keyword,
            explicit_type,
            left_bracket,
            members,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_element_initializer(ctx: &C, key: Self, arrow: Self, value: Self) -> Self {
        let syntax = SyntaxVariant::ElementInitializer(ctx.get_arena().alloc(ElementInitializerChildren {
            key,
            arrow,
            value,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_subscript_expression(ctx: &C, receiver: Self, left_bracket: Self, index: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::SubscriptExpression(ctx.get_arena().alloc(SubscriptExpressionChildren {
            receiver,
            left_bracket,
            index,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_embedded_subscript_expression(ctx: &C, receiver: Self, left_bracket: Self, index: Self, right_bracket: Self) -> Self {
        let syntax = SyntaxVariant::EmbeddedSubscriptExpression(ctx.get_arena().alloc(EmbeddedSubscriptExpressionChildren {
            receiver,
            left_bracket,
            index,
            right_bracket,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_awaitable_creation_expression(ctx: &C, attribute_spec: Self, async_: Self, compound_statement: Self) -> Self {
        let syntax = SyntaxVariant::AwaitableCreationExpression(ctx.get_arena().alloc(AwaitableCreationExpressionChildren {
            attribute_spec,
            async_,
            compound_statement,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_children_declaration(ctx: &C, keyword: Self, expression: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::XHPChildrenDeclaration(ctx.get_arena().alloc(XHPChildrenDeclarationChildren {
            keyword,
            expression,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_children_parenthesized_list(ctx: &C, left_paren: Self, xhp_children: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::XHPChildrenParenthesizedList(ctx.get_arena().alloc(XHPChildrenParenthesizedListChildren {
            left_paren,
            xhp_children,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_category_declaration(ctx: &C, keyword: Self, categories: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::XHPCategoryDeclaration(ctx.get_arena().alloc(XHPCategoryDeclarationChildren {
            keyword,
            categories,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_enum_type(ctx: &C, keyword: Self, left_brace: Self, values: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::XHPEnumType(ctx.get_arena().alloc(XHPEnumTypeChildren {
            keyword,
            left_brace,
            values,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_lateinit(ctx: &C, at: Self, keyword: Self) -> Self {
        let syntax = SyntaxVariant::XHPLateinit(ctx.get_arena().alloc(XHPLateinitChildren {
            at,
            keyword,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_required(ctx: &C, at: Self, keyword: Self) -> Self {
        let syntax = SyntaxVariant::XHPRequired(ctx.get_arena().alloc(XHPRequiredChildren {
            at,
            keyword,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_class_attribute_declaration(ctx: &C, keyword: Self, attributes: Self, semicolon: Self) -> Self {
        let syntax = SyntaxVariant::XHPClassAttributeDeclaration(ctx.get_arena().alloc(XHPClassAttributeDeclarationChildren {
            keyword,
            attributes,
            semicolon,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_class_attribute(ctx: &C, type_: Self, name: Self, initializer: Self, required: Self) -> Self {
        let syntax = SyntaxVariant::XHPClassAttribute(ctx.get_arena().alloc(XHPClassAttributeChildren {
            type_,
            name,
            initializer,
            required,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_simple_class_attribute(ctx: &C, type_: Self) -> Self {
        let syntax = SyntaxVariant::XHPSimpleClassAttribute(ctx.get_arena().alloc(XHPSimpleClassAttributeChildren {
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_simple_attribute(ctx: &C, name: Self, equal: Self, expression: Self) -> Self {
        let syntax = SyntaxVariant::XHPSimpleAttribute(ctx.get_arena().alloc(XHPSimpleAttributeChildren {
            name,
            equal,
            expression,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_spread_attribute(ctx: &C, left_brace: Self, spread_operator: Self, expression: Self, right_brace: Self) -> Self {
        let syntax = SyntaxVariant::XHPSpreadAttribute(ctx.get_arena().alloc(XHPSpreadAttributeChildren {
            left_brace,
            spread_operator,
            expression,
            right_brace,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_open(ctx: &C, left_angle: Self, name: Self, attributes: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::XHPOpen(ctx.get_arena().alloc(XHPOpenChildren {
            left_angle,
            name,
            attributes,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_expression(ctx: &C, open: Self, body: Self, close: Self) -> Self {
        let syntax = SyntaxVariant::XHPExpression(ctx.get_arena().alloc(XHPExpressionChildren {
            open,
            body,
            close,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_xhp_close(ctx: &C, left_angle: Self, name: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::XHPClose(ctx.get_arena().alloc(XHPCloseChildren {
            left_angle,
            name,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_type_constant(ctx: &C, left_type: Self, separator: Self, right_type: Self) -> Self {
        let syntax = SyntaxVariant::TypeConstant(ctx.get_arena().alloc(TypeConstantChildren {
            left_type,
            separator,
            right_type,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_vector_type_specifier(ctx: &C, keyword: Self, left_angle: Self, type_: Self, trailing_comma: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::VectorTypeSpecifier(ctx.get_arena().alloc(VectorTypeSpecifierChildren {
            keyword,
            left_angle,
            type_,
            trailing_comma,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_keyset_type_specifier(ctx: &C, keyword: Self, left_angle: Self, type_: Self, trailing_comma: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::KeysetTypeSpecifier(ctx.get_arena().alloc(KeysetTypeSpecifierChildren {
            keyword,
            left_angle,
            type_,
            trailing_comma,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_tuple_type_explicit_specifier(ctx: &C, keyword: Self, left_angle: Self, types: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::TupleTypeExplicitSpecifier(ctx.get_arena().alloc(TupleTypeExplicitSpecifierChildren {
            keyword,
            left_angle,
            types,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_varray_type_specifier(ctx: &C, keyword: Self, left_angle: Self, type_: Self, trailing_comma: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::VarrayTypeSpecifier(ctx.get_arena().alloc(VarrayTypeSpecifierChildren {
            keyword,
            left_angle,
            type_,
            trailing_comma,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_function_ctx_type_specifier(ctx: &C, keyword: Self, variable: Self) -> Self {
        let syntax = SyntaxVariant::FunctionCtxTypeSpecifier(ctx.get_arena().alloc(FunctionCtxTypeSpecifierChildren {
            keyword,
            variable,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_type_parameter(ctx: &C, attribute_spec: Self, reified: Self, variance: Self, name: Self, param_params: Self, constraints: Self) -> Self {
        let syntax = SyntaxVariant::TypeParameter(ctx.get_arena().alloc(TypeParameterChildren {
            attribute_spec,
            reified,
            variance,
            name,
            param_params,
            constraints,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_type_constraint(ctx: &C, keyword: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::TypeConstraint(ctx.get_arena().alloc(TypeConstraintChildren {
            keyword,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_context_constraint(ctx: &C, keyword: Self, ctx_list: Self) -> Self {
        let syntax = SyntaxVariant::ContextConstraint(ctx.get_arena().alloc(ContextConstraintChildren {
            keyword,
            ctx_list,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_darray_type_specifier(ctx: &C, keyword: Self, left_angle: Self, key: Self, comma: Self, value: Self, trailing_comma: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::DarrayTypeSpecifier(ctx.get_arena().alloc(DarrayTypeSpecifierChildren {
            keyword,
            left_angle,
            key,
            comma,
            value,
            trailing_comma,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_dictionary_type_specifier(ctx: &C, keyword: Self, left_angle: Self, members: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::DictionaryTypeSpecifier(ctx.get_arena().alloc(DictionaryTypeSpecifierChildren {
            keyword,
            left_angle,
            members,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_closure_type_specifier(ctx: &C, outer_left_paren: Self, function_keyword: Self, inner_left_paren: Self, parameter_list: Self, inner_right_paren: Self, contexts: Self, colon: Self, return_type: Self, outer_right_paren: Self) -> Self {
        let syntax = SyntaxVariant::ClosureTypeSpecifier(ctx.get_arena().alloc(ClosureTypeSpecifierChildren {
            outer_left_paren,
            function_keyword,
            inner_left_paren,
            parameter_list,
            inner_right_paren,
            contexts,
            colon,
            return_type,
            outer_right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_closure_parameter_type_specifier(ctx: &C, call_convention: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::ClosureParameterTypeSpecifier(ctx.get_arena().alloc(ClosureParameterTypeSpecifierChildren {
            call_convention,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_classname_type_specifier(ctx: &C, keyword: Self, left_angle: Self, type_: Self, trailing_comma: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::ClassnameTypeSpecifier(ctx.get_arena().alloc(ClassnameTypeSpecifierChildren {
            keyword,
            left_angle,
            type_,
            trailing_comma,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_field_specifier(ctx: &C, question: Self, name: Self, arrow: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::FieldSpecifier(ctx.get_arena().alloc(FieldSpecifierChildren {
            question,
            name,
            arrow,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_field_initializer(ctx: &C, name: Self, arrow: Self, value: Self) -> Self {
        let syntax = SyntaxVariant::FieldInitializer(ctx.get_arena().alloc(FieldInitializerChildren {
            name,
            arrow,
            value,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_shape_type_specifier(ctx: &C, keyword: Self, left_paren: Self, fields: Self, ellipsis: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::ShapeTypeSpecifier(ctx.get_arena().alloc(ShapeTypeSpecifierChildren {
            keyword,
            left_paren,
            fields,
            ellipsis,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_shape_expression(ctx: &C, keyword: Self, left_paren: Self, fields: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::ShapeExpression(ctx.get_arena().alloc(ShapeExpressionChildren {
            keyword,
            left_paren,
            fields,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_tuple_expression(ctx: &C, keyword: Self, left_paren: Self, items: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::TupleExpression(ctx.get_arena().alloc(TupleExpressionChildren {
            keyword,
            left_paren,
            items,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_generic_type_specifier(ctx: &C, class_type: Self, argument_list: Self) -> Self {
        let syntax = SyntaxVariant::GenericTypeSpecifier(ctx.get_arena().alloc(GenericTypeSpecifierChildren {
            class_type,
            argument_list,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_nullable_type_specifier(ctx: &C, question: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::NullableTypeSpecifier(ctx.get_arena().alloc(NullableTypeSpecifierChildren {
            question,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_like_type_specifier(ctx: &C, tilde: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::LikeTypeSpecifier(ctx.get_arena().alloc(LikeTypeSpecifierChildren {
            tilde,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_soft_type_specifier(ctx: &C, at: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::SoftTypeSpecifier(ctx.get_arena().alloc(SoftTypeSpecifierChildren {
            at,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_attributized_specifier(ctx: &C, attribute_spec: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::AttributizedSpecifier(ctx.get_arena().alloc(AttributizedSpecifierChildren {
            attribute_spec,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_reified_type_argument(ctx: &C, reified: Self, type_: Self) -> Self {
        let syntax = SyntaxVariant::ReifiedTypeArgument(ctx.get_arena().alloc(ReifiedTypeArgumentChildren {
            reified,
            type_,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_type_arguments(ctx: &C, left_angle: Self, types: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::TypeArguments(ctx.get_arena().alloc(TypeArgumentsChildren {
            left_angle,
            types,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_type_parameters(ctx: &C, left_angle: Self, parameters: Self, right_angle: Self) -> Self {
        let syntax = SyntaxVariant::TypeParameters(ctx.get_arena().alloc(TypeParametersChildren {
            left_angle,
            parameters,
            right_angle,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_tuple_type_specifier(ctx: &C, left_paren: Self, types: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::TupleTypeSpecifier(ctx.get_arena().alloc(TupleTypeSpecifierChildren {
            left_paren,
            types,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_union_type_specifier(ctx: &C, left_paren: Self, types: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::UnionTypeSpecifier(ctx.get_arena().alloc(UnionTypeSpecifierChildren {
            left_paren,
            types,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_intersection_type_specifier(ctx: &C, left_paren: Self, types: Self, right_paren: Self) -> Self {
        let syntax = SyntaxVariant::IntersectionTypeSpecifier(ctx.get_arena().alloc(IntersectionTypeSpecifierChildren {
            left_paren,
            types,
            right_paren,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_error(ctx: &C, error: Self) -> Self {
        let syntax = SyntaxVariant::ErrorSyntax(ctx.get_arena().alloc(ErrorSyntaxChildren {
            error,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_list_item(ctx: &C, item: Self, separator: Self) -> Self {
        let syntax = SyntaxVariant::ListItem(ctx.get_arena().alloc(ListItemChildren {
            item,
            separator,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

    fn make_enum_atom_expression(ctx: &C, hash: Self, expression: Self) -> Self {
        let syntax = SyntaxVariant::EnumAtomExpression(ctx.get_arena().alloc(EnumAtomExpressionChildren {
            hash,
            expression,
        }));
        let value = V::from_values(syntax.iter_children().map(|child| &child.value));
        Self::make(syntax, value)
    }

/**
 * Copyright (c) 2016, Facebook, Inc.
 * All rights reserved.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the "hack" directory of this source tree. An additional
 * directory.
 *
 **
 *
 * THIS FILE IS @generated; DO NOT EDIT IT
 * To regenerate this file, run
 *
 *   buck run //hphp/hack/src:generate_full_fidelity
 *
 **
 *
 */
use crate::{syntax_kind::SyntaxKind, lexable_token::LexableToken};
use super::{syntax::Syntax, syntax_variant_generated::SyntaxVariant};

impl<T: LexableToken, V> Syntax<'_, T, V> {
    pub fn kind(&self) -> SyntaxKind {
        match &self.children {
            SyntaxVariant::Missing => SyntaxKind::Missing,
            SyntaxVariant::Token (t) => SyntaxKind::Token(t.kind()),
            SyntaxVariant::SyntaxList (_) => SyntaxKind::SyntaxList,
            SyntaxVariant::EndOfFile {..} => SyntaxKind::EndOfFile,
            SyntaxVariant::Script {..} => SyntaxKind::Script,
            SyntaxVariant::QualifiedName {..} => SyntaxKind::QualifiedName,
            SyntaxVariant::SimpleTypeSpecifier {..} => SyntaxKind::SimpleTypeSpecifier,
            SyntaxVariant::LiteralExpression {..} => SyntaxKind::LiteralExpression,
            SyntaxVariant::PrefixedStringExpression {..} => SyntaxKind::PrefixedStringExpression,
            SyntaxVariant::PrefixedCodeExpression {..} => SyntaxKind::PrefixedCodeExpression,
            SyntaxVariant::VariableExpression {..} => SyntaxKind::VariableExpression,
            SyntaxVariant::PipeVariableExpression {..} => SyntaxKind::PipeVariableExpression,
            SyntaxVariant::FileAttributeSpecification {..} => SyntaxKind::FileAttributeSpecification,
            SyntaxVariant::EnumDeclaration {..} => SyntaxKind::EnumDeclaration,
            SyntaxVariant::EnumUse {..} => SyntaxKind::EnumUse,
            SyntaxVariant::Enumerator {..} => SyntaxKind::Enumerator,
            SyntaxVariant::EnumClassDeclaration {..} => SyntaxKind::EnumClassDeclaration,
            SyntaxVariant::EnumClassEnumerator {..} => SyntaxKind::EnumClassEnumerator,
            SyntaxVariant::RecordDeclaration {..} => SyntaxKind::RecordDeclaration,
            SyntaxVariant::RecordField {..} => SyntaxKind::RecordField,
            SyntaxVariant::AliasDeclaration {..} => SyntaxKind::AliasDeclaration,
            SyntaxVariant::PropertyDeclaration {..} => SyntaxKind::PropertyDeclaration,
            SyntaxVariant::PropertyDeclarator {..} => SyntaxKind::PropertyDeclarator,
            SyntaxVariant::NamespaceDeclaration {..} => SyntaxKind::NamespaceDeclaration,
            SyntaxVariant::NamespaceDeclarationHeader {..} => SyntaxKind::NamespaceDeclarationHeader,
            SyntaxVariant::NamespaceBody {..} => SyntaxKind::NamespaceBody,
            SyntaxVariant::NamespaceEmptyBody {..} => SyntaxKind::NamespaceEmptyBody,
            SyntaxVariant::NamespaceUseDeclaration {..} => SyntaxKind::NamespaceUseDeclaration,
            SyntaxVariant::NamespaceGroupUseDeclaration {..} => SyntaxKind::NamespaceGroupUseDeclaration,
            SyntaxVariant::NamespaceUseClause {..} => SyntaxKind::NamespaceUseClause,
            SyntaxVariant::FunctionDeclaration {..} => SyntaxKind::FunctionDeclaration,
            SyntaxVariant::FunctionDeclarationHeader {..} => SyntaxKind::FunctionDeclarationHeader,
            SyntaxVariant::Contexts {..} => SyntaxKind::Contexts,
            SyntaxVariant::WhereClause {..} => SyntaxKind::WhereClause,
            SyntaxVariant::WhereConstraint {..} => SyntaxKind::WhereConstraint,
            SyntaxVariant::MethodishDeclaration {..} => SyntaxKind::MethodishDeclaration,
            SyntaxVariant::MethodishTraitResolution {..} => SyntaxKind::MethodishTraitResolution,
            SyntaxVariant::ClassishDeclaration {..} => SyntaxKind::ClassishDeclaration,
            SyntaxVariant::ClassishBody {..} => SyntaxKind::ClassishBody,
            SyntaxVariant::TraitUsePrecedenceItem {..} => SyntaxKind::TraitUsePrecedenceItem,
            SyntaxVariant::TraitUseAliasItem {..} => SyntaxKind::TraitUseAliasItem,
            SyntaxVariant::TraitUseConflictResolution {..} => SyntaxKind::TraitUseConflictResolution,
            SyntaxVariant::TraitUse {..} => SyntaxKind::TraitUse,
            SyntaxVariant::RequireClause {..} => SyntaxKind::RequireClause,
            SyntaxVariant::ConstDeclaration {..} => SyntaxKind::ConstDeclaration,
            SyntaxVariant::ConstantDeclarator {..} => SyntaxKind::ConstantDeclarator,
            SyntaxVariant::TypeConstDeclaration {..} => SyntaxKind::TypeConstDeclaration,
            SyntaxVariant::ContextConstDeclaration {..} => SyntaxKind::ContextConstDeclaration,
            SyntaxVariant::DecoratedExpression {..} => SyntaxKind::DecoratedExpression,
            SyntaxVariant::ParameterDeclaration {..} => SyntaxKind::ParameterDeclaration,
            SyntaxVariant::VariadicParameter {..} => SyntaxKind::VariadicParameter,
            SyntaxVariant::OldAttributeSpecification {..} => SyntaxKind::OldAttributeSpecification,
            SyntaxVariant::AttributeSpecification {..} => SyntaxKind::AttributeSpecification,
            SyntaxVariant::Attribute {..} => SyntaxKind::Attribute,
            SyntaxVariant::InclusionExpression {..} => SyntaxKind::InclusionExpression,
            SyntaxVariant::InclusionDirective {..} => SyntaxKind::InclusionDirective,
            SyntaxVariant::CompoundStatement {..} => SyntaxKind::CompoundStatement,
            SyntaxVariant::ExpressionStatement {..} => SyntaxKind::ExpressionStatement,
            SyntaxVariant::MarkupSection {..} => SyntaxKind::MarkupSection,
            SyntaxVariant::MarkupSuffix {..} => SyntaxKind::MarkupSuffix,
            SyntaxVariant::UnsetStatement {..} => SyntaxKind::UnsetStatement,
            SyntaxVariant::UsingStatementBlockScoped {..} => SyntaxKind::UsingStatementBlockScoped,
            SyntaxVariant::UsingStatementFunctionScoped {..} => SyntaxKind::UsingStatementFunctionScoped,
            SyntaxVariant::WhileStatement {..} => SyntaxKind::WhileStatement,
            SyntaxVariant::IfStatement {..} => SyntaxKind::IfStatement,
            SyntaxVariant::ElseifClause {..} => SyntaxKind::ElseifClause,
            SyntaxVariant::ElseClause {..} => SyntaxKind::ElseClause,
            SyntaxVariant::TryStatement {..} => SyntaxKind::TryStatement,
            SyntaxVariant::CatchClause {..} => SyntaxKind::CatchClause,
            SyntaxVariant::FinallyClause {..} => SyntaxKind::FinallyClause,
            SyntaxVariant::DoStatement {..} => SyntaxKind::DoStatement,
            SyntaxVariant::ForStatement {..} => SyntaxKind::ForStatement,
            SyntaxVariant::ForeachStatement {..} => SyntaxKind::ForeachStatement,
            SyntaxVariant::SwitchStatement {..} => SyntaxKind::SwitchStatement,
            SyntaxVariant::SwitchSection {..} => SyntaxKind::SwitchSection,
            SyntaxVariant::SwitchFallthrough {..} => SyntaxKind::SwitchFallthrough,
            SyntaxVariant::CaseLabel {..} => SyntaxKind::CaseLabel,
            SyntaxVariant::DefaultLabel {..} => SyntaxKind::DefaultLabel,
            SyntaxVariant::ReturnStatement {..} => SyntaxKind::ReturnStatement,
            SyntaxVariant::YieldBreakStatement {..} => SyntaxKind::YieldBreakStatement,
            SyntaxVariant::ThrowStatement {..} => SyntaxKind::ThrowStatement,
            SyntaxVariant::BreakStatement {..} => SyntaxKind::BreakStatement,
            SyntaxVariant::ContinueStatement {..} => SyntaxKind::ContinueStatement,
            SyntaxVariant::EchoStatement {..} => SyntaxKind::EchoStatement,
            SyntaxVariant::ConcurrentStatement {..} => SyntaxKind::ConcurrentStatement,
            SyntaxVariant::SimpleInitializer {..} => SyntaxKind::SimpleInitializer,
            SyntaxVariant::AnonymousClass {..} => SyntaxKind::AnonymousClass,
            SyntaxVariant::AnonymousFunction {..} => SyntaxKind::AnonymousFunction,
            SyntaxVariant::AnonymousFunctionUseClause {..} => SyntaxKind::AnonymousFunctionUseClause,
            SyntaxVariant::LambdaExpression {..} => SyntaxKind::LambdaExpression,
            SyntaxVariant::LambdaSignature {..} => SyntaxKind::LambdaSignature,
            SyntaxVariant::CastExpression {..} => SyntaxKind::CastExpression,
            SyntaxVariant::ScopeResolutionExpression {..} => SyntaxKind::ScopeResolutionExpression,
            SyntaxVariant::MemberSelectionExpression {..} => SyntaxKind::MemberSelectionExpression,
            SyntaxVariant::SafeMemberSelectionExpression {..} => SyntaxKind::SafeMemberSelectionExpression,
            SyntaxVariant::EmbeddedMemberSelectionExpression {..} => SyntaxKind::EmbeddedMemberSelectionExpression,
            SyntaxVariant::YieldExpression {..} => SyntaxKind::YieldExpression,
            SyntaxVariant::PrefixUnaryExpression {..} => SyntaxKind::PrefixUnaryExpression,
            SyntaxVariant::PostfixUnaryExpression {..} => SyntaxKind::PostfixUnaryExpression,
            SyntaxVariant::BinaryExpression {..} => SyntaxKind::BinaryExpression,
            SyntaxVariant::IsExpression {..} => SyntaxKind::IsExpression,
            SyntaxVariant::AsExpression {..} => SyntaxKind::AsExpression,
            SyntaxVariant::NullableAsExpression {..} => SyntaxKind::NullableAsExpression,
            SyntaxVariant::ConditionalExpression {..} => SyntaxKind::ConditionalExpression,
            SyntaxVariant::EvalExpression {..} => SyntaxKind::EvalExpression,
            SyntaxVariant::DefineExpression {..} => SyntaxKind::DefineExpression,
            SyntaxVariant::IssetExpression {..} => SyntaxKind::IssetExpression,
            SyntaxVariant::FunctionCallExpression {..} => SyntaxKind::FunctionCallExpression,
            SyntaxVariant::FunctionPointerExpression {..} => SyntaxKind::FunctionPointerExpression,
            SyntaxVariant::ParenthesizedExpression {..} => SyntaxKind::ParenthesizedExpression,
            SyntaxVariant::BracedExpression {..} => SyntaxKind::BracedExpression,
            SyntaxVariant::ETSpliceExpression {..} => SyntaxKind::ETSpliceExpression,
            SyntaxVariant::EmbeddedBracedExpression {..} => SyntaxKind::EmbeddedBracedExpression,
            SyntaxVariant::ListExpression {..} => SyntaxKind::ListExpression,
            SyntaxVariant::CollectionLiteralExpression {..} => SyntaxKind::CollectionLiteralExpression,
            SyntaxVariant::ObjectCreationExpression {..} => SyntaxKind::ObjectCreationExpression,
            SyntaxVariant::ConstructorCall {..} => SyntaxKind::ConstructorCall,
            SyntaxVariant::RecordCreationExpression {..} => SyntaxKind::RecordCreationExpression,
            SyntaxVariant::DarrayIntrinsicExpression {..} => SyntaxKind::DarrayIntrinsicExpression,
            SyntaxVariant::DictionaryIntrinsicExpression {..} => SyntaxKind::DictionaryIntrinsicExpression,
            SyntaxVariant::KeysetIntrinsicExpression {..} => SyntaxKind::KeysetIntrinsicExpression,
            SyntaxVariant::VarrayIntrinsicExpression {..} => SyntaxKind::VarrayIntrinsicExpression,
            SyntaxVariant::VectorIntrinsicExpression {..} => SyntaxKind::VectorIntrinsicExpression,
            SyntaxVariant::ElementInitializer {..} => SyntaxKind::ElementInitializer,
            SyntaxVariant::SubscriptExpression {..} => SyntaxKind::SubscriptExpression,
            SyntaxVariant::EmbeddedSubscriptExpression {..} => SyntaxKind::EmbeddedSubscriptExpression,
            SyntaxVariant::AwaitableCreationExpression {..} => SyntaxKind::AwaitableCreationExpression,
            SyntaxVariant::XHPChildrenDeclaration {..} => SyntaxKind::XHPChildrenDeclaration,
            SyntaxVariant::XHPChildrenParenthesizedList {..} => SyntaxKind::XHPChildrenParenthesizedList,
            SyntaxVariant::XHPCategoryDeclaration {..} => SyntaxKind::XHPCategoryDeclaration,
            SyntaxVariant::XHPEnumType {..} => SyntaxKind::XHPEnumType,
            SyntaxVariant::XHPLateinit {..} => SyntaxKind::XHPLateinit,
            SyntaxVariant::XHPRequired {..} => SyntaxKind::XHPRequired,
            SyntaxVariant::XHPClassAttributeDeclaration {..} => SyntaxKind::XHPClassAttributeDeclaration,
            SyntaxVariant::XHPClassAttribute {..} => SyntaxKind::XHPClassAttribute,
            SyntaxVariant::XHPSimpleClassAttribute {..} => SyntaxKind::XHPSimpleClassAttribute,
            SyntaxVariant::XHPSimpleAttribute {..} => SyntaxKind::XHPSimpleAttribute,
            SyntaxVariant::XHPSpreadAttribute {..} => SyntaxKind::XHPSpreadAttribute,
            SyntaxVariant::XHPOpen {..} => SyntaxKind::XHPOpen,
            SyntaxVariant::XHPExpression {..} => SyntaxKind::XHPExpression,
            SyntaxVariant::XHPClose {..} => SyntaxKind::XHPClose,
            SyntaxVariant::TypeConstant {..} => SyntaxKind::TypeConstant,
            SyntaxVariant::VectorTypeSpecifier {..} => SyntaxKind::VectorTypeSpecifier,
            SyntaxVariant::KeysetTypeSpecifier {..} => SyntaxKind::KeysetTypeSpecifier,
            SyntaxVariant::TupleTypeExplicitSpecifier {..} => SyntaxKind::TupleTypeExplicitSpecifier,
            SyntaxVariant::VarrayTypeSpecifier {..} => SyntaxKind::VarrayTypeSpecifier,
            SyntaxVariant::FunctionCtxTypeSpecifier {..} => SyntaxKind::FunctionCtxTypeSpecifier,
            SyntaxVariant::TypeParameter {..} => SyntaxKind::TypeParameter,
            SyntaxVariant::TypeConstraint {..} => SyntaxKind::TypeConstraint,
            SyntaxVariant::ContextConstraint {..} => SyntaxKind::ContextConstraint,
            SyntaxVariant::DarrayTypeSpecifier {..} => SyntaxKind::DarrayTypeSpecifier,
            SyntaxVariant::DictionaryTypeSpecifier {..} => SyntaxKind::DictionaryTypeSpecifier,
            SyntaxVariant::ClosureTypeSpecifier {..} => SyntaxKind::ClosureTypeSpecifier,
            SyntaxVariant::ClosureParameterTypeSpecifier {..} => SyntaxKind::ClosureParameterTypeSpecifier,
            SyntaxVariant::ClassnameTypeSpecifier {..} => SyntaxKind::ClassnameTypeSpecifier,
            SyntaxVariant::FieldSpecifier {..} => SyntaxKind::FieldSpecifier,
            SyntaxVariant::FieldInitializer {..} => SyntaxKind::FieldInitializer,
            SyntaxVariant::ShapeTypeSpecifier {..} => SyntaxKind::ShapeTypeSpecifier,
            SyntaxVariant::ShapeExpression {..} => SyntaxKind::ShapeExpression,
            SyntaxVariant::TupleExpression {..} => SyntaxKind::TupleExpression,
            SyntaxVariant::GenericTypeSpecifier {..} => SyntaxKind::GenericTypeSpecifier,
            SyntaxVariant::NullableTypeSpecifier {..} => SyntaxKind::NullableTypeSpecifier,
            SyntaxVariant::LikeTypeSpecifier {..} => SyntaxKind::LikeTypeSpecifier,
            SyntaxVariant::SoftTypeSpecifier {..} => SyntaxKind::SoftTypeSpecifier,
            SyntaxVariant::AttributizedSpecifier {..} => SyntaxKind::AttributizedSpecifier,
            SyntaxVariant::ReifiedTypeArgument {..} => SyntaxKind::ReifiedTypeArgument,
            SyntaxVariant::TypeArguments {..} => SyntaxKind::TypeArguments,
            SyntaxVariant::TypeParameters {..} => SyntaxKind::TypeParameters,
            SyntaxVariant::TupleTypeSpecifier {..} => SyntaxKind::TupleTypeSpecifier,
            SyntaxVariant::UnionTypeSpecifier {..} => SyntaxKind::UnionTypeSpecifier,
            SyntaxVariant::IntersectionTypeSpecifier {..} => SyntaxKind::IntersectionTypeSpecifier,
            SyntaxVariant::ErrorSyntax {..} => SyntaxKind::ErrorSyntax,
            SyntaxVariant::ListItem {..} => SyntaxKind::ListItem,
            SyntaxVariant::EnumAtomExpression {..} => SyntaxKind::EnumAtomExpression,
        }
    }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use std::iter::{empty, once};

use super::{
    has_arena::HasArena, syntax_children_iterator::SyntaxChildrenIterator,
    syntax_variant_generated::SyntaxVariant,
};
use crate::{
    lexable_token::LexableToken,
    syntax::{SyntaxTypeBase, SyntaxValueType},
    syntax_kind::SyntaxKind,
    token_kind::TokenKind,
};
use bumpalo::collections::Vec;
use itertools::Either::{Left, Right};

#[derive(Debug, Clone)]
pub struct Syntax<'a, T, V> {
    pub children: SyntaxVariant<'a, T, V>,
    pub value: V,
}

impl<'a, T, V> Syntax<'a, T, V> {
    pub fn make(t: SyntaxVariant<'a, T, V>, v: V) -> Self {
        Self {
            children: t,
            value: v,
        }
    }

    pub fn get_token(&self) -> Option<&T> {
        match &self.children {
            SyntaxVariant::Token(t) => Some(&t),
            _ => None,
        }
    }

    #[allow(dead_code)]
    pub fn iter_children(&'a self) -> SyntaxChildrenIterator<'a, T, V> {
        self.children.iter_children()
    }

    pub fn syntax_node_to_list(&self) -> impl DoubleEndedIterator<Item = &Syntax<'a, T, V>> {
        match &self.children {
            SyntaxVariant::SyntaxList(x) => Left(x.iter()),
            SyntaxVariant::Missing => Right(Left(empty())),
            _ => Right(Right(once(self))),
        }
    }

    pub fn syntax_node_to_list_skip_separator(
        &self,
    ) -> impl DoubleEndedIterator<Item = &Syntax<'a, T, V>> {
        match &self.children {
            SyntaxVariant::SyntaxList(l) => Left(l.iter().map(|n| match &n.children {
                SyntaxVariant::ListItem(i) => &i.item,
                _ => n,
            })),
            SyntaxVariant::Missing => Right(Left(empty())),
            _ => Right(Right(once(self))),
        }
    }
}

impl<'a, T: Copy, V: SyntaxValueType<T>> Syntax<'a, T, V> {
    pub fn make_token(t: T) -> Self {
        let value = V::from_token(t);
        let syntax = SyntaxVariant::Token(t);
        Self::make(syntax, value)
    }

    pub fn make_missing(offset: usize) -> Self {
        let value = V::from_children(SyntaxKind::Missing, offset, empty());
        let syntax = SyntaxVariant::Missing;
        Self::make(syntax, value)
    }
}

impl<'a, T: LexableToken, V> Syntax<'a, T, V> {
    fn is_specific_token(&self, kind: TokenKind) -> bool {
        match &self.children {
            SyntaxVariant::Token(t) => t.kind() == kind,
            _ => false,
        }
    }

    pub fn is_public(&self) -> bool {
        self.is_specific_token(TokenKind::Public)
    }

    pub fn is_private(&self) -> bool {
        self.is_specific_token(TokenKind::Private)
    }

    pub fn is_protected(&self) -> bool {
        self.is_specific_token(TokenKind::Protected)
    }

    pub fn is_abstract(&self) -> bool {
        self.is_specific_token(TokenKind::Abstract)
    }

    pub fn is_static(&self) -> bool {
        self.is_specific_token(TokenKind::Static)
    }

    pub fn is_ampersand(&self) -> bool {
        self.is_specific_token(TokenKind::Ampersand)
    }

    pub fn is_ellipsis(&self) -> bool {
        self.is_specific_token(TokenKind::DotDotDot)
    }

    pub fn is_final(&self) -> bool {
        self.is_specific_token(TokenKind::Final)
    }

    pub fn is_xhp(&self) -> bool {
        self.is_specific_token(TokenKind::XHP)
    }

    pub fn is_async(&self) -> bool {
        self.is_specific_token(TokenKind::Async)
    }

    pub fn is_yield(&self) -> bool {
        self.is_specific_token(TokenKind::Yield)
    }

    pub fn is_construct(&self) -> bool {
        self.is_specific_token(TokenKind::Construct)
    }

    pub fn is_void(&self) -> bool {
        self.is_specific_token(TokenKind::Void)
    }

    pub fn is_left_brace(&self) -> bool {
        self.is_specific_token(TokenKind::LeftBrace)
    }

    pub fn is_comma(&self) -> bool {
        self.is_specific_token(TokenKind::Comma)
    }

    pub fn is_inout(&self) -> bool {
        self.is_specific_token(TokenKind::Inout)
    }

    pub fn is_this(&self) -> bool {
        self.is_specific_token(TokenKind::This)
    }

    pub fn is_name(&self) -> bool {
        self.is_specific_token(TokenKind::Name)
    }

    pub fn is_as_expression(&self) -> bool {
        self.kind() == SyntaxKind::AsExpression
    }

    pub fn is_missing(&self) -> bool {
        self.kind() == SyntaxKind::Missing
    }

    pub fn is_external(&self) -> bool {
        self.is_specific_token(TokenKind::Semicolon) || self.is_missing()
    }

    pub fn is_readonly(&self) -> bool {
        self.is_specific_token(TokenKind::Readonly)
    }

    pub fn is_namespace_empty_body(&self) -> bool {
        self.kind() == SyntaxKind::NamespaceEmptyBody
    }

    pub fn is_attribute_specification(&self) -> bool {
        self.kind() == SyntaxKind::AttributeSpecification
    }

    pub fn is_old_attribute_specification(&self) -> bool {
        self.kind() == SyntaxKind::OldAttributeSpecification
    }

    pub fn is_file_attribute_specification(&self) -> bool {
        self.kind() == SyntaxKind::FileAttributeSpecification
    }

    pub fn is_return_statement(&self) -> bool {
        self.kind() == SyntaxKind::ReturnStatement
    }

    pub fn is_conditional_expression(&self) -> bool {
        self.kind() == SyntaxKind::ConditionalExpression
    }

    pub fn is_safe_member_selection_expression(&self) -> bool {
        self.kind() == SyntaxKind::SafeMemberSelectionExpression
    }

    pub fn is_object_creation_expression(&self) -> bool {
        self.kind() == SyntaxKind::ObjectCreationExpression
    }

    pub fn is_compound_statement(&self) -> bool {
        self.kind() == SyntaxKind::CompoundStatement
    }

    pub fn is_methodish_declaration(&self) -> bool {
        self.kind() == SyntaxKind::MethodishDeclaration
    }

    pub fn is_function_declaration(&self) -> bool {
        self.kind() == SyntaxKind::FunctionDeclaration
    }

    pub fn is_xhp_open(&self) -> bool {
        self.kind() == SyntaxKind::XHPOpen
    }

    pub fn is_braced_expression(&self) -> bool {
        self.kind() == SyntaxKind::BracedExpression
    }

    pub fn is_syntax_list(&self) -> bool {
        self.kind() == SyntaxKind::SyntaxList
    }

    pub fn is_namespace_prefix(&self) -> bool {
        if let SyntaxVariant::QualifiedName(x) = &self.children {
            x.parts
                .syntax_node_to_list()
                .last()
                .map_or(false, |p| match &p.children {
                    SyntaxVariant::ListItem(x) => !&x.separator.is_missing(),
                    _ => false,
                })
        } else {
            false
        }
    }
}

impl<'a, C, T, V> SyntaxTypeBase<C> for Syntax<'a, T, V>
where
    T: LexableToken + Copy,
    V: SyntaxValueType<T>,
    C: HasArena<'a>,
{
    type Token = T;
    type Value = V;

    fn make_missing(_: &C, offset: usize) -> Self {
        Self::make_missing(offset)
    }

    fn make_token(_: &C, arg: T) -> Self {
        Self::make_token(arg)
    }

    fn make_list(ctx: &C, arg: std::vec::Vec<Self>, offset: usize) -> Self {
        // An empty list is represented by Missing; everything else is a
        // SyntaxList, even if the list has only one item.
        if arg.is_empty() {
            Self::make_missing(offset)
        } else {
            let mut list = Vec::with_capacity_in(arg.len(), ctx.get_arena());
            list.extend(arg.into_iter());
            let list = list.into_bump_slice();
            let nodes = list.iter().map(|x| &x.value);
            let value = V::from_children(SyntaxKind::SyntaxList, offset, nodes);
            let syntax = SyntaxVariant::SyntaxList(list);
            Self::make(syntax, value)
        }
    }

    fn value(&self) -> &Self::Value {
        &self.value
// Copyright (c) Facebook, Inc. and its affiliates.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::has_arena::HasArena;
use bumpalo::Bump;

#[derive(Clone)]
pub struct State<'a> {
    pub arena: &'a Bump,
}

impl<'a> HasArena<'a> for State<'a> {
    fn get_arena(&self) -> &'a Bump {
/**
 * Copyright (c) 2016, Facebook, Inc.
 * All rights reserved.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the "hack" directory of this source tree. An additional
 * directory.
 *
 **
 *
 * THIS FILE IS @generated; DO NOT EDIT IT
 * To regenerate this file, run
 *
 *   buck run //hphp/hack/src:generate_full_fidelity
 *
 **
 *
 */
use super::{serialize::WithContext, syntax::Syntax, syntax_variant_generated::*};
use serde::{ser::SerializeStruct, Serialize, Serializer};

impl<'a, T, V> Serialize for WithContext<'a, Syntax<'a, T, V>>
where
    T: 'a,
    WithContext<'a, T>: Serialize,
{
    fn serialize<S: Serializer>(&self, s: S) -> Result<S::Ok, S::Error> {
        match self.1.children {
            SyntaxVariant::Missing => {
                let mut ss = s.serialize_struct("", 1)?;
                ss.serialize_field("kind", "missing")?;
                ss.end()
            }
            SyntaxVariant::Token(ref t) => {
                let mut ss = s.serialize_struct("", 2)?;
                ss.serialize_field("kind", "token")?;
                ss.serialize_field("token", &self.with(t))?;
                ss.end()
            }
            SyntaxVariant::SyntaxList(l) => {
                let mut ss = s.serialize_struct("", 2)?;
                ss.serialize_field("kind", "list")?;
                ss.serialize_field("elements", &self.with(l))?;
                ss.end()
            }
            SyntaxVariant::EndOfFile (EndOfFileChildren{token} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "end_of_file")?;
      ss.serialize_field("end_of_file_token", &self.with(token))?;
      ss.end()
} 
SyntaxVariant::Script (ScriptChildren{declarations} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "script")?;
      ss.serialize_field("script_declarations", &self.with(declarations))?;
      ss.end()
} 
SyntaxVariant::QualifiedName (QualifiedNameChildren{parts} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "qualified_name")?;
      ss.serialize_field("qualified_name_parts", &self.with(parts))?;
      ss.end()
} 
SyntaxVariant::SimpleTypeSpecifier (SimpleTypeSpecifierChildren{specifier} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "simple_type_specifier")?;
      ss.serialize_field("simple_type_specifier", &self.with(specifier))?;
      ss.end()
} 
SyntaxVariant::LiteralExpression (LiteralExpressionChildren{expression} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "literal")?;
      ss.serialize_field("literal_expression", &self.with(expression))?;
      ss.end()
} 
SyntaxVariant::PrefixedStringExpression (PrefixedStringExpressionChildren{name,str} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "prefixed_string")?;
      ss.serialize_field("prefixed_string_name", &self.with(name))?;
ss.serialize_field("prefixed_string_str", &self.with(str))?;
      ss.end()
} 
SyntaxVariant::PrefixedCodeExpression (PrefixedCodeExpressionChildren{prefix,left_backtick,expression,right_backtick} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "prefixed_code")?;
      ss.serialize_field("prefixed_code_prefix", &self.with(prefix))?;
ss.serialize_field("prefixed_code_left_backtick", &self.with(left_backtick))?;
ss.serialize_field("prefixed_code_expression", &self.with(expression))?;
ss.serialize_field("prefixed_code_right_backtick", &self.with(right_backtick))?;
      ss.end()
} 
SyntaxVariant::VariableExpression (VariableExpressionChildren{expression} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "variable")?;
      ss.serialize_field("variable_expression", &self.with(expression))?;
      ss.end()
} 
SyntaxVariant::PipeVariableExpression (PipeVariableExpressionChildren{expression} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "pipe_variable")?;
      ss.serialize_field("pipe_variable_expression", &self.with(expression))?;
      ss.end()
} 
SyntaxVariant::FileAttributeSpecification (FileAttributeSpecificationChildren{left_double_angle,keyword,colon,attributes,right_double_angle} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "file_attribute_specification")?;
      ss.serialize_field("file_attribute_specification_left_double_angle", &self.with(left_double_angle))?;
ss.serialize_field("file_attribute_specification_keyword", &self.with(keyword))?;
ss.serialize_field("file_attribute_specification_colon", &self.with(colon))?;
ss.serialize_field("file_attribute_specification_attributes", &self.with(attributes))?;
ss.serialize_field("file_attribute_specification_right_double_angle", &self.with(right_double_angle))?;
      ss.end()
} 
SyntaxVariant::EnumDeclaration (EnumDeclarationChildren{attribute_spec,keyword,name,colon,base,type_,left_brace,use_clauses,enumerators,right_brace} ) => {
      let mut ss = s.serialize_struct("", 11)?;
      ss.serialize_field("kind", "enum_declaration")?;
      ss.serialize_field("enum_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("enum_keyword", &self.with(keyword))?;
ss.serialize_field("enum_name", &self.with(name))?;
ss.serialize_field("enum_colon", &self.with(colon))?;
ss.serialize_field("enum_base", &self.with(base))?;
ss.serialize_field("enum_type", &self.with(type_))?;
ss.serialize_field("enum_left_brace", &self.with(left_brace))?;
ss.serialize_field("enum_use_clauses", &self.with(use_clauses))?;
ss.serialize_field("enum_enumerators", &self.with(enumerators))?;
ss.serialize_field("enum_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::EnumUse (EnumUseChildren{keyword,names,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "enum_use")?;
      ss.serialize_field("enum_use_keyword", &self.with(keyword))?;
ss.serialize_field("enum_use_names", &self.with(names))?;
ss.serialize_field("enum_use_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::Enumerator (EnumeratorChildren{name,equal,value,semicolon} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "enumerator")?;
      ss.serialize_field("enumerator_name", &self.with(name))?;
ss.serialize_field("enumerator_equal", &self.with(equal))?;
ss.serialize_field("enumerator_value", &self.with(value))?;
ss.serialize_field("enumerator_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::EnumClassDeclaration (EnumClassDeclarationChildren{attribute_spec,enum_keyword,class_keyword,name,colon,base,extends,extends_list,left_brace,elements,right_brace} ) => {
      let mut ss = s.serialize_struct("", 12)?;
      ss.serialize_field("kind", "enum_class_declaration")?;
      ss.serialize_field("enum_class_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("enum_class_enum_keyword", &self.with(enum_keyword))?;
ss.serialize_field("enum_class_class_keyword", &self.with(class_keyword))?;
ss.serialize_field("enum_class_name", &self.with(name))?;
ss.serialize_field("enum_class_colon", &self.with(colon))?;
ss.serialize_field("enum_class_base", &self.with(base))?;
ss.serialize_field("enum_class_extends", &self.with(extends))?;
ss.serialize_field("enum_class_extends_list", &self.with(extends_list))?;
ss.serialize_field("enum_class_left_brace", &self.with(left_brace))?;
ss.serialize_field("enum_class_elements", &self.with(elements))?;
ss.serialize_field("enum_class_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::EnumClassEnumerator (EnumClassEnumeratorChildren{type_,name,equal,initial_value,semicolon} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "enum_class_enumerator")?;
      ss.serialize_field("enum_class_enumerator_type", &self.with(type_))?;
ss.serialize_field("enum_class_enumerator_name", &self.with(name))?;
ss.serialize_field("enum_class_enumerator_equal", &self.with(equal))?;
ss.serialize_field("enum_class_enumerator_initial_value", &self.with(initial_value))?;
ss.serialize_field("enum_class_enumerator_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::RecordDeclaration (RecordDeclarationChildren{attribute_spec,modifier,keyword,name,extends_keyword,extends_opt,left_brace,fields,right_brace} ) => {
      let mut ss = s.serialize_struct("", 10)?;
      ss.serialize_field("kind", "record_declaration")?;
      ss.serialize_field("record_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("record_modifier", &self.with(modifier))?;
ss.serialize_field("record_keyword", &self.with(keyword))?;
ss.serialize_field("record_name", &self.with(name))?;
ss.serialize_field("record_extends_keyword", &self.with(extends_keyword))?;
ss.serialize_field("record_extends_opt", &self.with(extends_opt))?;
ss.serialize_field("record_left_brace", &self.with(left_brace))?;
ss.serialize_field("record_fields", &self.with(fields))?;
ss.serialize_field("record_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::RecordField (RecordFieldChildren{type_,name,init,semi} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "record_field")?;
      ss.serialize_field("record_field_type", &self.with(type_))?;
ss.serialize_field("record_field_name", &self.with(name))?;
ss.serialize_field("record_field_init", &self.with(init))?;
ss.serialize_field("record_field_semi", &self.with(semi))?;
      ss.end()
} 
SyntaxVariant::AliasDeclaration (AliasDeclarationChildren{attribute_spec,keyword,name,generic_parameter,constraint,equal,type_,semicolon} ) => {
      let mut ss = s.serialize_struct("", 9)?;
      ss.serialize_field("kind", "alias_declaration")?;
      ss.serialize_field("alias_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("alias_keyword", &self.with(keyword))?;
ss.serialize_field("alias_name", &self.with(name))?;
ss.serialize_field("alias_generic_parameter", &self.with(generic_parameter))?;
ss.serialize_field("alias_constraint", &self.with(constraint))?;
ss.serialize_field("alias_equal", &self.with(equal))?;
ss.serialize_field("alias_type", &self.with(type_))?;
ss.serialize_field("alias_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::PropertyDeclaration (PropertyDeclarationChildren{attribute_spec,modifiers,type_,declarators,semicolon} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "property_declaration")?;
      ss.serialize_field("property_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("property_modifiers", &self.with(modifiers))?;
ss.serialize_field("property_type", &self.with(type_))?;
ss.serialize_field("property_declarators", &self.with(declarators))?;
ss.serialize_field("property_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::PropertyDeclarator (PropertyDeclaratorChildren{name,initializer} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "property_declarator")?;
      ss.serialize_field("property_name", &self.with(name))?;
ss.serialize_field("property_initializer", &self.with(initializer))?;
      ss.end()
} 
SyntaxVariant::NamespaceDeclaration (NamespaceDeclarationChildren{header,body} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "namespace_declaration")?;
      ss.serialize_field("namespace_header", &self.with(header))?;
ss.serialize_field("namespace_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::NamespaceDeclarationHeader (NamespaceDeclarationHeaderChildren{keyword,name} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "namespace_declaration_header")?;
      ss.serialize_field("namespace_keyword", &self.with(keyword))?;
ss.serialize_field("namespace_name", &self.with(name))?;
      ss.end()
} 
SyntaxVariant::NamespaceBody (NamespaceBodyChildren{left_brace,declarations,right_brace} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "namespace_body")?;
      ss.serialize_field("namespace_left_brace", &self.with(left_brace))?;
ss.serialize_field("namespace_declarations", &self.with(declarations))?;
ss.serialize_field("namespace_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::NamespaceEmptyBody (NamespaceEmptyBodyChildren{semicolon} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "namespace_empty_body")?;
      ss.serialize_field("namespace_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::NamespaceUseDeclaration (NamespaceUseDeclarationChildren{keyword,kind,clauses,semicolon} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "namespace_use_declaration")?;
      ss.serialize_field("namespace_use_keyword", &self.with(keyword))?;
ss.serialize_field("namespace_use_kind", &self.with(kind))?;
ss.serialize_field("namespace_use_clauses", &self.with(clauses))?;
ss.serialize_field("namespace_use_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::NamespaceGroupUseDeclaration (NamespaceGroupUseDeclarationChildren{keyword,kind,prefix,left_brace,clauses,right_brace,semicolon} ) => {
      let mut ss = s.serialize_struct("", 8)?;
      ss.serialize_field("kind", "namespace_group_use_declaration")?;
      ss.serialize_field("namespace_group_use_keyword", &self.with(keyword))?;
ss.serialize_field("namespace_group_use_kind", &self.with(kind))?;
ss.serialize_field("namespace_group_use_prefix", &self.with(prefix))?;
ss.serialize_field("namespace_group_use_left_brace", &self.with(left_brace))?;
ss.serialize_field("namespace_group_use_clauses", &self.with(clauses))?;
ss.serialize_field("namespace_group_use_right_brace", &self.with(right_brace))?;
ss.serialize_field("namespace_group_use_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::NamespaceUseClause (NamespaceUseClauseChildren{clause_kind,name,as_,alias} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "namespace_use_clause")?;
      ss.serialize_field("namespace_use_clause_kind", &self.with(clause_kind))?;
ss.serialize_field("namespace_use_name", &self.with(name))?;
ss.serialize_field("namespace_use_as", &self.with(as_))?;
ss.serialize_field("namespace_use_alias", &self.with(alias))?;
      ss.end()
} 
SyntaxVariant::FunctionDeclaration (FunctionDeclarationChildren{attribute_spec,declaration_header,body} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "function_declaration")?;
      ss.serialize_field("function_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("function_declaration_header", &self.with(declaration_header))?;
ss.serialize_field("function_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::FunctionDeclarationHeader (FunctionDeclarationHeaderChildren{modifiers,keyword,name,type_parameter_list,left_paren,parameter_list,right_paren,contexts,colon,readonly_return,type_,where_clause} ) => {
      let mut ss = s.serialize_struct("", 13)?;
      ss.serialize_field("kind", "function_declaration_header")?;
      ss.serialize_field("function_modifiers", &self.with(modifiers))?;
ss.serialize_field("function_keyword", &self.with(keyword))?;
ss.serialize_field("function_name", &self.with(name))?;
ss.serialize_field("function_type_parameter_list", &self.with(type_parameter_list))?;
ss.serialize_field("function_left_paren", &self.with(left_paren))?;
ss.serialize_field("function_parameter_list", &self.with(parameter_list))?;
ss.serialize_field("function_right_paren", &self.with(right_paren))?;
ss.serialize_field("function_contexts", &self.with(contexts))?;
ss.serialize_field("function_colon", &self.with(colon))?;
ss.serialize_field("function_readonly_return", &self.with(readonly_return))?;
ss.serialize_field("function_type", &self.with(type_))?;
ss.serialize_field("function_where_clause", &self.with(where_clause))?;
      ss.end()
} 
SyntaxVariant::Contexts (ContextsChildren{left_bracket,types,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "contexts")?;
      ss.serialize_field("contexts_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("contexts_types", &self.with(types))?;
ss.serialize_field("contexts_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::WhereClause (WhereClauseChildren{keyword,constraints} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "where_clause")?;
      ss.serialize_field("where_clause_keyword", &self.with(keyword))?;
ss.serialize_field("where_clause_constraints", &self.with(constraints))?;
      ss.end()
} 
SyntaxVariant::WhereConstraint (WhereConstraintChildren{left_type,operator,right_type} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "where_constraint")?;
      ss.serialize_field("where_constraint_left_type", &self.with(left_type))?;
ss.serialize_field("where_constraint_operator", &self.with(operator))?;
ss.serialize_field("where_constraint_right_type", &self.with(right_type))?;
      ss.end()
} 
SyntaxVariant::MethodishDeclaration (MethodishDeclarationChildren{attribute,function_decl_header,function_body,semicolon} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "methodish_declaration")?;
      ss.serialize_field("methodish_attribute", &self.with(attribute))?;
ss.serialize_field("methodish_function_decl_header", &self.with(function_decl_header))?;
ss.serialize_field("methodish_function_body", &self.with(function_body))?;
ss.serialize_field("methodish_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::MethodishTraitResolution (MethodishTraitResolutionChildren{attribute,function_decl_header,equal,name,semicolon} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "methodish_trait_resolution")?;
      ss.serialize_field("methodish_trait_attribute", &self.with(attribute))?;
ss.serialize_field("methodish_trait_function_decl_header", &self.with(function_decl_header))?;
ss.serialize_field("methodish_trait_equal", &self.with(equal))?;
ss.serialize_field("methodish_trait_name", &self.with(name))?;
ss.serialize_field("methodish_trait_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ClassishDeclaration (ClassishDeclarationChildren{attribute,modifiers,xhp,keyword,name,type_parameters,extends_keyword,extends_list,implements_keyword,implements_list,where_clause,body} ) => {
      let mut ss = s.serialize_struct("", 13)?;
      ss.serialize_field("kind", "classish_declaration")?;
      ss.serialize_field("classish_attribute", &self.with(attribute))?;
ss.serialize_field("classish_modifiers", &self.with(modifiers))?;
ss.serialize_field("classish_xhp", &self.with(xhp))?;
ss.serialize_field("classish_keyword", &self.with(keyword))?;
ss.serialize_field("classish_name", &self.with(name))?;
ss.serialize_field("classish_type_parameters", &self.with(type_parameters))?;
ss.serialize_field("classish_extends_keyword", &self.with(extends_keyword))?;
ss.serialize_field("classish_extends_list", &self.with(extends_list))?;
ss.serialize_field("classish_implements_keyword", &self.with(implements_keyword))?;
ss.serialize_field("classish_implements_list", &self.with(implements_list))?;
ss.serialize_field("classish_where_clause", &self.with(where_clause))?;
ss.serialize_field("classish_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::ClassishBody (ClassishBodyChildren{left_brace,elements,right_brace} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "classish_body")?;
      ss.serialize_field("classish_body_left_brace", &self.with(left_brace))?;
ss.serialize_field("classish_body_elements", &self.with(elements))?;
ss.serialize_field("classish_body_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::TraitUsePrecedenceItem (TraitUsePrecedenceItemChildren{name,keyword,removed_names} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "trait_use_precedence_item")?;
      ss.serialize_field("trait_use_precedence_item_name", &self.with(name))?;
ss.serialize_field("trait_use_precedence_item_keyword", &self.with(keyword))?;
ss.serialize_field("trait_use_precedence_item_removed_names", &self.with(removed_names))?;
      ss.end()
} 
SyntaxVariant::TraitUseAliasItem (TraitUseAliasItemChildren{aliasing_name,keyword,modifiers,aliased_name} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "trait_use_alias_item")?;
      ss.serialize_field("trait_use_alias_item_aliasing_name", &self.with(aliasing_name))?;
ss.serialize_field("trait_use_alias_item_keyword", &self.with(keyword))?;
ss.serialize_field("trait_use_alias_item_modifiers", &self.with(modifiers))?;
ss.serialize_field("trait_use_alias_item_aliased_name", &self.with(aliased_name))?;
      ss.end()
} 
SyntaxVariant::TraitUseConflictResolution (TraitUseConflictResolutionChildren{keyword,names,left_brace,clauses,right_brace} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "trait_use_conflict_resolution")?;
      ss.serialize_field("trait_use_conflict_resolution_keyword", &self.with(keyword))?;
ss.serialize_field("trait_use_conflict_resolution_names", &self.with(names))?;
ss.serialize_field("trait_use_conflict_resolution_left_brace", &self.with(left_brace))?;
ss.serialize_field("trait_use_conflict_resolution_clauses", &self.with(clauses))?;
ss.serialize_field("trait_use_conflict_resolution_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::TraitUse (TraitUseChildren{keyword,names,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "trait_use")?;
      ss.serialize_field("trait_use_keyword", &self.with(keyword))?;
ss.serialize_field("trait_use_names", &self.with(names))?;
ss.serialize_field("trait_use_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::RequireClause (RequireClauseChildren{keyword,kind,name,semicolon} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "require_clause")?;
      ss.serialize_field("require_keyword", &self.with(keyword))?;
ss.serialize_field("require_kind", &self.with(kind))?;
ss.serialize_field("require_name", &self.with(name))?;
ss.serialize_field("require_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ConstDeclaration (ConstDeclarationChildren{modifiers,keyword,type_specifier,declarators,semicolon} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "const_declaration")?;
      ss.serialize_field("const_modifiers", &self.with(modifiers))?;
ss.serialize_field("const_keyword", &self.with(keyword))?;
ss.serialize_field("const_type_specifier", &self.with(type_specifier))?;
ss.serialize_field("const_declarators", &self.with(declarators))?;
ss.serialize_field("const_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ConstantDeclarator (ConstantDeclaratorChildren{name,initializer} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "constant_declarator")?;
      ss.serialize_field("constant_declarator_name", &self.with(name))?;
ss.serialize_field("constant_declarator_initializer", &self.with(initializer))?;
      ss.end()
} 
SyntaxVariant::TypeConstDeclaration (TypeConstDeclarationChildren{attribute_spec,modifiers,keyword,type_keyword,name,type_parameters,type_constraint,equal,type_specifier,semicolon} ) => {
      let mut ss = s.serialize_struct("", 11)?;
      ss.serialize_field("kind", "type_const_declaration")?;
      ss.serialize_field("type_const_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("type_const_modifiers", &self.with(modifiers))?;
ss.serialize_field("type_const_keyword", &self.with(keyword))?;
ss.serialize_field("type_const_type_keyword", &self.with(type_keyword))?;
ss.serialize_field("type_const_name", &self.with(name))?;
ss.serialize_field("type_const_type_parameters", &self.with(type_parameters))?;
ss.serialize_field("type_const_type_constraint", &self.with(type_constraint))?;
ss.serialize_field("type_const_equal", &self.with(equal))?;
ss.serialize_field("type_const_type_specifier", &self.with(type_specifier))?;
ss.serialize_field("type_const_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ContextConstDeclaration (ContextConstDeclarationChildren{modifiers,const_keyword,ctx_keyword,name,type_parameters,constraint,equal,ctx_list,semicolon} ) => {
      let mut ss = s.serialize_struct("", 10)?;
      ss.serialize_field("kind", "context_const_declaration")?;
      ss.serialize_field("context_const_modifiers", &self.with(modifiers))?;
ss.serialize_field("context_const_const_keyword", &self.with(const_keyword))?;
ss.serialize_field("context_const_ctx_keyword", &self.with(ctx_keyword))?;
ss.serialize_field("context_const_name", &self.with(name))?;
ss.serialize_field("context_const_type_parameters", &self.with(type_parameters))?;
ss.serialize_field("context_const_constraint", &self.with(constraint))?;
ss.serialize_field("context_const_equal", &self.with(equal))?;
ss.serialize_field("context_const_ctx_list", &self.with(ctx_list))?;
ss.serialize_field("context_const_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::DecoratedExpression (DecoratedExpressionChildren{decorator,expression} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "decorated_expression")?;
      ss.serialize_field("decorated_expression_decorator", &self.with(decorator))?;
ss.serialize_field("decorated_expression_expression", &self.with(expression))?;
      ss.end()
} 
SyntaxVariant::ParameterDeclaration (ParameterDeclarationChildren{attribute,visibility,call_convention,readonly,type_,name,default_value} ) => {
      let mut ss = s.serialize_struct("", 8)?;
      ss.serialize_field("kind", "parameter_declaration")?;
      ss.serialize_field("parameter_attribute", &self.with(attribute))?;
ss.serialize_field("parameter_visibility", &self.with(visibility))?;
ss.serialize_field("parameter_call_convention", &self.with(call_convention))?;
ss.serialize_field("parameter_readonly", &self.with(readonly))?;
ss.serialize_field("parameter_type", &self.with(type_))?;
ss.serialize_field("parameter_name", &self.with(name))?;
ss.serialize_field("parameter_default_value", &self.with(default_value))?;
      ss.end()
} 
SyntaxVariant::VariadicParameter (VariadicParameterChildren{call_convention,type_,ellipsis} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "variadic_parameter")?;
      ss.serialize_field("variadic_parameter_call_convention", &self.with(call_convention))?;
ss.serialize_field("variadic_parameter_type", &self.with(type_))?;
ss.serialize_field("variadic_parameter_ellipsis", &self.with(ellipsis))?;
      ss.end()
} 
SyntaxVariant::OldAttributeSpecification (OldAttributeSpecificationChildren{left_double_angle,attributes,right_double_angle} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "old_attribute_specification")?;
      ss.serialize_field("old_attribute_specification_left_double_angle", &self.with(left_double_angle))?;
ss.serialize_field("old_attribute_specification_attributes", &self.with(attributes))?;
ss.serialize_field("old_attribute_specification_right_double_angle", &self.with(right_double_angle))?;
      ss.end()
} 
SyntaxVariant::AttributeSpecification (AttributeSpecificationChildren{attributes} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "attribute_specification")?;
      ss.serialize_field("attribute_specification_attributes", &self.with(attributes))?;
      ss.end()
} 
SyntaxVariant::Attribute (AttributeChildren{at,attribute_name} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "attribute")?;
      ss.serialize_field("attribute_at", &self.with(at))?;
ss.serialize_field("attribute_attribute_name", &self.with(attribute_name))?;
      ss.end()
} 
SyntaxVariant::InclusionExpression (InclusionExpressionChildren{require,filename} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "inclusion_expression")?;
      ss.serialize_field("inclusion_require", &self.with(require))?;
ss.serialize_field("inclusion_filename", &self.with(filename))?;
      ss.end()
} 
SyntaxVariant::InclusionDirective (InclusionDirectiveChildren{expression,semicolon} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "inclusion_directive")?;
      ss.serialize_field("inclusion_expression", &self.with(expression))?;
ss.serialize_field("inclusion_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::CompoundStatement (CompoundStatementChildren{left_brace,statements,right_brace} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "compound_statement")?;
      ss.serialize_field("compound_left_brace", &self.with(left_brace))?;
ss.serialize_field("compound_statements", &self.with(statements))?;
ss.serialize_field("compound_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::ExpressionStatement (ExpressionStatementChildren{expression,semicolon} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "expression_statement")?;
      ss.serialize_field("expression_statement_expression", &self.with(expression))?;
ss.serialize_field("expression_statement_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::MarkupSection (MarkupSectionChildren{hashbang,suffix} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "markup_section")?;
      ss.serialize_field("markup_hashbang", &self.with(hashbang))?;
ss.serialize_field("markup_suffix", &self.with(suffix))?;
      ss.end()
} 
SyntaxVariant::MarkupSuffix (MarkupSuffixChildren{less_than_question,name} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "markup_suffix")?;
      ss.serialize_field("markup_suffix_less_than_question", &self.with(less_than_question))?;
ss.serialize_field("markup_suffix_name", &self.with(name))?;
      ss.end()
} 
SyntaxVariant::UnsetStatement (UnsetStatementChildren{keyword,left_paren,variables,right_paren,semicolon} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "unset_statement")?;
      ss.serialize_field("unset_keyword", &self.with(keyword))?;
ss.serialize_field("unset_left_paren", &self.with(left_paren))?;
ss.serialize_field("unset_variables", &self.with(variables))?;
ss.serialize_field("unset_right_paren", &self.with(right_paren))?;
ss.serialize_field("unset_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::UsingStatementBlockScoped (UsingStatementBlockScopedChildren{await_keyword,using_keyword,left_paren,expressions,right_paren,body} ) => {
      let mut ss = s.serialize_struct("", 7)?;
      ss.serialize_field("kind", "using_statement_block_scoped")?;
      ss.serialize_field("using_block_await_keyword", &self.with(await_keyword))?;
ss.serialize_field("using_block_using_keyword", &self.with(using_keyword))?;
ss.serialize_field("using_block_left_paren", &self.with(left_paren))?;
ss.serialize_field("using_block_expressions", &self.with(expressions))?;
ss.serialize_field("using_block_right_paren", &self.with(right_paren))?;
ss.serialize_field("using_block_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::UsingStatementFunctionScoped (UsingStatementFunctionScopedChildren{await_keyword,using_keyword,expression,semicolon} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "using_statement_function_scoped")?;
      ss.serialize_field("using_function_await_keyword", &self.with(await_keyword))?;
ss.serialize_field("using_function_using_keyword", &self.with(using_keyword))?;
ss.serialize_field("using_function_expression", &self.with(expression))?;
ss.serialize_field("using_function_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::WhileStatement (WhileStatementChildren{keyword,left_paren,condition,right_paren,body} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "while_statement")?;
      ss.serialize_field("while_keyword", &self.with(keyword))?;
ss.serialize_field("while_left_paren", &self.with(left_paren))?;
ss.serialize_field("while_condition", &self.with(condition))?;
ss.serialize_field("while_right_paren", &self.with(right_paren))?;
ss.serialize_field("while_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::IfStatement (IfStatementChildren{keyword,left_paren,condition,right_paren,statement,elseif_clauses,else_clause} ) => {
      let mut ss = s.serialize_struct("", 8)?;
      ss.serialize_field("kind", "if_statement")?;
      ss.serialize_field("if_keyword", &self.with(keyword))?;
ss.serialize_field("if_left_paren", &self.with(left_paren))?;
ss.serialize_field("if_condition", &self.with(condition))?;
ss.serialize_field("if_right_paren", &self.with(right_paren))?;
ss.serialize_field("if_statement", &self.with(statement))?;
ss.serialize_field("if_elseif_clauses", &self.with(elseif_clauses))?;
ss.serialize_field("if_else_clause", &self.with(else_clause))?;
      ss.end()
} 
SyntaxVariant::ElseifClause (ElseifClauseChildren{keyword,left_paren,condition,right_paren,statement} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "elseif_clause")?;
      ss.serialize_field("elseif_keyword", &self.with(keyword))?;
ss.serialize_field("elseif_left_paren", &self.with(left_paren))?;
ss.serialize_field("elseif_condition", &self.with(condition))?;
ss.serialize_field("elseif_right_paren", &self.with(right_paren))?;
ss.serialize_field("elseif_statement", &self.with(statement))?;
      ss.end()
} 
SyntaxVariant::ElseClause (ElseClauseChildren{keyword,statement} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "else_clause")?;
      ss.serialize_field("else_keyword", &self.with(keyword))?;
ss.serialize_field("else_statement", &self.with(statement))?;
      ss.end()
} 
SyntaxVariant::TryStatement (TryStatementChildren{keyword,compound_statement,catch_clauses,finally_clause} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "try_statement")?;
      ss.serialize_field("try_keyword", &self.with(keyword))?;
ss.serialize_field("try_compound_statement", &self.with(compound_statement))?;
ss.serialize_field("try_catch_clauses", &self.with(catch_clauses))?;
ss.serialize_field("try_finally_clause", &self.with(finally_clause))?;
      ss.end()
} 
SyntaxVariant::CatchClause (CatchClauseChildren{keyword,left_paren,type_,variable,right_paren,body} ) => {
      let mut ss = s.serialize_struct("", 7)?;
      ss.serialize_field("kind", "catch_clause")?;
      ss.serialize_field("catch_keyword", &self.with(keyword))?;
ss.serialize_field("catch_left_paren", &self.with(left_paren))?;
ss.serialize_field("catch_type", &self.with(type_))?;
ss.serialize_field("catch_variable", &self.with(variable))?;
ss.serialize_field("catch_right_paren", &self.with(right_paren))?;
ss.serialize_field("catch_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::FinallyClause (FinallyClauseChildren{keyword,body} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "finally_clause")?;
      ss.serialize_field("finally_keyword", &self.with(keyword))?;
ss.serialize_field("finally_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::DoStatement (DoStatementChildren{keyword,body,while_keyword,left_paren,condition,right_paren,semicolon} ) => {
      let mut ss = s.serialize_struct("", 8)?;
      ss.serialize_field("kind", "do_statement")?;
      ss.serialize_field("do_keyword", &self.with(keyword))?;
ss.serialize_field("do_body", &self.with(body))?;
ss.serialize_field("do_while_keyword", &self.with(while_keyword))?;
ss.serialize_field("do_left_paren", &self.with(left_paren))?;
ss.serialize_field("do_condition", &self.with(condition))?;
ss.serialize_field("do_right_paren", &self.with(right_paren))?;
ss.serialize_field("do_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ForStatement (ForStatementChildren{keyword,left_paren,initializer,first_semicolon,control,second_semicolon,end_of_loop,right_paren,body} ) => {
      let mut ss = s.serialize_struct("", 10)?;
      ss.serialize_field("kind", "for_statement")?;
      ss.serialize_field("for_keyword", &self.with(keyword))?;
ss.serialize_field("for_left_paren", &self.with(left_paren))?;
ss.serialize_field("for_initializer", &self.with(initializer))?;
ss.serialize_field("for_first_semicolon", &self.with(first_semicolon))?;
ss.serialize_field("for_control", &self.with(control))?;
ss.serialize_field("for_second_semicolon", &self.with(second_semicolon))?;
ss.serialize_field("for_end_of_loop", &self.with(end_of_loop))?;
ss.serialize_field("for_right_paren", &self.with(right_paren))?;
ss.serialize_field("for_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::ForeachStatement (ForeachStatementChildren{keyword,left_paren,collection,await_keyword,as_,key,arrow,value,right_paren,body} ) => {
      let mut ss = s.serialize_struct("", 11)?;
      ss.serialize_field("kind", "foreach_statement")?;
      ss.serialize_field("foreach_keyword", &self.with(keyword))?;
ss.serialize_field("foreach_left_paren", &self.with(left_paren))?;
ss.serialize_field("foreach_collection", &self.with(collection))?;
ss.serialize_field("foreach_await_keyword", &self.with(await_keyword))?;
ss.serialize_field("foreach_as", &self.with(as_))?;
ss.serialize_field("foreach_key", &self.with(key))?;
ss.serialize_field("foreach_arrow", &self.with(arrow))?;
ss.serialize_field("foreach_value", &self.with(value))?;
ss.serialize_field("foreach_right_paren", &self.with(right_paren))?;
ss.serialize_field("foreach_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::SwitchStatement (SwitchStatementChildren{keyword,left_paren,expression,right_paren,left_brace,sections,right_brace} ) => {
      let mut ss = s.serialize_struct("", 8)?;
      ss.serialize_field("kind", "switch_statement")?;
      ss.serialize_field("switch_keyword", &self.with(keyword))?;
ss.serialize_field("switch_left_paren", &self.with(left_paren))?;
ss.serialize_field("switch_expression", &self.with(expression))?;
ss.serialize_field("switch_right_paren", &self.with(right_paren))?;
ss.serialize_field("switch_left_brace", &self.with(left_brace))?;
ss.serialize_field("switch_sections", &self.with(sections))?;
ss.serialize_field("switch_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::SwitchSection (SwitchSectionChildren{labels,statements,fallthrough} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "switch_section")?;
      ss.serialize_field("switch_section_labels", &self.with(labels))?;
ss.serialize_field("switch_section_statements", &self.with(statements))?;
ss.serialize_field("switch_section_fallthrough", &self.with(fallthrough))?;
      ss.end()
} 
SyntaxVariant::SwitchFallthrough (SwitchFallthroughChildren{keyword,semicolon} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "switch_fallthrough")?;
      ss.serialize_field("fallthrough_keyword", &self.with(keyword))?;
ss.serialize_field("fallthrough_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::CaseLabel (CaseLabelChildren{keyword,expression,colon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "case_label")?;
      ss.serialize_field("case_keyword", &self.with(keyword))?;
ss.serialize_field("case_expression", &self.with(expression))?;
ss.serialize_field("case_colon", &self.with(colon))?;
      ss.end()
} 
SyntaxVariant::DefaultLabel (DefaultLabelChildren{keyword,colon} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "default_label")?;
      ss.serialize_field("default_keyword", &self.with(keyword))?;
ss.serialize_field("default_colon", &self.with(colon))?;
      ss.end()
} 
SyntaxVariant::ReturnStatement (ReturnStatementChildren{keyword,expression,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "return_statement")?;
      ss.serialize_field("return_keyword", &self.with(keyword))?;
ss.serialize_field("return_expression", &self.with(expression))?;
ss.serialize_field("return_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::YieldBreakStatement (YieldBreakStatementChildren{keyword,break_,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "yield_break_statement")?;
      ss.serialize_field("yield_break_keyword", &self.with(keyword))?;
ss.serialize_field("yield_break_break", &self.with(break_))?;
ss.serialize_field("yield_break_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ThrowStatement (ThrowStatementChildren{keyword,expression,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "throw_statement")?;
      ss.serialize_field("throw_keyword", &self.with(keyword))?;
ss.serialize_field("throw_expression", &self.with(expression))?;
ss.serialize_field("throw_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::BreakStatement (BreakStatementChildren{keyword,semicolon} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "break_statement")?;
      ss.serialize_field("break_keyword", &self.with(keyword))?;
ss.serialize_field("break_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ContinueStatement (ContinueStatementChildren{keyword,semicolon} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "continue_statement")?;
      ss.serialize_field("continue_keyword", &self.with(keyword))?;
ss.serialize_field("continue_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::EchoStatement (EchoStatementChildren{keyword,expressions,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "echo_statement")?;
      ss.serialize_field("echo_keyword", &self.with(keyword))?;
ss.serialize_field("echo_expressions", &self.with(expressions))?;
ss.serialize_field("echo_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::ConcurrentStatement (ConcurrentStatementChildren{keyword,statement} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "concurrent_statement")?;
      ss.serialize_field("concurrent_keyword", &self.with(keyword))?;
ss.serialize_field("concurrent_statement", &self.with(statement))?;
      ss.end()
} 
SyntaxVariant::SimpleInitializer (SimpleInitializerChildren{equal,value} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "simple_initializer")?;
      ss.serialize_field("simple_initializer_equal", &self.with(equal))?;
ss.serialize_field("simple_initializer_value", &self.with(value))?;
      ss.end()
} 
SyntaxVariant::AnonymousClass (AnonymousClassChildren{class_keyword,left_paren,argument_list,right_paren,extends_keyword,extends_list,implements_keyword,implements_list,body} ) => {
      let mut ss = s.serialize_struct("", 10)?;
      ss.serialize_field("kind", "anonymous_class")?;
      ss.serialize_field("anonymous_class_class_keyword", &self.with(class_keyword))?;
ss.serialize_field("anonymous_class_left_paren", &self.with(left_paren))?;
ss.serialize_field("anonymous_class_argument_list", &self.with(argument_list))?;
ss.serialize_field("anonymous_class_right_paren", &self.with(right_paren))?;
ss.serialize_field("anonymous_class_extends_keyword", &self.with(extends_keyword))?;
ss.serialize_field("anonymous_class_extends_list", &self.with(extends_list))?;
ss.serialize_field("anonymous_class_implements_keyword", &self.with(implements_keyword))?;
ss.serialize_field("anonymous_class_implements_list", &self.with(implements_list))?;
ss.serialize_field("anonymous_class_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::AnonymousFunction (AnonymousFunctionChildren{attribute_spec,static_keyword,async_keyword,function_keyword,left_paren,parameters,right_paren,ctx_list,colon,readonly_return,type_,use_,body} ) => {
      let mut ss = s.serialize_struct("", 14)?;
      ss.serialize_field("kind", "anonymous_function")?;
      ss.serialize_field("anonymous_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("anonymous_static_keyword", &self.with(static_keyword))?;
ss.serialize_field("anonymous_async_keyword", &self.with(async_keyword))?;
ss.serialize_field("anonymous_function_keyword", &self.with(function_keyword))?;
ss.serialize_field("anonymous_left_paren", &self.with(left_paren))?;
ss.serialize_field("anonymous_parameters", &self.with(parameters))?;
ss.serialize_field("anonymous_right_paren", &self.with(right_paren))?;
ss.serialize_field("anonymous_ctx_list", &self.with(ctx_list))?;
ss.serialize_field("anonymous_colon", &self.with(colon))?;
ss.serialize_field("anonymous_readonly_return", &self.with(readonly_return))?;
ss.serialize_field("anonymous_type", &self.with(type_))?;
ss.serialize_field("anonymous_use", &self.with(use_))?;
ss.serialize_field("anonymous_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::AnonymousFunctionUseClause (AnonymousFunctionUseClauseChildren{keyword,left_paren,variables,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "anonymous_function_use_clause")?;
      ss.serialize_field("anonymous_use_keyword", &self.with(keyword))?;
ss.serialize_field("anonymous_use_left_paren", &self.with(left_paren))?;
ss.serialize_field("anonymous_use_variables", &self.with(variables))?;
ss.serialize_field("anonymous_use_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::LambdaExpression (LambdaExpressionChildren{attribute_spec,async_,signature,arrow,body} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "lambda_expression")?;
      ss.serialize_field("lambda_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("lambda_async", &self.with(async_))?;
ss.serialize_field("lambda_signature", &self.with(signature))?;
ss.serialize_field("lambda_arrow", &self.with(arrow))?;
ss.serialize_field("lambda_body", &self.with(body))?;
      ss.end()
} 
SyntaxVariant::LambdaSignature (LambdaSignatureChildren{left_paren,parameters,right_paren,contexts,colon,readonly_return,type_} ) => {
      let mut ss = s.serialize_struct("", 8)?;
      ss.serialize_field("kind", "lambda_signature")?;
      ss.serialize_field("lambda_left_paren", &self.with(left_paren))?;
ss.serialize_field("lambda_parameters", &self.with(parameters))?;
ss.serialize_field("lambda_right_paren", &self.with(right_paren))?;
ss.serialize_field("lambda_contexts", &self.with(contexts))?;
ss.serialize_field("lambda_colon", &self.with(colon))?;
ss.serialize_field("lambda_readonly_return", &self.with(readonly_return))?;
ss.serialize_field("lambda_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::CastExpression (CastExpressionChildren{left_paren,type_,right_paren,operand} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "cast_expression")?;
      ss.serialize_field("cast_left_paren", &self.with(left_paren))?;
ss.serialize_field("cast_type", &self.with(type_))?;
ss.serialize_field("cast_right_paren", &self.with(right_paren))?;
ss.serialize_field("cast_operand", &self.with(operand))?;
      ss.end()
} 
SyntaxVariant::ScopeResolutionExpression (ScopeResolutionExpressionChildren{qualifier,operator,name} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "scope_resolution_expression")?;
      ss.serialize_field("scope_resolution_qualifier", &self.with(qualifier))?;
ss.serialize_field("scope_resolution_operator", &self.with(operator))?;
ss.serialize_field("scope_resolution_name", &self.with(name))?;
      ss.end()
} 
SyntaxVariant::MemberSelectionExpression (MemberSelectionExpressionChildren{object,operator,name} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "member_selection_expression")?;
      ss.serialize_field("member_object", &self.with(object))?;
ss.serialize_field("member_operator", &self.with(operator))?;
ss.serialize_field("member_name", &self.with(name))?;
      ss.end()
} 
SyntaxVariant::SafeMemberSelectionExpression (SafeMemberSelectionExpressionChildren{object,operator,name} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "safe_member_selection_expression")?;
      ss.serialize_field("safe_member_object", &self.with(object))?;
ss.serialize_field("safe_member_operator", &self.with(operator))?;
ss.serialize_field("safe_member_name", &self.with(name))?;
      ss.end()
} 
SyntaxVariant::EmbeddedMemberSelectionExpression (EmbeddedMemberSelectionExpressionChildren{object,operator,name} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "embedded_member_selection_expression")?;
      ss.serialize_field("embedded_member_object", &self.with(object))?;
ss.serialize_field("embedded_member_operator", &self.with(operator))?;
ss.serialize_field("embedded_member_name", &self.with(name))?;
      ss.end()
} 
SyntaxVariant::YieldExpression (YieldExpressionChildren{keyword,operand} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "yield_expression")?;
      ss.serialize_field("yield_keyword", &self.with(keyword))?;
ss.serialize_field("yield_operand", &self.with(operand))?;
      ss.end()
} 
SyntaxVariant::PrefixUnaryExpression (PrefixUnaryExpressionChildren{operator,operand} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "prefix_unary_expression")?;
      ss.serialize_field("prefix_unary_operator", &self.with(operator))?;
ss.serialize_field("prefix_unary_operand", &self.with(operand))?;
      ss.end()
} 
SyntaxVariant::PostfixUnaryExpression (PostfixUnaryExpressionChildren{operand,operator} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "postfix_unary_expression")?;
      ss.serialize_field("postfix_unary_operand", &self.with(operand))?;
ss.serialize_field("postfix_unary_operator", &self.with(operator))?;
      ss.end()
} 
SyntaxVariant::BinaryExpression (BinaryExpressionChildren{left_operand,operator,right_operand} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "binary_expression")?;
      ss.serialize_field("binary_left_operand", &self.with(left_operand))?;
ss.serialize_field("binary_operator", &self.with(operator))?;
ss.serialize_field("binary_right_operand", &self.with(right_operand))?;
      ss.end()
} 
SyntaxVariant::IsExpression (IsExpressionChildren{left_operand,operator,right_operand} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "is_expression")?;
      ss.serialize_field("is_left_operand", &self.with(left_operand))?;
ss.serialize_field("is_operator", &self.with(operator))?;
ss.serialize_field("is_right_operand", &self.with(right_operand))?;
      ss.end()
} 
SyntaxVariant::AsExpression (AsExpressionChildren{left_operand,operator,right_operand} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "as_expression")?;
      ss.serialize_field("as_left_operand", &self.with(left_operand))?;
ss.serialize_field("as_operator", &self.with(operator))?;
ss.serialize_field("as_right_operand", &self.with(right_operand))?;
      ss.end()
} 
SyntaxVariant::NullableAsExpression (NullableAsExpressionChildren{left_operand,operator,right_operand} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "nullable_as_expression")?;
      ss.serialize_field("nullable_as_left_operand", &self.with(left_operand))?;
ss.serialize_field("nullable_as_operator", &self.with(operator))?;
ss.serialize_field("nullable_as_right_operand", &self.with(right_operand))?;
      ss.end()
} 
SyntaxVariant::ConditionalExpression (ConditionalExpressionChildren{test,question,consequence,colon,alternative} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "conditional_expression")?;
      ss.serialize_field("conditional_test", &self.with(test))?;
ss.serialize_field("conditional_question", &self.with(question))?;
ss.serialize_field("conditional_consequence", &self.with(consequence))?;
ss.serialize_field("conditional_colon", &self.with(colon))?;
ss.serialize_field("conditional_alternative", &self.with(alternative))?;
      ss.end()
} 
SyntaxVariant::EvalExpression (EvalExpressionChildren{keyword,left_paren,argument,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "eval_expression")?;
      ss.serialize_field("eval_keyword", &self.with(keyword))?;
ss.serialize_field("eval_left_paren", &self.with(left_paren))?;
ss.serialize_field("eval_argument", &self.with(argument))?;
ss.serialize_field("eval_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::DefineExpression (DefineExpressionChildren{keyword,left_paren,argument_list,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "define_expression")?;
      ss.serialize_field("define_keyword", &self.with(keyword))?;
ss.serialize_field("define_left_paren", &self.with(left_paren))?;
ss.serialize_field("define_argument_list", &self.with(argument_list))?;
ss.serialize_field("define_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::IssetExpression (IssetExpressionChildren{keyword,left_paren,argument_list,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "isset_expression")?;
      ss.serialize_field("isset_keyword", &self.with(keyword))?;
ss.serialize_field("isset_left_paren", &self.with(left_paren))?;
ss.serialize_field("isset_argument_list", &self.with(argument_list))?;
ss.serialize_field("isset_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::FunctionCallExpression (FunctionCallExpressionChildren{receiver,type_args,left_paren,argument_list,right_paren} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "function_call_expression")?;
      ss.serialize_field("function_call_receiver", &self.with(receiver))?;
ss.serialize_field("function_call_type_args", &self.with(type_args))?;
ss.serialize_field("function_call_left_paren", &self.with(left_paren))?;
ss.serialize_field("function_call_argument_list", &self.with(argument_list))?;
ss.serialize_field("function_call_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::FunctionPointerExpression (FunctionPointerExpressionChildren{receiver,type_args} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "function_pointer_expression")?;
      ss.serialize_field("function_pointer_receiver", &self.with(receiver))?;
ss.serialize_field("function_pointer_type_args", &self.with(type_args))?;
      ss.end()
} 
SyntaxVariant::ParenthesizedExpression (ParenthesizedExpressionChildren{left_paren,expression,right_paren} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "parenthesized_expression")?;
      ss.serialize_field("parenthesized_expression_left_paren", &self.with(left_paren))?;
ss.serialize_field("parenthesized_expression_expression", &self.with(expression))?;
ss.serialize_field("parenthesized_expression_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::BracedExpression (BracedExpressionChildren{left_brace,expression,right_brace} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "braced_expression")?;
      ss.serialize_field("braced_expression_left_brace", &self.with(left_brace))?;
ss.serialize_field("braced_expression_expression", &self.with(expression))?;
ss.serialize_field("braced_expression_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::ETSpliceExpression (ETSpliceExpressionChildren{dollar,left_brace,expression,right_brace} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "et_splice_expression")?;
      ss.serialize_field("et_splice_expression_dollar", &self.with(dollar))?;
ss.serialize_field("et_splice_expression_left_brace", &self.with(left_brace))?;
ss.serialize_field("et_splice_expression_expression", &self.with(expression))?;
ss.serialize_field("et_splice_expression_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::EmbeddedBracedExpression (EmbeddedBracedExpressionChildren{left_brace,expression,right_brace} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "embedded_braced_expression")?;
      ss.serialize_field("embedded_braced_expression_left_brace", &self.with(left_brace))?;
ss.serialize_field("embedded_braced_expression_expression", &self.with(expression))?;
ss.serialize_field("embedded_braced_expression_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::ListExpression (ListExpressionChildren{keyword,left_paren,members,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "list_expression")?;
      ss.serialize_field("list_keyword", &self.with(keyword))?;
ss.serialize_field("list_left_paren", &self.with(left_paren))?;
ss.serialize_field("list_members", &self.with(members))?;
ss.serialize_field("list_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::CollectionLiteralExpression (CollectionLiteralExpressionChildren{name,left_brace,initializers,right_brace} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "collection_literal_expression")?;
      ss.serialize_field("collection_literal_name", &self.with(name))?;
ss.serialize_field("collection_literal_left_brace", &self.with(left_brace))?;
ss.serialize_field("collection_literal_initializers", &self.with(initializers))?;
ss.serialize_field("collection_literal_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::ObjectCreationExpression (ObjectCreationExpressionChildren{new_keyword,object} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "object_creation_expression")?;
      ss.serialize_field("object_creation_new_keyword", &self.with(new_keyword))?;
ss.serialize_field("object_creation_object", &self.with(object))?;
      ss.end()
} 
SyntaxVariant::ConstructorCall (ConstructorCallChildren{type_,left_paren,argument_list,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "constructor_call")?;
      ss.serialize_field("constructor_call_type", &self.with(type_))?;
ss.serialize_field("constructor_call_left_paren", &self.with(left_paren))?;
ss.serialize_field("constructor_call_argument_list", &self.with(argument_list))?;
ss.serialize_field("constructor_call_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::RecordCreationExpression (RecordCreationExpressionChildren{type_,left_bracket,members,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "record_creation_expression")?;
      ss.serialize_field("record_creation_type", &self.with(type_))?;
ss.serialize_field("record_creation_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("record_creation_members", &self.with(members))?;
ss.serialize_field("record_creation_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::DarrayIntrinsicExpression (DarrayIntrinsicExpressionChildren{keyword,explicit_type,left_bracket,members,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "darray_intrinsic_expression")?;
      ss.serialize_field("darray_intrinsic_keyword", &self.with(keyword))?;
ss.serialize_field("darray_intrinsic_explicit_type", &self.with(explicit_type))?;
ss.serialize_field("darray_intrinsic_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("darray_intrinsic_members", &self.with(members))?;
ss.serialize_field("darray_intrinsic_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::DictionaryIntrinsicExpression (DictionaryIntrinsicExpressionChildren{keyword,explicit_type,left_bracket,members,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "dictionary_intrinsic_expression")?;
      ss.serialize_field("dictionary_intrinsic_keyword", &self.with(keyword))?;
ss.serialize_field("dictionary_intrinsic_explicit_type", &self.with(explicit_type))?;
ss.serialize_field("dictionary_intrinsic_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("dictionary_intrinsic_members", &self.with(members))?;
ss.serialize_field("dictionary_intrinsic_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::KeysetIntrinsicExpression (KeysetIntrinsicExpressionChildren{keyword,explicit_type,left_bracket,members,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "keyset_intrinsic_expression")?;
      ss.serialize_field("keyset_intrinsic_keyword", &self.with(keyword))?;
ss.serialize_field("keyset_intrinsic_explicit_type", &self.with(explicit_type))?;
ss.serialize_field("keyset_intrinsic_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("keyset_intrinsic_members", &self.with(members))?;
ss.serialize_field("keyset_intrinsic_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::VarrayIntrinsicExpression (VarrayIntrinsicExpressionChildren{keyword,explicit_type,left_bracket,members,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "varray_intrinsic_expression")?;
      ss.serialize_field("varray_intrinsic_keyword", &self.with(keyword))?;
ss.serialize_field("varray_intrinsic_explicit_type", &self.with(explicit_type))?;
ss.serialize_field("varray_intrinsic_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("varray_intrinsic_members", &self.with(members))?;
ss.serialize_field("varray_intrinsic_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::VectorIntrinsicExpression (VectorIntrinsicExpressionChildren{keyword,explicit_type,left_bracket,members,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "vector_intrinsic_expression")?;
      ss.serialize_field("vector_intrinsic_keyword", &self.with(keyword))?;
ss.serialize_field("vector_intrinsic_explicit_type", &self.with(explicit_type))?;
ss.serialize_field("vector_intrinsic_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("vector_intrinsic_members", &self.with(members))?;
ss.serialize_field("vector_intrinsic_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::ElementInitializer (ElementInitializerChildren{key,arrow,value} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "element_initializer")?;
      ss.serialize_field("element_key", &self.with(key))?;
ss.serialize_field("element_arrow", &self.with(arrow))?;
ss.serialize_field("element_value", &self.with(value))?;
      ss.end()
} 
SyntaxVariant::SubscriptExpression (SubscriptExpressionChildren{receiver,left_bracket,index,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "subscript_expression")?;
      ss.serialize_field("subscript_receiver", &self.with(receiver))?;
ss.serialize_field("subscript_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("subscript_index", &self.with(index))?;
ss.serialize_field("subscript_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::EmbeddedSubscriptExpression (EmbeddedSubscriptExpressionChildren{receiver,left_bracket,index,right_bracket} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "embedded_subscript_expression")?;
      ss.serialize_field("embedded_subscript_receiver", &self.with(receiver))?;
ss.serialize_field("embedded_subscript_left_bracket", &self.with(left_bracket))?;
ss.serialize_field("embedded_subscript_index", &self.with(index))?;
ss.serialize_field("embedded_subscript_right_bracket", &self.with(right_bracket))?;
      ss.end()
} 
SyntaxVariant::AwaitableCreationExpression (AwaitableCreationExpressionChildren{attribute_spec,async_,compound_statement} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "awaitable_creation_expression")?;
      ss.serialize_field("awaitable_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("awaitable_async", &self.with(async_))?;
ss.serialize_field("awaitable_compound_statement", &self.with(compound_statement))?;
      ss.end()
} 
SyntaxVariant::XHPChildrenDeclaration (XHPChildrenDeclarationChildren{keyword,expression,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "xhp_children_declaration")?;
      ss.serialize_field("xhp_children_keyword", &self.with(keyword))?;
ss.serialize_field("xhp_children_expression", &self.with(expression))?;
ss.serialize_field("xhp_children_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::XHPChildrenParenthesizedList (XHPChildrenParenthesizedListChildren{left_paren,xhp_children,right_paren} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "xhp_children_parenthesized_list")?;
      ss.serialize_field("xhp_children_list_left_paren", &self.with(left_paren))?;
ss.serialize_field("xhp_children_list_xhp_children", &self.with(xhp_children))?;
ss.serialize_field("xhp_children_list_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::XHPCategoryDeclaration (XHPCategoryDeclarationChildren{keyword,categories,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "xhp_category_declaration")?;
      ss.serialize_field("xhp_category_keyword", &self.with(keyword))?;
ss.serialize_field("xhp_category_categories", &self.with(categories))?;
ss.serialize_field("xhp_category_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::XHPEnumType (XHPEnumTypeChildren{keyword,left_brace,values,right_brace} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "xhp_enum_type")?;
      ss.serialize_field("xhp_enum_keyword", &self.with(keyword))?;
ss.serialize_field("xhp_enum_left_brace", &self.with(left_brace))?;
ss.serialize_field("xhp_enum_values", &self.with(values))?;
ss.serialize_field("xhp_enum_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::XHPLateinit (XHPLateinitChildren{at,keyword} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "xhp_lateinit")?;
      ss.serialize_field("xhp_lateinit_at", &self.with(at))?;
ss.serialize_field("xhp_lateinit_keyword", &self.with(keyword))?;
      ss.end()
} 
SyntaxVariant::XHPRequired (XHPRequiredChildren{at,keyword} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "xhp_required")?;
      ss.serialize_field("xhp_required_at", &self.with(at))?;
ss.serialize_field("xhp_required_keyword", &self.with(keyword))?;
      ss.end()
} 
SyntaxVariant::XHPClassAttributeDeclaration (XHPClassAttributeDeclarationChildren{keyword,attributes,semicolon} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "xhp_class_attribute_declaration")?;
      ss.serialize_field("xhp_attribute_keyword", &self.with(keyword))?;
ss.serialize_field("xhp_attribute_attributes", &self.with(attributes))?;
ss.serialize_field("xhp_attribute_semicolon", &self.with(semicolon))?;
      ss.end()
} 
SyntaxVariant::XHPClassAttribute (XHPClassAttributeChildren{type_,name,initializer,required} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "xhp_class_attribute")?;
      ss.serialize_field("xhp_attribute_decl_type", &self.with(type_))?;
ss.serialize_field("xhp_attribute_decl_name", &self.with(name))?;
ss.serialize_field("xhp_attribute_decl_initializer", &self.with(initializer))?;
ss.serialize_field("xhp_attribute_decl_required", &self.with(required))?;
      ss.end()
} 
SyntaxVariant::XHPSimpleClassAttribute (XHPSimpleClassAttributeChildren{type_} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "xhp_simple_class_attribute")?;
      ss.serialize_field("xhp_simple_class_attribute_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::XHPSimpleAttribute (XHPSimpleAttributeChildren{name,equal,expression} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "xhp_simple_attribute")?;
      ss.serialize_field("xhp_simple_attribute_name", &self.with(name))?;
ss.serialize_field("xhp_simple_attribute_equal", &self.with(equal))?;
ss.serialize_field("xhp_simple_attribute_expression", &self.with(expression))?;
      ss.end()
} 
SyntaxVariant::XHPSpreadAttribute (XHPSpreadAttributeChildren{left_brace,spread_operator,expression,right_brace} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "xhp_spread_attribute")?;
      ss.serialize_field("xhp_spread_attribute_left_brace", &self.with(left_brace))?;
ss.serialize_field("xhp_spread_attribute_spread_operator", &self.with(spread_operator))?;
ss.serialize_field("xhp_spread_attribute_expression", &self.with(expression))?;
ss.serialize_field("xhp_spread_attribute_right_brace", &self.with(right_brace))?;
      ss.end()
} 
SyntaxVariant::XHPOpen (XHPOpenChildren{left_angle,name,attributes,right_angle} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "xhp_open")?;
      ss.serialize_field("xhp_open_left_angle", &self.with(left_angle))?;
ss.serialize_field("xhp_open_name", &self.with(name))?;
ss.serialize_field("xhp_open_attributes", &self.with(attributes))?;
ss.serialize_field("xhp_open_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::XHPExpression (XHPExpressionChildren{open,body,close} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "xhp_expression")?;
      ss.serialize_field("xhp_open", &self.with(open))?;
ss.serialize_field("xhp_body", &self.with(body))?;
ss.serialize_field("xhp_close", &self.with(close))?;
      ss.end()
} 
SyntaxVariant::XHPClose (XHPCloseChildren{left_angle,name,right_angle} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "xhp_close")?;
      ss.serialize_field("xhp_close_left_angle", &self.with(left_angle))?;
ss.serialize_field("xhp_close_name", &self.with(name))?;
ss.serialize_field("xhp_close_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::TypeConstant (TypeConstantChildren{left_type,separator,right_type} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "type_constant")?;
      ss.serialize_field("type_constant_left_type", &self.with(left_type))?;
ss.serialize_field("type_constant_separator", &self.with(separator))?;
ss.serialize_field("type_constant_right_type", &self.with(right_type))?;
      ss.end()
} 
SyntaxVariant::VectorTypeSpecifier (VectorTypeSpecifierChildren{keyword,left_angle,type_,trailing_comma,right_angle} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "vector_type_specifier")?;
      ss.serialize_field("vector_type_keyword", &self.with(keyword))?;
ss.serialize_field("vector_type_left_angle", &self.with(left_angle))?;
ss.serialize_field("vector_type_type", &self.with(type_))?;
ss.serialize_field("vector_type_trailing_comma", &self.with(trailing_comma))?;
ss.serialize_field("vector_type_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::KeysetTypeSpecifier (KeysetTypeSpecifierChildren{keyword,left_angle,type_,trailing_comma,right_angle} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "keyset_type_specifier")?;
      ss.serialize_field("keyset_type_keyword", &self.with(keyword))?;
ss.serialize_field("keyset_type_left_angle", &self.with(left_angle))?;
ss.serialize_field("keyset_type_type", &self.with(type_))?;
ss.serialize_field("keyset_type_trailing_comma", &self.with(trailing_comma))?;
ss.serialize_field("keyset_type_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::TupleTypeExplicitSpecifier (TupleTypeExplicitSpecifierChildren{keyword,left_angle,types,right_angle} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "tuple_type_explicit_specifier")?;
      ss.serialize_field("tuple_type_keyword", &self.with(keyword))?;
ss.serialize_field("tuple_type_left_angle", &self.with(left_angle))?;
ss.serialize_field("tuple_type_types", &self.with(types))?;
ss.serialize_field("tuple_type_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::VarrayTypeSpecifier (VarrayTypeSpecifierChildren{keyword,left_angle,type_,trailing_comma,right_angle} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "varray_type_specifier")?;
      ss.serialize_field("varray_keyword", &self.with(keyword))?;
ss.serialize_field("varray_left_angle", &self.with(left_angle))?;
ss.serialize_field("varray_type", &self.with(type_))?;
ss.serialize_field("varray_trailing_comma", &self.with(trailing_comma))?;
ss.serialize_field("varray_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::FunctionCtxTypeSpecifier (FunctionCtxTypeSpecifierChildren{keyword,variable} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "function_ctx_type_specifier")?;
      ss.serialize_field("function_ctx_type_keyword", &self.with(keyword))?;
ss.serialize_field("function_ctx_type_variable", &self.with(variable))?;
      ss.end()
} 
SyntaxVariant::TypeParameter (TypeParameterChildren{attribute_spec,reified,variance,name,param_params,constraints} ) => {
      let mut ss = s.serialize_struct("", 7)?;
      ss.serialize_field("kind", "type_parameter")?;
      ss.serialize_field("type_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("type_reified", &self.with(reified))?;
ss.serialize_field("type_variance", &self.with(variance))?;
ss.serialize_field("type_name", &self.with(name))?;
ss.serialize_field("type_param_params", &self.with(param_params))?;
ss.serialize_field("type_constraints", &self.with(constraints))?;
      ss.end()
} 
SyntaxVariant::TypeConstraint (TypeConstraintChildren{keyword,type_} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "type_constraint")?;
      ss.serialize_field("constraint_keyword", &self.with(keyword))?;
ss.serialize_field("constraint_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::ContextConstraint (ContextConstraintChildren{keyword,ctx_list} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "context_constraint")?;
      ss.serialize_field("ctx_constraint_keyword", &self.with(keyword))?;
ss.serialize_field("ctx_constraint_ctx_list", &self.with(ctx_list))?;
      ss.end()
} 
SyntaxVariant::DarrayTypeSpecifier (DarrayTypeSpecifierChildren{keyword,left_angle,key,comma,value,trailing_comma,right_angle} ) => {
      let mut ss = s.serialize_struct("", 8)?;
      ss.serialize_field("kind", "darray_type_specifier")?;
      ss.serialize_field("darray_keyword", &self.with(keyword))?;
ss.serialize_field("darray_left_angle", &self.with(left_angle))?;
ss.serialize_field("darray_key", &self.with(key))?;
ss.serialize_field("darray_comma", &self.with(comma))?;
ss.serialize_field("darray_value", &self.with(value))?;
ss.serialize_field("darray_trailing_comma", &self.with(trailing_comma))?;
ss.serialize_field("darray_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::DictionaryTypeSpecifier (DictionaryTypeSpecifierChildren{keyword,left_angle,members,right_angle} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "dictionary_type_specifier")?;
      ss.serialize_field("dictionary_type_keyword", &self.with(keyword))?;
ss.serialize_field("dictionary_type_left_angle", &self.with(left_angle))?;
ss.serialize_field("dictionary_type_members", &self.with(members))?;
ss.serialize_field("dictionary_type_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::ClosureTypeSpecifier (ClosureTypeSpecifierChildren{outer_left_paren,function_keyword,inner_left_paren,parameter_list,inner_right_paren,contexts,colon,return_type,outer_right_paren} ) => {
      let mut ss = s.serialize_struct("", 10)?;
      ss.serialize_field("kind", "closure_type_specifier")?;
      ss.serialize_field("closure_outer_left_paren", &self.with(outer_left_paren))?;
ss.serialize_field("closure_function_keyword", &self.with(function_keyword))?;
ss.serialize_field("closure_inner_left_paren", &self.with(inner_left_paren))?;
ss.serialize_field("closure_parameter_list", &self.with(parameter_list))?;
ss.serialize_field("closure_inner_right_paren", &self.with(inner_right_paren))?;
ss.serialize_field("closure_contexts", &self.with(contexts))?;
ss.serialize_field("closure_colon", &self.with(colon))?;
ss.serialize_field("closure_return_type", &self.with(return_type))?;
ss.serialize_field("closure_outer_right_paren", &self.with(outer_right_paren))?;
      ss.end()
} 
SyntaxVariant::ClosureParameterTypeSpecifier (ClosureParameterTypeSpecifierChildren{call_convention,type_} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "closure_parameter_type_specifier")?;
      ss.serialize_field("closure_parameter_call_convention", &self.with(call_convention))?;
ss.serialize_field("closure_parameter_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::ClassnameTypeSpecifier (ClassnameTypeSpecifierChildren{keyword,left_angle,type_,trailing_comma,right_angle} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "classname_type_specifier")?;
      ss.serialize_field("classname_keyword", &self.with(keyword))?;
ss.serialize_field("classname_left_angle", &self.with(left_angle))?;
ss.serialize_field("classname_type", &self.with(type_))?;
ss.serialize_field("classname_trailing_comma", &self.with(trailing_comma))?;
ss.serialize_field("classname_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::FieldSpecifier (FieldSpecifierChildren{question,name,arrow,type_} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "field_specifier")?;
      ss.serialize_field("field_question", &self.with(question))?;
ss.serialize_field("field_name", &self.with(name))?;
ss.serialize_field("field_arrow", &self.with(arrow))?;
ss.serialize_field("field_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::FieldInitializer (FieldInitializerChildren{name,arrow,value} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "field_initializer")?;
      ss.serialize_field("field_initializer_name", &self.with(name))?;
ss.serialize_field("field_initializer_arrow", &self.with(arrow))?;
ss.serialize_field("field_initializer_value", &self.with(value))?;
      ss.end()
} 
SyntaxVariant::ShapeTypeSpecifier (ShapeTypeSpecifierChildren{keyword,left_paren,fields,ellipsis,right_paren} ) => {
      let mut ss = s.serialize_struct("", 6)?;
      ss.serialize_field("kind", "shape_type_specifier")?;
      ss.serialize_field("shape_type_keyword", &self.with(keyword))?;
ss.serialize_field("shape_type_left_paren", &self.with(left_paren))?;
ss.serialize_field("shape_type_fields", &self.with(fields))?;
ss.serialize_field("shape_type_ellipsis", &self.with(ellipsis))?;
ss.serialize_field("shape_type_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::ShapeExpression (ShapeExpressionChildren{keyword,left_paren,fields,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "shape_expression")?;
      ss.serialize_field("shape_expression_keyword", &self.with(keyword))?;
ss.serialize_field("shape_expression_left_paren", &self.with(left_paren))?;
ss.serialize_field("shape_expression_fields", &self.with(fields))?;
ss.serialize_field("shape_expression_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::TupleExpression (TupleExpressionChildren{keyword,left_paren,items,right_paren} ) => {
      let mut ss = s.serialize_struct("", 5)?;
      ss.serialize_field("kind", "tuple_expression")?;
      ss.serialize_field("tuple_expression_keyword", &self.with(keyword))?;
ss.serialize_field("tuple_expression_left_paren", &self.with(left_paren))?;
ss.serialize_field("tuple_expression_items", &self.with(items))?;
ss.serialize_field("tuple_expression_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::GenericTypeSpecifier (GenericTypeSpecifierChildren{class_type,argument_list} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "generic_type_specifier")?;
      ss.serialize_field("generic_class_type", &self.with(class_type))?;
ss.serialize_field("generic_argument_list", &self.with(argument_list))?;
      ss.end()
} 
SyntaxVariant::NullableTypeSpecifier (NullableTypeSpecifierChildren{question,type_} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "nullable_type_specifier")?;
      ss.serialize_field("nullable_question", &self.with(question))?;
ss.serialize_field("nullable_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::LikeTypeSpecifier (LikeTypeSpecifierChildren{tilde,type_} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "like_type_specifier")?;
      ss.serialize_field("like_tilde", &self.with(tilde))?;
ss.serialize_field("like_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::SoftTypeSpecifier (SoftTypeSpecifierChildren{at,type_} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "soft_type_specifier")?;
      ss.serialize_field("soft_at", &self.with(at))?;
ss.serialize_field("soft_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::AttributizedSpecifier (AttributizedSpecifierChildren{attribute_spec,type_} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "attributized_specifier")?;
      ss.serialize_field("attributized_specifier_attribute_spec", &self.with(attribute_spec))?;
ss.serialize_field("attributized_specifier_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::ReifiedTypeArgument (ReifiedTypeArgumentChildren{reified,type_} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "reified_type_argument")?;
      ss.serialize_field("reified_type_argument_reified", &self.with(reified))?;
ss.serialize_field("reified_type_argument_type", &self.with(type_))?;
      ss.end()
} 
SyntaxVariant::TypeArguments (TypeArgumentsChildren{left_angle,types,right_angle} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "type_arguments")?;
      ss.serialize_field("type_arguments_left_angle", &self.with(left_angle))?;
ss.serialize_field("type_arguments_types", &self.with(types))?;
ss.serialize_field("type_arguments_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::TypeParameters (TypeParametersChildren{left_angle,parameters,right_angle} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "type_parameters")?;
      ss.serialize_field("type_parameters_left_angle", &self.with(left_angle))?;
ss.serialize_field("type_parameters_parameters", &self.with(parameters))?;
ss.serialize_field("type_parameters_right_angle", &self.with(right_angle))?;
      ss.end()
} 
SyntaxVariant::TupleTypeSpecifier (TupleTypeSpecifierChildren{left_paren,types,right_paren} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "tuple_type_specifier")?;
      ss.serialize_field("tuple_left_paren", &self.with(left_paren))?;
ss.serialize_field("tuple_types", &self.with(types))?;
ss.serialize_field("tuple_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::UnionTypeSpecifier (UnionTypeSpecifierChildren{left_paren,types,right_paren} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "union_type_specifier")?;
      ss.serialize_field("union_left_paren", &self.with(left_paren))?;
ss.serialize_field("union_types", &self.with(types))?;
ss.serialize_field("union_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::IntersectionTypeSpecifier (IntersectionTypeSpecifierChildren{left_paren,types,right_paren} ) => {
      let mut ss = s.serialize_struct("", 4)?;
      ss.serialize_field("kind", "intersection_type_specifier")?;
      ss.serialize_field("intersection_left_paren", &self.with(left_paren))?;
ss.serialize_field("intersection_types", &self.with(types))?;
ss.serialize_field("intersection_right_paren", &self.with(right_paren))?;
      ss.end()
} 
SyntaxVariant::ErrorSyntax (ErrorSyntaxChildren{error} ) => {
      let mut ss = s.serialize_struct("", 2)?;
      ss.serialize_field("kind", "error")?;
      ss.serialize_field("error_error", &self.with(error))?;
      ss.end()
} 
SyntaxVariant::ListItem (ListItemChildren{item,separator} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "list_item")?;
      ss.serialize_field("list_item", &self.with(item))?;
ss.serialize_field("list_separator", &self.with(separator))?;
      ss.end()
} 
SyntaxVariant::EnumAtomExpression (EnumAtomExpressionChildren{hash,expression} ) => {
      let mut ss = s.serialize_struct("", 3)?;
      ss.serialize_field("kind", "enum_atom")?;
      ss.serialize_field("enum_atom_hash", &self.with(hash))?;
ss.serialize_field("enum_atom_expression", &self.with(expression))?;
      ss.end()
} 
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::positioned_trivia::PositionedTrivia;
use crate::compact_trivia::CompactTrivia;

pub type PositionedValue<'a> = internal::PositionedValue<'a, CompactTrivia>;
pub type PositionedValueFullTrivia<'a> = internal::PositionedValue<'a, PositionedTrivia<'a>>;

mod internal {
    use crate::{
        lexable_token::LexableToken,
        lexable_trivia::LexableTrivia,
        syntax::{SyntaxValueType, SyntaxValueWithKind},
        syntax_by_ref::positioned_token::internal::PositionedToken,
        syntax_kind::SyntaxKind,
        token_kind::TokenKind,
    };
    use std::matches;

    #[derive(Debug, Clone)]
    pub enum PositionedValue<'a, Trivia> {
        /// value for a token node is token itself
        TokenValue(PositionedToken<'a, Trivia>),
        /// value for a range denoted by pair of tokens
        TokenSpan(PositionedToken<'a, Trivia>, PositionedToken<'a, Trivia>),
        Missing {
            offset: usize,
        },
    }

    impl<'a, Trivia> PositionedValue<'a, Trivia>
    where
        Trivia: LexableTrivia + Clone,
    {
        pub fn width(&self) -> usize {
            match self {
                PositionedValue::TokenValue(t) => t.width(),
                PositionedValue::TokenSpan(left, right) => {
                    (right.end_offset() - left.start_offset()) + 1
                }
                PositionedValue::Missing { .. } => 0,
            }
        }

        pub fn start_offset(&self) -> usize {
            use PositionedValue::*;
            match &self {
                TokenValue(t) => t
                    .leading_start_offset()
                    .expect("invariant violation for Positioned Syntax"),
                TokenSpan(left, _) => left
                    .leading_start_offset()
                    .expect("invariant violation for Positioned Syntax"),
                Missing { offset, .. } => *offset,
            }
        }

        pub fn leading_width(&self) -> usize {
            use PositionedValue::*;
            match self {
                TokenValue(t) => t.leading_width(),
                TokenSpan(left, _) => left.leading_width(),
                Missing { .. } => 0,
            }
        }

        pub fn trailing_width(&self) -> usize {
            use PositionedValue::*;
            match self {
                TokenValue(t) => t.trailing_width(),
                TokenSpan(_, right) => right.trailing_width(),
                Missing { .. } => 0,
            }
        }

        pub fn leading_token(&self) -> Option<PositionedToken<'a, Trivia>> {
            use PositionedValue::*;
            match self {
                TokenValue(l) => Some(l.clone()),
                TokenSpan(left, _) => Some(left.clone()),
                _ => None,
            }
        }

        pub fn trailing_token(&self) -> Option<PositionedToken<'a, Trivia>> {
            use PositionedValue::*;
            match self {
                TokenValue(r) => Some(r.clone()),
                TokenSpan(_, right) => Some(right.clone()),
                _ => None,
            }
        }

        fn value_from_outer_children(first: &Self, last: &Self) -> Self {
            use PositionedValue::*;
            match (first, last) {
                (TokenValue(_), TokenValue(_))
                | (TokenSpan(_, _), TokenValue(_))
                | (TokenValue(_), TokenSpan(_, _))
                | (TokenSpan(_, _), TokenSpan(_, _)) => {
                    let l = first.leading_token().unwrap();
                    let r = last.trailing_token().unwrap();
                    if PositionedToken::inner_ptr_eq(&l, &r) {
                        TokenValue(l)
                    } else {
                        TokenSpan(l, r)
                    }
                }
                // can have two missing nodes if first and last child nodes of
                // the node are missing - this means that entire node is missing.
                // NOTE: offset must match otherwise it will mean that there is a real node
                // in between that should be picked instead
                (Missing { offset: o1 }, Missing { offset: o2 }) if o1 == o2 => first.clone(),
                _ => panic!(),
            }
        }
    }

    impl<'a, Trivia: 'a> SyntaxValueType<PositionedToken<'a, Trivia>> for PositionedValue<'a, Trivia>
    where
        Trivia: LexableTrivia + Clone,
    {
        fn from_values<'b>(child_values: impl Iterator<Item = &'b Self>) -> Self
        where
            'a: 'b,
        {
            use PositionedValue::*;
            let mut first = None;
            let mut first_non_zero = None;
            let mut last_non_zero = None;
            let mut last = None;
            for value in child_values {
                match (first.is_some(), first_non_zero.is_some(), value) {
                    (false, false, TokenValue { .. }) | (false, false, TokenSpan { .. }) => {
                        // first iteration and first node has some token representation -
                        // record it as first, first_non_zero, last and last_non_zero
                        first = Some(value);
                        first_non_zero = Some(value);
                        last_non_zero = Some(value);
                        last = Some(value);
                    }
                    (false, false, Missing { .. }) => {
                        // first iteration - first node is missing -
                        // record it as first and last
                        first = Some(value);
                        first_non_zero = None;
                        last_non_zero = None;
                        last = Some(value);
                    }
                    (true, false, TokenValue { .. }) | (true, false, TokenSpan { .. }) => {
                        // in progress, found first node that include tokens -
                        // record it as first_non_zero, last and last_non_zero
                        first_non_zero = Some(value);
                        last_non_zero = Some(value);
                        last = Some(value);
                    }
                    (true, true, TokenValue { .. }) | (true, true, TokenSpan { .. }) => {
                        // in progress found some node that includes tokens -
                        // record it as last_non_zero and last
                        last_non_zero = Some(value);
                        last = Some(value);
                    }
                    _ => {
                        // in progress, stepped on missing node -
                        // record it as last and move on
                        last = Some(value);
                    }
                }
            }
            match (first, first_non_zero, last_non_zero, last) {
                (_, Some(first_non_zero), Some(last_non_zero), _) => {
                    Self::value_from_outer_children(first_non_zero, last_non_zero)
                }
                (Some(first), None, None, Some(last)) => {
                    Self::value_from_outer_children(first, last)
                }
                _ => panic!("how did we get a node with no children in value_from_syntax?"),
            }
        }

        fn from_token(token: PositionedToken<'a, Trivia>) -> Self {
            if token.kind() == TokenKind::EndOfFile || token.full_width() == 0 {
                PositionedValue::Missing {
                    offset: token.end_offset(),
                }
            } else {
                PositionedValue::TokenValue(token)
            }
        }

        fn from_children<'b>(
            _: SyntaxKind,
            offset: usize,
            nodes: impl Iterator<Item = &'b Self>,
        ) -> Self
        where
            'a: 'b,
        {
            // We need to determine the offset, leading, middle and trailing widths of
            // the node to be constructed based on its children.  If the children are
            // all of zero width -- including the case where there are no children at
            // all -- then we make a zero-width value at the given offset.
            // Otherwise, we can determine the associated value from the first and last
            // children that have width.
            let mut have_width = nodes.filter(|x| x.width() > 0).peekable();
            match have_width.peek() {
                None => PositionedValue::Missing { offset },
                Some(first) => Self::value_from_outer_children(first, have_width.last().unwrap()),
            }
        }
    }

    impl<'a, Trivia: std::fmt::Debug> SyntaxValueWithKind for PositionedValue<'a, Trivia>
    where
        Trivia: LexableTrivia + Clone,
    {
        fn is_missing(&self) -> bool {
            matches!(self, PositionedValue::Missing { .. })
        }

        fn token_kind(&self) -> Option<TokenKind> {
            match self {
                PositionedValue::TokenValue(pt) => Some(pt.kind()),
                _ => None,
            }
        }
/**
 * Copyright (c) 2016, Facebook, Inc.
 * All rights reserved.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the "hack" directory of this source tree. An additional
 * directory.
 *
 **
 *
 * THIS FILE IS @generated; DO NOT EDIT IT
 * To regenerate this file, run
 *
 *   buck run //hphp/hack/src:generate_full_fidelity
 *
 **
 *
 */
use super::{
    syntax::Syntax,
    syntax_children_iterator::SyntaxChildrenIterator,
};

#[derive(Debug, Clone)]
pub enum SyntaxVariant<'a, T, V> {
    Token(T),
    Missing,
    SyntaxList(&'a [Syntax<'a, T, V>]),
    EndOfFile(&'a EndOfFileChildren<'a, T, V>),
    Script(&'a ScriptChildren<'a, T, V>),
    QualifiedName(&'a QualifiedNameChildren<'a, T, V>),
    SimpleTypeSpecifier(&'a SimpleTypeSpecifierChildren<'a, T, V>),
    LiteralExpression(&'a LiteralExpressionChildren<'a, T, V>),
    PrefixedStringExpression(&'a PrefixedStringExpressionChildren<'a, T, V>),
    PrefixedCodeExpression(&'a PrefixedCodeExpressionChildren<'a, T, V>),
    VariableExpression(&'a VariableExpressionChildren<'a, T, V>),
    PipeVariableExpression(&'a PipeVariableExpressionChildren<'a, T, V>),
    FileAttributeSpecification(&'a FileAttributeSpecificationChildren<'a, T, V>),
    EnumDeclaration(&'a EnumDeclarationChildren<'a, T, V>),
    EnumUse(&'a EnumUseChildren<'a, T, V>),
    Enumerator(&'a EnumeratorChildren<'a, T, V>),
    EnumClassDeclaration(&'a EnumClassDeclarationChildren<'a, T, V>),
    EnumClassEnumerator(&'a EnumClassEnumeratorChildren<'a, T, V>),
    RecordDeclaration(&'a RecordDeclarationChildren<'a, T, V>),
    RecordField(&'a RecordFieldChildren<'a, T, V>),
    AliasDeclaration(&'a AliasDeclarationChildren<'a, T, V>),
    PropertyDeclaration(&'a PropertyDeclarationChildren<'a, T, V>),
    PropertyDeclarator(&'a PropertyDeclaratorChildren<'a, T, V>),
    NamespaceDeclaration(&'a NamespaceDeclarationChildren<'a, T, V>),
    NamespaceDeclarationHeader(&'a NamespaceDeclarationHeaderChildren<'a, T, V>),
    NamespaceBody(&'a NamespaceBodyChildren<'a, T, V>),
    NamespaceEmptyBody(&'a NamespaceEmptyBodyChildren<'a, T, V>),
    NamespaceUseDeclaration(&'a NamespaceUseDeclarationChildren<'a, T, V>),
    NamespaceGroupUseDeclaration(&'a NamespaceGroupUseDeclarationChildren<'a, T, V>),
    NamespaceUseClause(&'a NamespaceUseClauseChildren<'a, T, V>),
    FunctionDeclaration(&'a FunctionDeclarationChildren<'a, T, V>),
    FunctionDeclarationHeader(&'a FunctionDeclarationHeaderChildren<'a, T, V>),
    Contexts(&'a ContextsChildren<'a, T, V>),
    WhereClause(&'a WhereClauseChildren<'a, T, V>),
    WhereConstraint(&'a WhereConstraintChildren<'a, T, V>),
    MethodishDeclaration(&'a MethodishDeclarationChildren<'a, T, V>),
    MethodishTraitResolution(&'a MethodishTraitResolutionChildren<'a, T, V>),
    ClassishDeclaration(&'a ClassishDeclarationChildren<'a, T, V>),
    ClassishBody(&'a ClassishBodyChildren<'a, T, V>),
    TraitUsePrecedenceItem(&'a TraitUsePrecedenceItemChildren<'a, T, V>),
    TraitUseAliasItem(&'a TraitUseAliasItemChildren<'a, T, V>),
    TraitUseConflictResolution(&'a TraitUseConflictResolutionChildren<'a, T, V>),
    TraitUse(&'a TraitUseChildren<'a, T, V>),
    RequireClause(&'a RequireClauseChildren<'a, T, V>),
    ConstDeclaration(&'a ConstDeclarationChildren<'a, T, V>),
    ConstantDeclarator(&'a ConstantDeclaratorChildren<'a, T, V>),
    TypeConstDeclaration(&'a TypeConstDeclarationChildren<'a, T, V>),
    ContextConstDeclaration(&'a ContextConstDeclarationChildren<'a, T, V>),
    DecoratedExpression(&'a DecoratedExpressionChildren<'a, T, V>),
    ParameterDeclaration(&'a ParameterDeclarationChildren<'a, T, V>),
    VariadicParameter(&'a VariadicParameterChildren<'a, T, V>),
    OldAttributeSpecification(&'a OldAttributeSpecificationChildren<'a, T, V>),
    AttributeSpecification(&'a AttributeSpecificationChildren<'a, T, V>),
    Attribute(&'a AttributeChildren<'a, T, V>),
    InclusionExpression(&'a InclusionExpressionChildren<'a, T, V>),
    InclusionDirective(&'a InclusionDirectiveChildren<'a, T, V>),
    CompoundStatement(&'a CompoundStatementChildren<'a, T, V>),
    ExpressionStatement(&'a ExpressionStatementChildren<'a, T, V>),
    MarkupSection(&'a MarkupSectionChildren<'a, T, V>),
    MarkupSuffix(&'a MarkupSuffixChildren<'a, T, V>),
    UnsetStatement(&'a UnsetStatementChildren<'a, T, V>),
    UsingStatementBlockScoped(&'a UsingStatementBlockScopedChildren<'a, T, V>),
    UsingStatementFunctionScoped(&'a UsingStatementFunctionScopedChildren<'a, T, V>),
    WhileStatement(&'a WhileStatementChildren<'a, T, V>),
    IfStatement(&'a IfStatementChildren<'a, T, V>),
    ElseifClause(&'a ElseifClauseChildren<'a, T, V>),
    ElseClause(&'a ElseClauseChildren<'a, T, V>),
    TryStatement(&'a TryStatementChildren<'a, T, V>),
    CatchClause(&'a CatchClauseChildren<'a, T, V>),
    FinallyClause(&'a FinallyClauseChildren<'a, T, V>),
    DoStatement(&'a DoStatementChildren<'a, T, V>),
    ForStatement(&'a ForStatementChildren<'a, T, V>),
    ForeachStatement(&'a ForeachStatementChildren<'a, T, V>),
    SwitchStatement(&'a SwitchStatementChildren<'a, T, V>),
    SwitchSection(&'a SwitchSectionChildren<'a, T, V>),
    SwitchFallthrough(&'a SwitchFallthroughChildren<'a, T, V>),
    CaseLabel(&'a CaseLabelChildren<'a, T, V>),
    DefaultLabel(&'a DefaultLabelChildren<'a, T, V>),
    ReturnStatement(&'a ReturnStatementChildren<'a, T, V>),
    YieldBreakStatement(&'a YieldBreakStatementChildren<'a, T, V>),
    ThrowStatement(&'a ThrowStatementChildren<'a, T, V>),
    BreakStatement(&'a BreakStatementChildren<'a, T, V>),
    ContinueStatement(&'a ContinueStatementChildren<'a, T, V>),
    EchoStatement(&'a EchoStatementChildren<'a, T, V>),
    ConcurrentStatement(&'a ConcurrentStatementChildren<'a, T, V>),
    SimpleInitializer(&'a SimpleInitializerChildren<'a, T, V>),
    AnonymousClass(&'a AnonymousClassChildren<'a, T, V>),
    AnonymousFunction(&'a AnonymousFunctionChildren<'a, T, V>),
    AnonymousFunctionUseClause(&'a AnonymousFunctionUseClauseChildren<'a, T, V>),
    LambdaExpression(&'a LambdaExpressionChildren<'a, T, V>),
    LambdaSignature(&'a LambdaSignatureChildren<'a, T, V>),
    CastExpression(&'a CastExpressionChildren<'a, T, V>),
    ScopeResolutionExpression(&'a ScopeResolutionExpressionChildren<'a, T, V>),
    MemberSelectionExpression(&'a MemberSelectionExpressionChildren<'a, T, V>),
    SafeMemberSelectionExpression(&'a SafeMemberSelectionExpressionChildren<'a, T, V>),
    EmbeddedMemberSelectionExpression(&'a EmbeddedMemberSelectionExpressionChildren<'a, T, V>),
    YieldExpression(&'a YieldExpressionChildren<'a, T, V>),
    PrefixUnaryExpression(&'a PrefixUnaryExpressionChildren<'a, T, V>),
    PostfixUnaryExpression(&'a PostfixUnaryExpressionChildren<'a, T, V>),
    BinaryExpression(&'a BinaryExpressionChildren<'a, T, V>),
    IsExpression(&'a IsExpressionChildren<'a, T, V>),
    AsExpression(&'a AsExpressionChildren<'a, T, V>),
    NullableAsExpression(&'a NullableAsExpressionChildren<'a, T, V>),
    ConditionalExpression(&'a ConditionalExpressionChildren<'a, T, V>),
    EvalExpression(&'a EvalExpressionChildren<'a, T, V>),
    DefineExpression(&'a DefineExpressionChildren<'a, T, V>),
    IssetExpression(&'a IssetExpressionChildren<'a, T, V>),
    FunctionCallExpression(&'a FunctionCallExpressionChildren<'a, T, V>),
    FunctionPointerExpression(&'a FunctionPointerExpressionChildren<'a, T, V>),
    ParenthesizedExpression(&'a ParenthesizedExpressionChildren<'a, T, V>),
    BracedExpression(&'a BracedExpressionChildren<'a, T, V>),
    ETSpliceExpression(&'a ETSpliceExpressionChildren<'a, T, V>),
    EmbeddedBracedExpression(&'a EmbeddedBracedExpressionChildren<'a, T, V>),
    ListExpression(&'a ListExpressionChildren<'a, T, V>),
    CollectionLiteralExpression(&'a CollectionLiteralExpressionChildren<'a, T, V>),
    ObjectCreationExpression(&'a ObjectCreationExpressionChildren<'a, T, V>),
    ConstructorCall(&'a ConstructorCallChildren<'a, T, V>),
    RecordCreationExpression(&'a RecordCreationExpressionChildren<'a, T, V>),
    DarrayIntrinsicExpression(&'a DarrayIntrinsicExpressionChildren<'a, T, V>),
    DictionaryIntrinsicExpression(&'a DictionaryIntrinsicExpressionChildren<'a, T, V>),
    KeysetIntrinsicExpression(&'a KeysetIntrinsicExpressionChildren<'a, T, V>),
    VarrayIntrinsicExpression(&'a VarrayIntrinsicExpressionChildren<'a, T, V>),
    VectorIntrinsicExpression(&'a VectorIntrinsicExpressionChildren<'a, T, V>),
    ElementInitializer(&'a ElementInitializerChildren<'a, T, V>),
    SubscriptExpression(&'a SubscriptExpressionChildren<'a, T, V>),
    EmbeddedSubscriptExpression(&'a EmbeddedSubscriptExpressionChildren<'a, T, V>),
    AwaitableCreationExpression(&'a AwaitableCreationExpressionChildren<'a, T, V>),
    XHPChildrenDeclaration(&'a XHPChildrenDeclarationChildren<'a, T, V>),
    XHPChildrenParenthesizedList(&'a XHPChildrenParenthesizedListChildren<'a, T, V>),
    XHPCategoryDeclaration(&'a XHPCategoryDeclarationChildren<'a, T, V>),
    XHPEnumType(&'a XHPEnumTypeChildren<'a, T, V>),
    XHPLateinit(&'a XHPLateinitChildren<'a, T, V>),
    XHPRequired(&'a XHPRequiredChildren<'a, T, V>),
    XHPClassAttributeDeclaration(&'a XHPClassAttributeDeclarationChildren<'a, T, V>),
    XHPClassAttribute(&'a XHPClassAttributeChildren<'a, T, V>),
    XHPSimpleClassAttribute(&'a XHPSimpleClassAttributeChildren<'a, T, V>),
    XHPSimpleAttribute(&'a XHPSimpleAttributeChildren<'a, T, V>),
    XHPSpreadAttribute(&'a XHPSpreadAttributeChildren<'a, T, V>),
    XHPOpen(&'a XHPOpenChildren<'a, T, V>),
    XHPExpression(&'a XHPExpressionChildren<'a, T, V>),
    XHPClose(&'a XHPCloseChildren<'a, T, V>),
    TypeConstant(&'a TypeConstantChildren<'a, T, V>),
    VectorTypeSpecifier(&'a VectorTypeSpecifierChildren<'a, T, V>),
    KeysetTypeSpecifier(&'a KeysetTypeSpecifierChildren<'a, T, V>),
    TupleTypeExplicitSpecifier(&'a TupleTypeExplicitSpecifierChildren<'a, T, V>),
    VarrayTypeSpecifier(&'a VarrayTypeSpecifierChildren<'a, T, V>),
    FunctionCtxTypeSpecifier(&'a FunctionCtxTypeSpecifierChildren<'a, T, V>),
    TypeParameter(&'a TypeParameterChildren<'a, T, V>),
    TypeConstraint(&'a TypeConstraintChildren<'a, T, V>),
    ContextConstraint(&'a ContextConstraintChildren<'a, T, V>),
    DarrayTypeSpecifier(&'a DarrayTypeSpecifierChildren<'a, T, V>),
    DictionaryTypeSpecifier(&'a DictionaryTypeSpecifierChildren<'a, T, V>),
    ClosureTypeSpecifier(&'a ClosureTypeSpecifierChildren<'a, T, V>),
    ClosureParameterTypeSpecifier(&'a ClosureParameterTypeSpecifierChildren<'a, T, V>),
    ClassnameTypeSpecifier(&'a ClassnameTypeSpecifierChildren<'a, T, V>),
    FieldSpecifier(&'a FieldSpecifierChildren<'a, T, V>),
    FieldInitializer(&'a FieldInitializerChildren<'a, T, V>),
    ShapeTypeSpecifier(&'a ShapeTypeSpecifierChildren<'a, T, V>),
    ShapeExpression(&'a ShapeExpressionChildren<'a, T, V>),
    TupleExpression(&'a TupleExpressionChildren<'a, T, V>),
    GenericTypeSpecifier(&'a GenericTypeSpecifierChildren<'a, T, V>),
    NullableTypeSpecifier(&'a NullableTypeSpecifierChildren<'a, T, V>),
    LikeTypeSpecifier(&'a LikeTypeSpecifierChildren<'a, T, V>),
    SoftTypeSpecifier(&'a SoftTypeSpecifierChildren<'a, T, V>),
    AttributizedSpecifier(&'a AttributizedSpecifierChildren<'a, T, V>),
    ReifiedTypeArgument(&'a ReifiedTypeArgumentChildren<'a, T, V>),
    TypeArguments(&'a TypeArgumentsChildren<'a, T, V>),
    TypeParameters(&'a TypeParametersChildren<'a, T, V>),
    TupleTypeSpecifier(&'a TupleTypeSpecifierChildren<'a, T, V>),
    UnionTypeSpecifier(&'a UnionTypeSpecifierChildren<'a, T, V>),
    IntersectionTypeSpecifier(&'a IntersectionTypeSpecifierChildren<'a, T, V>),
    ErrorSyntax(&'a ErrorSyntaxChildren<'a, T, V>),
    ListItem(&'a ListItemChildren<'a, T, V>),
    EnumAtomExpression(&'a EnumAtomExpressionChildren<'a, T, V>),
}

#[derive(Debug, Clone)]
pub struct EndOfFileChildren<'a, T, V> {
    pub token: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ScriptChildren<'a, T, V> {
    pub declarations: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct QualifiedNameChildren<'a, T, V> {
    pub parts: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SimpleTypeSpecifierChildren<'a, T, V> {
    pub specifier: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct LiteralExpressionChildren<'a, T, V> {
    pub expression: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct PrefixedStringExpressionChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub str: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct PrefixedCodeExpressionChildren<'a, T, V> {
    pub prefix: Syntax<'a, T, V>,
    pub left_backtick: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub right_backtick: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct VariableExpressionChildren<'a, T, V> {
    pub expression: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct PipeVariableExpressionChildren<'a, T, V> {
    pub expression: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FileAttributeSpecificationChildren<'a, T, V> {
    pub left_double_angle: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub attributes: Syntax<'a, T, V>,
    pub right_double_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EnumDeclarationChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub base: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub use_clauses: Syntax<'a, T, V>,
    pub enumerators: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EnumUseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub names: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EnumeratorChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub equal: Syntax<'a, T, V>,
    pub value: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EnumClassDeclarationChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub enum_keyword: Syntax<'a, T, V>,
    pub class_keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub base: Syntax<'a, T, V>,
    pub extends: Syntax<'a, T, V>,
    pub extends_list: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub elements: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EnumClassEnumeratorChildren<'a, T, V> {
    pub type_: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub equal: Syntax<'a, T, V>,
    pub initial_value: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct RecordDeclarationChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub modifier: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub extends_keyword: Syntax<'a, T, V>,
    pub extends_opt: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub fields: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct RecordFieldChildren<'a, T, V> {
    pub type_: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub init: Syntax<'a, T, V>,
    pub semi: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AliasDeclarationChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub generic_parameter: Syntax<'a, T, V>,
    pub constraint: Syntax<'a, T, V>,
    pub equal: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct PropertyDeclarationChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub modifiers: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub declarators: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct PropertyDeclaratorChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub initializer: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NamespaceDeclarationChildren<'a, T, V> {
    pub header: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NamespaceDeclarationHeaderChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NamespaceBodyChildren<'a, T, V> {
    pub left_brace: Syntax<'a, T, V>,
    pub declarations: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NamespaceEmptyBodyChildren<'a, T, V> {
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NamespaceUseDeclarationChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub kind: Syntax<'a, T, V>,
    pub clauses: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NamespaceGroupUseDeclarationChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub kind: Syntax<'a, T, V>,
    pub prefix: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub clauses: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NamespaceUseClauseChildren<'a, T, V> {
    pub clause_kind: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub as_: Syntax<'a, T, V>,
    pub alias: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FunctionDeclarationChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub declaration_header: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FunctionDeclarationHeaderChildren<'a, T, V> {
    pub modifiers: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub type_parameter_list: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub parameter_list: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub contexts: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub readonly_return: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub where_clause: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ContextsChildren<'a, T, V> {
    pub left_bracket: Syntax<'a, T, V>,
    pub types: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct WhereClauseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub constraints: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct WhereConstraintChildren<'a, T, V> {
    pub left_type: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub right_type: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct MethodishDeclarationChildren<'a, T, V> {
    pub attribute: Syntax<'a, T, V>,
    pub function_decl_header: Syntax<'a, T, V>,
    pub function_body: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct MethodishTraitResolutionChildren<'a, T, V> {
    pub attribute: Syntax<'a, T, V>,
    pub function_decl_header: Syntax<'a, T, V>,
    pub equal: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ClassishDeclarationChildren<'a, T, V> {
    pub attribute: Syntax<'a, T, V>,
    pub modifiers: Syntax<'a, T, V>,
    pub xhp: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub type_parameters: Syntax<'a, T, V>,
    pub extends_keyword: Syntax<'a, T, V>,
    pub extends_list: Syntax<'a, T, V>,
    pub implements_keyword: Syntax<'a, T, V>,
    pub implements_list: Syntax<'a, T, V>,
    pub where_clause: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ClassishBodyChildren<'a, T, V> {
    pub left_brace: Syntax<'a, T, V>,
    pub elements: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TraitUsePrecedenceItemChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub removed_names: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TraitUseAliasItemChildren<'a, T, V> {
    pub aliasing_name: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub modifiers: Syntax<'a, T, V>,
    pub aliased_name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TraitUseConflictResolutionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub names: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub clauses: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TraitUseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub names: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct RequireClauseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub kind: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ConstDeclarationChildren<'a, T, V> {
    pub modifiers: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub type_specifier: Syntax<'a, T, V>,
    pub declarators: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ConstantDeclaratorChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub initializer: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TypeConstDeclarationChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub modifiers: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
    pub type_keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub type_parameters: Syntax<'a, T, V>,
    pub type_constraint: Syntax<'a, T, V>,
    pub equal: Syntax<'a, T, V>,
    pub type_specifier: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ContextConstDeclarationChildren<'a, T, V> {
    pub modifiers: Syntax<'a, T, V>,
    pub const_keyword: Syntax<'a, T, V>,
    pub ctx_keyword: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub type_parameters: Syntax<'a, T, V>,
    pub constraint: Syntax<'a, T, V>,
    pub equal: Syntax<'a, T, V>,
    pub ctx_list: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DecoratedExpressionChildren<'a, T, V> {
    pub decorator: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ParameterDeclarationChildren<'a, T, V> {
    pub attribute: Syntax<'a, T, V>,
    pub visibility: Syntax<'a, T, V>,
    pub call_convention: Syntax<'a, T, V>,
    pub readonly: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub default_value: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct VariadicParameterChildren<'a, T, V> {
    pub call_convention: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub ellipsis: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct OldAttributeSpecificationChildren<'a, T, V> {
    pub left_double_angle: Syntax<'a, T, V>,
    pub attributes: Syntax<'a, T, V>,
    pub right_double_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AttributeSpecificationChildren<'a, T, V> {
    pub attributes: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AttributeChildren<'a, T, V> {
    pub at: Syntax<'a, T, V>,
    pub attribute_name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct InclusionExpressionChildren<'a, T, V> {
    pub require: Syntax<'a, T, V>,
    pub filename: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct InclusionDirectiveChildren<'a, T, V> {
    pub expression: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct CompoundStatementChildren<'a, T, V> {
    pub left_brace: Syntax<'a, T, V>,
    pub statements: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ExpressionStatementChildren<'a, T, V> {
    pub expression: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct MarkupSectionChildren<'a, T, V> {
    pub hashbang: Syntax<'a, T, V>,
    pub suffix: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct MarkupSuffixChildren<'a, T, V> {
    pub less_than_question: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct UnsetStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub variables: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct UsingStatementBlockScopedChildren<'a, T, V> {
    pub await_keyword: Syntax<'a, T, V>,
    pub using_keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub expressions: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct UsingStatementFunctionScopedChildren<'a, T, V> {
    pub await_keyword: Syntax<'a, T, V>,
    pub using_keyword: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct WhileStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub condition: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct IfStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub condition: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub statement: Syntax<'a, T, V>,
    pub elseif_clauses: Syntax<'a, T, V>,
    pub else_clause: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ElseifClauseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub condition: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub statement: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ElseClauseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub statement: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TryStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub compound_statement: Syntax<'a, T, V>,
    pub catch_clauses: Syntax<'a, T, V>,
    pub finally_clause: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct CatchClauseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub variable: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FinallyClauseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DoStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
    pub while_keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub condition: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ForStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub initializer: Syntax<'a, T, V>,
    pub first_semicolon: Syntax<'a, T, V>,
    pub control: Syntax<'a, T, V>,
    pub second_semicolon: Syntax<'a, T, V>,
    pub end_of_loop: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ForeachStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub collection: Syntax<'a, T, V>,
    pub await_keyword: Syntax<'a, T, V>,
    pub as_: Syntax<'a, T, V>,
    pub key: Syntax<'a, T, V>,
    pub arrow: Syntax<'a, T, V>,
    pub value: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SwitchStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub sections: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SwitchSectionChildren<'a, T, V> {
    pub labels: Syntax<'a, T, V>,
    pub statements: Syntax<'a, T, V>,
    pub fallthrough: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SwitchFallthroughChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct CaseLabelChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DefaultLabelChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ReturnStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct YieldBreakStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub break_: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ThrowStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct BreakStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ContinueStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EchoStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub expressions: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ConcurrentStatementChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub statement: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SimpleInitializerChildren<'a, T, V> {
    pub equal: Syntax<'a, T, V>,
    pub value: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AnonymousClassChildren<'a, T, V> {
    pub class_keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub argument_list: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub extends_keyword: Syntax<'a, T, V>,
    pub extends_list: Syntax<'a, T, V>,
    pub implements_keyword: Syntax<'a, T, V>,
    pub implements_list: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AnonymousFunctionChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub static_keyword: Syntax<'a, T, V>,
    pub async_keyword: Syntax<'a, T, V>,
    pub function_keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub parameters: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub ctx_list: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub readonly_return: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub use_: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AnonymousFunctionUseClauseChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub variables: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct LambdaExpressionChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub async_: Syntax<'a, T, V>,
    pub signature: Syntax<'a, T, V>,
    pub arrow: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct LambdaSignatureChildren<'a, T, V> {
    pub left_paren: Syntax<'a, T, V>,
    pub parameters: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub contexts: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub readonly_return: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct CastExpressionChildren<'a, T, V> {
    pub left_paren: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
    pub operand: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ScopeResolutionExpressionChildren<'a, T, V> {
    pub qualifier: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct MemberSelectionExpressionChildren<'a, T, V> {
    pub object: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SafeMemberSelectionExpressionChildren<'a, T, V> {
    pub object: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EmbeddedMemberSelectionExpressionChildren<'a, T, V> {
    pub object: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct YieldExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub operand: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct PrefixUnaryExpressionChildren<'a, T, V> {
    pub operator: Syntax<'a, T, V>,
    pub operand: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct PostfixUnaryExpressionChildren<'a, T, V> {
    pub operand: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct BinaryExpressionChildren<'a, T, V> {
    pub left_operand: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub right_operand: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct IsExpressionChildren<'a, T, V> {
    pub left_operand: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub right_operand: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AsExpressionChildren<'a, T, V> {
    pub left_operand: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub right_operand: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NullableAsExpressionChildren<'a, T, V> {
    pub left_operand: Syntax<'a, T, V>,
    pub operator: Syntax<'a, T, V>,
    pub right_operand: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ConditionalExpressionChildren<'a, T, V> {
    pub test: Syntax<'a, T, V>,
    pub question: Syntax<'a, T, V>,
    pub consequence: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub alternative: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EvalExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub argument: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DefineExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub argument_list: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct IssetExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub argument_list: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FunctionCallExpressionChildren<'a, T, V> {
    pub receiver: Syntax<'a, T, V>,
    pub type_args: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub argument_list: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FunctionPointerExpressionChildren<'a, T, V> {
    pub receiver: Syntax<'a, T, V>,
    pub type_args: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ParenthesizedExpressionChildren<'a, T, V> {
    pub left_paren: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct BracedExpressionChildren<'a, T, V> {
    pub left_brace: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ETSpliceExpressionChildren<'a, T, V> {
    pub dollar: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EmbeddedBracedExpressionChildren<'a, T, V> {
    pub left_brace: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ListExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct CollectionLiteralExpressionChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub initializers: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ObjectCreationExpressionChildren<'a, T, V> {
    pub new_keyword: Syntax<'a, T, V>,
    pub object: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ConstructorCallChildren<'a, T, V> {
    pub type_: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub argument_list: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct RecordCreationExpressionChildren<'a, T, V> {
    pub type_: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DarrayIntrinsicExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub explicit_type: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DictionaryIntrinsicExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub explicit_type: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct KeysetIntrinsicExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub explicit_type: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct VarrayIntrinsicExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub explicit_type: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct VectorIntrinsicExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub explicit_type: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ElementInitializerChildren<'a, T, V> {
    pub key: Syntax<'a, T, V>,
    pub arrow: Syntax<'a, T, V>,
    pub value: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SubscriptExpressionChildren<'a, T, V> {
    pub receiver: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub index: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EmbeddedSubscriptExpressionChildren<'a, T, V> {
    pub receiver: Syntax<'a, T, V>,
    pub left_bracket: Syntax<'a, T, V>,
    pub index: Syntax<'a, T, V>,
    pub right_bracket: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AwaitableCreationExpressionChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub async_: Syntax<'a, T, V>,
    pub compound_statement: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPChildrenDeclarationChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPChildrenParenthesizedListChildren<'a, T, V> {
    pub left_paren: Syntax<'a, T, V>,
    pub xhp_children: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPCategoryDeclarationChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub categories: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPEnumTypeChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_brace: Syntax<'a, T, V>,
    pub values: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPLateinitChildren<'a, T, V> {
    pub at: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPRequiredChildren<'a, T, V> {
    pub at: Syntax<'a, T, V>,
    pub keyword: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPClassAttributeDeclarationChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub attributes: Syntax<'a, T, V>,
    pub semicolon: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPClassAttributeChildren<'a, T, V> {
    pub type_: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub initializer: Syntax<'a, T, V>,
    pub required: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPSimpleClassAttributeChildren<'a, T, V> {
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPSimpleAttributeChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub equal: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPSpreadAttributeChildren<'a, T, V> {
    pub left_brace: Syntax<'a, T, V>,
    pub spread_operator: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
    pub right_brace: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPOpenChildren<'a, T, V> {
    pub left_angle: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub attributes: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPExpressionChildren<'a, T, V> {
    pub open: Syntax<'a, T, V>,
    pub body: Syntax<'a, T, V>,
    pub close: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct XHPCloseChildren<'a, T, V> {
    pub left_angle: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TypeConstantChildren<'a, T, V> {
    pub left_type: Syntax<'a, T, V>,
    pub separator: Syntax<'a, T, V>,
    pub right_type: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct VectorTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_angle: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub trailing_comma: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct KeysetTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_angle: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub trailing_comma: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TupleTypeExplicitSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_angle: Syntax<'a, T, V>,
    pub types: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct VarrayTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_angle: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub trailing_comma: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FunctionCtxTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub variable: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TypeParameterChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub reified: Syntax<'a, T, V>,
    pub variance: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub param_params: Syntax<'a, T, V>,
    pub constraints: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TypeConstraintChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ContextConstraintChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub ctx_list: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DarrayTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_angle: Syntax<'a, T, V>,
    pub key: Syntax<'a, T, V>,
    pub comma: Syntax<'a, T, V>,
    pub value: Syntax<'a, T, V>,
    pub trailing_comma: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct DictionaryTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_angle: Syntax<'a, T, V>,
    pub members: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ClosureTypeSpecifierChildren<'a, T, V> {
    pub outer_left_paren: Syntax<'a, T, V>,
    pub function_keyword: Syntax<'a, T, V>,
    pub inner_left_paren: Syntax<'a, T, V>,
    pub parameter_list: Syntax<'a, T, V>,
    pub inner_right_paren: Syntax<'a, T, V>,
    pub contexts: Syntax<'a, T, V>,
    pub colon: Syntax<'a, T, V>,
    pub return_type: Syntax<'a, T, V>,
    pub outer_right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ClosureParameterTypeSpecifierChildren<'a, T, V> {
    pub call_convention: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ClassnameTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_angle: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
    pub trailing_comma: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FieldSpecifierChildren<'a, T, V> {
    pub question: Syntax<'a, T, V>,
    pub name: Syntax<'a, T, V>,
    pub arrow: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct FieldInitializerChildren<'a, T, V> {
    pub name: Syntax<'a, T, V>,
    pub arrow: Syntax<'a, T, V>,
    pub value: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ShapeTypeSpecifierChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub fields: Syntax<'a, T, V>,
    pub ellipsis: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ShapeExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub fields: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TupleExpressionChildren<'a, T, V> {
    pub keyword: Syntax<'a, T, V>,
    pub left_paren: Syntax<'a, T, V>,
    pub items: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct GenericTypeSpecifierChildren<'a, T, V> {
    pub class_type: Syntax<'a, T, V>,
    pub argument_list: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct NullableTypeSpecifierChildren<'a, T, V> {
    pub question: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct LikeTypeSpecifierChildren<'a, T, V> {
    pub tilde: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct SoftTypeSpecifierChildren<'a, T, V> {
    pub at: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct AttributizedSpecifierChildren<'a, T, V> {
    pub attribute_spec: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ReifiedTypeArgumentChildren<'a, T, V> {
    pub reified: Syntax<'a, T, V>,
    pub type_: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TypeArgumentsChildren<'a, T, V> {
    pub left_angle: Syntax<'a, T, V>,
    pub types: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TypeParametersChildren<'a, T, V> {
    pub left_angle: Syntax<'a, T, V>,
    pub parameters: Syntax<'a, T, V>,
    pub right_angle: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct TupleTypeSpecifierChildren<'a, T, V> {
    pub left_paren: Syntax<'a, T, V>,
    pub types: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct UnionTypeSpecifierChildren<'a, T, V> {
    pub left_paren: Syntax<'a, T, V>,
    pub types: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct IntersectionTypeSpecifierChildren<'a, T, V> {
    pub left_paren: Syntax<'a, T, V>,
    pub types: Syntax<'a, T, V>,
    pub right_paren: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ErrorSyntaxChildren<'a, T, V> {
    pub error: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct ListItemChildren<'a, T, V> {
    pub item: Syntax<'a, T, V>,
    pub separator: Syntax<'a, T, V>,
}

#[derive(Debug, Clone)]
pub struct EnumAtomExpressionChildren<'a, T, V> {
    pub hash: Syntax<'a, T, V>,
    pub expression: Syntax<'a, T, V>,
}



impl<'a, T, V> SyntaxVariant<'a, T, V> {
    pub fn iter_children(&'a self) -> SyntaxChildrenIterator<'a, T, V> {
        SyntaxChildrenIterator {
            syntax: &self,
            index: 0,
            index_back: 0,
        }
    }
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use super::{syntax::*, syntax_variant_generated::SyntaxVariant};
pub struct SyntaxChildrenIterator<'a, T, V> {
    pub syntax: &'a SyntaxVariant<'a, T, V>,
    pub index: usize,
    pub index_back: usize,
}

impl<'a, T, V> Iterator for SyntaxChildrenIterator<'a, T, V> {
    type Item = &'a Syntax<'a, T, V>;
    fn next(&mut self) -> Option<Self::Item> {
        self.next_impl(true)
    }
}

// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

use bumpalo::Bump;

pub trait HasArena<'a> {
    fn get_arena(&self) -> &'a Bump;
// Copyright (c) 2019, Facebook, Inc.
// All rights reserved.
//
// This source code is licensed under the MIT license found in the
// LICENSE file in the "hack" directory of this source tree.

pub mod arena_state;
pub mod has_arena;
pub mod positioned_syntax;
pub mod positioned_token;
pub mod positioned_trivia;
pub mod positioned_value;
pub mod serialize;
pub mod syntax;
pub mod syntax_impl_generated;
pub mod syntax_variant_generated;

mod syntax_children_iterator;
mod syntax_children_iterator_generated;
mod syntax_serialize_generated;
/**
 * Copyright (c) 2016, Facebook, Inc.
 * All rights reserved.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the "hack" directory of this source tree. An additional
 * directory.
 *
 **
 *
 * THIS FILE IS @generated; DO NOT EDIT IT
 * To regenerate this file, run
 *
 *   buck run //hphp/hack/src:generate_full_fidelity
 *
 **
 *
 */
use super::{
    syntax_children_iterator::*,
    syntax_variant_generated::*,
    syntax::*
};

impl<'a, T, V> SyntaxChildrenIterator<'a, T, V> {
    pub fn next_impl(&mut self, direction : bool) -> Option<&'a Syntax<'a, T, V>> {
        use SyntaxVariant::*;
        let get_index = |len| {
            let back_index_plus_1 = len - self.index_back;
            if back_index_plus_1 <= self.index {
                return None
            }
            if direction {
                Some (self.index)
            } else {
                Some (back_index_plus_1 - 1)
            }
        };
        let res = match self.syntax {
            Missing => None,
            Token (_) => None,
            SyntaxList(elems) => {
                get_index(elems.len()).and_then(|x| elems.get(x))
            },
            EndOfFile(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.token),
                        _ => None,
                    }
                })
            },
            Script(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.declarations),
                        _ => None,
                    }
                })
            },
            QualifiedName(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.parts),
                        _ => None,
                    }
                })
            },
            SimpleTypeSpecifier(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.specifier),
                        _ => None,
                    }
                })
            },
            LiteralExpression(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.expression),
                        _ => None,
                    }
                })
            },
            PrefixedStringExpression(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.name),
                    1 => Some(&x.str),
                        _ => None,
                    }
                })
            },
            PrefixedCodeExpression(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.prefix),
                    1 => Some(&x.left_backtick),
                    2 => Some(&x.expression),
                    3 => Some(&x.right_backtick),
                        _ => None,
                    }
                })
            },
            VariableExpression(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.expression),
                        _ => None,
                    }
                })
            },
            PipeVariableExpression(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.expression),
                        _ => None,
                    }
                })
            },
            FileAttributeSpecification(x) => {
                get_index(5).and_then(|index| { match index {
                        0 => Some(&x.left_double_angle),
                    1 => Some(&x.keyword),
                    2 => Some(&x.colon),
                    3 => Some(&x.attributes),
                    4 => Some(&x.right_double_angle),
                        _ => None,
                    }
                })
            },
            EnumDeclaration(x) => {
                get_index(10).and_then(|index| { match index {
                        0 => Some(&x.attribute_spec),
                    1 => Some(&x.keyword),
                    2 => Some(&x.name),
                    3 => Some(&x.colon),
                    4 => Some(&x.base),
                    5 => Some(&x.type_),
                    6 => Some(&x.left_brace),
                    7 => Some(&x.use_clauses),
                    8 => Some(&x.enumerators),
                    9 => Some(&x.right_brace),
                        _ => None,
                    }
                })
            },
            EnumUse(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.names),
                    2 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            Enumerator(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.name),
                    1 => Some(&x.equal),
                    2 => Some(&x.value),
                    3 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            EnumClassDeclaration(x) => {
                get_index(11).and_then(|index| { match index {
                        0 => Some(&x.attribute_spec),
                    1 => Some(&x.enum_keyword),
                    2 => Some(&x.class_keyword),
                    3 => Some(&x.name),
                    4 => Some(&x.colon),
                    5 => Some(&x.base),
                    6 => Some(&x.extends),
                    7 => Some(&x.extends_list),
                    8 => Some(&x.left_brace),
                    9 => Some(&x.elements),
                    10 => Some(&x.right_brace),
                        _ => None,
                    }
                })
            },
            EnumClassEnumerator(x) => {
                get_index(5).and_then(|index| { match index {
                        0 => Some(&x.type_),
                    1 => Some(&x.name),
                    2 => Some(&x.equal),
                    3 => Some(&x.initial_value),
                    4 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            RecordDeclaration(x) => {
                get_index(9).and_then(|index| { match index {
                        0 => Some(&x.attribute_spec),
                    1 => Some(&x.modifier),
                    2 => Some(&x.keyword),
                    3 => Some(&x.name),
                    4 => Some(&x.extends_keyword),
                    5 => Some(&x.extends_opt),
                    6 => Some(&x.left_brace),
                    7 => Some(&x.fields),
                    8 => Some(&x.right_brace),
                        _ => None,
                    }
                })
            },
            RecordField(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.type_),
                    1 => Some(&x.name),
                    2 => Some(&x.init),
                    3 => Some(&x.semi),
                        _ => None,
                    }
                })
            },
            AliasDeclaration(x) => {
                get_index(8).and_then(|index| { match index {
                        0 => Some(&x.attribute_spec),
                    1 => Some(&x.keyword),
                    2 => Some(&x.name),
                    3 => Some(&x.generic_parameter),
                    4 => Some(&x.constraint),
                    5 => Some(&x.equal),
                    6 => Some(&x.type_),
                    7 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            PropertyDeclaration(x) => {
                get_index(5).and_then(|index| { match index {
                        0 => Some(&x.attribute_spec),
                    1 => Some(&x.modifiers),
                    2 => Some(&x.type_),
                    3 => Some(&x.declarators),
                    4 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            PropertyDeclarator(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.name),
                    1 => Some(&x.initializer),
                        _ => None,
                    }
                })
            },
            NamespaceDeclaration(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.header),
                    1 => Some(&x.body),
                        _ => None,
                    }
                })
            },
            NamespaceDeclarationHeader(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.name),
                        _ => None,
                    }
                })
            },
            NamespaceBody(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.left_brace),
                    1 => Some(&x.declarations),
                    2 => Some(&x.right_brace),
                        _ => None,
                    }
                })
            },
            NamespaceEmptyBody(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            NamespaceUseDeclaration(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.kind),
                    2 => Some(&x.clauses),
                    3 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            NamespaceGroupUseDeclaration(x) => {
                get_index(7).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.kind),
                    2 => Some(&x.prefix),
                    3 => Some(&x.left_brace),
                    4 => Some(&x.clauses),
                    5 => Some(&x.right_brace),
                    6 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            NamespaceUseClause(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.clause_kind),
                    1 => Some(&x.name),
                    2 => Some(&x.as_),
                    3 => Some(&x.alias),
                        _ => None,
                    }
                })
            },
            FunctionDeclaration(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.attribute_spec),
                    1 => Some(&x.declaration_header),
                    2 => Some(&x.body),
                        _ => None,
                    }
                })
            },
            FunctionDeclarationHeader(x) => {
                get_index(12).and_then(|index| { match index {
                        0 => Some(&x.modifiers),
                    1 => Some(&x.keyword),
                    2 => Some(&x.name),
                    3 => Some(&x.type_parameter_list),
                    4 => Some(&x.left_paren),
                    5 => Some(&x.parameter_list),
                    6 => Some(&x.right_paren),
                    7 => Some(&x.contexts),
                    8 => Some(&x.colon),
                    9 => Some(&x.readonly_return),
                    10 => Some(&x.type_),
                    11 => Some(&x.where_clause),
                        _ => None,
                    }
                })
            },
            Contexts(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.left_bracket),
                    1 => Some(&x.types),
                    2 => Some(&x.right_bracket),
                        _ => None,
                    }
                })
            },
            WhereClause(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.constraints),
                        _ => None,
                    }
                })
            },
            WhereConstraint(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.left_type),
                    1 => Some(&x.operator),
                    2 => Some(&x.right_type),
                        _ => None,
                    }
                })
            },
            MethodishDeclaration(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.attribute),
                    1 => Some(&x.function_decl_header),
                    2 => Some(&x.function_body),
                    3 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            MethodishTraitResolution(x) => {
                get_index(5).and_then(|index| { match index {
                        0 => Some(&x.attribute),
                    1 => Some(&x.function_decl_header),
                    2 => Some(&x.equal),
                    3 => Some(&x.name),
                    4 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            ClassishDeclaration(x) => {
                get_index(12).and_then(|index| { match index {
                        0 => Some(&x.attribute),
                    1 => Some(&x.modifiers),
                    2 => Some(&x.xhp),
                    3 => Some(&x.keyword),
                    4 => Some(&x.name),
                    5 => Some(&x.type_parameters),
                    6 => Some(&x.extends_keyword),
                    7 => Some(&x.extends_list),
                    8 => Some(&x.implements_keyword),
                    9 => Some(&x.implements_list),
                    10 => Some(&x.where_clause),
                    11 => Some(&x.body),
                        _ => None,
                    }
                })
            },
            ClassishBody(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.left_brace),
                    1 => Some(&x.elements),
                    2 => Some(&x.right_brace),
                        _ => None,
                    }
                })
            },
            TraitUsePrecedenceItem(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.name),
                    1 => Some(&x.keyword),
                    2 => Some(&x.removed_names),
                        _ => None,
                    }
                })
            },
            TraitUseAliasItem(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.aliasing_name),
                    1 => Some(&x.keyword),
                    2 => Some(&x.modifiers),
                    3 => Some(&x.aliased_name),
                        _ => None,
                    }
                })
            },
            TraitUseConflictResolution(x) => {
                get_index(5).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.names),
                    2 => Some(&x.left_brace),
                    3 => Some(&x.clauses),
                    4 => Some(&x.right_brace),
                        _ => None,
                    }
                })
            },
            TraitUse(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.names),
                    2 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            RequireClause(x) => {
                get_index(4).and_then(|index| { match index {
                        0 => Some(&x.keyword),
                    1 => Some(&x.kind),
                    2 => Some(&x.name),
                    3 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            ConstDeclaration(x) => {
                get_index(5).and_then(|index| { match index {
                        0 => Some(&x.modifiers),
                    1 => Some(&x.keyword),
                    2 => Some(&x.type_specifier),
                    3 => Some(&x.declarators),
                    4 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            ConstantDeclarator(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.name),
                    1 => Some(&x.initializer),
                        _ => None,
                    }
                })
            },
            TypeConstDeclaration(x) => {
                get_index(10).and_then(|index| { match index {
                        0 => Some(&x.attribute_spec),
                    1 => Some(&x.modifiers),
                    2 => Some(&x.keyword),
                    3 => Some(&x.type_keyword),
                    4 => Some(&x.name),
                    5 => Some(&x.type_parameters),
                    6 => Some(&x.type_constraint),
                    7 => Some(&x.equal),
                    8 => Some(&x.type_specifier),
                    9 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            ContextConstDeclaration(x) => {
                get_index(9).and_then(|index| { match index {
                        0 => Some(&x.modifiers),
                    1 => Some(&x.const_keyword),
                    2 => Some(&x.ctx_keyword),
                    3 => Some(&x.name),
                    4 => Some(&x.type_parameters),
                    5 => Some(&x.constraint),
                    6 => Some(&x.equal),
                    7 => Some(&x.ctx_list),
                    8 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            DecoratedExpression(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.decorator),
                    1 => Some(&x.expression),
                        _ => None,
                    }
                })
            },
            ParameterDeclaration(x) => {
                get_index(7).and_then(|index| { match index {
                        0 => Some(&x.attribute),
                    1 => Some(&x.visibility),
                    2 => Some(&x.call_convention),
                    3 => Some(&x.readonly),
                    4 => Some(&x.type_),
                    5 => Some(&x.name),
                    6 => Some(&x.default_value),
                        _ => None,
                    }
                })
            },
            VariadicParameter(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.call_convention),
                    1 => Some(&x.type_),
                    2 => Some(&x.ellipsis),
                        _ => None,
                    }
                })
            },
            OldAttributeSpecification(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.left_double_angle),
                    1 => Some(&x.attributes),
                    2 => Some(&x.right_double_angle),
                        _ => None,
                    }
                })
            },
            AttributeSpecification(x) => {
                get_index(1).and_then(|index| { match index {
                        0 => Some(&x.attributes),
                        _ => None,
                    }
                })
            },
            Attribute(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.at),
                    1 => Some(&x.attribute_name),
                        _ => None,
                    }
                })
            },
            InclusionExpression(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.require),
                    1 => Some(&x.filename),
                        _ => None,
                    }
                })
            },
            InclusionDirective(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.expression),
                    1 => Some(&x.semicolon),
                        _ => None,
                    }
                })
            },
            CompoundStatement(x) => {
                get_index(3).and_then(|index| { match index {
                        0 => Some(&x.left_brace),
                    1 => Some(&x.statements),
                    2 => Some(&x.right_brace),
                        _ => None,
                    }
                })
            },
            ExpressionStatement(x) => {
                get_index(2).and_then(|index| { match index {
                        0 => Some(&x.expression),
