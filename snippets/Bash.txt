# Copyright 2019 Wason Technology, LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

if [ $# -eq 0 ]
  then
    echo "No bat file specified"
    return
fi

#echo `dirname "$(readlink -f "$_")"`
___update_env_func___() {
tmpbat=$(mktemp --suffix .bat)
rc=$?; if [[ $rc != 0 ]]; then 
  echo "Could not create temporary bat file"
  return $rc 
fi

echo "@echo off " >> $tmpbat
echo "call \"$@\" 1>&2 " >> $tmpbat
echo "if %errorlevel% neq 0 exit /b %errorlevel%" >> $tmpbat
echo "printenv " >> $tmpbat
echo "if %errorlevel% neq 0 exit /b %errorlevel%" >> $tmpbat
rc=$?; if [[ $rc != 0 ]]; then 
  echo "Could not write temporary bat file"
  return $rc
fi

tmpbat_win=$(basename $tmpbat)
env_data=$(cmd "/c call %TEMP%\\$tmpbat_win ")
rc=$?; if [[ $rc != 0 ]]; then 
  echo "Could not run temporary bat file"
  return $rc 
fi

echo
echo
echo

#Space at the end is lost for some reason,
#save and restore PS1
ps1_old=$PS1

while read -r line; do
    echo "export $line"
    export "$line"     
done <<< "$env_data"

export PS1="$ps1_old"
}
#!/bin/bash -ex

DIR=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )
cd $DIR

if [ "x${ghprbPullId}" == "x" ]
then
	exit 1
fi

ant -Djava.net.preferIPv4Stack=true -Dplatform=linux64 -Dlinux64=1 clean build

ERRORS=`grep '<error' ../app/test-bin/TEST-*.xml | wc -l`
if [ $ERRORS -ne 0 ] ;
then
	exit $ERRORS
fi

VERSION="PR-${ghprbPullId}-BUILD-${BUILD_NUMBER}"

#!/bin/bash -ex

DIR=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )
cd $DIR

rm -f ../arduino-*.tar.xz
rm -f ../arduino-*.zip

ant -Djava.net.preferIPv4Stack=true -Dplatform=linux32 $@ clean dist
mv linux/arduino-*-linux32.tar.xz ../

ant -Djava.net.preferIPv4Stack=true -Dplatform=linux64 $@ clean dist
mv linux/arduino-*-linux64.tar.xz ../

ant -Djava.net.preferIPv4Stack=true -Dplatform=linuxarm $@ clean dist
mv linux/arduino-*-linuxarm.tar.xz ../

ant -Djava.net.preferIPv4Stack=true -Dplatform=linuxaarch64 $@ clean dist
mv linux/arduino-*-linuxaarch64.tar.xz ../

ant -Djava.net.preferIPv4Stack=true -Dplatform=windows $@ clean dist
mv windows/arduino-*-windows.zip ../

ant -Djava.net.preferIPv4Stack=true -Dplatform=macosx $@ clean dist
mv macosx/arduino-*-macosx.zip ../
#!/bin/bash -e

cd linux/work

./arduino --board arduino:avr:uno --verify examples/01.Basics/Blink/Blink.ino

for s in `find examples/0{1,2,3,4,5,6,7,8}* -name '*.ino' -not -name '*MultiSerial*'`
do
	echo arduino:avr:uno $s
	./arduino-builder -hardware ./hardware -tools ./hardware/tools/avr -tools ./tools-builder -libraries ./libraries -fqbn arduino:avr:uno $s
	echo
done

for s in `find libraries/{Ethernet,Firmata,GSM,LiquidCrystal,SD,Servo,SpacebrewYun,Stepper,Temboo,TFT,WiFi} -name '*.ino' -not -name 'StandardFirmataEthernet.ino' -not -name 'StandardFirmataYun.ino' -not -name 'StandardFirmataChipKIT.ino' -not -name 'firmata_test.ino' -not -wholename 'libraries/Bridge/examples/Temboo*'`
do
	echo arduino:avr:uno $s
	./arduino-builder -hardware ./hardware -tools ./hardware/tools/avr -tools ./tools-builder -libraries ./libraries -fqbn arduino:avr:uno $s
	echo
done

for s in `find examples/0{1,2,3,4,5,6,7,8,9}* -name '*.ino'`
do
	echo arduino:avr:leonardo $s
	./arduino-builder -hardware ./hardware -tools ./hardware/tools/avr -tools ./tools-builder -libraries ./libraries -fqbn arduino:avr:leonardo $s
	echo
done

for s in `find libraries/{Bridge,Esplora,Ethernet,Firmata,GSM,Keyboard,LiquidCrystal,Mouse,Robot_Control,RobotIRremote,Robot_Motor,SD,Servo,SpacebrewYun,Stepper,Temboo,TFT,WiFi} -name '*.ino' -not -name 'StandardFirmataEthernet.ino' -not -name 'StandardFirmataChipKIT.ino' -not -name 'firmata_test.ino' -not -wholename 'libraries/Bridge/examples/Temboo*'`
do
	echo arduino:avr:leonardo $s
	./arduino-builder -hardware ./hardware -tools ./hardware/tools/avr -tools ./tools-builder -libraries ./libraries -fqbn arduino:avr:leonardo $s
	echo
done

for s in `find examples/0{1,2,3,4,5,6,7,8}* -name '*.ino'`
do
	echo arduino:avr:mega:cpu=atmega2560 $s
	./arduino-builder -hardware ./hardware -tools ./hardware/tools/avr -tools ./tools-builder -libraries ./libraries -fqbn arduino:avr:mega:cpu=atmega2560 $s
	echo
done

for s in `find libraries/{Bridge,Esplora,Ethernet,Firmata,GSM,Keyboard,LiquidCrystal,Mouse,Robot_Control,RobotIRremote,Robot_Motor,SD,Servo,SpacebrewYun,Stepper,Temboo,TFT,WiFi} -name '*.ino' -not -name 'StandardFirmataEthernet.ino' -not -name 'StandardFirmataChipKIT.ino' -not -name 'firmata_test.ino' -not -wholename 'libraries/Bridge/examples/Temboo*'`
do
	echo arduino:avr:mega:cpu=atmega2560 $s
	./arduino-builder -hardware ./hardware -tools ./hardware/tools/avr -tools ./tools-builder -libraries ./libraries -fqbn arduino:avr:mega:cpu=atmega2560 $s
# written by David Pravec
#   - feel free to /msg alekibango on IRC if you want to talk about this file

# TODO: check if --config|-c was used and use configured config file for queries
# TODO: solve somehow completion for  salt -G pythonversion:[tab]
#       (not sure what to do with lists)
# TODO: --range[tab] --   how?
# TODO: --compound[tab] -- how?
# TODO: use history to extract some words, esp. if ${cur} is empty
# TODO: TEST EVERYTHING a lot
# TODO: is it ok to use '--timeout 2' ?


_salt_get_grains(){
    if [ "$1" = 'local' ] ; then
        salt-call --log-level=error --out=txt -- grains.ls | sed  's/^.*\[//' | tr -d ",']" |sed 's:\([a-z0-9]\) :\1\: :g'
    else
      salt '*' --timeout 2 --hide-timeout --log-level=error --out=txt -- grains.ls | sed  's/^.*\[//' | tr -d ",']" |sed 's:\([a-z0-9]\) :\1\: :g'
    fi
}

_salt_get_grain_values(){
    if [ "$1" = 'local' ] ; then
        salt-call --log-level=error --out=txt -- grains.item $1 |sed 's/^\S*:\s//' |grep -v '^\s*$'
    else
        salt '*' --timeout 2 --hide-timeout --log-level=error --out=txt -- grains.item $1 |sed 's/^\S*:\s//' |grep -v '^\s*$'
    fi
}

_salt_get_keys(){
    for type in $*; do
      # remove header from data:
      salt-key --no-color -l $type | tail -n+2
    done
}

_salt_list_functions(){
    # salt-call: get all functions on this minion
    # salt: get all functions on all minions
    # sed: remove all array overhead and convert to newline separated list
    # sort: chop out doubled entries, so overhead is minimal later during actual completion
    if [ "$1" = 'local' ] ; then
        salt-call --log-level=quiet --out=txt -- sys.list_functions \
          | sed "s/^.*\[//;s/[],']//g;s/ /\n/g" \
          | sort -u
    else
        salt '*' --timeout 2 --hide-timeout --log-level=quiet --out=txt -- sys.list_functions \
          | sed "s/^.*\[//;s/[],']//g;s/ /\n/g" \
          | sort -u
    fi
}

_salt_get_coms() {
    CACHE_DIR="$HOME/.cache/salt-${1}-comp-cache_functions"
    local _salt_cache_functions=${SALT_COMP_CACHE_FUNCTIONS:=$CACHE_DIR}
    local _salt_cache_timeout=${SALT_COMP_CACHE_TIMEOUT:='last hour'}

    if [ ! -d "$(dirname ${_salt_cache_functions})" ]; then
        mkdir -p "$(dirname ${_salt_cache_functions})"
    fi

    # Regenerate cache if timed out
    if [[ "$(stat --format=%Z ${_salt_cache_functions} 2>/dev/null)" -lt "$(date --date="${_salt_cache_timeout}" +%s)" ]]; then
	_salt_list_functions $1 > "${_salt_cache_functions}"
    fi

    # filter results, to only print the part to next dot (or end of function)
    sed 's/^\('${cur}'\(\.\|[^.]*\)\)\?.*/\1/' "${_salt_cache_functions}" | sort -u
}

_salt(){

    local cur prev opts _salt_grains _salt_coms pprev ppprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    if [ ${COMP_CWORD} -gt 2 ]; then
        pprev="${COMP_WORDS[COMP_CWORD-2]}"
    fi
    if [ ${COMP_CWORD} -gt 3 ]; then
        ppprev="${COMP_WORDS[COMP_CWORD-3]}"
    fi

    opts="-h --help -d --doc --documentation --version --versions-report -c \
          --config-dir= -v --verbose -t --timeout= -s --static -b --batch= \
          --batch-size= -E --pcre -L --list -G --grain --grain-pcre -N \
          --nodegroup -R --range -C --compound -I --pillar \
          --return= -a --auth= --eauth= --extended-auth= -T --make-token -S \
          --ipcidr --out=pprint --out=yaml --out=overstatestage --out=json \
          --out=raw --out=highstate --out=key --out=txt --no-color --out-indent= "

    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    # 2 special cases for filling up grain values
    case "${pprev}" in
    -G|--grain|--grain-pcre)
    if [ "${cur}" = ":" ]; then
        COMPREPLY=($(compgen -W "`_salt_get_grain_values ${prev}`"))
        return 0
    fi
    ;;
    esac
    case "${ppprev}" in
    -G|--grain|--grain-pcre)
        if [ "${prev}" = ":" ]; then
        COMPREPLY=( $(compgen -W "`_salt_get_grain_values ${pprev}`" -- ${cur}) )
        return 0
        fi
    ;;
    esac

    if [ "${cur}" = "=" ] && [[ "${prev}" == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ "${pprev}" == --* ]]; then
       prev="${pprev}"
    fi

   case "${prev}" in

     -c|--config)
        COMPREPLY=($(compgen -f -- ${cur}))
        return 0
        ;;
     salt)
        COMPREPLY=($(compgen -W "\'*\' ${opts} $(_salt_get_keys acc)" -- ${cur}))
        return 0
        ;;
     -E|--pcre)
        COMPREPLY=($(compgen -W "$(_salt_get_keys acc)" -- ${cur}))
        return 0
        ;;
     -G|--grain|--grain-pcre)
        COMPREPLY=($(compgen -W "$(_salt_get_grains)" -- ${cur}))
        return 0
        ;;
     -C|--compound)
        COMPREPLY=() # TODO: finish this one? how?
        return 0
        ;;
     -t|--timeout)
        COMPREPLY=($( compgen -W "1 2 3 4 5 6 7 8 9 10 15 20 30 40 60 90 120 180" -- ${cur}))
        return 0
        ;;
     -b|--batch|--batch-size)
        COMPREPLY=($(compgen -W "1 2 3 4 5 6 7 8 9 10 15 20 30 40 50 60 70 80 90 100 120 150 200"))
        return 0
        ;;
     -N|--nodegroup)
        MASTER_CONFIG='/etc/salt/master'
        COMPREPLY=($(compgen -W "`awk -F ':'  'BEGIN {print_line = 0};  /^nodegroups/ {print_line = 1;getline } print_line && /^  */ {print $1} /^[^ ]/ {print_line = 0}' <${MASTER_CONFIG}`" -- ${cur}))
        return 0
     ;;
    esac

    _salt_coms=$(_salt_get_coms remote)

    # If there are still dots in the suggestion, do not append space
    grep "^${cur}.*\." "${_salt_coms}" &>/dev/null && compopt -o nospace

    all="${opts} ${_salt_coms}"
    COMPREPLY=( $(compgen -W "${all}" -- ${cur}) )

  return 0
}

complete -F _salt salt


_saltkey(){
    local cur prev opts prev pprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    opts="-c --config-dir= -h --help --version --versions-report -q --quiet \
          -y --yes --gen-keys= --gen-keys-dir= --keysize= --key-logfile= \
          -l --list= -L --list-all -a --accept= -A --accept-all \
          -r --reject= -R --reject-all -p --print= -P --print-all \
          -d --delete= -D --delete-all -f --finger= -F --finger-all \
          --out=pprint --out=yaml --out=overstatestage --out=json --out=raw \
          --out=highstate --out=key --out=txt --no-color --out-indent= "
    if [ ${COMP_CWORD} -gt 2 ]; then
        pprev="${COMP_WORDS[COMP_CWORD-2]}"
    fi
    if [ ${COMP_CWORD} -gt 3 ]; then
        ppprev="${COMP_WORDS[COMP_CWORD-3]}"
    fi
    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    if [ "${cur}" = "=" ] && [[ "${prev}" == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ "${pprev}" == --* ]]; then
       prev="${pprev}"
    fi

    case "${prev}" in
     -a|--accept)
        COMPREPLY=($(compgen -W "$(_salt_get_keys un rej)" -- ${cur}))
        return 0
      ;;
     -r|--reject)
        COMPREPLY=($(compgen -W "$(_salt_get_keys acc)" -- ${cur}))
        return 0
        ;;
     -d|--delete)
        COMPREPLY=($(compgen -W "$(_salt_get_keys acc un rej)" -- ${cur}))
        return 0
        ;;
     -c|--config)
        COMPREPLY=($(compgen -f -- ${cur}))
        return 0
        ;;
     --keysize)
        COMPREPLY=($(compgen -W "2048 3072 4096 5120 6144" -- ${cur}))
        return 0
        ;;
     --gen-keys)
        return 0
        ;;
     --gen-keys-dir)
        COMPREPLY=($(compgen -d -- ${cur}))
        return 0
        ;;
     -p|--print)
        COMPREPLY=($(compgen -W "$(_salt_get_keys acc un rej)" -- ${cur}))
        return 0
     ;;
     -l|--list)
        COMPREPLY=($(compgen -W "pre un acc accepted unaccepted rej rejected all" -- ${cur}))
        return 0
     ;;
     --accept-all)
        return 0
     ;;
    esac
    COMPREPLY=($(compgen -W "${opts} " -- ${cur}))
    return 0
}

complete -F _saltkey salt-key

_saltcall(){
    local cur prev opts _salt_coms pprev ppprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    opts="-h --help -d --doc --documentation --version --versions-report \
          -m --module-dirs= -g --grains --return= --local -c --config-dir= -l --log-level= \
          --out=pprint --out=yaml --out=overstatestage --out=json --out=raw \
          --out=highstate --out=key --out=txt --no-color --out-indent= "
    if [ ${COMP_CWORD} -gt 2 ]; then
        pprev="${COMP_WORDS[COMP_CWORD-2]}"
    fi
    if [ ${COMP_CWORD} -gt 3 ]; then
        ppprev="${COMP_WORDS[COMP_CWORD-3]}"
    fi
    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    if [ "${cur}" = "=" ] && [[ ${prev} == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ ${pprev} == --* ]]; then
       prev="${pprev}"
    fi

    case ${prev} in
        -m|--module-dirs)
                COMPREPLY=( $(compgen -d ${cur} ))
                return 0
                ;;
        -l|--log-level)
                COMPREPLY=( $(compgen -W "info none garbage trace warning error debug" -- ${cur}))
                return 0
                ;;
        -g|grains)
                return 0
                ;;
        salt-call)
                COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
                return 0
                ;;
    esac

    _salt_coms=$(_salt_get_coms local)

    # If there are still dots in the suggestion, do not append space
    grep "^${cur}.*\." "${_salt_coms}" &>/dev/null && compopt -o nospace

    COMPREPLY=( $(compgen -W "${opts} ${_salt_coms}" -- ${cur} ))
    return 0
}

complete -F _saltcall salt-call


_saltcp(){
    local cur prev opts target prefpart postpart helper filt pprev ppprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    opts="-t --timeout= -s --static -b --batch= --batch-size= \
          -h --help --version --versions-report -c --config-dir= \
          -E --pcre -L --list -G --grain --grain-pcre -N --nodegroup \
          -R --range -C --compound -I --pillar \
          --out=pprint --out=yaml --out=overstatestage --out=json --out=raw \
          --out=highstate --out=key --out=txt --no-color --out-indent= "
    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    if [ "${cur}" = "=" ] && [[ "${prev}" == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ "${pprev}" == --* ]]; then
       prev=${pprev}
    fi

    case ${prev} in
        salt-cp)
            COMPREPLY=($(compgen -W "${opts} $(_salt_get_keys acc)" -- ${cur}))
            return 0
            ;;
        -t|--timeout)
            # those numbers are just a hint
            COMPREPLY=($(compgen -W "2 3 4 8 10 15 20 25 30 40 60 90 120 180 240 300" -- ${cur} ))
            return 0
            ;;
    -E|--pcre)
            COMPREPLY=($(compgen -W "$(_salt_get_keys acc)" -- ${cur}))
            return 0
            ;;
    -L|--list)
            # IMPROVEMENTS ARE WELCOME
            prefpart="${cur%,*},"
            postpart=${cur##*,}
            filt="^\($(echo ${cur}| sed 's:,:\\|:g')\)$"
            helper=($(_salt_get_keys acc | grep -v "${filt}" | sed "s/^/${prefpart}/"))
            COMPREPLY=($(compgen -W "${helper[*]}" -- ${cur}))
            return 0
            ;;
    -G|--grain|--grain-pcre)
            COMPREPLY=($(compgen -W "$(_salt_get_grains)" -- ${cur}))
            return 0
            ;;
    # FIXME
    -R|--range)
            # FIXME ??
            return 0
            ;;
    -C|--compound)
            # FIXME ??
            return 0
            ;;
    -c|--config)
            COMPREPLY=($(compgen -f -- ${cur}))
            return 0
            ;;
    esac

# shellcheck shell=bash

# Borrowed from Git's git-sh-setup.
#
# See git.git commit 92c62a3f4 (from 2010!); as of 2020 with Git 2.26,
# this function has only needed one edit since then, adding localization
# with gettext, which we can omit.
require_clean_work_tree () {
    local action="$1"

    git rev-parse --verify HEAD >/dev/null || exit 1
    git update-index -q --ignore-submodules --refresh
    local err=0

    if ! git diff-files --quiet --ignore-submodules; then
        echo >&2 "Cannot $action: You have unstaged changes."
        err=1
    fi

    if ! git diff-index --cached --quiet --ignore-submodules HEAD --; then
        if [ $err = 0 ]; then
            echo >&2 "Cannot $action: Your index contains uncommitted changes."
        else
            echo >&2 "Additionally, your index contains uncommitted changes."
        fi
        err=1
    fi

    if [ $err = 1 ]; then
        git status --short
#!/usr/bin/env bash

set -eux -o pipefail

# make sure git is installed
set +e
git --version
gitres=$?
set -e

if [[ $gitres -ne 0 ]]; then
  ansible-playbook collection-tests/install-git.yml -i ../../inventory "$@"
fi

dir="$(pwd)"

uninstall_git() {
  cd "$dir"
  ansible-playbook collection-tests/uninstall-git.yml -i ../../inventory "$@"
}

# This is kind of a hack. The uninstall playbook has no way to know the result
# of the install playbook to determine if it changed. So instead, we assume
# that if git wasn't found to begin with, it was installed by the playbook and
# and needs to be removed when we exit.
if [[ $gitres -ne 0 ]]; then
  trap uninstall_git EXIT
fi

# init sub project
mkdir "${WORK_DIR}/sub"
cd "${WORK_DIR}/sub"
touch "README.md"
git init
git config user.name 'Ansible Test'
git config user.email 'ansible-test@ansible.com'
git add "README.md"
git commit -m "Initial commit."

# init super project
rm -rf "${WORK_DIR}/super" # needed when re-creating in place
mkdir "${WORK_DIR}/super"
cp -a "${TEST_DIR}/ansible_collections" "${WORK_DIR}/super"
cd "${GIT_TOP_LEVEL}"
git init

# add submodule
git submodule add "${WORK_DIR}/sub" "${SUBMODULE_DST}"

# prepare for tests
expected="${WORK_DIR}/expected.txt"
actual="${WORK_DIR}/actual.txt"
cd "${WORK_DIR}/super/ansible_collections/ns/col"
mkdir tests/.git
touch tests/.git/keep.txt  # make sure ansible-test correctly ignores version control within collection subdirectories
find . -type f ! -path '*/.git/*' ! -name .git | sed 's|^\./||' | sort >"${expected}"
set -x

# test at the collection base
ansible-test env --list-files | sort >"${actual}"
#!/usr/bin/env bash

_tmuxinator() {
    COMPREPLY=()
    local word
    word="${COMP_WORDS[COMP_CWORD]}"

    if [ "$COMP_CWORD" -eq 1 ]; then
        local commands="$(compgen -W "$(tmuxinator commands)" -- "$word")"
        local projects="$(compgen -W "$(tmuxinator completions start)" -- "$word")"

        COMPREPLY=( $commands $projects )
    elif [ "$COMP_CWORD" -eq 2 ]; then
        local words
        words=("${COMP_WORDS[@]}")
        unset words[0]
        unset words[$COMP_CWORD]
        local completions
        completions=$(tmuxinator completions "${words[@]}")
        COMPREPLY=( $(compgen -W "$completions" -- "$word") )
#!/bin/bash

_fastlane_complete() {
  COMPREPLY=()
  local word="${COMP_WORDS[COMP_CWORD]}"
  local completions=""

  # look for Fastfile either in this directory or fastlane/ then grab the lane names
  if [[ -e "Fastfile" ]]; then
    file="Fastfile"
  elif [[ -e "fastlane/Fastfile" ]]; then
    file="fastlane/Fastfile"
  elif [[ -e ".fastlane/Fastfile" ]]; then
    file=".fastlane/Fastfile"
  fi

  # parse 'beta' out of 'lane :beta do', etc
  completions=$(grep "^\s*lane \:" $file | awk -F ':' '{print $2}' | awk -F ' ' '{print $1}')
  completions="$completions update_fastlane"

#!/usr/bin/env bash

#
# @file esp8266-arduino-doc.bash
# @author Ivan Grokhotkov (https://github.com/igrr)
# @author Pascal Gollor (https://github.com/pgollor)
#
#
# This script build the documentation for a specific Arduino ESP8266 release version.
#
# Packages needed by this script:
# * linux commands: ln, cp, mkdir, rm, wget
# * git
#
# ruby gems:
# * jekyll
# * redcarpet
# * rb-pygments
#
# gem install [lib]
#

set -e

# some variable definitions
tmp_path=$1
doc_src_path=$2
arduinoESP_src=$(cd $PWD/..; pwd)
version="$(git --work-tree=$arduinoESP_src --git-dir=$arduinoESP_src/.git describe --tags --always)"
release_date=$(date "+%b_%d,_%Y") # format for badge link
build_date=$(date "+%b %d, %Y")
destination_path="$tmp_path/doc"
doc_template_url="https://github.com/igrr/esp8266-arduino-docs.git"
url="https://esp8266.github.io/Arduino"

# control output
echo "Arduino ESP8266 source dir: "$arduinoESP_src
echo "                   version: "$version
echo "              release date: "$release_date
echo "                build date: "$build_date
echo "    put documentation into: "$destination_path
echo "documentation template url: "$doc_template_url
echo "                       url: "$url

# continue?
read -e -p "Do you wish to continue (y/n)? " -n 1 decision
if echo "$decision" | grep -iq "^y" ;then
	echo "okay"
else
	echo "bye bye"
	exit
fi


# delete old doc dir
rm -fR $destination_path

# create destination directories
mkdir -p $destination_path/src
mkdir -p $destination_path/$version

# copy doc files to destination source dir
cp -R $arduinoESP_src/doc/* $destination_path/src

# download doc template
rsync -av $doc_src_path/ $destination_path/build/
# git clone $doc_template_url $destination_path/build

# create versions.html file

# ... read versions
pushd $arduinoESP_src
old_versions=$(git ls-tree -d --name-only remotes/origin/gh-pages versions/ | sed -e 's/versions\///g')
popd

echo -e "\nREAD old versions:"

found_current_version="false"
case "${old_versions[@]}" in *"$version"*) found_current_version="true" ;; esac

if [ "$found_current_version" = "false" ]; then
	old_versions=$version" "$old_versions
fi

# ... fill versions.html
for VER in $old_versions
do
	echo $VER
	echo "<li><a href=\"versions/$VER\">$VER</a></li>" >> $destination_path/build/_includes/versions.html
done
echo ""


# into build dir
pushd $destination_path/build

# link documentation source
ln -s ../src doc

# link documentation destination
ln -s ../$version _site

# add subtitle and basurl
echo "url: \"$url\"" > _config_local.yml
echo "version: $version"  >> _config_local.yml
echo "build_date: $build_date" >> _config_local.yml
echo "baseurl: /Arduino/versions/$version" >> _config_local.yml
mv doc/reference_items.yml _data/reference_items.yml

# build with jekyll
jekyll build --config _config.yml,_config_local.yml

popd


unset PYENV_VERSION
unset PYENV_DIR

# guard against executing this block twice due to bats internals
if [ -z "$PYENV_TEST_DIR" ]; then
  PYENV_TEST_DIR="${BATS_TMPDIR}/pyenv"
  export PYENV_TEST_DIR="$(mktemp -d "${PYENV_TEST_DIR}.XXX" 2>/dev/null || echo "$PYENV_TEST_DIR")"

  if enable -f "${BATS_TEST_DIRNAME}"/../libexec/pyenv-realpath.dylib realpath 2>/dev/null; then
    export PYENV_TEST_DIR="$(realpath "$PYENV_TEST_DIR")"
  else
    if [ -n "$PYENV_NATIVE_EXT" ]; then
      echo "pyenv: failed to load \`realpath' builtin" >&2
      exit 1
    fi
  fi

  export PYENV_ROOT="${PYENV_TEST_DIR}/root"
  export HOME="${PYENV_TEST_DIR}/home"
  export PYENV_HOOK_PATH="${PYENV_ROOT}/pyenv.d"

  PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin
  PATH="${PYENV_TEST_DIR}/bin:$PATH"
  PATH="${BATS_TEST_DIRNAME}/../libexec:$PATH"
  PATH="${BATS_TEST_DIRNAME}/libexec:$PATH"
  PATH="${PYENV_ROOT}/shims:$PATH"
  export PATH

  for xdg_var in `env 2>/dev/null | grep ^XDG_ | cut -d= -f1`; do unset "$xdg_var"; done
  unset xdg_var
fi

teardown() {
  rm -rf "$PYENV_TEST_DIR"
}

flunk() {
  { if [ "$#" -eq 0 ]; then cat -
    else echo "$@"
    fi
  } | sed "s:${PYENV_TEST_DIR}:TEST_DIR:g" >&2
  return 1
}

assert_success() {
  if [ "$status" -ne 0 ]; then
    flunk "command failed with exit status $status"
  elif [ "$#" -gt 0 ]; then
    assert_output "$1"
  fi
}

assert_failure() {
  if [ "$status" -eq 0 ]; then
    flunk "expected failed exit status"
  elif [ "$#" -gt 0 ]; then
    assert_output "$1"
  fi
}

assert_equal() {
  if [ "$1" != "$2" ]; then
    { echo "expected: $1"
      echo "actual:   $2"
    } | flunk
  fi
}

assert_output() {
  local expected
  if [ $# -eq 0 ]; then expected="$(cat -)"
  else expected="$1"
  fi
  assert_equal "$expected" "$output"
}

assert_line() {
  if [ "$1" -ge 0 ] 2>/dev/null; then
    assert_equal "$2" "${lines[$1]}"
  else
    local line
    for line in "${lines[@]}"; do
      if [ "$line" = "$1" ]; then return 0; fi
    done
    flunk "expected line \`$1'"
  fi
}

refute_line() {
  if [ "$1" -ge 0 ] 2>/dev/null; then
    local num_lines="${#lines[@]}"
    if [ "$1" -lt "$num_lines" ]; then
      flunk "output has $num_lines lines"
    fi
  else
    local line
    for line in "${lines[@]}"; do
      if [ "$line" = "$1" ]; then
        flunk "expected to not find line \`$line'"
      fi
    done
  fi
}

assert() {
  if ! "$@"; then
    flunk "failed: $@"
  fi
}

# Output a modified PATH that ensures that the given executable is not present,
# but in which system utils necessary for pyenv operation are still available.
path_without() {
  local exe="$1"
  local path=":${PATH}:"
  local found alt util
  for found in $(which -a "$exe"); do
    found="${found%/*}"
    if [ "$found" != "${PYENV_ROOT}/shims" ]; then
      alt="${PYENV_TEST_DIR}/$(echo "${found#/}" | tr '/' '-')"
      mkdir -p "$alt"
      for util in bash head cut readlink greadlink; do
        if [ -x "${found}/$util" ]; then
          ln -s "${found}/$util" "${alt}/$util"
        fi
      done
      path="${path/:${found}:/:${alt}:}"
    fi
  done
  path="${path#:}"
  echo "${path%:}"
}

create_hook() {
  mkdir -p "${PYENV_HOOK_PATH}/$1"
_pyenv() {
  COMPREPLY=()
  local word="${COMP_WORDS[COMP_CWORD]}"

  if [ "$COMP_CWORD" -eq 1 ]; then
    COMPREPLY=( $(compgen -W "$(pyenv commands)" -- "$word") )
  else
    local words=("${COMP_WORDS[@]}")
    unset words[0]
    unset words[$COMP_CWORD]
    local completions=$(pyenv completions "${words[@]}")
    COMPREPLY=( $(compgen -W "$completions" -- "$word") )
  fi
}

PYENV_PIP_REHASH_ROOT="${BASH_SOURCE[0]%/*}/pip-rehash"
PYENV_REHASH_COMMAND="${PYENV_COMMAND##*/}"

# Remove any version information, from e.g. "pip2" or "pip3.4".
if [[ $PYENV_REHASH_COMMAND =~ ^(pip|easy_install)[23](\.\d)?$ ]]; then
  PYENV_REHASH_COMMAND="${BASH_REMATCH[1]}"
fi

if [ -x "${PYENV_PIP_REHASH_ROOT}/${PYENV_REHASH_COMMAND}" ]; then
  PYENV_COMMAND_PATH="${PYENV_PIP_REHASH_ROOT}/${PYENV_REHASH_COMMAND##*/}"
PROTOTYPE_SOURCE_SHIM_PATH="${SHIM_PATH}/.pyenv-source-shim"

shims=()
shopt -s nullglob
for shim in $(cat "${BASH_SOURCE%/*}/source.d/"*".list" | sort | uniq | sed -e 's/#.*$//' | sed -e '/^[[:space:]]*$/d'); do
  if [ -n "${shim##*/}" ]; then
    shims[${#shims[*]}]="${shim})return 0;;"
  fi
done
shopt -u nullglob
eval "source_shim(){ case \"\${1##*/}\" in ${shims[@]} *)return 1;;esac;}"

cat > "${PROTOTYPE_SOURCE_SHIM_PATH}" <<SH
[ -n "\$PYENV_DEBUG" ] && set -x
export PYENV_ROOT="${PYENV_ROOT}"
program="\$("$(command -v pyenv)" which "\${BASH_SOURCE##*/}")"
if [ -e "\${program}" ]; then
  . "\${program}" "\$@"
fi
SH
chmod +x "${PROTOTYPE_SOURCE_SHIM_PATH}"

shopt -s nullglob
for shim in "${SHIM_PATH}/"*; do
  if source_shim "${shim}"; then
    cp "${PROTOTYPE_SOURCE_SHIM_PATH}" "${shim}"
  fi
done
shopt -u nullglob

# Anaconda comes with binaries of system packages (e.g. `openssl`, `curl`).
# Creating shims for those binaries will prevent pyenv users to run those
# commands normally when not using Anaconda.
#
# This hooks is intended to skip creating shims for those executables.

conda_exists() {
  shopt -s nullglob
  local condas=($(echo "${PYENV_ROOT}/versions/"*"/bin/conda" "${PYENV_ROOT}/versions/"*"/envs/"*"/bin/conda"))
  shopt -u nullglob
  [ -n "${condas}" ]
}

shims=()
shopt -s nullglob
for shim in $(cat "${BASH_SOURCE%/*}/conda.d/"*".list" | sort | uniq | sed -e 's/#.*$//' | sed -e '/^[[:space:]]*$/d'); do
  if [ -n "${shim##*/}" ]; then
    shims[${#shims[*]}]="${shim})return 0;;"
  fi
done
shopt -u nullglob
eval "conda_shim(){ case \"\${1##*/}\" in ${shims[@]} *)return 1;;esac;}"

# override `make_shims` to avoid conflict between pyenv-virtualenv's `envs.bash`
# https://github.com/pyenv/pyenv-virtualenv/blob/v20160716/etc/pyenv.d/rehash/envs.bash
make_shims() {
  local file shim
  for file do
    shim="${file##*/}"
    if ! conda_shim "${shim}" 1>&2; then
      register_shim "$shim"
    fi
  done
}

deregister_conda_shims() {
  local shim
  local shims=()
  for shim in ${registered_shims}; do
    if ! conda_shim "${shim}" 1>&2; then
      shims[${#shims[*]}]="${shim}"
    fi
  done
  registered_shims=" ${shims[@]} "
}
export TMP="$BATS_TEST_DIRNAME/tmp"
export PYTHON_BUILD_CURL_OPTS=
export PYTHON_BUILD_HTTP_CLIENT="curl"

if [ "$FIXTURE_ROOT" != "$BATS_TEST_DIRNAME/fixtures" ]; then
  export FIXTURE_ROOT="$BATS_TEST_DIRNAME/fixtures"
  export INSTALL_ROOT="$TMP/install"
  PATH="/usr/bin:/bin:/usr/sbin:/sbin"
  if [ "FreeBSD" = "$(uname -s)" ]; then
    PATH="/usr/local/bin:$PATH"
  fi
  PATH="$BATS_TEST_DIRNAME/../bin:$PATH"
  PATH="$TMP/bin:$PATH"
  export PATH
fi

teardown() {
  rm -fr "${TMP:?}"/*
}

stub() {
  local program="$1"
  local prefix="$(echo "$program" | tr a-z- A-Z_)"
  shift

  export "${prefix}_STUB_PLAN"="${TMP}/${program}-stub-plan"
  export "${prefix}_STUB_RUN"="${TMP}/${program}-stub-run"
  export "${prefix}_STUB_END"=

  mkdir -p "${TMP}/bin"
  ln -sf "${BATS_TEST_DIRNAME}/stubs/stub" "${TMP}/bin/${program}"

  touch "${TMP}/${program}-stub-plan"
  for arg in "$@"; do printf "%s\n" "$arg" >> "${TMP}/${program}-stub-plan"; done
}

unstub() {
  local program="$1"
  local prefix="$(echo "$program" | tr a-z- A-Z_)"
  local path="${TMP}/bin/${program}"

  export "${prefix}_STUB_END"=1

  local STATUS=0
  "$path" || STATUS="$?"

  rm -f "$path"
  rm -f "${TMP}/${program}-stub-plan" "${TMP}/${program}-stub-run"
  return "$STATUS"
}

run_inline_definition() {
  local definition="${TMP}/build-definition"
  cat > "$definition"
  run python-build "$definition" "${1:-$INSTALL_ROOT}"
}

install_fixture() {
  local args

  while [ "${1#-}" != "$1" ]; do
    args="$args $1"
    shift 1
  done

  local name="$1"
  local destination="$2"
  [ -n "$destination" ] || destination="$INSTALL_ROOT"

  run python-build $args "$FIXTURE_ROOT/$name" "$destination"
}

assert() {
  if ! "$@"; then
    flunk "failed: $@"
  fi
}

refute() {
  if "$@"; then
    flunk "expected to fail: $@"
  fi
}

flunk() {
  { if [ "$#" -eq 0 ]; then cat -
    else echo "$@"
    fi
  } | sed "s:${TMP}:\${TMP}:g" >&2
  return 1
}

assert_success() {
  if [ "$status" -ne 0 ]; then
    { echo "command failed with exit status $status"
      echo "output: $output"
    } | flunk
  elif [ "$#" -gt 0 ]; then
    assert_output "$1"
  fi
}

assert_failure() {
  if [ "$status" -eq 0 ]; then
    flunk "expected failed exit status"
  elif [ "$#" -gt 0 ]; then
    assert_output "$1"
  fi
}

assert_equal() {
  if [ "$1" != "$2" ]; then
    { echo "expected: $1"
      echo "actual:   $2"
    } | flunk
  fi
}

assert_output() {
  local expected
  if [ $# -eq 0 ]; then expected="$(cat -)"
  else expected="$1"
  fi
  assert_equal "$expected" "$output"
}

assert_output_contains() {
  local expected="$1"
  if [ -z "$expected" ]; then
    echo "assert_output_contains needs an argument" >&2
    return 1
  fi
  echo "$output" | $(type -p ggrep grep | head -1) -F "$expected" >/dev/null || {
    { echo "expected output to contain $expected"
      echo "actual: $output"
#!/usr/bin/env bash

# Copyright ©2017 The Gonum Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# Generate code for blas32.
echo Generating blas32/conv.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv.go
cat blas64/conv.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
\
>> blas32/conv.go

echo Generating blas32/conv_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv_test.go
cat blas64/conv_test.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
\
>> blas32/conv_test.go

echo Generating blas32/conv_symmetric.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv_symmetric.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
\
>> blas32/conv_symmetric.go

echo Generating blas32/conv_symmetric_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv_symmetric_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
\
>> blas32/conv_symmetric_test.go


# Generate code for cblas128.
echo Generating cblas128/conv.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv.go
cat blas64/conv.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
\
>> cblas128/conv.go

echo Generating cblas128/conv_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_test.go
cat blas64/conv_test.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's_"math"_math "math/cmplx"_' \
\
>> cblas128/conv_test.go

echo Generating cblas128/conv_symmetric.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_symmetric.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
\
>> cblas128/conv_symmetric.go

echo Generating cblas128/conv_symmetric_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_symmetric_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's_"math"_math "math/cmplx"_' \
\
>> cblas128/conv_symmetric_test.go

echo Generating cblas128/conv_hermitian.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_hermitian.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
      -e 's/Sym/Herm/g' \
\
>> cblas128/conv_hermitian.go

echo Generating cblas128/conv_hermitian_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_hermitian_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
      -e 's/Sym/Herm/g' \
      -e 's_"math"_math "math/cmplx"_' \
\
>> cblas128/conv_hermitian_test.go


# Generate code for cblas64.
echo Generating cblas64/conv.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv.go
cat blas64/conv.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
\
>> cblas64/conv.go

echo Generating cblas64/conv_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv_test.go
cat blas64/conv_test.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/cmplx64"_' \
\
>> cblas64/conv_test.go

echo Generating cblas64/conv_hermitian.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv_hermitian.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
      -e 's/Sym/Herm/g' \
\
>> cblas64/conv_hermitian.go

echo Generating cblas64/conv_hermitian_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv_hermitian_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
#!/usr/bin/env bash

# Copyright ©2015 The Gonum Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

WARNINGF32='//\
// Float32 implementations are autogenerated and not directly tested.\
'
WARNINGC64='//\
// Complex64 implementations are autogenerated and not directly tested.\
'

# Level1 routines.

echo Generating level1float32.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32.go
cat level1float64.go \
| gofmt -r 'blas.Float64Level1 -> blas.Float32Level1' \
\
| gofmt -r 'float64 -> float32' \
| gofmt -r 'blas.DrotmParams -> blas.SrotmParams' \
\
| gofmt -r 'f64.AxpyInc -> f32.AxpyInc' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
| gofmt -r 'f64.ScalInc -> f32.ScalInc' \
| gofmt -r 'f64.ScalUnitary -> f32.ScalUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e "s_^\(func (Implementation) \)Id\(.*\)\$_$WARNINGF32\1Is\2_" \
      -e 's_^// Id_// Is_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
>> level1float32.go

echo Generating level1cmplx64.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1cmplx64.go
cat level1cmplx128.go \
| gofmt -r 'blas.Complex128Level1 -> blas.Complex64Level1' \
\
| gofmt -r 'float64 -> float32' \
| gofmt -r 'complex128 -> complex64' \
\
| gofmt -r 'c128.AxpyInc -> c64.AxpyInc' \
| gofmt -r 'c128.AxpyUnitary -> c64.AxpyUnitary' \
| gofmt -r 'c128.DotcInc -> c64.DotcInc' \
| gofmt -r 'c128.DotcUnitary -> c64.DotcUnitary' \
| gofmt -r 'c128.DotuInc -> c64.DotuInc' \
| gofmt -r 'c128.DotuUnitary -> c64.DotuUnitary' \
| gofmt -r 'c128.ScalInc -> c64.ScalInc' \
| gofmt -r 'c128.ScalUnitary -> c64.ScalUnitary' \
| gofmt -r 'dcabs1 -> scabs1' \
\
| sed -e "s_^\(func (Implementation) \)Zdot\(.*\)\$_$WARNINGC64\1Cdot\2_" \
      -e 's_^// Zdot_// Cdot_' \
      -e "s_^\(func (Implementation) \)Zdscal\(.*\)\$_$WARNINGC64\1Csscal\2_" \
      -e 's_^// Zdscal_// Csscal_' \
      -e "s_^\(func (Implementation) \)Z\(.*\)\$_$WARNINGC64\1C\2_" \
      -e 's_^// Z_// C_' \
      -e "s_^\(func (Implementation) \)Iz\(.*\)\$_$WARNINGC64\1Ic\2_" \
      -e 's_^// Iz_// Ic_' \
      -e "s_^\(func (Implementation) \)Dz\(.*\)\$_$WARNINGC64\1Sc\2_" \
      -e 's_^// Dz_// Sc_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/c128"_"gonum.org/v1/gonum/internal/asm/c64"_' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
>> level1cmplx64.go

echo Generating level1float32_sdot.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32_sdot.go
cat level1float64_ddot.go \
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.DotInc -> f32.DotInc' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level1float32_sdot.go

echo Generating level1float32_dsdot.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32_dsdot.go
cat level1float64_ddot.go \
| gofmt -r '[]float64 -> []float32' \
\
| gofmt -r 'f64.DotInc -> f32.DdotInc' \
| gofmt -r 'f64.DotUnitary -> f32.DdotUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1Ds\2_" \
      -e 's_^// D_// Ds_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level1float32_dsdot.go

echo Generating level1float32_sdsdot.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32_sdsdot.go
cat level1float64_ddot.go \
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.DotInc(x, y, f(n), f(incX), f(incY), f(ix), f(iy)) -> alpha + float32(f32.DdotInc(x, y, f(n), f(incX), f(incY), f(ix), f(iy)))' \
| gofmt -r 'f64.DotUnitary(a, b) -> alpha + float32(f32.DdotUnitary(a, b))' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1Sds\2_" \
      -e 's_^// D\(.*\)$_// Sds\1 plus a constant_' \
      -e 's_\\sum_alpha + \\sum_' \
      -e 's/n int/n int, alpha float32/' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level1float32_sdsdot.go


# Level2 routines.

echo Generating level2float32.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level2float32.go
cat level2float64.go \
| gofmt -r 'blas.Float64Level2 -> blas.Float32Level2' \
\
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.AxpyInc -> f32.AxpyInc' \
| gofmt -r 'f64.AxpyIncTo -> f32.AxpyIncTo' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.AxpyUnitaryTo -> f32.AxpyUnitaryTo' \
| gofmt -r 'f64.DotInc -> f32.DotInc' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
| gofmt -r 'f64.ScalInc -> f32.ScalInc' \
| gofmt -r 'f64.ScalUnitary -> f32.ScalUnitary' \
| gofmt -r 'f64.Ger -> f32.Ger' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level2float32.go

echo Generating level2cmplx64.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level2cmplx64.go
cat level2cmplx128.go \
| gofmt -r 'blas.Complex128Level2 -> blas.Complex64Level2' \
\
| gofmt -r 'complex128 -> complex64' \
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'c128.AxpyInc -> c64.AxpyInc' \
| gofmt -r 'c128.AxpyUnitary -> c64.AxpyUnitary' \
| gofmt -r 'c128.DotuInc -> c64.DotuInc' \
| gofmt -r 'c128.DotuUnitary -> c64.DotuUnitary' \
| gofmt -r 'c128.ScalInc -> c64.ScalInc' \
| gofmt -r 'c128.ScalUnitary -> c64.ScalUnitary' \
\
| sed -e "s_^\(func (Implementation) \)Z\(.*\)\$_$WARNINGC64\1C\2_" \
      -e 's_^// Z_// C_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/c128"_"gonum.org/v1/gonum/internal/asm/c64"_' \
      -e 's_"math/cmplx"_cmplx "gonum.org/v1/gonum/internal/cmplx64"_' \
>> level2cmplx64.go

# Level3 routines.

echo Generating level3float32.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level3float32.go
cat level3float64.go \
| gofmt -r 'blas.Float64Level3 -> blas.Float32Level3' \
\
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.AxpyUnitaryTo -> f32.AxpyUnitaryTo' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
| gofmt -r 'f64.ScalUnitary -> f32.ScalUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level3float32.go

echo Generating sgemm.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > sgemm.go
cat dgemm.go \
| gofmt -r 'float64 -> float32' \
| gofmt -r 'sliceView64 -> sliceView32' \
\
| gofmt -r 'dgemmParallel -> sgemmParallel' \
| gofmt -r 'computeNumBlocks64 -> computeNumBlocks32' \
| gofmt -r 'dgemmSerial -> sgemmSerial' \
| gofmt -r 'dgemmSerialNotNot -> sgemmSerialNotNot' \
| gofmt -r 'dgemmSerialTransNot -> sgemmSerialTransNot' \
| gofmt -r 'dgemmSerialNotTrans -> sgemmSerialNotTrans' \
| gofmt -r 'dgemmSerialTransTrans -> sgemmSerialTransTrans' \
\
| gofmt -r 'f64.AxpyInc -> f32.AxpyInc' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_^// d_// s_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> sgemm.go

echo Generating level3cmplx64.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level3cmplx64.go
cat level3cmplx128.go \
| gofmt -r 'blas.Complex128Level3 -> blas.Complex64Level3' \
\
| gofmt -r 'float64 -> float32' \
| gofmt -r 'complex128 -> complex64' \
\
| gofmt -r 'c128.ScalUnitary -> c64.ScalUnitary' \
| gofmt -r 'c128.DscalUnitary -> c64.SscalUnitary' \
| gofmt -r 'c128.DotcUnitary -> c64.DotcUnitary' \
| gofmt -r 'c128.AxpyUnitary -> c64.AxpyUnitary' \
| gofmt -r 'c128.DotuUnitary -> c64.DotuUnitary' \
\
| sed -e "s_^\(func (Implementation) \)Z\(.*\)\$_$WARNINGC64\1C\2_" \
      -e 's_^// Z_// C_' \
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/bin/bash

go test || exit
for action in $@; do go $action; done

mkdir -p bin
find regretable examples/* ext/* -maxdepth 0 -type d | while read d; do
	(cd $d
	go build -o ../../bin/$(basename $d)
	find *_test.go -maxdepth 0 2>/dev/null|while read f;do
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
# setup and teardown for tests
setup_environment() {
    rm -r .home/
    mkdir .home/

#
# Rudimentary Bash completion definition for nnn.
#
# Author:
#   Arun Prakash Jana <engineerarun@gmail.com>
#

_nnn ()
{
    COMPREPLY=()
    local IFS=$'\n'
    local cur=$2 prev=$3
    local -a opts
    opts=(
        -a
        -A
        -b
        -c
        -C
        -d
        -D
        -e
        -E
        -f
        -F
        -g
        -H
        -J
        -K
        -l
        -n
        -o
        -p
        -P
        -Q
        -r
        -R
        -s
        -S
        -t
        -T
        -U
        -V
        -w
        -x
        -h
    )
    if [[ $prev == -b ]]; then
        local bookmarks=$(echo $NNN_BMS | awk -F: -v RS=\; '{print $1}')
        COMPREPLY=( $(compgen -W "$bookmarks" -- "$cur") )
    elif [[ $prev == -l ]]; then
        return 1
    elif [[ $prev == -p ]]; then
        COMPREPLY=( $(compgen -f -d -- "$cur") )
    elif [[ $prev == -P ]]; then
        local plugins=$(echo $NNN_PLUG | awk -F: -v RS=\; '{print $1}')
        COMPREPLY=( $(compgen -W "$plugins" -- "$cur") )
    elif [[ $prev == -s ]]; then
        local sessions_dir=${XDG_CONFIG_HOME:-$HOME/.config}/nnn/sessions
        COMPREPLY=( $(cd "$sessions_dir" && compgen -f -d -- "$cur") )
    elif [[ $prev == -t ]]; then
        return 1
    elif [[ $prev == -T ]]; then
        local keys=$(echo "a d e r s t v" | awk -v RS=' ' '{print $0}')
        COMPREPLY=( $(compgen -W "$keys" -- "$cur") )
    elif [[ $cur == -* ]]; then
        COMPREPLY=( $(compgen -W "${opts[*]}" -- "$cur") )
    else
        COMPREPLY=( $(compgen -f -d -- "$cur") )
    fi
#!/usr/bin/env bash


_http_complete() {
    local cur_word=${COMP_WORDS[COMP_CWORD]}
    local prev_word=${COMP_WORDS[COMP_CWORD - 1]}

    if [[ "$cur_word" == -*  ]]; then
        _http_complete_options "$cur_word"
    fi
}

complete -o default -F _http_complete http

_http_complete_options() {
    local cur_word=$1
    local options="-j --json -f --form --pretty -s --style -p --print
    -v --verbose -h --headers -b --body -S --stream -o --output -d --download
    -c --continue --session --session-read-only -a --auth --auth-type --proxy
    --follow --verify --cert --cert-key --timeout --check-status --ignore-stdin
#! /bin/bash

# Copyright (c) Facebook, Inc. and its affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

set -e

todo=$1
# other options can be transmitted
shift

# the training data of the Deep1B dataset
deep1bdir=/datasets01_101/simsearch/041218/deep1b
traindata=$deep1bdir/learn.fvecs

# this is for small tests
nvec=1000000
k=4000

# for the real run
# nvec=50000000
# k=1000000

# working directory for the real run
workdir=/checkpoint/matthijs/ondisk_distributed
mkdir -p $workdir/{vslices,hslices}

if [ -z "$todo" ]; then
    echo "nothing to do"
    exit 1
elif [ $todo == test_kmeans_0 ]; then
    # non distributed baseline
    python distributed_kmeans.py \
           --indata $traindata --i1 $nvec \
           --k $k

elif [ $todo == test_kmeans_1 ]; then
    # using all the machine's GPUs
    python distributed_kmeans.py \
           --indata $traindata --i1 $nvec \
           --k $k --gpu -1

elif [ $todo == test_kmeans_2 ]; then
    # distrbuted run, with one local server per GPU
    ngpu=$( echo /dev/nvidia? | wc -w )
    baseport=12012

    # kill background porcesses on output of this script
    trap 'kill -HUP 0' 0

    hostports=''

    for((gpu=0;gpu<ngpu;gpu++)); do
        # range of vectors to assign to each sever
        i0=$((nvec * gpu / ngpu))
        i1=$((nvec * (gpu + 1) / ngpu))
        port=$(( baseport + gpu ))

        echo "start server $gpu for range $i0:$i1"

        python distributed_kmeans.py \
               --indata $traindata \
               --i0 $i0 --i1 $i1 \
               --server --gpu $gpu \
               --port $port --ipv4 &

        hostports="$hostports localhost:$port"
    done

    # lame way of making sure all servers are running
    sleep 5s

    python distributed_kmeans.py \
           --client --servers "$hostports" \
           --k $k --ipv4

elif [ $todo == slurm_distributed_kmeans ]; then

    nserv=5

    srun -n$nserv \
         --time=48:00:00 \
         --cpus-per-task=40 --gres=gpu:4 --mem=100G \
         --partition=priority --comment='priority is the only one that works'  \
         -l bash $( realpath $0 ) slurm_within_kmeans_server

elif [ $todo == slurm_within_kmeans_server ]; then

   nserv=$SLURM_NPROCS
   [ ! -z "$nserv" ] || (echo "should be run by slurm"; exit 1)
   rank=$SLURM_PROCID

   baseport=12012

   i0=$((nvec * rank / nserv))
   i1=$((nvec * (rank + 1) / nserv))
   port=$(( baseport + rank ))

   echo "host $(hostname) start server $rank for range $i0:$i1 port $port"

   if [ $rank != 0 ]; then

       python -u distributed_kmeans.py \
              --indata $traindata \
              --i0 $i0 --i1 $i1 \
              --server --gpu -1 \
              --port $port --ipv4
   else
       # master process

       # kill background processes on output of this script
       trap 'kill -HUP 0' 0

       python -u distributed_kmeans.py \
              --indata $traindata \
              --i0 $i0 --i1 $i1 \
              --server --gpu -1 \
              --port $port --ipv4 &

       # Slurm has a somewhat convoluted way of specifying the nodes
       # assigned to each task. This is to parse the SLURM_TASKS_PER_NODE variable
       function parse_tasks_per_node () {
           local blocks=$1
           for block in ${blocks//,/ }; do
               if [ ${block/x/} != $block ]; then
                   tpn="${block%(*}"
                   repeat=${block#*x}
                   repeat=${repeat%?}
                   for((i=0;i<repeat;i++)); do
                       echo $tpn
                   done
               else
                   echo $block
               fi
            done
       }

       hostports=""
       port=$baseport
       echo VARS $SLURM_TASKS_PER_NODE $SLURM_JOB_NODELIST
       tasks_per_node=( $( parse_tasks_per_node $SLURM_TASKS_PER_NODE ) )
       nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
       n=${#nodes[*]}
       for((i=0;i<n;i++)); do
           hostname=${nodes[i]}
           for((j=0;j<tasks_per_node[i];j++)); do
               hostports="$hostports $hostname:$port"
               ((port++))
           done
       done

       echo HOSTPORTS $hostports

       sleep 20s

       # run client
       python distributed_kmeans.py \
           --client --servers "$hostports" \
           --k $k --ipv4 "$@"

       echo "Done, kill the job"
       scancel $SLURM_JOBID

   fi

elif [ $todo == deep1b_clustering ]; then
    # also set nvec=500M and k=10M in the top of the file
    nserv=20

    srun -n$nserv \
         --time=48:00:00 \
         --cpus-per-task=40 --gres=gpu:4 --mem=100G \
         --partition=priority --comment='priority is the only one that works'  \
         -l bash $( realpath $0 ) slurm_within_kmeans_server \
         --out $workdir/1M_centroids.npy

elif [ $todo == make_index_vslices ]; then

    # vslice: slice per database shards

    nvec=1000000000
    nslice=200

    for((i=0;i<nslice;i++)); do
        i0=$((nvec * i / nslice))
        i1=$((nvec * (i + 1) / nslice))

        # make the script to be run by sbatch
        cat > $workdir/vslices/slice$i.bash <<EOF
#!/bin/bash

srun python -u make_index_vslice.py \
                 --inputindex $workdir/trained.faissindex \
                 --input $deep1bdir/base.fvecs \
                 --nt 40 \
                 --i0 $i0 --i1 $i1 \
                 -o $workdir/vslices/slice$i.faissindex

EOF
        # specify resources for script and run it
        sbatch -n1 \
             --time=48:00:00 \
             --cpus-per-task=40 --gres=gpu:0 --mem=200G \
             --output=$workdir/vslices/slice$i.log \
             --job-name=vslice$i.c \
             $workdir/vslices/slice$i.bash
        echo "logs in $workdir/vslices/slice$i.log"

    done

elif [ $todo == make_index_hslices ]; then

    # hslice: slice per inverted lists

    nlist=1000000
    nslice=50

    for((i=0;i<nslice;i++)); do
        i0=$((nlist * i / nslice))
        i1=$((nlist * (i + 1) / nslice))

        # make the script to be run by sbatch
        cat > $workdir/hslices/slice$i.bash <<EOF
#!/bin/bash

srun python -u merge_to_ondisk.py \
                 --input $workdir/vslices/slice{0..199}.faissindex \
                 --nt 20 \
                 --l0 $i0 --l1 $i1 \
                 --output $workdir/hslices/slice$i.faissindex \
                 --outputIL $workdir/hslices/slice$i.invlists


EOF
        # specify resources for script and run it
        sbatch -n1 \
             --time=48:00:00 \
             --cpus-per-task=20 --gres=gpu:0 --mem=200G \
             --output=$workdir/hslices/slice$i.log \
             --job-name=hslice$i.a \
             --constraint=pascal \
             $workdir/hslices/slice$i.bash
        echo "logs in $workdir/hslices/slice$i.log"

    done

elif [ $todo == run_search_servers ]; then

    nserv=3

    srun -n$nserv \
         --time=48:00:00 \
         --cpus-per-task=64 --gres=gpu:0 --mem=100G \
         --constraint=pascal \
         --partition=priority --comment='priority is the only one that works'  \
         -l python -u search_server.py --port 12012


set -e

# Copyright (c) Facebook, Inc. and its affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

# @nolint

# This script launches the experiments on a cluster
# It assumes two shell functions are defined:
#
#    run_on_1machine: runs a command on one (full) machine on a cluster
#
#    run_on_8gpu: runs a command on one machine with 8 GPUs
#
# the two functions are called as:
#
#    run_on_1machine <name> <command>
#
# the stdout of the command should be stored in $logdir/<name>.stdout


function run_on ()
{
    sys="$1"
    shift
    name="$1"
    shift
    script="$logdir/$name.sh"

    if [ -e "$script" ]; then
        echo script "$script" exists
        return
    fi

    # srun handles special characters fine, but the shell interpreter
    # does not
    escaped_cmd=$( printf "%q " "$@" )

    cat > $script <<EOF
#! /bin/bash
srun $escaped_cmd
EOF

    echo -n "$logdir/$name.stdout "
    sbatch -n1 -J "$name" \
           $sys \
            --comment='priority is the only one that works'  \
           --output="$logdir/$name.stdout" \
           "$script"

}


function run_on_1machine {
    run_on "--cpus-per-task=80 --gres=gpu:0 --mem=500G --time=70:00:00 --partition=priority" "$@"
}

function run_on_1machine_1h {
    run_on "--cpus-per-task=80 --gres=gpu:2 --mem=100G --time=1:00:00 --partition=priority" "$@"
}

function run_on_1machine_3h {
    run_on "--cpus-per-task=80 --gres=gpu:2 --mem=100G --time=3:00:00 --partition=priority" "$@"
}

function run_on_4gpu_3h {
    run_on "--cpus-per-task=40 --gres=gpu:4 --mem=100G --time=3:00:00 --partition=priority" "$@"
}

function run_on_8gpu () {
    run_on "--cpus-per-task=80 --gres=gpu:8 --mem=100G --time=70:00:00 --partition=priority" "$@"
}


# prepare output directories
# set to some directory where all indexes, can be written.
basedir=/checkpoint/matthijs/bench_all_ivf

logdir=$basedir/logs
indexdir=$basedir/indexes
centdir=$basedir/precomputed_clusters

mkdir -p $logdir $indexdir


# adds an option to use a pretrained quantizer
function add_precomputed_quantizer () {
    local db="$1"
    local coarse="$2"

    case $db in
        bigann*) rname=bigann ;;
        deep*)   rname=deep ;;
        sift1M) return;;
        music-100) return ;;
        glove) return ;;
        *) echo "bad db"; exit 1;;
    esac

    case $coarse in
        IVF65536*)
            cname=clustering.db${rname}1M.IVF65536.faissindex
            copt="--get_centroids_from $centdir/$cname"
            ;;
        IVF262144*)
            cname=clustering.db${rname}1M.IVF262144.faissindex
            copt="--get_centroids_from $centdir/$cname"
            ;;
        IVF1048576*)
            cname=clustering.db${rname}1M.IVF1048576.faissindex
            copt="--get_centroids_from $centdir/$cname"
            ;;
        IVF4194304*)
            cname=clustering.db${rname}1M.IVF4194304.faissindex
            copt="--get_centroids_from $centdir/$cname"
            ;;
        *)
        copt="" ;;
    esac

    echo $copt
}

function get_db_dim () {
    local db="$1"
    case $db in
        sift1M) dim=128;;
        bigann*) dim=128;;
        deep*) dim=96;;
        music-100) dim=100;;
        glove) dim=100;;
        *) echo "bad db"; exit 1;;
    esac
    echo $dim
}


# replace HD = half dim with the half of the dimension we need to handle
# relying that variables are global by default...
function replace_coarse_PQHD () {
    local coarse="$1"
    local dim=$2


    coarseD=${coarse//PQHD/PQ$((dim/2))}
    coarse16=${coarse//PQHD/PQ8}
    coarse32=${coarse//PQHD/PQ16}
    coarse64=${coarse//PQHD/PQ32}
    coarse128=${coarse//PQHD/PQ64}
    coarse256=${coarse//PQHD/PQ128}
    coarse112=${coarse//PQHD/PQ56}

}



if false; then



###############################################
# comparison with SCANN

for db in sift1M deep1M glove music-100
do
    opt=""
    if [ $db == glove ]; then
        opt="--measure inter"
    fi

    run_on_1machine_1h cmp_with_scann.$db.c \
        python -u cmp_with_scann.py --db $db \
        --lib faiss $opt --thenscann

done




############################### Preliminary SIFT1M experiment


for db in sift1M  ; do

    for coarse in  IVF1024
    do
        indexkeys="
            HNSW32
            $coarse,SQfp16
            $coarse,SQ4
            $coarse,SQ8
            $coarse,PQ32x8
            $coarse,PQ64x4
            $coarse,PQ64x4fs
            $coarse,PQ64x4fs,RFlat
            $coarse,PQ64x4fs,Refine(SQfp16)
            $coarse,PQ64x4fs,Refine(SQ8)
            OPQ64,$coarse,PQ64x4fs
            OPQ64,$coarse,PQ64x4fs,RFlat
        "
        indexkeys="
            $coarse,PQ64x4fsr
            $coarse,PQ64x4fsr,RFlat
        "

        # OPQ actually degrades the results on SIFT1M, so let's ignore

        for indexkey in $indexkeys
        do
            # escape nasty characters
            key="autotune.db$db.${indexkey//,/_}"
            key="${key//(/_}"
            key="${key//)/_}"
            run_on_1machine_1h $key.a \
                 python -u bench_all_ivf.py \
                    --db $db \
                    --indexkey "$indexkey" \
                    --maxtrain 0  \
                    --indexfile $indexdir/$key.faissindex \
                    --searchthreads 32
        done
    done
done




############################### 1M experiments

fi
# for db in sift1M deep1M music-100 glove; do

for db in glove music-100; do

    dim=$( get_db_dim $db )

    for coarse in IVF1024 IVF4096_HNSW32
    do

        replace_coarse_PQHD "$coarse" $dim

        indexkeys="
            $coarseD,PQ$((dim/2))x4fs
            $coarseD,PQ$((dim/2))x4fsr

            OPQ8_64,$coarse64,PQ8
            PCAR16,$coarse16,SQ4
            OPQ16_64,$coarse64,PQ16x4fs
            OPQ16_64,$coarse64,PQ16x4fsr

            OPQ16_64,$coarse64,PQ16
            PCAR16,$coarse16,SQ8
            PCAR32,$coarse32,SQ4
            OPQ32_64,$coarse64,PQ32x4fs
            OPQ32_64,$coarse64,PQ32x4fsr

            OPQ32_128,$coarse128,PQ32
            PCAR32,$coarse32,SQ8
            PCAR64,$coarse64,SQ4
            PCAR16,$coarse16,SQfp16
            OPQ64_128,$coarse128,PQ64x4fs
            OPQ64_128,$coarse128,PQ64x4fsr

            OPQ64_128,$coarse128,PQ64
            PCAR64,$coarse64,SQ8
            PCAR32,$coarse32,SQfp16
            PCAR128,$coarse128,SQ4
            OPQ128_256,$coarse256,PQ128x4fs
            OPQ128_256,$coarse256,PQ128x4fsr
            OPQ16_64,$coarse64,PQ16x4fs,Refine(OPQ56_112,PQ56)
            OPQ16_64,$coarse64,PQ16x4fs,Refine(PCAR72,SQ6)
            OPQ32_64,$coarse64,PQ16x4fs,Refine(PCAR64,SQ6)
            OPQ32_64,$coarse64,PQ32x4fs,Refine(OPQ48_96,PQ48)
            OPQ64_128,$coarse,PQ64x12

            OPQ64_128,$coarse,PQ64x4fs,RFlat
            OPQ64_128,$coarse,PQ64x4fs,Refine(SQfp16)
            OPQ64_128,$coarse,PQ64x4fs,Refine(SQ8)
            OPQ64_128,$coarse,PQ64x4fs,Refine(SQ6)
            OPQ64_128,$coarse,PQ64x4fs,Refine(SQ4)
            OPQ32_64,$coarse,PQ32x4fs,Refine(SQfp16)
            OPQ32_64,$coarse,PQ32x4fs,Refine(SQ8)
            OPQ32_64,$coarse,PQ32x4fs,Refine(SQ6)
            OPQ32_64,$coarse,PQ32x4fs,Refine(SQ4)

        "

        indexkeys="
            $coarseD,PQ$((dim/2))x4fs
            $coarseD,PQ$((dim/2))x4fsr
            $coarseD,PQ$((dim/2))x4fsr,RFlat
            $coarseD,PQ$((dim/2))x4fsr,Refine(SQfp16)
            $coarseD,PQ$((dim/2))x4fsr,Refine(SQ8)
            $coarseD,PQ$((dim/4))x4fs
            $coarseD,PQ$((dim/4))x4fsr
            $coarseD,PQ$((dim/4))x4fsr,RFlat
            $coarseD,PQ$((dim/4))x4fsr,Refine(SQfp16)
            $coarseD,PQ$((dim/4))x4fsr,Refine(SQ8)
            $coarseD,PQ$((dim/2))
            $coarseD,PQ$((dim/4))
            HNSW32,Flat
        "

        indexkeys="HNSW32,Flat"

        for indexkey in $indexkeys
        do
            key=autotune.db$db.${indexkey//,/_}
            key="${key//(/_}"
            key="${key//)/_}"
            run_on_1machine_3h $key.q \
              python -u bench_all_ivf.py \
                    --db $db \
                    --indexkey "$indexkey" \
                    --maxtrain 0  \
                    --indexfile "$indexdir/$key.faissindex" \
                    $( add_precomputed_quantizer $db $coarse ) \
                    --searchthreads 32 \
                    --min_test_duration 3
        done


    done
done

if false; then

############################################
# precompute centroids on GPU for large vocabularies

for db in deep1M bigann1M; do

    for ncent in 262144 65536 1048576 4194304; do

        key=clustering.db$db.IVF$ncent
        run_on_4gpu_3h $key.e \
            python -u bench_all_ivf.py \
                --db $db \
                --indexkey IVF$ncent,SQ8 \
                --maxtrain 100000000  \
                --indexfile $centdir/$key.faissindex \
                --searchthreads 32 \
                --min_test_duration 3 \
                --add_bs 1000000 \
                --train_on_gpu

    done
done

###############################
## coarse quantizer experiments on the centroids of deep1B


for k in 4 8 16 64 256; do

    for ncent in 65536 262144 1048576 4194304; do
        db=deep_centroids_$ncent

        # compute square root of ncent...
        for(( ls=0; ncent > (1 << (2 * ls)); ls++)); do
            echo -n
        done
        sncent=$(( 1 << ls ))

        indexkeys="
            IVF$((sncent/2)),PQ48x4fs,RFlat
            IVF$((sncent*2)),PQ48x4fs,RFlat
            HNSW32
            PQ48x4fs
            PQ48x4fs,RFlat
            IVF$sncent,PQ48x4fs,RFlat
        "

        for indexkey in $indexkeys; do
            key="cent_index.db$db.k$k.$indexkey"
            run_on_1machine_1h "$key.b" \
                    python -u bench_all_ivf.py \
                    --db $db \
                    --indexkey "$indexkey" \
                    --maxtrain 0  \
                    --inter \
                    --searchthreads 32 \
                    --k $k
        done

    done
done


############################### 10M experiments


for db in deep10M bigann10M; do

    coarses="
        IVF65536(IVF256,PQHDx4fs,RFlat)
        IVF16384_HNSW32
        IVF65536_HNSW32
        IVF262144_HNSW32
        IVF262144(IVF512,PQHDx4fs,RFlat)
    "

    dim=$( get_db_dim $db )

    for coarse in $coarses
    do

        replace_coarse_PQHD "$coarse" $dim

        indexkeys="
            $coarseD,PQ$((dim/2))x4fs

            OPQ8_64,$coarse64,PQ8
            PCAR16,$coarse16,SQ4
            OPQ16_64,$coarse64,PQ16x4fs
            OPQ16_64,$coarse64,PQ16x4fsr

            OPQ16_64,$coarse64,PQ16
            PCAR16,$coarse16,SQ8
            PCAR32,$coarse32,SQ4
            OPQ32_64,$coarse64,PQ32x4fs
            OPQ32_64,$coarse64,PQ32x4fsr

            OPQ32_128,$coarse128,PQ32
            PCAR32,$coarse32,SQ8
            PCAR64,$coarse64,SQ4
            PCAR16,$coarse16,SQfp16
            OPQ64_128,$coarse128,PQ64x4fs
            OPQ64_128,$coarse128,PQ64x4fsr

            OPQ64_128,$coarse128,PQ64
            PCAR64,$coarse64,SQ8
            PCAR32,$coarse32,SQfp16
            PCAR128,$coarse128,SQ4
            OPQ128_256,$coarse256,PQ128x4fs
            OPQ128_256,$coarse256,PQ128x4fsr
            OPQ56_112,$coarse112,PQ7+56
            OPQ16_64,$coarse64,PQ16x4fs,Refine(OPQ56_112,PQ56)
            OPQ16_64,$coarse64,PQ16x4fs,Refine(PCAR72,SQ6)
            OPQ32_64,$coarse64,PQ16x4fs,Refine(PCAR64,SQ6)
            OPQ32_64,$coarse64,PQ32x4fs,Refine(OPQ48_96,PQ48)
        "

        indexkeys="
            OPQ16_64,$coarse64,PQ16x4fsr
            OPQ32_64,$coarse64,PQ32x4fsr
            OPQ64_128,$coarse128,PQ64x4fsr
            OPQ128_256,$coarse256,PQ128x4fsr
        "


        for indexkey in $indexkeys
        do
            key=autotune.db$db.${indexkey//,/_}
            key="${key//(/_}"
            key="${key//)/_}"
            run_on_1machine_3h $key.l \
              python -u bench_all_ivf.py \
                    --db $db \
                    --indexkey "$indexkey" \
                    --maxtrain 0  \
                    --indexfile "$indexdir/$key.faissindex" \
                    $( add_precomputed_quantizer $db $coarse ) \
                    --searchthreads 32 \
                    --min_test_duration 3 \
                    --autotune_max nprobe:2000
        done
    done
done


############################### 100M experiments

for db in deep100M bigann100M; do
    coarses="
        IVF65536_HNSW32
        IVF262144_HNSW32
        IVF262144(IVF512,PQHDx4fs,RFlat)
        IVF1048576_HNSW32
        IVF1048576(IVF1024,PQHDx4fs,RFlat)
    "
    dim=$( get_db_dim $db )

    for coarse in $coarses
    do
        replace_coarse_PQHD "$coarse" $dim

        indexkeys="
            OPQ8_64,$coarse64,PQ8
            OPQ16_64,$coarse64,PQ16x4fs

            PCAR32,$coarse32,SQ4
            OPQ16_64,$coarse64,PQ16
            OPQ32_64,$coarse64,PQ32x4fs

            OPQ32_128,$coarse128,PQ32
            PCAR64,$coarse64,SQ4
            PCAR32,$coarse32,SQ8
            OPQ64_128,$coarse128,PQ64x4fs

            PCAR128,$coarse128,SQ4
            OPQ64_128,$coarse128,PQ64

            PCAR32,$coarse32,SQfp16
            PCAR64,$coarse64,SQ8
            OPQ128_256,$coarse256,PQ128x4fs

            OPQ56_112,$coarse112,PQ7+56
            OPQ16_64,$coarse64,PQ16x4fs,Refine(OPQ56_112,PQ56)

            $coarseD,PQ$((dim/2))x4fs
        "

        indexkeys="
            OPQ128_256,$coarse256,PQ128x4fsr
            OPQ64_128,$coarse128,PQ64x4fsr
            OPQ32_64,$coarse64,PQ32x4fsr
            OPQ16_64,$coarse64,PQ16x4fsr
            OPQ16_64,$coarse64,PQ16x4fsr,Refine(OPQ56_112,PQ56)
        "

        for indexkey in $indexkeys
        do
            key=autotune.db$db.${indexkey//,/_}
            key="${key//(/_}"
            key="${key//)/_}"
            run_on_1machine $key.e \
                 python -u bench_all_ivf.py \
                    --db $db \
                    --indexkey "$indexkey" \
                    --maxtrain 0  \
                    --indexfile $indexdir/$key.faissindex \
                    --searchthreads 32 \
                    --min_test_duration 3 \
                    $( add_precomputed_quantizer $db $coarse ) \
                    --add_bs 1000000 \
                    --autotune_max nprobe:2000

        done
    done
done


#################################
# 1B-scale experiment



for db in deep1B bigann1B; do
    coarses="
        IVF1048576_HNSW32
        IVF4194304_HNSW32
        IVF4194304(IVF1024,PQHDx4fs,RFlat)
    "
    dim=$( get_db_dim $db )

    for coarse in $coarses; do

        replace_coarse_PQHD "$coarse" $dim


        indexkeys="
            OPQ8_64,$coarse64,PQ8
            OPQ16_64,$coarse64,PQ16x4fsr

            OPQ16_64,$coarse64,PQ16
            OPQ32_64,$coarse64,PQ32x4fsr

            OPQ32_128,$coarse128,PQ32
            OPQ64_128,$coarse128,PQ64x4fsr

            OPQ64_128,$coarse128,PQ64
            OPQ128_256,$coarse256,PQ128x4fsr
            OPQ56_112,$coarse112,PQ7+56
            OPQ16_64,$coarse64,PQ16x4fs,Refine(OPQ56_112,PQ56)

            $coarseD,PQ$((dim/2))x4fs
        "

        for indexkey in $indexkeys
        do
            key=autotune.db$db.${indexkey//,/_}
            key="${key//(/_}"
            key="${key//)/_}"
            run_on_1machine $key.d \
                 python -u bench_all_ivf.py \
                    --db $db \
                    --indexkey "$indexkey" \
                    --maxtrain 0  \
                    --indexfile $indexdir/$key.faissindex \
                    --searchthreads 32 \
                    --min_test_duration 3 \
                    $( add_precomputed_quantizer $db $coarse ) \
                    --add_bs 1000000 \
                    --autotune_max nprobe:3000
        done
    done

#!/bin/bash -e
# Copyright (c) Facebook, Inc. and its affiliates.

# Function to retry functions that sometimes timeout or have flaky failures
retry () {
    $*  || (sleep 1 && $*) || (sleep 2 && $*) || (sleep 4 && $*) || (sleep 8 && $*)
}
# Install with pip a bit more robustly than the default
pip_install() {
  retry pip install --progress-bar off "$@"
}


setup_cuda() {
  # Now work out the CUDA settings
  # Like other torch domain libraries, we choose common GPU architectures only.
  # See more details at https://github.com/pytorch/pytorch/blob/master/torch/utils/cpp_extension.py#L1363
  export FORCE_CUDA=1
  case "$CU_VERSION" in
    cu110)
      export CUDA_HOME=/usr/local/cuda-11.0/
      # NOTE: may need to add 8.6 in the next ver
      export TORCH_CUDA_ARCH_LIST="3.7;5.0;5.2;6.0+PTX;6.1+PTX;7.0+PTX;7.5+PTX;8.0+PTX"
      ;;
    cu102)
      export CUDA_HOME=/usr/local/cuda-10.2/
      export TORCH_CUDA_ARCH_LIST="3.7;5.0;5.2;6.0+PTX;6.1+PTX;7.0+PTX;7.5+PTX"
      ;;
    cu101)
      export CUDA_HOME=/usr/local/cuda-10.1/
      export TORCH_CUDA_ARCH_LIST="3.7;5.0;5.2;6.0+PTX;6.1+PTX;7.0+PTX;7.5+PTX"
      ;;
    cu100)
      export CUDA_HOME=/usr/local/cuda-10.0/
      export TORCH_CUDA_ARCH_LIST="3.7;5.0;5.2;6.0+PTX;6.1+PTX;7.0+PTX;7.5+PTX"
      ;;
    cu92)
      export CUDA_HOME=/usr/local/cuda-9.2/
      export TORCH_CUDA_ARCH_LIST="3.7;5.0;5.2;6.0+PTX;6.1+PTX;7.0+PTX"
      ;;
    cpu)
      unset FORCE_CUDA
      export CUDA_VISIBLE_DEVICES=
      ;;
    *)
      echo "Unrecognized CU_VERSION=$CU_VERSION"
      exit 1
      ;;
  esac
}

setup_wheel_python() {
  case "$PYTHON_VERSION" in
    3.6) python_abi=cp36-cp36m ;;
    3.7) python_abi=cp37-cp37m ;;
    3.8) python_abi=cp38-cp38 ;;
    *)
      echo "Unrecognized PYTHON_VERSION=$PYTHON_VERSION"
      exit 1
      ;;
#!/bin/bash
set -e
rm -rf types
node_modules/.bin/tsc --project tsconfig.types.json
cp -r types/src/* dist
#!/bin/bash

# Recreates the v_nodes_http.json files in this directory. This is
# meant to be an "every once in a while" thing that we do only when
# we want to add a new version of Elasticsearch or configure the
# nodes differently. That is why we don't do this in gradle. It also
# allows us to play fast and loose with error handling. If something
# goes wrong you have to manually clean up which is good because it
# leaves around the kinds of things that we need to debug the failure.

# I built this file so the next time I have to regenerate these
# v_nodes_http.json files I won't have to reconfigure Elasticsearch
# from scratch. While I was at it I took the time to make sure that
# when we do rebuild the files they don't jump around too much. That
# way the diffs are smaller.

set -e

script_path="$( cd "$(dirname "$0")" ; pwd -P )"
work=$(mktemp -d)
pushd ${work} >> /dev/null
echo Working in ${work}

wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.0.0/elasticsearch-2.0.0.tar.gz
wget https://artifacts-no-kpi.elastic.co/downloads/elasticsearch/elasticsearch-5.0.0.tar.gz
wget https://artifacts-no-kpi.elastic.co/downloads/elasticsearch/elasticsearch-6.0.0.tar.gz
sha1sum -c - << __SHAs
e369d8579bd3a2e8b5344278d5043f19f14cac88 elasticsearch-2.0.0.tar.gz
d25f6547bccec9f0b5ea7583815f96a6f50849e0 elasticsearch-5.0.0.tar.gz
__SHAs
sha512sum -c - << __SHAs
25bb622d2fc557d8b8eded634a9b333766f7b58e701359e1bcfafee390776eb323cb7ea7a5e02e8803e25d8b1d3aabec0ec1b0cf492d0bab5689686fe440181c elasticsearch-6.0.0.tar.gz
__SHAs


function do_version() {
    local version=$1
    local nodes='m1 m2 m3 d1 d2 d3 c1 c2'
    rm -rf ${version}
    mkdir -p ${version}
    pushd ${version} >> /dev/null

    tar xf ../elasticsearch-${version}.tar.gz
    local http_port=9200
    for node in ${nodes}; do
        mkdir ${node}
        cp -r elasticsearch-${version}/* ${node}
        local master=$([[ "$node" =~ ^m.* ]] && echo true || echo false)
        local data=$([[ "$node" =~ ^d.* ]] && echo true || echo false)
        # m2 is always master and data for these test just so we have a node like that
        data=$([[ "$node" == 'm2' ]] && echo true || echo ${data})
        local attr=$([ ${version} == '2.0.0' ] && echo '' || echo '.attr')
        local transport_port=$((http_port+100))

        cat >> ${node}/config/elasticsearch.yml << __ES_YML
node.name:          ${node}
node.master:        ${master}
node.data:          ${data}
node${attr}.dummy:  everyone_has_me
node${attr}.number: ${node:1}
node${attr}.array:  [${node:0:1}, ${node:1}]
http.port:          ${http_port}
transport.tcp.port: ${transport_port}
discovery.zen.minimum_master_nodes: 3
discovery.zen.ping.unicast.hosts: ['localhost:9300','localhost:9301','localhost:9302']
__ES_YML

        if [ ${version} != '2.0.0' ]; then
            perl -pi -e 's/-Xm([sx]).+/-Xm${1}512m/g' ${node}/config/jvm.options
        fi

        echo "starting ${version}/${node}..."
        ${node}/bin/elasticsearch -d -p ${node}/pidfile

        ((http_port++))
    done

    echo "waiting for cluster to form"
    # got to wait for all the nodes
    until curl -s localhost:9200; do
        sleep .25
    done

    echo "waiting for all nodes to join"
    until [ $(echo ${nodes} | wc -w) -eq $(curl -s localhost:9200/_cat/nodes | wc -l) ]; do
        sleep .25
    done

    # jq sorts the nodes by their http host so the file doesn't jump around when we regenerate it
    curl -s localhost:9200/_nodes/http?pretty \
        | jq '[to_entries[] | ( select(.key == "nodes").value|to_entries|sort_by(.value.http.publish_address)|from_entries|{"key": "nodes", "value": .} ) // .] | from_entries' \
        > ${script_path}/${version}_nodes_http.json

    for node in ${nodes}; do
        echo "stopping ${version}/${node}..."
        kill $(cat ${node}/pidfile)
    done

    popd >> /dev/null
}

JAVA_HOME=$JAVA8_HOME do_version 2.0.0
JAVA_HOME=$JAVA8_HOME do_version 5.0.0
JAVA_HOME=$JAVA8_HOME do_version 6.0.0

#!/bin/bash

# check dependencies
(
    type docker &>/dev/null || ( echo "docker is not available"; exit 1 )
    type curl &>/dev/null || ( echo "curl is not available"; exit 1 )
)>&2

# Assert that $1 is the outputof a command $2
function assert {
    local expected_output=$1
    shift
    local actual_output
    actual_output=$("$@")
    actual_output="${actual_output//[$'\t\r\n']}" # remove newlines
    if ! [ "$actual_output" = "$expected_output" ]; then
        echo "expected: \"$expected_output\""
        echo "actual:   \"$actual_output\""
        false
    fi
}

# Retry a command $1 times until it succeeds. Wait $2 seconds between retries.
function retry {
    local attempts=$1
    shift
    local delay=$1
    shift
    local i

    for ((i=0; i < attempts; i++)); do
        run "$@"
        if [ "$status" -eq 0 ]; then
            return 0
        fi
        sleep $delay
    done

    echo "Command \"$*\" failed $attempts times. Status: $status. Output: $output" >&2
    false
}

function docker_build {
    if [ -n "$JENKINS_VERSION" ]; then
        docker build --build-arg JENKINS_VERSION=$JENKINS_VERSION --build-arg JENKINS_SHA=$JENKINS_SHA "$@"
    else
        docker build "$@"
    fi
}

function get_jenkins_url {
    if [ -z "${DOCKER_HOST}" ]; then
        DOCKER_IP=localhost
    else
        DOCKER_IP=$(echo "$DOCKER_HOST" | sed -e 's|tcp://\(.*\):[0-9]*|\1|')
    fi
    echo "http://$DOCKER_IP:$(docker port "$SUT_CONTAINER" 8080 | cut -d: -f2)"
}

function get_jenkins_password {
    docker logs "$SUT_CONTAINER" 2>&1 | grep -A 2 "Please use the following password to proceed to installation" | tail -n 1
}

function test_url {
    run curl --user "admin:$(get_jenkins_password)" --output /dev/null --silent --head --fail --connect-timeout 30 --max-time 60 "$(get_jenkins_url)$1"
    if [ "$status" -eq 0 ]; then
        true
    else
        echo "URL $(get_jenkins_url)$1 failed" >&2
        echo "output: $output" >&2
        false
    fi
}

function cleanup {
    docker kill "$1" &>/dev/null ||:
    docker rm -fv "$1" &>/dev/null ||:
}

function unzip_manifest {
# bash/zsh completion support for core Git.
#
# Copyright (C) 2006,2007 Shawn O. Pearce <spearce@spearce.org>
# Conceptually based on gitcompletion (http://gitweb.hawaga.org.uk/).
# Distributed under the GNU General Public License, version 2.0.
#
# The contained completion routines provide support for completing:
#
#    *) local and remote branch names
#    *) local and remote tag names
#    *) .git/remotes file names
#    *) git 'subcommands'
#    *) git email aliases for git-send-email
#    *) tree paths within 'ref:path/to/file' expressions
#    *) file paths within current working directory and index
#    *) common --long-options
#
# To use these routines:
#
#    1) Copy this file to somewhere (e.g. ~/.git-completion.bash).
#    2) Add the following line to your .bashrc/.zshrc:
#        source ~/.git-completion.bash
#    3) Consider changing your PS1 to also show the current branch,
#       see git-prompt.sh for details.
#
# If you use complex aliases of form '!f() { ... }; f', you can use the null
# command ':' as the first command in the function body to declare the desired
# completion style.  For example '!f() { : git commit ; ... }; f' will
# tell the completion to use commit completion.  This also works with aliases
# of form "!sh -c '...'".  For example, "!sh -c ': git commit ; ... '".
#
# Compatible with bash 3.2.57.
#
# You can set the following environment variables to influence the behavior of
# the completion routines:
#
#   GIT_COMPLETION_CHECKOUT_NO_GUESS
#
#     When set to "1", do not include "DWIM" suggestions in git-checkout
#     and git-switch completion (e.g., completing "foo" when "origin/foo"
#     exists).
#
#   GIT_COMPLETION_SHOW_ALL
#
#     When set to "1" suggest all options, including options which are
#     typically hidden (e.g. '--allow-empty' for 'git commit').

# Discovers the path to the git repository taking any '--git-dir=<path>' and
# '-C <path>' options into account and stores it in the $__git_repo_path
# variable.
__git_find_repo_path ()
{
	if [ -n "${__git_repo_path-}" ]; then
		# we already know where it is
		return
	fi

	if [ -n "${__git_C_args-}" ]; then
		__git_repo_path="$(git "${__git_C_args[@]}" \
			${__git_dir:+--git-dir="$__git_dir"} \
			rev-parse --absolute-git-dir 2>/dev/null)"
	elif [ -n "${__git_dir-}" ]; then
		test -d "$__git_dir" &&
		__git_repo_path="$__git_dir"
	elif [ -n "${GIT_DIR-}" ]; then
		test -d "${GIT_DIR-}" &&
		__git_repo_path="$GIT_DIR"
	elif [ -d .git ]; then
		__git_repo_path=.git
	else
		__git_repo_path="$(git rev-parse --git-dir 2>/dev/null)"
	fi
}

# Deprecated: use __git_find_repo_path() and $__git_repo_path instead
# __gitdir accepts 0 or 1 arguments (i.e., location)
# returns location of .git repo
__gitdir ()
{
	if [ -z "${1-}" ]; then
		__git_find_repo_path || return 1
		echo "$__git_repo_path"
	elif [ -d "$1/.git" ]; then
		echo "$1/.git"
	else
		echo "$1"
	fi
}

# Runs git with all the options given as argument, respecting any
# '--git-dir=<path>' and '-C <path>' options present on the command line
__git ()
{
	git ${__git_C_args:+"${__git_C_args[@]}"} \
		${__git_dir:+--git-dir="$__git_dir"} "$@" 2>/dev/null
}

# Removes backslash escaping, single quotes and double quotes from a word,
# stores the result in the variable $dequoted_word.
# 1: The word to dequote.
__git_dequote ()
{
	local rest="$1" len ch

	dequoted_word=""

	while test -n "$rest"; do
		len=${#dequoted_word}
		dequoted_word="$dequoted_word${rest%%[\\\'\"]*}"
		rest="${rest:$((${#dequoted_word}-$len))}"

		case "${rest:0:1}" in
		\\)
			ch="${rest:1:1}"
			case "$ch" in
			$'\n')
				;;
			*)
				dequoted_word="$dequoted_word$ch"
				;;
			esac
			rest="${rest:2}"
			;;
		\')
			rest="${rest:1}"
			len=${#dequoted_word}
			dequoted_word="$dequoted_word${rest%%\'*}"
			rest="${rest:$((${#dequoted_word}-$len+1))}"
			;;
		\")
			rest="${rest:1}"
			while test -n "$rest" ; do
				len=${#dequoted_word}
				dequoted_word="$dequoted_word${rest%%[\\\"]*}"
				rest="${rest:$((${#dequoted_word}-$len))}"
				case "${rest:0:1}" in
				\\)
					ch="${rest:1:1}"
					case "$ch" in
					\"|\\|\$|\`)
						dequoted_word="$dequoted_word$ch"
						;;
					$'\n')
						;;
					*)
						dequoted_word="$dequoted_word\\$ch"
						;;
					esac
					rest="${rest:2}"
					;;
				\")
					rest="${rest:1}"
					break
					;;
				esac
			done
			;;
		esac
	done
}

# The following function is based on code from:
#
#   bash_completion - programmable completion functions for bash 3.2+
#
#   Copyright © 2006-2008, Ian Macdonald <ian@caliban.org>
#             © 2009-2010, Bash Completion Maintainers
#                     <bash-completion-devel@lists.alioth.debian.org>
#
#   This program is free software; you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation; either version 2, or (at your option)
#   any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, see <http://www.gnu.org/licenses/>.
#
#   The latest version of this software can be obtained here:
#
#   http://bash-completion.alioth.debian.org/
#
#   RELEASE: 2.x

# This function can be used to access a tokenized list of words
# on the command line:
#
#	__git_reassemble_comp_words_by_ref '=:'
#	if test "${words_[cword_-1]}" = -w
#	then
#		...
#	fi
#
# The argument should be a collection of characters from the list of
# word completion separators (COMP_WORDBREAKS) to treat as ordinary
# characters.
#
# This is roughly equivalent to going back in time and setting
# COMP_WORDBREAKS to exclude those characters.  The intent is to
# make option types like --date=<type> and <rev>:<path> easy to
# recognize by treating each shell word as a single token.
#
# It is best not to set COMP_WORDBREAKS directly because the value is
# shared with other completion scripts.  By the time the completion
# function gets called, COMP_WORDS has already been populated so local
# changes to COMP_WORDBREAKS have no effect.
#
# Output: words_, cword_, cur_.

__git_reassemble_comp_words_by_ref()
{
	local exclude i j first
	# Which word separators to exclude?
	exclude="${1//[^$COMP_WORDBREAKS]}"
	cword_=$COMP_CWORD
	if [ -z "$exclude" ]; then
		words_=("${COMP_WORDS[@]}")
		return
	fi
	# List of word completion separators has shrunk;
	# re-assemble words to complete.
	for ((i=0, j=0; i < ${#COMP_WORDS[@]}; i++, j++)); do
		# Append each nonempty word consisting of just
		# word separator characters to the current word.
		first=t
		while
			[ $i -gt 0 ] &&
			[ -n "${COMP_WORDS[$i]}" ] &&
			# word consists of excluded word separators
			[ "${COMP_WORDS[$i]//[^$exclude]}" = "${COMP_WORDS[$i]}" ]
		do
			# Attach to the previous token,
			# unless the previous token is the command name.
			if [ $j -ge 2 ] && [ -n "$first" ]; then
				((j--))
			fi
			first=
			words_[$j]=${words_[j]}${COMP_WORDS[i]}
			if [ $i = $COMP_CWORD ]; then
				cword_=$j
			fi
			if (($i < ${#COMP_WORDS[@]} - 1)); then
				((i++))
			else
				# Done.
				return
			fi
		done
		words_[$j]=${words_[j]}${COMP_WORDS[i]}
		if [ $i = $COMP_CWORD ]; then
			cword_=$j
		fi
	done
}

if ! type _get_comp_words_by_ref >/dev/null 2>&1; then
_get_comp_words_by_ref ()
{
	local exclude cur_ words_ cword_
	if [ "$1" = "-n" ]; then
		exclude=$2
		shift 2
	fi
	__git_reassemble_comp_words_by_ref "$exclude"
	cur_=${words_[cword_]}
	while [ $# -gt 0 ]; do
		case "$1" in
		cur)
			cur=$cur_
			;;
		prev)
			prev=${words_[$cword_-1]}
			;;
		words)
			words=("${words_[@]}")
			;;
		cword)
			cword=$cword_
			;;
		esac
		shift
	done
}
fi

# Fills the COMPREPLY array with prefiltered words without any additional
# processing.
# Callers must take care of providing only words that match the current word
# to be completed and adding any prefix and/or suffix (trailing space!), if
# necessary.
# 1: List of newline-separated matching completion words, complete with
#    prefix and suffix.
__gitcomp_direct ()
{
	local IFS=$'\n'

	COMPREPLY=($1)
}

# Similar to __gitcomp_direct, but appends to COMPREPLY instead.
# Callers must take care of providing only words that match the current word
# to be completed and adding any prefix and/or suffix (trailing space!), if
# necessary.
# 1: List of newline-separated matching completion words, complete with
#    prefix and suffix.
__gitcomp_direct_append ()
{
	local IFS=$'\n'

	COMPREPLY+=($1)
}

__gitcompappend ()
{
	local x i=${#COMPREPLY[@]}
	for x in $1; do
		if [[ "$x" == "$3"* ]]; then
			COMPREPLY[i++]="$2$x$4"
		fi
	done
}

__gitcompadd ()
{
	COMPREPLY=()
	__gitcompappend "$@"
}

# Generates completion reply, appending a space to possible completion words,
# if necessary.
# It accepts 1 to 4 arguments:
# 1: List of possible completion words.
# 2: A prefix to be added to each possible completion word (optional).
# 3: Generate possible completion matches for this word (optional).
# 4: A suffix to be appended to each possible completion word (optional).
__gitcomp ()
{
	local cur_="${3-$cur}"

	case "$cur_" in
	*=)
		;;
	--no-*)
		local c i=0 IFS=$' \t\n'
		for c in $1; do
			if [[ $c == "--" ]]; then
				continue
			fi
			c="$c${4-}"
			if [[ $c == "$cur_"* ]]; then
				case $c in
				--*=|*.) ;;
				*) c="$c " ;;
				esac
				COMPREPLY[i++]="${2-}$c"
			fi
		done
		;;
	*)
		local c i=0 IFS=$' \t\n'
		for c in $1; do
			if [[ $c == "--" ]]; then
				c="--no-...${4-}"
				if [[ $c == "$cur_"* ]]; then
					COMPREPLY[i++]="${2-}$c "
				fi
				break
			fi
			c="$c${4-}"
			if [[ $c == "$cur_"* ]]; then
				case $c in
				*=|*.) ;;
				*) c="$c " ;;
				esac
				COMPREPLY[i++]="${2-}$c"
			fi
		done
		;;
	esac
}

# Clear the variables caching builtins' options when (re-)sourcing
# the completion script.
if [[ -n ${ZSH_VERSION-} ]]; then
	unset ${(M)${(k)parameters[@]}:#__gitcomp_builtin_*} 2>/dev/null
else
	unset $(compgen -v __gitcomp_builtin_)
fi

__gitcomp_builtin_add_default=" --dry-run --verbose --interactive --patch --edit --force --update --renormalize --intent-to-add --all --ignore-removal --refresh --ignore-errors --ignore-missing --chmod= --pathspec-from-file= --pathspec-file-nul --no-dry-run -- --no-verbose --no-interactive --no-patch --no-edit --no-force --no-update --no-renormalize --no-intent-to-add --no-all --no-ignore-removal --no-refresh --no-ignore-errors --no-ignore-missing --no-chmod --no-pathspec-from-file --no-pathspec-file-nul"
__gitcomp_builtin_am_default=" --interactive --3way --quiet --signoff --utf8 --keep --keep-non-patch --message-id --keep-cr --no-keep-cr --scissors --whitespace= --ignore-space-change --ignore-whitespace --directory= --exclude= --include= --patch-format= --reject --resolvemsg= --continue --resolved --skip --abort --quit --show-current-patch --committer-date-is-author-date --ignore-date --rerere-autoupdate --gpg-sign -- --no-interactive --no-3way --no-quiet --no-signoff --no-utf8 --no-keep --no-keep-non-patch --no-message-id --no-scissors --no-whitespace --no-ignore-space-change --no-ignore-whitespace --no-directory --no-exclude --no-include --no-patch-format --no-reject --no-resolvemsg --no-committer-date-is-author-date --no-ignore-date --no-rerere-autoupdate --no-gpg-sign"
__gitcomp_builtin_apply_default=" --exclude= --include= --no-add --stat --numstat --summary --check --index --intent-to-add --cached --apply --3way --build-fake-ancestor= --whitespace= --ignore-space-change --ignore-whitespace --reverse --unidiff-zero --reject --allow-overlap --verbose --inaccurate-eof --recount --directory= --add -- --no-stat --no-numstat --no-summary --no-check --no-index --no-intent-to-add --no-cached --no-apply --no-3way --no-build-fake-ancestor --no-whitespace --no-ignore-space-change --no-ignore-whitespace --no-reverse --no-unidiff-zero --no-reject --no-allow-overlap --no-verbose --no-inaccurate-eof --no-recount --no-directory"
__gitcomp_builtin_archive_default=" --output= --remote= --exec= --no-output -- --no-remote --no-exec"
__gitcomp_builtin_bisect__helper_default=" --next-all --write-terms --bisect-clean-state --check-expected-revs --bisect-reset --bisect-write --check-and-set-terms --bisect-next-check --bisect-terms --bisect-start --bisect-next --bisect-auto-next --bisect-autostart --no-log --log"
__gitcomp_builtin_blame_default=" --incremental --root --show-stats --progress --score-debug --show-name --show-number --porcelain --line-porcelain --show-email --ignore-rev= --ignore-revs-file= --color-lines --color-by-age --minimal --contents= --abbrev --no-incremental -- --no-root --no-show-stats --no-progress --no-score-debug --no-show-name --no-show-number --no-porcelain --no-line-porcelain --no-show-email --no-ignore-rev --no-ignore-revs-file --no-color-lines --no-color-by-age --no-minimal --no-contents --no-abbrev"
__gitcomp_builtin_branch_default=" --verbose --quiet --track --set-upstream-to= --unset-upstream --color --remotes --contains --no-contains --abbrev --all --delete --move --copy --list --show-current --create-reflog --edit-description --merged --no-merged --column --sort= --points-at= --ignore-case --format= -- --no-verbose --no-quiet --no-track --no-set-upstream-to --no-unset-upstream --no-color --no-remotes --no-abbrev --no-all --no-delete --no-move --no-copy --no-list --no-show-current --no-create-reflog --no-edit-description --no-column --no-points-at --no-ignore-case --no-format"
__gitcomp_builtin_bugreport_default=" --output-directory= --suffix= --no-output-directory -- --no-suffix"
__gitcomp_builtin_cat_file_default=" --textconv --filters --path= --allow-unknown-type --buffer --batch --batch-check --follow-symlinks --batch-all-objects --unordered --no-path -- --no-allow-unknown-type --no-buffer --no-follow-symlinks --no-batch-all-objects --no-unordered"
__gitcomp_builtin_check_attr_default=" --all --cached --stdin --no-all -- --no-cached --no-stdin"
__gitcomp_builtin_check_ignore_default=" --quiet --verbose --stdin --non-matching --no-index --index -- --no-quiet --no-verbose --no-stdin --no-non-matching"
__gitcomp_builtin_check_mailmap_default=" --stdin --no-stdin"
__gitcomp_builtin_checkout_default=" --guess --overlay --quiet --recurse-submodules --progress --merge --conflict= --detach --track --orphan= --ignore-other-worktrees --ours --theirs --patch --ignore-skip-worktree-bits --pathspec-from-file= --pathspec-file-nul --no-guess -- --no-overlay --no-quiet --no-recurse-submodules --no-progress --no-merge --no-conflict --no-detach --no-track --no-orphan --no-ignore-other-worktrees --no-patch --no-ignore-skip-worktree-bits --no-pathspec-from-file --no-pathspec-file-nul"
__gitcomp_builtin_checkout_index_default=" --all --force --quiet --no-create --index --stdin --temp --prefix= --stage= --create -- --no-all --no-force --no-quiet --no-index --no-stdin --no-temp --no-prefix"
__gitcomp_builtin_cherry_default=" --abbrev --verbose --no-abbrev -- --no-verbose"
__gitcomp_builtin_cherry_pick_default=" --quit --continue --abort --skip --cleanup= --no-commit --edit --signoff --mainline= --rerere-autoupdate --strategy= --strategy-option= --gpg-sign --ff --allow-empty --allow-empty-message --keep-redundant-commits --commit -- --no-cleanup --no-edit --no-signoff --no-mainline --no-rerere-autoupdate --no-strategy --no-strategy-option --no-gpg-sign --no-ff --no-allow-empty --no-allow-empty-message --no-keep-redundant-commits"
__gitcomp_builtin_clean_default=" --quiet --dry-run --interactive --exclude= --no-quiet -- --no-dry-run --no-interactive"
__gitcomp_builtin_clone_default=" --verbose --quiet --progress --no-checkout --bare --mirror --local --no-hardlinks --shared --recurse-submodules --recursive --jobs= --template= --reference= --reference-if-able= --dissociate --origin= --branch= --upload-pack= --depth= --shallow-since= --shallow-exclude= --single-branch --no-tags --shallow-submodules --separate-git-dir= --config= --server-option= --ipv4 --ipv6 --filter= --remote-submodules --sparse --checkout --hardlinks --tags -- --no-verbose --no-quiet --no-progress --no-bare --no-mirror --no-local --no-shared --no-recurse-submodules --no-recursive --no-jobs --no-template --no-reference --no-reference-if-able --no-dissociate --no-origin --no-branch --no-upload-pack --no-depth --no-shallow-since --no-shallow-exclude --no-single-branch --no-shallow-submodules --no-separate-git-dir --no-config --no-server-option --no-ipv4 --no-ipv6 --no-filter --no-remote-submodules --no-sparse"
__gitcomp_builtin_column_default=" --command= --mode --raw-mode= --width= --indent= --nl= --padding= --no-command -- --no-mode --no-raw-mode --no-width --no-indent --no-nl --no-padding"
__gitcomp_builtin_commit_default=" --quiet --verbose --file= --author= --date= --message= --reedit-message= --reuse-message= --fixup= --squash= --reset-author --signoff --template= --edit --cleanup= --status --gpg-sign --all --include --interactive --patch --only --no-verify --dry-run --short --branch --ahead-behind --porcelain --long --null --amend --no-post-rewrite --untracked-files --pathspec-from-file= --pathspec-file-nul --verify --post-rewrite -- --no-quiet --no-verbose --no-file --no-author --no-date --no-message --no-reedit-message --no-reuse-message --no-fixup --no-squash --no-reset-author --no-signoff --no-template --no-edit --no-cleanup --no-status --no-gpg-sign --no-all --no-include --no-interactive --no-patch --no-only --no-dry-run --no-short --no-branch --no-ahead-behind --no-porcelain --no-long --no-null --no-amend --no-untracked-files --no-pathspec-from-file --no-pathspec-file-nul"
__gitcomp_builtin_commit_graph_default=" --object-dir= --no-object-dir"
__gitcomp_builtin_config_default=" --global --system --local --worktree --file= --blob= --get --get-all --get-regexp --get-urlmatch --replace-all --add --unset --unset-all --rename-section --remove-section --list --edit --get-color --get-colorbool --type= --bool --int --bool-or-int --bool-or-str --path --expiry-date --null --name-only --includes --show-origin --show-scope --default= --no-global -- --no-system --no-local --no-worktree --no-file --no-blob --no-get --no-get-all --no-get-regexp --no-get-urlmatch --no-replace-all --no-add --no-unset --no-unset-all --no-rename-section --no-remove-section --no-list --no-edit --no-get-color --no-get-colorbool --no-type --no-null --no-name-only --no-includes --no-show-origin --no-show-scope --no-default"
__gitcomp_builtin_count_objects_default=" --verbose --human-readable --no-verbose -- --no-human-readable"
__gitcomp_builtin_credential_cache_default=" --timeout= --socket= --no-timeout -- --no-socket"
__gitcomp_builtin_credential_cache__daemon_default=" --debug --no-debug"
__gitcomp_builtin_credential_store_default=" --file= --no-file"
__gitcomp_builtin_describe_default=" --contains --debug --all --tags --long --first-parent --abbrev --exact-match --candidates= --match= --exclude= --always --dirty --broken --no-contains -- --no-debug --no-all --no-tags --no-long --no-first-parent --no-abbrev --no-exact-match --no-candidates --no-match --no-exclude --no-always --no-dirty --no-broken"
__gitcomp_builtin_difftool_default=" --gui --dir-diff --no-prompt --symlinks --tool= --tool-help --trust-exit-code --extcmd= --no-index -- --no-gui --no-dir-diff --no-symlinks --no-tool --no-tool-help --no-trust-exit-code --no-extcmd"
__gitcomp_builtin_env__helper_default=" --type= --default= --exit-code --no-default -- --no-exit-code"
__gitcomp_builtin_fast_export_default=" --progress= --signed-tags= --tag-of-filtered-object= --reencode= --export-marks= --import-marks= --import-marks-if-exists= --fake-missing-tagger --full-tree --use-done-feature --no-data --refspec= --anonymize --anonymize-map= --reference-excluded-parents --show-original-ids --mark-tags --data -- --no-progress --no-signed-tags --no-tag-of-filtered-object --no-reencode --no-export-marks --no-import-marks --no-import-marks-if-exists --no-fake-missing-tagger --no-full-tree --no-use-done-feature --no-refspec --no-anonymize --no-reference-excluded-parents --no-show-original-ids --no-mark-tags"
__gitcomp_builtin_fetch_default=" --verbose --quiet --all --set-upstream --append --upload-pack= --force --multiple --tags --jobs= --prune --prune-tags --recurse-submodules --dry-run --write-fetch-head --keep --update-head-ok --progress --depth= --shallow-since= --shallow-exclude= --deepen= --unshallow --update-shallow --refmap= --server-option= --ipv4 --ipv6 --negotiation-tip= --filter= --auto-maintenance --auto-gc --show-forced-updates --write-commit-graph --stdin --no-verbose -- --no-quiet --no-all --no-set-upstream --no-append --no-upload-pack --no-force --no-multiple --no-tags --no-jobs --no-prune --no-prune-tags --no-recurse-submodules --no-dry-run --no-write-fetch-head --no-keep --no-update-head-ok --no-progress --no-depth --no-shallow-since --no-shallow-exclude --no-deepen --no-update-shallow --no-server-option --no-ipv4 --no-ipv6 --no-negotiation-tip --no-filter --no-auto-maintenance --no-auto-gc --no-show-forced-updates --no-write-commit-graph --no-stdin"
__gitcomp_builtin_fmt_merge_msg_default=" --log --message= --file= --no-log -- --no-message --no-file"
__gitcomp_builtin_for_each_ref_default=" --shell --perl --python --tcl --count= --format= --color --sort= --points-at= --merged --no-merged --contains --no-contains --ignore-case -- --no-shell --no-perl --no-python --no-tcl --no-count --no-format --no-color --no-points-at --no-ignore-case"
__gitcomp_builtin_format_patch_default=" --numbered --no-numbered --signoff --stdout --cover-letter --numbered-files --suffix= --start-number= --reroll-count= --rfc --cover-from-description= --subject-prefix= --output-directory= --keep-subject --no-binary --zero-commit --ignore-if-in-upstream --no-stat --add-header= --to= --cc= --from --in-reply-to= --attach --inline --thread --signature= --base= --signature-file= --quiet --progress --interdiff= --range-diff= --creation-factor= --binary -- --no-numbered --no-signoff --no-stdout --no-cover-letter --no-numbered-files --no-suffix --no-start-number --no-reroll-count --no-cover-from-description --no-zero-commit --no-ignore-if-in-upstream --no-add-header --no-to --no-cc --no-from --no-in-reply-to --no-attach --no-thread --no-signature --no-base --no-signature-file --no-quiet --no-progress --no-interdiff --no-range-diff --no-creation-factor"
__gitcomp_builtin_fsck_default=" --verbose --unreachable --dangling --tags --root --cache --reflogs --full --connectivity-only --strict --lost-found --progress --name-objects --no-verbose -- --no-unreachable --no-dangling --no-tags --no-root --no-cache --no-reflogs --no-full --no-connectivity-only --no-strict --no-lost-found --no-progress --no-name-objects"
__gitcomp_builtin_fsck_objects_default=" --verbose --unreachable --dangling --tags --root --cache --reflogs --full --connectivity-only --strict --lost-found --progress --name-objects --no-verbose -- --no-unreachable --no-dangling --no-tags --no-root --no-cache --no-reflogs --no-full --no-connectivity-only --no-strict --no-lost-found --no-progress --no-name-objects"
__gitcomp_builtin_gc_default=" --quiet --prune --aggressive --keep-largest-pack --no-quiet -- --no-prune --no-aggressive --no-keep-largest-pack"
__gitcomp_builtin_grep_default=" --cached --no-index --untracked --exclude-standard --recurse-submodules --invert-match --ignore-case --word-regexp --text --textconv --recursive --max-depth= --extended-regexp --basic-regexp --fixed-strings --perl-regexp --line-number --column --full-name --files-with-matches --name-only --files-without-match --only-matching --count --color --break --heading --context= --before-context= --after-context= --threads= --show-function --function-context --and --or --not --quiet --all-match --index -- --no-cached --no-untracked --no-exclude-standard --no-recurse-submodules --no-invert-match --no-ignore-case --no-word-regexp --no-text --no-textconv --no-recursive --no-extended-regexp --no-basic-regexp --no-fixed-strings --no-perl-regexp --no-line-number --no-column --no-full-name --no-files-with-matches --no-name-only --no-files-without-match --no-only-matching --no-count --no-color --no-break --no-heading --no-context --no-before-context --no-after-context --no-threads --no-show-function --no-function-context --no-or --no-quiet --no-all-match"
__gitcomp_builtin_hash_object_default=" --stdin --stdin-paths --no-filters --literally --path= --filters -- --no-stdin --no-stdin-paths --no-literally --no-path"
__gitcomp_builtin_help_default=" --all --guides --config --man --web --info --verbose --no-all -- --no-guides --no-config --no-man --no-web --no-info --no-verbose"
__gitcomp_builtin_init_default=" --template= --bare --shared --quiet --separate-git-dir= --initial-branch= --object-format= --no-template -- --no-bare --no-quiet --no-separate-git-dir --no-initial-branch --no-object-format"
__gitcomp_builtin_init_db_default=" --template= --bare --shared --quiet --separate-git-dir= --initial-branch= --object-format= --no-template -- --no-bare --no-quiet --no-separate-git-dir --no-initial-branch --no-object-format"
__gitcomp_builtin_interpret_trailers_default=" --in-place --trim-empty --where= --if-exists= --if-missing= --only-trailers --only-input --unfold --parse --no-divider --trailer= --divider -- --no-in-place --no-trim-empty --no-where --no-if-exists --no-if-missing --no-only-trailers --no-only-input --no-unfold --no-trailer"
__gitcomp_builtin_log_default=" --quiet --source --use-mailmap --mailmap --decorate-refs= --decorate-refs-exclude= --decorate --no-quiet -- --no-source --no-use-mailmap --no-mailmap --no-decorate-refs --no-decorate-refs-exclude --no-decorate"
__gitcomp_builtin_ls_files_default=" --cached --deleted --modified --others --ignored --stage --killed --directory --eol --empty-directory --unmerged --resolve-undo --exclude= --exclude-from= --exclude-per-directory= --exclude-standard --full-name --recurse-submodules --error-unmatch --with-tree= --abbrev --debug --no-cached -- --no-deleted --no-modified --no-others --no-ignored --no-stage --no-killed --no-directory --no-eol --no-empty-directory --no-unmerged --no-resolve-undo --no-exclude-per-directory --no-recurse-submodules --no-error-unmatch --no-with-tree --no-abbrev --no-debug"
__gitcomp_builtin_ls_remote_default=" --quiet --upload-pack= --tags --heads --refs --get-url --sort= --symref --server-option= --no-quiet -- --no-upload-pack --no-tags --no-heads --no-refs --no-get-url --no-symref --no-server-option"
__gitcomp_builtin_ls_tree_default=" --long --name-only --name-status --full-name --full-tree --abbrev --no-long -- --no-name-only --no-name-status --no-full-name --no-full-tree --no-abbrev"
__gitcomp_builtin_merge_default=" --stat --summary --log --squash --commit --edit --cleanup= --ff --ff-only --rerere-autoupdate --verify-signatures --strategy= --strategy-option= --message= --file --verbose --quiet --abort --quit --continue --allow-unrelated-histories --progress --gpg-sign --autostash --overwrite-ignore --signoff --no-verify --verify -- --no-stat --no-summary --no-log --no-squash --no-commit --no-edit --no-cleanup --no-ff --no-rerere-autoupdate --no-verify-signatures --no-strategy --no-strategy-option --no-message --no-verbose --no-quiet --no-abort --no-quit --no-continue --no-allow-unrelated-histories --no-progress --no-gpg-sign --no-autostash --no-overwrite-ignore --no-signoff"
__gitcomp_builtin_merge_base_default=" --all --octopus --independent --is-ancestor --fork-point --no-all"
__gitcomp_builtin_merge_file_default=" --stdout --diff3 --ours --theirs --union --marker-size= --quiet --no-stdout -- --no-diff3 --no-ours --no-theirs --no-union --no-marker-size --no-quiet"
__gitcomp_builtin_mktree_default=" --missing --batch --no-missing -- --no-batch"
__gitcomp_builtin_multi_pack_index_default=" --object-dir= --progress --batch-size= --no-object-dir -- --no-progress"
__gitcomp_builtin_mv_default=" --verbose --dry-run --no-verbose -- --no-dry-run"
__gitcomp_builtin_name_rev_default=" --name-only --tags --refs= --exclude= --all --stdin --undefined --always --no-name-only -- --no-tags --no-refs --no-exclude --no-all --no-stdin --no-undefined --no-always"
__gitcomp_builtin_notes_default=" --ref= --no-ref"
__gitcomp_builtin_pack_objects_default=" --quiet --progress --all-progress --all-progress-implied --index-version= --max-pack-size= --local --incremental --window= --window-memory= --depth= --reuse-delta --reuse-object --delta-base-offset --threads= --non-empty --revs --unpacked --all --reflog --indexed-objects --stdout --include-tag --keep-unreachable --pack-loose-unreachable --unpack-unreachable --sparse --thin --shallow --honor-pack-keep --keep-pack= --compression= --keep-true-parents --use-bitmap-index --write-bitmap-index --filter= --missing= --exclude-promisor-objects --delta-islands --uri-protocol= --no-quiet -- --no-progress --no-all-progress --no-all-progress-implied --no-local --no-incremental --no-window --no-depth --no-reuse-delta --no-reuse-object --no-delta-base-offset --no-threads --no-non-empty --no-revs --no-stdout --no-include-tag --no-keep-unreachable --no-pack-loose-unreachable --no-unpack-unreachable --no-sparse --no-thin --no-shallow --no-honor-pack-keep --no-keep-pack --no-compression --no-keep-true-parents --no-use-bitmap-index --no-write-bitmap-index --no-filter --no-exclude-promisor-objects --no-delta-islands --no-uri-protocol"
__gitcomp_builtin_pack_refs_default=" --all --prune --no-all -- --no-prune"
__gitcomp_builtin_pickaxe_default=" --incremental --root --show-stats --progress --score-debug --show-name --show-number --porcelain --line-porcelain --show-email --ignore-rev= --ignore-revs-file= --color-lines --color-by-age --minimal --contents= --abbrev --no-incremental -- --no-root --no-show-stats --no-progress --no-score-debug --no-show-name --no-show-number --no-porcelain --no-line-porcelain --no-show-email --no-ignore-rev --no-ignore-revs-file --no-color-lines --no-color-by-age --no-minimal --no-contents --no-abbrev"
__gitcomp_builtin_prune_default=" --dry-run --verbose --progress --expire= --exclude-promisor-objects --no-dry-run -- --no-verbose --no-progress --no-expire --no-exclude-promisor-objects"
__gitcomp_builtin_prune_packed_default=" --dry-run --quiet --no-dry-run -- --no-quiet"
__gitcomp_builtin_pull_default=" --verbose --quiet --progress --recurse-submodules --rebase --stat --log --signoff --squash --commit --edit --cleanup= --ff --ff-only --verify-signatures --autostash --strategy= --strategy-option= --gpg-sign --allow-unrelated-histories --all --append --upload-pack= --force --tags --prune --jobs --dry-run --keep --depth= --shallow-since= --shallow-exclude= --deepen= --unshallow --update-shallow --refmap= --server-option= --ipv4 --ipv6 --negotiation-tip= --show-forced-updates --set-upstream --no-verbose -- --no-quiet --no-progress --no-recurse-submodules --no-rebase --no-stat --no-log --no-signoff --no-squash --no-commit --no-edit --no-cleanup --no-ff --no-verify-signatures --no-autostash --no-strategy --no-strategy-option --no-gpg-sign --no-allow-unrelated-histories --no-all --no-append --no-upload-pack --no-force --no-tags --no-prune --no-jobs --no-dry-run --no-keep --no-depth --no-shallow-since --no-shallow-exclude --no-deepen --no-update-shallow --no-server-option --no-ipv4 --no-ipv6 --no-negotiation-tip --no-show-forced-updates --no-set-upstream"
__gitcomp_builtin_push_default=" --verbose --quiet --repo= --all --mirror --delete --tags --dry-run --porcelain --force --force-with-lease --recurse-submodules= --receive-pack= --exec= --set-upstream --progress --prune --no-verify --follow-tags --signed --atomic --push-option= --ipv4 --ipv6 --verify -- --no-verbose --no-quiet --no-repo --no-all --no-mirror --no-delete --no-tags --no-dry-run --no-porcelain --no-force --no-force-with-lease --no-recurse-submodules --no-receive-pack --no-exec --no-set-upstream --no-progress --no-prune --no-follow-tags --no-signed --no-atomic --no-push-option --no-ipv4 --no-ipv6"
__gitcomp_builtin_range_diff_default=" --creation-factor= --no-dual-color --notes --patch --no-patch --unified --function-context --raw --patch-with-raw --patch-with-stat --numstat --shortstat --dirstat --cumulative --dirstat-by-file --check --summary --name-only --name-status --stat --stat-width= --stat-name-width= --stat-graph-width= --stat-count= --compact-summary --binary --full-index --color --ws-error-highlight= --abbrev --src-prefix= --dst-prefix= --line-prefix= --no-prefix --inter-hunk-context= --output-indicator-new= --output-indicator-old= --output-indicator-context= --break-rewrites --find-renames --irreversible-delete --find-copies --find-copies-harder --no-renames --rename-empty --follow --minimal --ignore-all-space --ignore-space-change --ignore-space-at-eol --ignore-cr-at-eol --ignore-blank-lines --indent-heuristic --patience --histogram --diff-algorithm= --anchored= --word-diff --word-diff-regex= --color-words --color-moved --color-moved-ws= --relative --text --exit-code --quiet --ext-diff --textconv --ignore-submodules --submodule --ita-invisible-in-index --ita-visible-in-index --pickaxe-all --pickaxe-regex --find-object= --diff-filter= --output= --dual-color -- --no-creation-factor --no-notes --no-function-context --no-compact-summary --no-full-index --no-color --no-abbrev --no-find-copies-harder --no-rename-empty --no-follow --no-minimal --no-indent-heuristic --no-color-moved --no-color-moved-ws --no-relative --no-text --no-exit-code --no-quiet --no-ext-diff --no-textconv"
__gitcomp_builtin_read_tree_default=" --index-output= --empty --verbose --trivial --aggressive --reset --prefix= --exclude-per-directory= --dry-run --no-sparse-checkout --debug-unpack --recurse-submodules --quiet --sparse-checkout -- --no-empty --no-verbose --no-trivial --no-aggressive --no-reset --no-dry-run --no-debug-unpack --no-recurse-submodules --no-quiet"
__gitcomp_builtin_rebase_default=" --onto= --keep-base --no-verify --quiet --verbose --no-stat --signoff --committer-date-is-author-date --reset-author-date --ignore-whitespace --whitespace= --force-rebase --no-ff --continue --skip --abort --quit --edit-todo --show-current-patch --apply --merge --interactive --rerere-autoupdate --empty= --autosquash --gpg-sign --autostash --exec= --rebase-merges --fork-point --strategy= --strategy-option= --root --reschedule-failed-exec --reapply-cherry-picks --verify --stat --ff -- --no-onto --no-keep-base --no-quiet --no-verbose --no-signoff --no-committer-date-is-author-date --no-reset-author-date --no-ignore-whitespace --no-whitespace --no-force-rebase --no-rerere-autoupdate --no-autosquash --no-gpg-sign --no-autostash --no-exec --no-rebase-merges --no-fork-point --no-strategy --no-strategy-option --no-root --no-reschedule-failed-exec --no-reapply-cherry-picks"
__gitcomp_builtin_rebase__interactive_default=" --ff --rebase-merges --rebase-cousins --autosquash --signoff --verbose --continue --skip --edit-todo --show-current-patch --shorten-ids --expand-ids --check-todo-list --rearrange-squash --add-exec-commands --onto= --restrict-revision= --squash-onto= --upstream= --head-name= --gpg-sign --strategy= --strategy-opts= --switch-to= --onto-name= --cmd= --rerere-autoupdate --reschedule-failed-exec --no-ff -- --no-rebase-merges --no-rebase-cousins --no-autosquash --no-signoff --no-verbose --no-head-name --no-gpg-sign --no-strategy --no-strategy-opts --no-switch-to --no-onto-name --no-cmd --no-rerere-autoupdate --no-reschedule-failed-exec"
__gitcomp_builtin_receive_pack_default=" --quiet --no-quiet"
__gitcomp_builtin_reflog_default=" --quiet --source --use-mailmap --mailmap --decorate-refs= --decorate-refs-exclude= --decorate --no-quiet -- --no-source --no-use-mailmap --no-mailmap --no-decorate-refs --no-decorate-refs-exclude --no-decorate"
__gitcomp_builtin_remote_default=" --verbose --no-verbose"
__gitcomp_builtin_repack_default=" --quiet --local --write-bitmap-index --delta-islands --unpack-unreachable= --keep-unreachable --window= --window-memory= --depth= --threads= --max-pack-size= --pack-kept-objects --keep-pack= --no-quiet -- --no-local --no-write-bitmap-index --no-delta-islands --no-unpack-unreachable --no-keep-unreachable --no-window --no-window-memory --no-depth --no-threads --no-max-pack-size --no-pack-kept-objects --no-keep-pack"
__gitcomp_builtin_replace_default=" --list --delete --edit --graft --convert-graft-file --raw --format= --no-raw -- --no-format"
__gitcomp_builtin_rerere_default=" --rerere-autoupdate --no-rerere-autoupdate"
__gitcomp_builtin_reset_default=" --quiet --mixed --soft --hard --merge --keep --recurse-submodules --patch --intent-to-add --pathspec-from-file= --pathspec-file-nul --no-quiet -- --no-mixed --no-soft --no-hard --no-merge --no-keep --no-recurse-submodules --no-patch --no-intent-to-add --no-pathspec-from-file --no-pathspec-file-nul"
__gitcomp_builtin_restore_default=" --source= --staged --worktree --ignore-unmerged --overlay --quiet --recurse-submodules --progress --merge --conflict= --ours --theirs --patch --ignore-skip-worktree-bits --pathspec-from-file= --pathspec-file-nul --no-source -- --no-staged --no-worktree --no-ignore-unmerged --no-overlay --no-quiet --no-recurse-submodules --no-progress --no-merge --no-conflict --no-patch --no-ignore-skip-worktree-bits --no-pathspec-from-file --no-pathspec-file-nul"
__gitcomp_builtin_revert_default=" --quit --continue --abort --skip --cleanup= --no-commit --edit --signoff --mainline= --rerere-autoupdate --strategy= --strategy-option= --gpg-sign --commit -- --no-cleanup --no-edit --no-signoff --no-mainline --no-rerere-autoupdate --no-strategy --no-strategy-option --no-gpg-sign"
__gitcomp_builtin_rm_default=" --dry-run --quiet --cached --ignore-unmatch --pathspec-from-file= --pathspec-file-nul --no-dry-run -- --no-quiet --no-cached --no-ignore-unmatch --no-pathspec-from-file --no-pathspec-file-nul"
__gitcomp_builtin_send_pack_default=" --verbose --quiet --receive-pack= --exec= --remote= --all --dry-run --mirror --force --signed --push-option= --progress --thin --atomic --stateless-rpc --stdin --helper-status --force-with-lease --no-verbose -- --no-quiet --no-receive-pack --no-exec --no-remote --no-all --no-dry-run --no-mirror --no-force --no-signed --no-push-option --no-progress --no-thin --no-atomic --no-stateless-rpc --no-stdin --no-helper-status --no-force-with-lease"
__gitcomp_builtin_shortlog_default=" --committer --numbered --summary --email --group= --no-committer -- --no-numbered --no-summary --no-email --no-group"
__gitcomp_builtin_show_default=" --quiet --source --use-mailmap --mailmap --decorate-refs= --decorate-refs-exclude= --decorate --no-quiet -- --no-source --no-use-mailmap --no-mailmap --no-decorate-refs --no-decorate-refs-exclude --no-decorate"
__gitcomp_builtin_show_branch_default=" --all --remotes --color --more --list --no-name --current --sha1-name --merge-base --independent --topo-order --topics --sparse --date-order --reflog --name -- --no-all --no-remotes --no-color --no-more --no-list --no-current --no-sha1-name --no-merge-base --no-independent --no-topo-order --no-topics --no-sparse --no-date-order"
__gitcomp_builtin_show_index_default=" --object-format= --no-object-format"
__gitcomp_builtin_show_ref_default=" --tags --heads --verify --head --dereference --hash --abbrev --quiet --exclude-existing --no-tags -- --no-heads --no-verify --no-head --no-dereference --no-hash --no-abbrev --no-quiet"
__gitcomp_builtin_sparse_checkout_default=""
__gitcomp_builtin_stage_default=" --dry-run --verbose --interactive --patch --edit --force --update --renormalize --intent-to-add --all --ignore-removal --refresh --ignore-errors --ignore-missing --chmod= --pathspec-from-file= --pathspec-file-nul --no-dry-run -- --no-verbose --no-interactive --no-patch --no-edit --no-force --no-update --no-renormalize --no-intent-to-add --no-all --no-ignore-removal --no-refresh --no-ignore-errors --no-ignore-missing --no-chmod --no-pathspec-from-file --no-pathspec-file-nul"
__gitcomp_builtin_stash_default=""
__gitcomp_builtin_status_default=" --verbose --short --branch --show-stash --ahead-behind --porcelain --long --null --untracked-files --ignored --ignore-submodules --column --no-renames --find-renames --renames -- --no-verbose --no-short --no-branch --no-show-stash --no-ahead-behind --no-porcelain --no-long --no-null --no-untracked-files --no-ignored --no-ignore-submodules --no-column"
__gitcomp_builtin_stripspace_default=" --strip-comments --comment-lines"
__gitcomp_builtin_switch_default=" --create= --force-create= --guess --discard-changes --quiet --recurse-submodules --progress --merge --conflict= --detach --track --orphan= --ignore-other-worktrees --no-create -- --no-force-create --no-guess --no-discard-changes --no-quiet --no-recurse-submodules --no-progress --no-merge --no-conflict --no-detach --no-track --no-orphan --no-ignore-other-worktrees"
__gitcomp_builtin_symbolic_ref_default=" --quiet --delete --short --no-quiet -- --no-delete --no-short"
__gitcomp_builtin_tag_default=" --list --delete --verify --annotate --message= --file= --edit --sign --cleanup= --local-user= --force --create-reflog --column --contains --no-contains --merged --no-merged --sort= --points-at --format= --color --ignore-case -- --no-annotate --no-file --no-edit --no-sign --no-cleanup --no-local-user --no-force --no-create-reflog --no-column --no-points-at --no-format --no-color --no-ignore-case"
__gitcomp_builtin_update_index_default=" --ignore-submodules --add --replace --remove --unmerged --refresh --really-refresh --cacheinfo --chmod= --assume-unchanged --no-assume-unchanged --skip-worktree --no-skip-worktree --ignore-skip-worktree-entries --info-only --force-remove --stdin --index-info --unresolve --again --ignore-missing --verbose --clear-resolve-undo --index-version= --split-index --untracked-cache --test-untracked-cache --force-untracked-cache --force-write-index --fsmonitor --fsmonitor-valid --no-fsmonitor-valid -- --no-ignore-submodules --no-add --no-replace --no-remove --no-unmerged --no-ignore-skip-worktree-entries --no-info-only --no-force-remove --no-ignore-missing --no-verbose --no-index-version --no-split-index --no-untracked-cache --no-test-untracked-cache --no-force-untracked-cache --no-force-write-index --no-fsmonitor"
__gitcomp_builtin_update_ref_default=" --no-deref --stdin --create-reflog --deref -- --no-stdin --no-create-reflog"
__gitcomp_builtin_update_server_info_default=" --force --no-force"
__gitcomp_builtin_upload_pack_default=" --stateless-rpc --advertise-refs --strict --timeout= --no-stateless-rpc -- --no-advertise-refs --no-strict --no-timeout"
__gitcomp_builtin_verify_commit_default=" --verbose --raw --no-verbose -- --no-raw"
__gitcomp_builtin_verify_pack_default=" --verbose --stat-only --object-format= --no-verbose -- --no-stat-only --no-object-format"
__gitcomp_builtin_verify_tag_default=" --verbose --raw --format= --no-verbose -- --no-raw --no-format"
__gitcomp_builtin_version_default=" --build-options --no-build-options"
__gitcomp_builtin_whatchanged_default=" --quiet --source --use-mailmap --mailmap --decorate-refs= --decorate-refs-exclude= --decorate --no-quiet -- --no-source --no-use-mailmap --no-mailmap --no-decorate-refs --no-decorate-refs-exclude --no-decorate"
__gitcomp_builtin_write_tree_default=" --missing-ok --prefix= --no-missing-ok -- --no-prefix"
__gitcomp_builtin_send_email_default=" --numbered --no-numbered --signoff --stdout --cover-letter --numbered-files --suffix= --start-number= --reroll-count= --rfc --cover-from-description= --subject-prefix= --output-directory= --keep-subject --no-binary --zero-commit --ignore-if-in-upstream --no-stat --add-header= --to= --cc= --from --in-reply-to= --attach --inline --thread --signature= --base= --signature-file= --quiet --progress --interdiff= --range-diff= --creation-factor= --binary -- --no-numbered --no-signoff --no-stdout --no-cover-letter --no-numbered-files --no-suffix --no-start-number --no-reroll-count --no-cover-from-description --no-zero-commit --no-ignore-if-in-upstream --no-add-header --no-to --no-cc --no-from --no-in-reply-to --no-attach --no-thread --no-signature --no-base --no-signature-file --no-quiet --no-progress --no-interdiff --no-range-diff --no-creation-factor"

__gitcomp_builtin_get_default ()
{
	eval "test -n \"\$${1}_default\" && echo \"\$${1}_default\""
}

# This function is equivalent to
#
#    __gitcomp "$(git xxx --git-completion-helper) ..."
#
# except that the output is cached. Accept 1-3 arguments:
# 1: the git command to execute, this is also the cache key
# 2: extra options to be added on top (e.g. negative forms)
# 3: options to be excluded
__gitcomp_builtin ()
{
	# spaces must be replaced with underscore for multi-word
	# commands, e.g. "git remote add" becomes remote_add.
	local cmd="$1"
	local incl="${2-}"
	local excl="${3-}"

	local var=__gitcomp_builtin_"${cmd//-/_}"
	local options
	eval "options=\${$var-}"

	if [ -z "$options" ]; then
		local completion_helper
		if [ "$GIT_COMPLETION_SHOW_ALL" = "1" ]; then
			completion_helper="--git-completion-helper-all"
		else
			completion_helper="--git-completion-helper"
		fi
		completion="$(__git ${cmd/_/ } $completion_helper ||
			__gitcomp_builtin_get_default $var)" || return
		# leading and trailing spaces are significant to make
		# option removal work correctly.
		options=" $incl $completion "

		for i in $excl; do
			options="${options/ $i / }"
		done
		eval "$var=\"$options\""
	fi

	__gitcomp "$options"
}

# Variation of __gitcomp_nl () that appends to the existing list of
# completion candidates, COMPREPLY.
__gitcomp_nl_append ()
{
	local IFS=$'\n'
	__gitcompappend "$1" "${2-}" "${3-$cur}" "${4- }"
}

# Generates completion reply from newline-separated possible completion words
# by appending a space to all of them.
# It accepts 1 to 4 arguments:
# 1: List of possible completion words, separated by a single newline.
# 2: A prefix to be added to each possible completion word (optional).
# 3: Generate possible completion matches for this word (optional).
# 4: A suffix to be appended to each possible completion word instead of
#    the default space (optional).  If specified but empty, nothing is
#    appended.
__gitcomp_nl ()
{
	COMPREPLY=()
	__gitcomp_nl_append "$@"
}

# Fills the COMPREPLY array with prefiltered paths without any additional
# processing.
# Callers must take care of providing only paths that match the current path
# to be completed and adding any prefix path components, if necessary.
# 1: List of newline-separated matching paths, complete with all prefix
#    path components.
__gitcomp_file_direct ()
{
	local IFS=$'\n'

	COMPREPLY=($1)

	# use a hack to enable file mode in bash < 4
	compopt -o filenames +o nospace 2>/dev/null ||
	compgen -f /non-existing-dir/ >/dev/null ||
	true
}

# Generates completion reply with compgen from newline-separated possible
# completion filenames.
# It accepts 1 to 3 arguments:
# 1: List of possible completion filenames, separated by a single newline.
# 2: A directory prefix to be added to each possible completion filename
#    (optional).
# 3: Generate possible completion matches for this word (optional).
__gitcomp_file ()
{
	local IFS=$'\n'

	# XXX does not work when the directory prefix contains a tilde,
	# since tilde expansion is not applied.
	# This means that COMPREPLY will be empty and Bash default
	# completion will be used.
	__gitcompadd "$1" "${2-}" "${3-$cur}" ""

	# use a hack to enable file mode in bash < 4
	compopt -o filenames +o nospace 2>/dev/null ||
	compgen -f /non-existing-dir/ >/dev/null ||
	true
}

# Execute 'git ls-files', unless the --committable option is specified, in
# which case it runs 'git diff-index' to find out the files that can be
# committed.  It return paths relative to the directory specified in the first
# argument, and using the options specified in the second argument.
__git_ls_files_helper ()
{
	if [ "$2" == "--committable" ]; then
		__git -C "$1" -c core.quotePath=false diff-index \
			--name-only --relative HEAD -- "${3//\\/\\\\}*"
	else
		# NOTE: $2 is not quoted in order to support multiple options
		__git -C "$1" -c core.quotePath=false ls-files \
			--exclude-standard $2 -- "${3//\\/\\\\}*"
	fi
}


# __git_index_files accepts 1 or 2 arguments:
# 1: Options to pass to ls-files (required).
# 2: A directory path (optional).
#    If provided, only files within the specified directory are listed.
#    Sub directories are never recursed.  Path must have a trailing
#    slash.
# 3: List only paths matching this path component (optional).
__git_index_files ()
{
	local root="$2" match="$3"

	__git_ls_files_helper "$root" "$1" "${match:-?}" |
	awk -F / -v pfx="${2//\\/\\\\}" '{
		paths[$1] = 1
	}
	END {
		for (p in paths) {
			if (substr(p, 1, 1) != "\"") {
				# No special characters, easy!
				print pfx p
				continue
			}

			# The path is quoted.
			p = dequote(p)
			if (p == "")
				continue

			# Even when a directory name itself does not contain
			# any special characters, it will still be quoted if
			# any of its (stripped) trailing path components do.
			# Because of this we may have seen the same directory
			# both quoted and unquoted.
			if (p in paths)
				# We have seen the same directory unquoted,
				# skip it.
				continue
			else
				print pfx p
		}
	}
	function dequote(p,    bs_idx, out, esc, esc_idx, dec) {
		# Skip opening double quote.
		p = substr(p, 2)

		# Interpret backslash escape sequences.
		while ((bs_idx = index(p, "\\")) != 0) {
			out = out substr(p, 1, bs_idx - 1)
			esc = substr(p, bs_idx + 1, 1)
			p = substr(p, bs_idx + 2)

			if ((esc_idx = index("abtvfr\"\\", esc)) != 0) {
				# C-style one-character escape sequence.
				out = out substr("\a\b\t\v\f\r\"\\",
						 esc_idx, 1)
			} else if (esc == "n") {
				# Uh-oh, a newline character.
				# We cannot reliably put a pathname
				# containing a newline into COMPREPLY,
				# and the newline would create a mess.
				# Skip this path.
				return ""
			} else {
				# Must be a \nnn octal value, then.
				dec = esc             * 64 + \
				      substr(p, 1, 1) * 8  + \
				      substr(p, 2, 1)
				out = out sprintf("%c", dec)
				p = substr(p, 3)
			}
		}
		# Drop closing double quote, if there is one.
		# (There is not any if this is a directory, as it was
		# already stripped with the trailing path components.)
		if (substr(p, length(p), 1) == "\"")
			out = out substr(p, 1, length(p) - 1)
		else
			out = out p

		return out
	}'
}

# __git_complete_index_file requires 1 argument:
# 1: the options to pass to ls-file
#
# The exception is --committable, which finds the files appropriate commit.
__git_complete_index_file ()
{
	local dequoted_word pfx="" cur_

	__git_dequote "$cur"

	case "$dequoted_word" in
	?*/*)
		pfx="${dequoted_word%/*}/"
		cur_="${dequoted_word##*/}"
		;;
	*)
		cur_="$dequoted_word"
	esac

	__gitcomp_file_direct "$(__git_index_files "$1" "$pfx" "$cur_")"
}

# Lists branches from the local repository.
# 1: A prefix to be added to each listed branch (optional).
# 2: List only branches matching this word (optional; list all branches if
#    unset or empty).
# 3: A suffix to be appended to each listed branch (optional).
__git_heads ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"

	__git for-each-ref --format="${pfx//\%/%%}%(refname:strip=2)$sfx" \
			"refs/heads/$cur_*" "refs/heads/$cur_*/**"
}

# Lists branches from remote repositories.
# 1: A prefix to be added to each listed branch (optional).
# 2: List only branches matching this word (optional; list all branches if
#    unset or empty).
# 3: A suffix to be appended to each listed branch (optional).
__git_remote_heads ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"

	__git for-each-ref --format="${pfx//\%/%%}%(refname:strip=2)$sfx" \
			"refs/remotes/$cur_*" "refs/remotes/$cur_*/**"
}

# Lists tags from the local repository.
# Accepts the same positional parameters as __git_heads() above.
__git_tags ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"

	__git for-each-ref --format="${pfx//\%/%%}%(refname:strip=2)$sfx" \
			"refs/tags/$cur_*" "refs/tags/$cur_*/**"
}

# List unique branches from refs/remotes used for 'git checkout' and 'git
# switch' tracking DWIMery.
# 1: A prefix to be added to each listed branch (optional)
# 2: List only branches matching this word (optional; list all branches if
#    unset or empty).
# 3: A suffix to be appended to each listed branch (optional).
__git_dwim_remote_heads ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"
	local fer_pfx="${pfx//\%/%%}" # "escape" for-each-ref format specifiers

	# employ the heuristic used by git checkout and git switch
	# Try to find a remote branch that cur_es the completion word
	# but only output if the branch name is unique
	__git for-each-ref --format="$fer_pfx%(refname:strip=3)$sfx" \
		--sort="refname:strip=3" \
		"refs/remotes/*/$cur_*" "refs/remotes/*/$cur_*/**" | \
	uniq -u
}

# Lists refs from the local (by default) or from a remote repository.
# It accepts 0, 1 or 2 arguments:
# 1: The remote to list refs from (optional; ignored, if set but empty).
#    Can be the name of a configured remote, a path, or a URL.
# 2: In addition to local refs, list unique branches from refs/remotes/ for
#    'git checkout's tracking DWIMery (optional; ignored, if set but empty).
# 3: A prefix to be added to each listed ref (optional).
# 4: List only refs matching this word (optional; list all refs if unset or
#    empty).
# 5: A suffix to be appended to each listed ref (optional; ignored, if set
#    but empty).
#
# Use __git_complete_refs() instead.
__git_refs ()
{
	local i hash dir track="${2-}"
	local list_refs_from=path remote="${1-}"
	local format refs
	local pfx="${3-}" cur_="${4-$cur}" sfx="${5-}"
	local match="${4-}"
	local fer_pfx="${pfx//\%/%%}" # "escape" for-each-ref format specifiers

	__git_find_repo_path
	dir="$__git_repo_path"

	if [ -z "$remote" ]; then
		if [ -z "$dir" ]; then
			return
		fi
	else
		if __git_is_configured_remote "$remote"; then
			# configured remote takes precedence over a
			# local directory with the same name
			list_refs_from=remote
		elif [ -d "$remote/.git" ]; then
			dir="$remote/.git"
		elif [ -d "$remote" ]; then
			dir="$remote"
		else
			list_refs_from=url
		fi
	fi

	if [ "$list_refs_from" = path ]; then
		if [[ "$cur_" == ^* ]]; then
			pfx="$pfx^"
			fer_pfx="$fer_pfx^"
			cur_=${cur_#^}
			match=${match#^}
		fi
		case "$cur_" in
		refs|refs/*)
			format="refname"
			refs=("$match*" "$match*/**")
			track=""
			;;
		*)
			for i in HEAD FETCH_HEAD ORIG_HEAD MERGE_HEAD REBASE_HEAD; do
				case "$i" in
				$match*)
					if [ -e "$dir/$i" ]; then
						echo "$pfx$i$sfx"
					fi
					;;
				esac
			done
			format="refname:strip=2"
			refs=("refs/tags/$match*" "refs/tags/$match*/**"
				"refs/heads/$match*" "refs/heads/$match*/**"
				"refs/remotes/$match*" "refs/remotes/$match*/**")
			;;
		esac
		__git_dir="$dir" __git for-each-ref --format="$fer_pfx%($format)$sfx" \
			"${refs[@]}"
		if [ -n "$track" ]; then
			__git_dwim_remote_heads "$pfx" "$match" "$sfx"
		fi
		return
	fi
	case "$cur_" in
	refs|refs/*)
		__git ls-remote "$remote" "$match*" | \
		while read -r hash i; do
			case "$i" in
			*^{}) ;;
			*) echo "$pfx$i$sfx" ;;
			esac
		done
		;;
	*)
		if [ "$list_refs_from" = remote ]; then
			case "HEAD" in
			$match*)	echo "${pfx}HEAD$sfx" ;;
			esac
			__git for-each-ref --format="$fer_pfx%(refname:strip=3)$sfx" \
				"refs/remotes/$remote/$match*" \
				"refs/remotes/$remote/$match*/**"
		else
			local query_symref
			case "HEAD" in
			$match*)	query_symref="HEAD" ;;
			esac
			__git ls-remote "$remote" $query_symref \
				"refs/tags/$match*" "refs/heads/$match*" \
				"refs/remotes/$match*" |
			while read -r hash i; do
				case "$i" in
				*^{})	;;
				refs/*)	echo "$pfx${i#refs/*/}$sfx" ;;
				*)	echo "$pfx$i$sfx" ;;  # symbolic refs
				esac
			done
		fi
		;;
	esac
}

# Completes refs, short and long, local and remote, symbolic and pseudo.
#
# Usage: __git_complete_refs [<option>]...
# --remote=<remote>: The remote to list refs from, can be the name of a
#                    configured remote, a path, or a URL.
# --dwim: List unique remote branches for 'git switch's tracking DWIMery.
# --pfx=<prefix>: A prefix to be added to each ref.
# --cur=<word>: The current ref to be completed.  Defaults to the current
#               word to be completed.
# --sfx=<suffix>: A suffix to be appended to each ref instead of the default
#                 space.
# --mode=<mode>: What set of refs to complete, one of 'refs' (the default) to
#                complete all refs, 'heads' to complete only branches, or
#                'remote-heads' to complete only remote branches. Note that
#                --remote is only compatible with --mode=refs.
__git_complete_refs ()
{
	local remote= dwim= pfx= cur_="$cur" sfx=" " mode="refs"

	while test $# != 0; do
		case "$1" in
		--remote=*)	remote="${1##--remote=}" ;;
		--dwim)		dwim="yes" ;;
		# --track is an old spelling of --dwim
		--track)	dwim="yes" ;;
		--pfx=*)	pfx="${1##--pfx=}" ;;
		--cur=*)	cur_="${1##--cur=}" ;;
		--sfx=*)	sfx="${1##--sfx=}" ;;
		--mode=*)	mode="${1##--mode=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	# complete references based on the specified mode
	case "$mode" in
		refs)
			__gitcomp_direct "$(__git_refs "$remote" "" "$pfx" "$cur_" "$sfx")" ;;
		heads)
			__gitcomp_direct "$(__git_heads "$pfx" "$cur_" "$sfx")" ;;
		remote-heads)
			__gitcomp_direct "$(__git_remote_heads "$pfx" "$cur_" "$sfx")" ;;
		*)
			return 1 ;;
	esac

	# Append DWIM remote branch names if requested
	if [ "$dwim" = "yes" ]; then
		__gitcomp_direct_append "$(__git_dwim_remote_heads "$pfx" "$cur_" "$sfx")"
	fi
}

# __git_refs2 requires 1 argument (to pass to __git_refs)
# Deprecated: use __git_complete_fetch_refspecs() instead.
__git_refs2 ()
{
	local i
	for i in $(__git_refs "$1"); do
		echo "$i:$i"
	done
}

# Completes refspecs for fetching from a remote repository.
# 1: The remote repository.
# 2: A prefix to be added to each listed refspec (optional).
# 3: The ref to be completed as a refspec instead of the current word to be
#    completed (optional)
# 4: A suffix to be appended to each listed refspec instead of the default
#    space (optional).
__git_complete_fetch_refspecs ()
{
	local i remote="$1" pfx="${2-}" cur_="${3-$cur}" sfx="${4- }"

	__gitcomp_direct "$(
		for i in $(__git_refs "$remote" "" "" "$cur_") ; do
			echo "$pfx$i:$i$sfx"
		done
		)"
}

# __git_refs_remotes requires 1 argument (to pass to ls-remote)
__git_refs_remotes ()
{
	local i hash
	__git ls-remote "$1" 'refs/heads/*' | \
	while read -r hash i; do
		echo "$i:refs/remotes/$1/${i#refs/heads/}"
	done
}

__git_remotes ()
{
	__git_find_repo_path
	test -d "$__git_repo_path/remotes" && ls -1 "$__git_repo_path/remotes"
	__git remote
}

# Returns true if $1 matches the name of a configured remote, false otherwise.
__git_is_configured_remote ()
{
	local remote
	for remote in $(__git_remotes); do
		if [ "$remote" = "$1" ]; then
			return 0
		fi
	done
	return 1
}

__git_list_merge_strategies ()
{
	LANG=C LC_ALL=C git merge -s help 2>&1 |
	sed -n -e '/[Aa]vailable strategies are: /,/^$/{
		s/\.$//
		s/.*://
		s/^[ 	]*//
		s/[ 	]*$//
		p
	}'
}

__git_merge_strategies_default='octopus ours recursive resolve subtree'
__git_merge_strategies=
# 'git merge -s help' (and thus detection of the merge strategy
# list) fails, unfortunately, if run outside of any git working
# tree.  __git_merge_strategies is set to the empty string in
# that case, and the detection will be repeated the next time it
# is needed.
__git_compute_merge_strategies ()
{
	test -n "$__git_merge_strategies" ||
	{ __git_merge_strategies=$(__git_list_merge_strategies);
		__git_merge_strategies="${__git_merge_strategies:-__git_merge_strategies_default}"; }
}

__git_merge_strategy_options="ours theirs subtree subtree= patience
	histogram diff-algorithm= ignore-space-change ignore-all-space
	ignore-space-at-eol renormalize no-renormalize no-renames
	find-renames find-renames= rename-threshold="

__git_complete_revlist_file ()
{
	local dequoted_word pfx ls ref cur_="$cur"
	case "$cur_" in
	*..?*:*)
		return
		;;
	?*:*)
		ref="${cur_%%:*}"
		cur_="${cur_#*:}"

		__git_dequote "$cur_"

		case "$dequoted_word" in
		?*/*)
			pfx="${dequoted_word%/*}"
			cur_="${dequoted_word##*/}"
			ls="$ref:$pfx"
			pfx="$pfx/"
			;;
		*)
			cur_="$dequoted_word"
			ls="$ref"
			;;
		esac

		case "$COMP_WORDBREAKS" in
		*:*) : great ;;
		*)   pfx="$ref:$pfx" ;;
		esac

		__gitcomp_file "$(__git ls-tree "$ls" \
				| sed 's/^.*	//
				       s/$//')" \
			"$pfx" "$cur_"
		;;
	*...*)
		pfx="${cur_%...*}..."
		cur_="${cur_#*...}"
		__git_complete_refs --pfx="$pfx" --cur="$cur_"
		;;
	*..*)
		pfx="${cur_%..*}.."
		cur_="${cur_#*..}"
		__git_complete_refs --pfx="$pfx" --cur="$cur_"
		;;
	*)
		__git_complete_refs
		;;
	esac
}

__git_complete_file ()
{
	__git_complete_revlist_file
}

__git_complete_revlist ()
{
	__git_complete_revlist_file
}

__git_complete_remote_or_refspec ()
{
	local cur_="$cur" cmd="${words[1]}"
	local i c=2 remote="" pfx="" lhs=1 no_complete_refspec=0
	if [ "$cmd" = "remote" ]; then
		((c++))
	fi
	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		--mirror) [ "$cmd" = "push" ] && no_complete_refspec=1 ;;
		-d|--delete) [ "$cmd" = "push" ] && lhs=0 ;;
		--all)
			case "$cmd" in
			push) no_complete_refspec=1 ;;
			fetch)
				return
				;;
			*) ;;
			esac
			;;
		--multiple) no_complete_refspec=1; break ;;
		-*) ;;
		*) remote="$i"; break ;;
		esac
		((c++))
	done
	if [ -z "$remote" ]; then
		__gitcomp_nl "$(__git_remotes)"
		return
	fi
	if [ $no_complete_refspec = 1 ]; then
		return
	fi
	[ "$remote" = "." ] && remote=
	case "$cur_" in
	*:*)
		case "$COMP_WORDBREAKS" in
		*:*) : great ;;
		*)   pfx="${cur_%%:*}:" ;;
		esac
		cur_="${cur_#*:}"
		lhs=0
		;;
	+*)
		pfx="+"
		cur_="${cur_#+}"
		;;
	esac
	case "$cmd" in
	fetch)
		if [ $lhs = 1 ]; then
			__git_complete_fetch_refspecs "$remote" "$pfx" "$cur_"
		else
			__git_complete_refs --pfx="$pfx" --cur="$cur_"
		fi
		;;
	pull|remote)
		if [ $lhs = 1 ]; then
			__git_complete_refs --remote="$remote" --pfx="$pfx" --cur="$cur_"
		else
			__git_complete_refs --pfx="$pfx" --cur="$cur_"
		fi
		;;
	push)
		if [ $lhs = 1 ]; then
			__git_complete_refs --pfx="$pfx" --cur="$cur_"
		else
			__git_complete_refs --remote="$remote" --pfx="$pfx" --cur="$cur_"
		fi
		;;
	esac
}

__git_complete_strategy ()
{
	__git_compute_merge_strategies
	case "$prev" in
	-s|--strategy)
		__gitcomp "$__git_merge_strategies"
		return 0
		;;
	-X)
		__gitcomp "$__git_merge_strategy_options"
		return 0
		;;
	esac
	case "$cur" in
	--strategy=*)
		__gitcomp "$__git_merge_strategies" "" "${cur##--strategy=}"
		return 0
		;;
	--strategy-option=*)
		__gitcomp "$__git_merge_strategy_options" "" "${cur##--strategy-option=}"
		return 0
		;;
	esac
	return 1
}

__git_all_commands=
__git_compute_all_commands ()
{
	test -n "$__git_all_commands" ||
	__git_all_commands=$(__git --list-cmds=main,others,alias,nohelpers)
}

# Lists all set config variables starting with the given section prefix,
# with the prefix removed.
__git_get_config_variables ()
{
	local section="$1" i IFS=$'\n'
	for i in $(__git config --name-only --get-regexp "^$section\..*"); do
		echo "${i#$section.}"
	done
}

__git_pretty_aliases ()
{
	__git_get_config_variables "pretty"
}

# __git_aliased_command requires 1 argument
__git_aliased_command ()
{
	local cur=$1 last list word cmdline

	while [[ -n "$cur" ]]; do
		if [[ "$list" == *" $cur "* ]]; then
			# loop detected
			return
		fi

		cmdline=$(__git config --get "alias.$cur")
		list=" $cur $list"
		last=$cur
		cur=

		for word in $cmdline; do
			case "$word" in
			\!gitk|gitk)
				cur="gitk"
				break
				;;
			\!*)	: shell command alias ;;
			-*)	: option ;;
			*=*)	: setting env ;;
			git)	: git itself ;;
			\(\))   : skip parens of shell function definition ;;
			{)	: skip start of shell helper function ;;
			:)	: skip null command ;;
			\'*)	: skip opening quote after sh -c ;;
			*)
				cur="$word"
				break
			esac
		done
	done

	cur=$last
	if [[ "$cur" != "$1" ]]; then
		echo "$cur"
	fi
}

# Check whether one of the given words is present on the command line,
# and print the first word found.
#
# Usage: __git_find_on_cmdline [<option>]... "<wordlist>"
# --show-idx: Optionally show the index of the found word in the $words array.
__git_find_on_cmdline ()
{
	local word c=1 show_idx

	while test $# -gt 1; do
		case "$1" in
		--show-idx)	show_idx=y ;;
		*)		return 1 ;;
		esac
		shift
	done
	local wordlist="$1"

	while [ $c -lt $cword ]; do
		for word in $wordlist; do
			if [ "$word" = "${words[c]}" ]; then
				if [ -n "${show_idx-}" ]; then
					echo "$c $word"
				else
					echo "$word"
				fi
				return
			fi
		done
		((c++))
	done
}

# Similar to __git_find_on_cmdline, except that it loops backwards and thus
# prints the *last* word found. Useful for finding which of two options that
# supersede each other came last, such as "--guess" and "--no-guess".
#
# Usage: __git_find_last_on_cmdline [<option>]... "<wordlist>"
# --show-idx: Optionally show the index of the found word in the $words array.
__git_find_last_on_cmdline ()
{
	local word c=$cword show_idx

	while test $# -gt 1; do
		case "$1" in
		--show-idx)	show_idx=y ;;
		*)		return 1 ;;
		esac
		shift
	done
	local wordlist="$1"

	while [ $c -gt 1 ]; do
		((c--))
		for word in $wordlist; do
			if [ "$word" = "${words[c]}" ]; then
				if [ -n "$show_idx" ]; then
					echo "$c $word"
				else
					echo "$word"
				fi
				return
			fi
		done
	done
}

# Echo the value of an option set on the command line or config
#
# $1: short option name
# $2: long option name including =
# $3: list of possible values
# $4: config string (optional)
#
# example:
# result="$(__git_get_option_value "-d" "--do-something=" \
#     "yes no" "core.doSomething")"
#
# result is then either empty (no option set) or "yes" or "no"
#
# __git_get_option_value requires 3 arguments
__git_get_option_value ()
{
	local c short_opt long_opt val
	local result= values config_key word

	short_opt="$1"
	long_opt="$2"
	values="$3"
	config_key="$4"

	((c = $cword - 1))
	while [ $c -ge 0 ]; do
		word="${words[c]}"
		for val in $values; do
			if [ "$short_opt$val" = "$word" ] ||
			   [ "$long_opt$val"  = "$word" ]; then
				result="$val"
				break 2
			fi
		done
		((c--))
	done

	if [ -n "$config_key" ] && [ -z "$result" ]; then
		result="$(__git config "$config_key")"
	fi

	echo "$result"
}

__git_has_doubledash ()
{
	local c=1
	while [ $c -lt $cword ]; do
		if [ "--" = "${words[c]}" ]; then
			return 0
		fi
		((c++))
	done
	return 1
}

# Try to count non option arguments passed on the command line for the
# specified git command.
# When options are used, it is necessary to use the special -- option to
# tell the implementation were non option arguments begin.
# XXX this can not be improved, since options can appear everywhere, as
# an example:
#	git mv x -n y
#
# __git_count_arguments requires 1 argument: the git command executed.
__git_count_arguments ()
{
	local word i c=0

	# Skip "git" (first argument)
	for ((i=1; i < ${#words[@]}; i++)); do
		word="${words[i]}"

		case "$word" in
			--)
				# Good; we can assume that the following are only non
				# option arguments.
				((c = 0))
				;;
			"$1")
				# Skip the specified git command and discard git
				# main options
				((c = 0))
				;;
			?*)
				((c++))
				;;
		esac
	done

	printf "%d" $c
}

__git_whitespacelist="nowarn warn error error-all fix"
__git_patchformat="mbox stgit stgit-series hg mboxrd"
__git_showcurrentpatch="diff raw"
__git_am_inprogress_options="--skip --continue --resolved --abort --quit --show-current-patch"

_git_am ()
{
	__git_find_repo_path
	if [ -d "$__git_repo_path"/rebase-apply ]; then
		__gitcomp "$__git_am_inprogress_options"
		return
	fi
	case "$cur" in
	--whitespace=*)
		__gitcomp "$__git_whitespacelist" "" "${cur##--whitespace=}"
		return
		;;
	--patch-format=*)
		__gitcomp "$__git_patchformat" "" "${cur##--patch-format=}"
		return
		;;
	--show-current-patch=*)
		__gitcomp "$__git_showcurrentpatch" "" "${cur##--show-current-patch=}"
		return
		;;
	--*)
		__gitcomp_builtin am "" \
			"$__git_am_inprogress_options"
		return
	esac
}

_git_apply ()
{
	case "$cur" in
	--whitespace=*)
		__gitcomp "$__git_whitespacelist" "" "${cur##--whitespace=}"
		return
		;;
	--*)
		__gitcomp_builtin apply
		return
	esac
}

_git_add ()
{
	case "$cur" in
	--chmod=*)
		__gitcomp "+x -x" "" "${cur##--chmod=}"
		return
		;;
	--*)
		__gitcomp_builtin add
		return
	esac

	local complete_opt="--others --modified --directory --no-empty-directory"
	if test -n "$(__git_find_on_cmdline "-u --update")"
	then
		complete_opt="--modified"
	fi
	__git_complete_index_file "$complete_opt"
}

_git_archive ()
{
	case "$cur" in
	--format=*)
		__gitcomp "$(git archive --list)" "" "${cur##--format=}"
		return
		;;
	--remote=*)
		__gitcomp_nl "$(__git_remotes)" "" "${cur##--remote=}"
		return
		;;
	--*)
		__gitcomp_builtin archive "--format= --list --verbose --prefix= --worktree-attributes"
		return
		;;
	esac
	__git_complete_file
}

_git_bisect ()
{
	__git_has_doubledash && return

	local subcommands="start bad good skip reset visualize replay log run"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__git_find_repo_path
		if [ -f "$__git_repo_path"/BISECT_START ]; then
			__gitcomp "$subcommands"
		else
			__gitcomp "replay start"
		fi
		return
	fi

	case "$subcommand" in
	bad|good|reset|skip|start)
		__git_complete_refs
		;;
	*)
		;;
	esac
}

__git_ref_fieldlist="refname objecttype objectsize objectname upstream push HEAD symref"

_git_branch ()
{
	local i c=1 only_local_ref="n" has_r="n"

	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		-d|--delete|-m|--move)	only_local_ref="y" ;;
		-r|--remotes)		has_r="y" ;;
		esac
		((c++))
	done

	case "$cur" in
	--set-upstream-to=*)
		__git_complete_refs --cur="${cur##--set-upstream-to=}"
		;;
	--*)
		__gitcomp_builtin branch
		;;
	*)
		if [ $only_local_ref = "y" -a $has_r = "n" ]; then
			__gitcomp_direct "$(__git_heads "" "$cur" " ")"
		else
			__git_complete_refs
		fi
		;;
	esac
}

_git_bundle ()
{
	local cmd="${words[2]}"
	case "$cword" in
	2)
		__gitcomp "create list-heads verify unbundle"
		;;
	3)
		# looking for a file
		;;
	*)
		case "$cmd" in
			create)
				__git_complete_revlist
			;;
		esac
		;;
	esac
}

# Helper function to decide whether or not we should enable DWIM logic for
# git-switch and git-checkout.
#
# To decide between the following rules in priority order
# 1) the last provided of "--guess" or "--no-guess" explicitly enable or
#    disable completion of DWIM logic respectively.
# 2) If the --no-track option is provided, take this as a hint to disable the
#    DWIM completion logic
# 3) If GIT_COMPLETION_CHECKOUT_NO_GUESS is set, disable the DWIM completion
#    logic, as requested by the user.
# 4) Enable DWIM logic otherwise.
#
__git_checkout_default_dwim_mode ()
{
	local last_option dwim_opt="--dwim"

	if [ "${GIT_COMPLETION_CHECKOUT_NO_GUESS-}" = "1" ]; then
		dwim_opt=""
	fi

	# --no-track disables DWIM, but with lower priority than
	# --guess/--no-guess
	if [ -n "$(__git_find_on_cmdline "--no-track")" ]; then
		dwim_opt=""
	fi

	# Find the last provided --guess or --no-guess
	last_option="$(__git_find_last_on_cmdline "--guess --no-guess")"
	case "$last_option" in
		--guess)
			dwim_opt="--dwim"
			;;
		--no-guess)
			dwim_opt=""
			;;
	esac

	echo "$dwim_opt"
}

_git_checkout ()
{
	__git_has_doubledash && return

	local dwim_opt="$(__git_checkout_default_dwim_mode)"

	case "$prev" in
	-b|-B|--orphan)
		# Complete local branches (and DWIM branch
		# remote branch names) for an option argument
		# specifying a new branch name. This is for
		# convenience, assuming new branches are
		# possibly based on pre-existing branch names.
		__git_complete_refs $dwim_opt --mode="heads"
		return
		;;
	*)
		;;
	esac

	case "$cur" in
	--conflict=*)
		__gitcomp "diff3 merge" "" "${cur##--conflict=}"
		;;
	--*)
		__gitcomp_builtin checkout
		;;
	*)
		# At this point, we've already handled special completion for
		# the arguments to -b/-B, and --orphan. There are 3 main
		# things left we can possibly complete:
		# 1) a start-point for -b/-B, -d/--detach, or --orphan
		# 2) a remote head, for --track
		# 3) an arbitrary reference, possibly including DWIM names
		#

		if [ -n "$(__git_find_on_cmdline "-b -B -d --detach --orphan")" ]; then
			__git_complete_refs --mode="refs"
		elif [ -n "$(__git_find_on_cmdline "--track")" ]; then
			__git_complete_refs --mode="remote-heads"
		else
			__git_complete_refs $dwim_opt --mode="refs"
		fi
		;;
	esac
}

__git_sequencer_inprogress_options="--continue --quit --abort --skip"

__git_cherry_pick_inprogress_options=$__git_sequencer_inprogress_options

_git_cherry_pick ()
{
	__git_find_repo_path
	if [ -f "$__git_repo_path"/CHERRY_PICK_HEAD ]; then
		__gitcomp "$__git_cherry_pick_inprogress_options"
		return
	fi

	__git_complete_strategy && return

	case "$cur" in
	--*)
		__gitcomp_builtin cherry-pick "" \
			"$__git_cherry_pick_inprogress_options"
		;;
	*)
		__git_complete_refs
		;;
	esac
}

_git_clean ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin clean
		return
		;;
	esac

	# XXX should we check for -x option ?
	__git_complete_index_file "--others --directory"
}

_git_clone ()
{
	case "$prev" in
	-c|--config)
		__git_complete_config_variable_name_and_value
		return
		;;
	esac
	case "$cur" in
	--config=*)
		__git_complete_config_variable_name_and_value \
			--cur="${cur##--config=}"
		return
		;;
	--*)
		__gitcomp_builtin clone
		return
		;;
	esac
}

__git_untracked_file_modes="all no normal"

_git_commit ()
{
	case "$prev" in
	-c|-C)
		__git_complete_refs
		return
		;;
	esac

	case "$cur" in
	--cleanup=*)
		__gitcomp "default scissors strip verbatim whitespace
			" "" "${cur##--cleanup=}"
		return
		;;
	--reuse-message=*|--reedit-message=*|\
	--fixup=*|--squash=*)
		__git_complete_refs --cur="${cur#*=}"
		return
		;;
	--untracked-files=*)
		__gitcomp "$__git_untracked_file_modes" "" "${cur##--untracked-files=}"
		return
		;;
	--*)
		__gitcomp_builtin commit
		return
	esac

	if __git rev-parse --verify --quiet HEAD >/dev/null; then
		__git_complete_index_file "--committable"
	else
		# This is the first commit
		__git_complete_index_file "--cached"
	fi
}

_git_describe ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin describe
		return
	esac
	__git_complete_refs
}

__git_diff_algorithms="myers minimal patience histogram"

__git_diff_submodule_formats="diff log short"

__git_color_moved_opts="no default plain blocks zebra dimmed-zebra"

__git_color_moved_ws_opts="no ignore-space-at-eol ignore-space-change
			ignore-all-space allow-indentation-change"

__git_diff_common_options="--stat --numstat --shortstat --summary
			--patch-with-stat --name-only --name-status --color
			--no-color --color-words --no-renames --check
			--color-moved --color-moved= --no-color-moved
			--color-moved-ws= --no-color-moved-ws
			--full-index --binary --abbrev --diff-filter=
			--find-copies-harder --ignore-cr-at-eol
			--text --ignore-space-at-eol --ignore-space-change
			--ignore-all-space --ignore-blank-lines --exit-code
			--quiet --ext-diff --no-ext-diff
			--no-prefix --src-prefix= --dst-prefix=
			--inter-hunk-context=
			--patience --histogram --minimal
			--raw --word-diff --word-diff-regex=
			--dirstat --dirstat= --dirstat-by-file
			--dirstat-by-file= --cumulative
			--diff-algorithm=
			--submodule --submodule= --ignore-submodules
			--indent-heuristic --no-indent-heuristic
			--textconv --no-textconv
"

_git_diff ()
{
	__git_has_doubledash && return

	case "$cur" in
	--diff-algorithm=*)
		__gitcomp "$__git_diff_algorithms" "" "${cur##--diff-algorithm=}"
		return
		;;
	--submodule=*)
		__gitcomp "$__git_diff_submodule_formats" "" "${cur##--submodule=}"
		return
		;;
	--color-moved=*)
		__gitcomp "$__git_color_moved_opts" "" "${cur##--color-moved=}"
		return
		;;
	--color-moved-ws=*)
		__gitcomp "$__git_color_moved_ws_opts" "" "${cur##--color-moved-ws=}"
		return
		;;
	--*)
		__gitcomp "--cached --staged --pickaxe-all --pickaxe-regex
			--base --ours --theirs --no-index
			$__git_diff_common_options
			"
		return
		;;
	esac
	__git_complete_revlist_file
}

__git_mergetools_common="diffuse diffmerge ecmerge emerge kdiff3 meld opendiff
			tkdiff vimdiff nvimdiff gvimdiff xxdiff araxis p4merge
			bc codecompare smerge
"

_git_difftool ()
{
	__git_has_doubledash && return

	case "$cur" in
	--tool=*)
		__gitcomp "$__git_mergetools_common kompare" "" "${cur##--tool=}"
		return
		;;
	--*)
		__gitcomp_builtin difftool "$__git_diff_common_options
					--base --cached --ours --theirs
					--pickaxe-all --pickaxe-regex
					--relative --staged
					"
		return
		;;
	esac
	__git_complete_revlist_file
}

__git_fetch_recurse_submodules="yes on-demand no"

_git_fetch ()
{
	case "$cur" in
	--recurse-submodules=*)
		__gitcomp "$__git_fetch_recurse_submodules" "" "${cur##--recurse-submodules=}"
		return
		;;
	--filter=*)
		__gitcomp "blob:none blob:limit= sparse:oid=" "" "${cur##--filter=}"
		return
		;;
	--*)
		__gitcomp_builtin fetch
		return
		;;
	esac
	__git_complete_remote_or_refspec
}

__git_format_patch_extra_options="
	--full-index --not --all --no-prefix --src-prefix=
	--dst-prefix= --notes
"

_git_format_patch ()
{
	case "$cur" in
	--thread=*)
		__gitcomp "
			deep shallow
			" "" "${cur##--thread=}"
		return
		;;
	--base=*|--interdiff=*|--range-diff=*)
		__git_complete_refs --cur="${cur#--*=}"
		return
		;;
	--*)
		__gitcomp_builtin format-patch "$__git_format_patch_extra_options"
		return
		;;
	esac
	__git_complete_revlist
}

_git_fsck ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin fsck
		return
		;;
	esac
}

_git_gitk ()
{
	_gitk
}

# Lists matching symbol names from a tag (as in ctags) file.
# 1: List symbol names matching this word.
# 2: The tag file to list symbol names from.
# 3: A prefix to be added to each listed symbol name (optional).
# 4: A suffix to be appended to each listed symbol name (optional).
__git_match_ctag () {
	awk -v pfx="${3-}" -v sfx="${4-}" "
		/^${1//\//\\/}/ { print pfx \$1 sfx }
		" "$2"
}

# Complete symbol names from a tag file.
# Usage: __git_complete_symbol [<option>]...
# --tags=<file>: The tag file to list symbol names from instead of the
#                default "tags".
# --pfx=<prefix>: A prefix to be added to each symbol name.
# --cur=<word>: The current symbol name to be completed.  Defaults to
#               the current word to be completed.
# --sfx=<suffix>: A suffix to be appended to each symbol name instead
#                 of the default space.
__git_complete_symbol () {
	local tags=tags pfx="" cur_="${cur-}" sfx=" "

	while test $# != 0; do
		case "$1" in
		--tags=*)	tags="${1##--tags=}" ;;
		--pfx=*)	pfx="${1##--pfx=}" ;;
		--cur=*)	cur_="${1##--cur=}" ;;
		--sfx=*)	sfx="${1##--sfx=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	if test -r "$tags"; then
		__gitcomp_direct "$(__git_match_ctag "$cur_" "$tags" "$pfx" "$sfx")"
	fi
}

_git_grep ()
{
	__git_has_doubledash && return

	case "$cur" in
	--*)
		__gitcomp_builtin grep
		return
		;;
	esac

	case "$cword,$prev" in
	2,*|*,-*)
		__git_complete_symbol && return
		;;
	esac

	__git_complete_refs
}

_git_help ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin help
		return
		;;
	esac
	if test -n "$GIT_TESTING_ALL_COMMAND_LIST"
	then
		__gitcomp "$GIT_TESTING_ALL_COMMAND_LIST $(__git --list-cmds=alias,list-guide) gitk"
	else
		__gitcomp "$(__git --list-cmds=main,nohelpers,alias,list-guide) gitk"
	fi
}

_git_init ()
{
	case "$cur" in
	--shared=*)
		__gitcomp "
			false true umask group all world everybody
			" "" "${cur##--shared=}"
		return
		;;
	--*)
		__gitcomp_builtin init
		return
		;;
	esac
}

_git_ls_files ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin ls-files
		return
		;;
	esac

	# XXX ignore options like --modified and always suggest all cached
	# files.
	__git_complete_index_file "--cached"
}

_git_ls_remote ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin ls-remote
		return
		;;
	esac
	__gitcomp_nl "$(__git_remotes)"
}

_git_ls_tree ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin ls-tree
		return
		;;
	esac

	__git_complete_file
}

# Options that go well for log, shortlog and gitk
__git_log_common_options="
	--not --all
	--branches --tags --remotes
	--first-parent --merges --no-merges
	--max-count=
	--max-age= --since= --after=
	--min-age= --until= --before=
	--min-parents= --max-parents=
	--no-min-parents --no-max-parents
"
# Options that go well for log and gitk (not shortlog)
__git_log_gitk_options="
	--dense --sparse --full-history
	--simplify-merges --simplify-by-decoration
	--left-right --notes --no-notes
"
# Options that go well for log and shortlog (not gitk)
__git_log_shortlog_options="
	--author= --committer= --grep=
	--all-match --invert-grep
"

__git_log_pretty_formats="oneline short medium full fuller reference email raw format: tformat: mboxrd"
__git_log_date_formats="relative iso8601 iso8601-strict rfc2822 short local default raw unix format:"

_git_log ()
{
	__git_has_doubledash && return
	__git_find_repo_path

	local merge=""
	if [ -f "$__git_repo_path/MERGE_HEAD" ]; then
		merge="--merge"
	fi
	case "$prev,$cur" in
	-L,:*:*)
		return	# fall back to Bash filename completion
		;;
	-L,:*)
		__git_complete_symbol --cur="${cur#:}" --sfx=":"
		return
		;;
	-G,*|-S,*)
		__git_complete_symbol
		return
		;;
	esac
	case "$cur" in
	--pretty=*|--format=*)
		__gitcomp "$__git_log_pretty_formats $(__git_pretty_aliases)
			" "" "${cur#*=}"
		return
		;;
	--date=*)
		__gitcomp "$__git_log_date_formats" "" "${cur##--date=}"
		return
		;;
	--decorate=*)
		__gitcomp "full short no" "" "${cur##--decorate=}"
		return
		;;
	--diff-algorithm=*)
		__gitcomp "$__git_diff_algorithms" "" "${cur##--diff-algorithm=}"
		return
		;;
	--submodule=*)
		__gitcomp "$__git_diff_submodule_formats" "" "${cur##--submodule=}"
		return
		;;
	--no-walk=*)
		__gitcomp "sorted unsorted" "" "${cur##--no-walk=}"
		return
		;;
	--*)
		__gitcomp "
			$__git_log_common_options
			$__git_log_shortlog_options
			$__git_log_gitk_options
			--root --topo-order --date-order --reverse
			--follow --full-diff
			--abbrev-commit --no-abbrev-commit --abbrev=
			--relative-date --date=
			--pretty= --format= --oneline
			--show-signature
			--cherry-mark
			--cherry-pick
			--graph
			--decorate --decorate= --no-decorate
			--walk-reflogs
			--no-walk --no-walk= --do-walk
			--parents --children
			--expand-tabs --expand-tabs= --no-expand-tabs
			--patch
			$merge
			$__git_diff_common_options
			--pickaxe-all --pickaxe-regex
			--patch --no-patch
			"
		return
		;;
	-L:*:*)
		return	# fall back to Bash filename completion
		;;
	-L:*)
		__git_complete_symbol --cur="${cur#-L:}" --sfx=":"
		return
		;;
	-G*)
		__git_complete_symbol --pfx="-G" --cur="${cur#-G}"
		return
		;;
	-S*)
		__git_complete_symbol --pfx="-S" --cur="${cur#-S}"
		return
		;;
	esac
	__git_complete_revlist
}

_git_merge ()
{
	__git_complete_strategy && return

	case "$cur" in
	--*)
		__gitcomp_builtin merge
		return
	esac
	__git_complete_refs
}

_git_mergetool ()
{
	case "$cur" in
	--tool=*)
		__gitcomp "$__git_mergetools_common tortoisemerge" "" "${cur##--tool=}"
		return
		;;
	--*)
		__gitcomp "--tool= --prompt --no-prompt --gui --no-gui"
		return
		;;
	esac
}

_git_merge_base ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin merge-base
		return
		;;
	esac
	__git_complete_refs
}

_git_mv ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin mv
		return
		;;
	esac

	if [ $(__git_count_arguments "mv") -gt 0 ]; then
		# We need to show both cached and untracked files (including
		# empty directories) since this may not be the last argument.
		__git_complete_index_file "--cached --others --directory"
	else
		__git_complete_index_file "--cached"
	fi
}

_git_notes ()
{
	local subcommands='add append copy edit get-ref list merge prune remove show'
	local subcommand="$(__git_find_on_cmdline "$subcommands")"

	case "$subcommand,$cur" in
	,--*)
		__gitcomp_builtin notes
		;;
	,*)
		case "$prev" in
		--ref)
			__git_complete_refs
			;;
		*)
			__gitcomp "$subcommands --ref"
			;;
		esac
		;;
	*,--reuse-message=*|*,--reedit-message=*)
		__git_complete_refs --cur="${cur#*=}"
		;;
	*,--*)
		__gitcomp_builtin notes_$subcommand
		;;
	prune,*|get-ref,*)
		# this command does not take a ref, do not complete it
		;;
	*)
		case "$prev" in
		-m|-F)
			;;
		*)
			__git_complete_refs
			;;
		esac
		;;
	esac
}

_git_pull ()
{
	__git_complete_strategy && return

	case "$cur" in
	--recurse-submodules=*)
		__gitcomp "$__git_fetch_recurse_submodules" "" "${cur##--recurse-submodules=}"
		return
		;;
	--*)
		__gitcomp_builtin pull

		return
		;;
	esac
	__git_complete_remote_or_refspec
}

__git_push_recurse_submodules="check on-demand only"

__git_complete_force_with_lease ()
{
	local cur_=$1

	case "$cur_" in
	--*=)
		;;
	*:*)
		__git_complete_refs --cur="${cur_#*:}"
		;;
	*)
		__git_complete_refs --cur="$cur_"
		;;
	esac
}

_git_push ()
{
	case "$prev" in
	--repo)
		__gitcomp_nl "$(__git_remotes)"
		return
		;;
	--recurse-submodules)
		__gitcomp "$__git_push_recurse_submodules"
		return
		;;
	esac
	case "$cur" in
	--repo=*)
		__gitcomp_nl "$(__git_remotes)" "" "${cur##--repo=}"
		return
		;;
	--recurse-submodules=*)
		__gitcomp "$__git_push_recurse_submodules" "" "${cur##--recurse-submodules=}"
		return
		;;
	--force-with-lease=*)
		__git_complete_force_with_lease "${cur##--force-with-lease=}"
		return
		;;
	--*)
		__gitcomp_builtin push
		return
		;;
	esac
	__git_complete_remote_or_refspec
}

_git_range_diff ()
{
	case "$cur" in
	--*)
		__gitcomp "
			--creation-factor= --no-dual-color
			$__git_diff_common_options
		"
		return
		;;
	esac
	__git_complete_revlist
}

__git_rebase_inprogress_options="--continue --skip --abort --quit --show-current-patch"
__git_rebase_interactive_inprogress_options="$__git_rebase_inprogress_options --edit-todo"

_git_rebase ()
{
	__git_find_repo_path
	if [ -f "$__git_repo_path"/rebase-merge/interactive ]; then
		__gitcomp "$__git_rebase_interactive_inprogress_options"
		return
	elif [ -d "$__git_repo_path"/rebase-apply ] || \
	     [ -d "$__git_repo_path"/rebase-merge ]; then
		__gitcomp "$__git_rebase_inprogress_options"
		return
	fi
	__git_complete_strategy && return
	case "$cur" in
	--whitespace=*)
		__gitcomp "$__git_whitespacelist" "" "${cur##--whitespace=}"
		return
		;;
	--onto=*)
		__git_complete_refs --cur="${cur##--onto=}"
		return
		;;
	--*)
		__gitcomp_builtin rebase "" \
			"$__git_rebase_interactive_inprogress_options"

		return
	esac
	__git_complete_refs
}

_git_reflog ()
{
	local subcommands="show delete expire"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"

	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
	else
		__git_complete_refs
	fi
}

__git_send_email_confirm_options="always never auto cc compose"
__git_send_email_suppresscc_options="author self cc bodycc sob cccmd body all"

_git_send_email ()
{
	case "$prev" in
	--to|--cc|--bcc|--from)
		__gitcomp "$(__git send-email --dump-aliases)"
		return
		;;
	esac

	case "$cur" in
	--confirm=*)
		__gitcomp "
			$__git_send_email_confirm_options
			" "" "${cur##--confirm=}"
		return
		;;
	--suppress-cc=*)
		__gitcomp "
			$__git_send_email_suppresscc_options
			" "" "${cur##--suppress-cc=}"

		return
		;;
	--smtp-encryption=*)
		__gitcomp "ssl tls" "" "${cur##--smtp-encryption=}"
		return
		;;
	--thread=*)
		__gitcomp "
			deep shallow
			" "" "${cur##--thread=}"
		return
		;;
	--to=*|--cc=*|--bcc=*|--from=*)
		__gitcomp "$(__git send-email --dump-aliases)" "" "${cur#--*=}"
		return
		;;
	--*)
		__gitcomp_builtin send-email "--annotate --bcc --cc --cc-cmd --chain-reply-to
			--compose --confirm= --dry-run --envelope-sender
			--from --identity
			--in-reply-to --no-chain-reply-to --no-signed-off-by-cc
			--no-suppress-from --no-thread --quiet --reply-to
			--signed-off-by-cc --smtp-pass --smtp-server
			--smtp-server-port --smtp-encryption= --smtp-user
			--subject --suppress-cc= --suppress-from --thread --to
			--validate --no-validate
			$__git_format_patch_extra_options"
		return
		;;
	esac
	__git_complete_revlist
}

_git_stage ()
{
	_git_add
}

_git_status ()
{
	local complete_opt
	local untracked_state

	case "$cur" in
	--ignore-submodules=*)
		__gitcomp "none untracked dirty all" "" "${cur##--ignore-submodules=}"
		return
		;;
	--untracked-files=*)
		__gitcomp "$__git_untracked_file_modes" "" "${cur##--untracked-files=}"
		return
		;;
	--column=*)
		__gitcomp "
			always never auto column row plain dense nodense
			" "" "${cur##--column=}"
		return
		;;
	--*)
		__gitcomp_builtin status
		return
		;;
	esac

	untracked_state="$(__git_get_option_value "-u" "--untracked-files=" \
		"$__git_untracked_file_modes" "status.showUntrackedFiles")"

	case "$untracked_state" in
	no)
		# --ignored option does not matter
		complete_opt=
		;;
	all|normal|*)
		complete_opt="--cached --directory --no-empty-directory --others"

		if [ -n "$(__git_find_on_cmdline "--ignored")" ]; then
			complete_opt="$complete_opt --ignored --exclude=*"
		fi
		;;
	esac

	__git_complete_index_file "$complete_opt"
}

_git_switch ()
{
	local dwim_opt="$(__git_checkout_default_dwim_mode)"

	case "$prev" in
	-c|-C|--orphan)
		# Complete local branches (and DWIM branch
		# remote branch names) for an option argument
		# specifying a new branch name. This is for
		# convenience, assuming new branches are
		# possibly based on pre-existing branch names.
		__git_complete_refs $dwim_opt --mode="heads"
		return
		;;
	*)
		;;
	esac

	case "$cur" in
	--conflict=*)
		__gitcomp "diff3 merge" "" "${cur##--conflict=}"
		;;
	--*)
		__gitcomp_builtin switch
		;;
	*)
		# Unlike in git checkout, git switch --orphan does not take
		# a start point. Thus we really have nothing to complete after
		# the branch name.
		if [ -n "$(__git_find_on_cmdline "--orphan")" ]; then
			return
		fi

		# At this point, we've already handled special completion for
		# -c/-C, and --orphan. There are 3 main things left to
		# complete:
		# 1) a start-point for -c/-C or -d/--detach
		# 2) a remote head, for --track
		# 3) a branch name, possibly including DWIM remote branches

		if [ -n "$(__git_find_on_cmdline "-c -C -d --detach")" ]; then
			__git_complete_refs --mode="refs"
		elif [ -n "$(__git_find_on_cmdline "--track")" ]; then
			__git_complete_refs --mode="remote-heads"
		else
			__git_complete_refs $dwim_opt --mode="heads"
		fi
		;;
	esac
}

__git_config_get_set_variables ()
{
	local prevword word config_file= c=$cword
	while [ $c -gt 1 ]; do
		word="${words[c]}"
		case "$word" in
		--system|--global|--local|--file=*)
			config_file="$word"
			break
			;;
		-f|--file)
			config_file="$word $prevword"
			break
			;;
		esac
		prevword=$word
		c=$((--c))
	done

	__git config $config_file --name-only --list
}

__git_config_vars=
__git_compute_config_vars ()
{
	test -n "$__git_config_vars" ||
	__git_config_vars="$(git help --config-for-completion | sort -u)"
}

# Completes possible values of various configuration variables.
#
# Usage: __git_complete_config_variable_value [<option>]...
# --varname=<word>: The name of the configuration variable whose value is
#                   to be completed.  Defaults to the previous word on the
#                   command line.
# --cur=<word>: The current value to be completed.  Defaults to the current
#               word to be completed.
__git_complete_config_variable_value ()
{
	local varname="$prev" cur_="$cur"

	while test $# != 0; do
		case "$1" in
		--varname=*)	varname="${1##--varname=}" ;;
		--cur=*)	cur_="${1##--cur=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	if [ "${BASH_VERSINFO[0]:-0}" -ge 4 ]; then
		varname="${varname,,}"
	else
		varname="$(echo "$varname" |tr A-Z a-z)"
	fi

	case "$varname" in
	branch.*.remote|branch.*.pushremote)
		__gitcomp_nl "$(__git_remotes)" "" "$cur_"
		return
		;;
	branch.*.merge)
		__git_complete_refs --cur="$cur_"
		return
		;;
	branch.*.rebase)
		__gitcomp "false true merges preserve interactive" "" "$cur_"
		return
		;;
	remote.pushdefault)
		__gitcomp_nl "$(__git_remotes)" "" "$cur_"
		return
		;;
	remote.*.fetch)
		local remote="${varname#remote.}"
		remote="${remote%.fetch}"
		if [ -z "$cur_" ]; then
			__gitcomp_nl "refs/heads/" "" "" ""
			return
		fi
		__gitcomp_nl "$(__git_refs_remotes "$remote")" "" "$cur_"
		return
		;;
	remote.*.push)
		local remote="${varname#remote.}"
		remote="${remote%.push}"
		__gitcomp_nl "$(__git for-each-ref \
			--format='%(refname):%(refname)' refs/heads)" "" "$cur_"
		return
		;;
	pull.twohead|pull.octopus)
		__git_compute_merge_strategies
		__gitcomp "$__git_merge_strategies" "" "$cur_"
		return
		;;
	color.pager)
		__gitcomp "false true" "" "$cur_"
		return
		;;
	color.*.*)
		__gitcomp "
			normal black red green yellow blue magenta cyan white
			bold dim ul blink reverse
			" "" "$cur_"
		return
		;;
	color.*)
		__gitcomp "false true always never auto" "" "$cur_"
		return
		;;
	diff.submodule)
		__gitcomp "$__git_diff_submodule_formats" "" "$cur_"
		return
		;;
	help.format)
		__gitcomp "man info web html" "" "$cur_"
		return
		;;
	log.date)
		__gitcomp "$__git_log_date_formats" "" "$cur_"
		return
		;;
	sendemail.aliasfiletype)
		__gitcomp "mutt mailrc pine elm gnus" "" "$cur_"
		return
		;;
	sendemail.confirm)
		__gitcomp "$__git_send_email_confirm_options" "" "$cur_"
		return
		;;
	sendemail.suppresscc)
		__gitcomp "$__git_send_email_suppresscc_options" "" "$cur_"
		return
		;;
	sendemail.transferencoding)
		__gitcomp "7bit 8bit quoted-printable base64" "" "$cur_"
		return
		;;
	*.*)
		return
		;;
	esac
}

# Completes configuration sections, subsections, variable names.
#
# Usage: __git_complete_config_variable_name [<option>]...
# --cur=<word>: The current configuration section/variable name to be
#               completed.  Defaults to the current word to be completed.
# --sfx=<suffix>: A suffix to be appended to each fully completed
#                 configuration variable name (but not to sections or
#                 subsections) instead of the default space.
__git_complete_config_variable_name ()
{
	local cur_="$cur" sfx

	while test $# != 0; do
		case "$1" in
		--cur=*)	cur_="${1##--cur=}" ;;
		--sfx=*)	sfx="${1##--sfx=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	case "$cur_" in
	branch.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "remote pushRemote merge mergeOptions rebase" "$pfx" "$cur_" "$sfx"
		return
		;;
	branch.*)
		local pfx="${cur_%.*}."
		cur_="${cur_#*.}"
		__gitcomp_direct "$(__git_heads "$pfx" "$cur_" ".")"
		__gitcomp_nl_append $'autoSetupMerge\nautoSetupRebase\n' "$pfx" "$cur_" "${sfx:- }"
		return
		;;
	guitool.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "
			argPrompt cmd confirm needsFile noConsole noRescan
			prompt revPrompt revUnmerged title
			" "$pfx" "$cur_" "$sfx"
		return
		;;
	difftool.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "cmd path" "$pfx" "$cur_" "$sfx"
		return
		;;
	man.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "cmd path" "$pfx" "$cur_" "$sfx"
		return
		;;
	mergetool.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "cmd path trustExitCode" "$pfx" "$cur_" "$sfx"
		return
		;;
	pager.*)
		local pfx="${cur_%.*}."
		cur_="${cur_#*.}"
		__git_compute_all_commands
		__gitcomp_nl "$__git_all_commands" "$pfx" "$cur_" "${sfx:- }"
		return
		;;
	remote.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "
			url proxy fetch push mirror skipDefaultUpdate
			receivepack uploadpack tagOpt pushurl
			" "$pfx" "$cur_" "$sfx"
		return
		;;
	remote.*)
		local pfx="${cur_%.*}."
		cur_="${cur_#*.}"
		__gitcomp_nl "$(__git_remotes)" "$pfx" "$cur_" "."
		__gitcomp_nl_append "pushDefault" "$pfx" "$cur_" "${sfx:- }"
		return
		;;
	url.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "insteadOf pushInsteadOf" "$pfx" "$cur_" "$sfx"
		return
		;;
	*.*)
		__git_compute_config_vars
		__gitcomp "$__git_config_vars" "" "$cur_" "$sfx"
		;;
	*)
		__git_compute_config_vars
		__gitcomp "$(echo "$__git_config_vars" |
				awk -F . '{
					sections[$1] = 1
				}
				END {
					for (s in sections)
						print s "."
				}
				')" "" "$cur_"
		;;
	esac
}

# Completes '='-separated configuration sections/variable names and values
# for 'git -c section.name=value'.
#
# Usage: __git_complete_config_variable_name_and_value [<option>]...
# --cur=<word>: The current configuration section/variable name/value to be
#               completed. Defaults to the current word to be completed.
__git_complete_config_variable_name_and_value ()
{
	local cur_="$cur"

	while test $# != 0; do
		case "$1" in
		--cur=*)	cur_="${1##--cur=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	case "$cur_" in
	*=*)
		__git_complete_config_variable_value \
			--varname="${cur_%%=*}" --cur="${cur_#*=}"
		;;
	*)
		__git_complete_config_variable_name --cur="$cur_" --sfx='='
		;;
	esac
}

_git_config ()
{
	case "$prev" in
	--get|--get-all|--unset|--unset-all)
		__gitcomp_nl "$(__git_config_get_set_variables)"
		return
		;;
	*.*)
		__git_complete_config_variable_value
		return
		;;
	esac
	case "$cur" in
	--*)
		__gitcomp_builtin config
		;;
	*)
		__git_complete_config_variable_name
		;;
	esac
}

_git_remote ()
{
	local subcommands="
		add rename remove set-head set-branches
		get-url set-url show prune update
		"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		case "$cur" in
		--*)
			__gitcomp_builtin remote
			;;
		*)
			__gitcomp "$subcommands"
			;;
		esac
		return
	fi

	case "$subcommand,$cur" in
	add,--*)
		__gitcomp_builtin remote_add
		;;
	add,*)
		;;
	set-head,--*)
		__gitcomp_builtin remote_set-head
		;;
	set-branches,--*)
		__gitcomp_builtin remote_set-branches
		;;
	set-head,*|set-branches,*)
		__git_complete_remote_or_refspec
		;;
	update,--*)
		__gitcomp_builtin remote_update
		;;
	update,*)
		__gitcomp "$(__git_remotes) $(__git_get_config_variables "remotes")"
		;;
	set-url,--*)
		__gitcomp_builtin remote_set-url
		;;
	get-url,--*)
		__gitcomp_builtin remote_get-url
		;;
	prune,--*)
		__gitcomp_builtin remote_prune
		;;
	*)
		__gitcomp_nl "$(__git_remotes)"
		;;
	esac
}

_git_replace ()
{
	case "$cur" in
	--format=*)
		__gitcomp "short medium long" "" "${cur##--format=}"
		return
		;;
	--*)
		__gitcomp_builtin replace
		return
		;;
	esac
	__git_complete_refs
}

_git_rerere ()
{
	local subcommands="clear forget diff remaining status gc"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if test -z "$subcommand"
	then
		__gitcomp "$subcommands"
		return
	fi
}

_git_reset ()
{
	__git_has_doubledash && return

	case "$cur" in
	--*)
		__gitcomp_builtin reset
		return
		;;
	esac
	__git_complete_refs
}

_git_restore ()
{
	case "$prev" in
	-s)
		__git_complete_refs
		return
		;;
	esac

	case "$cur" in
	--conflict=*)
		__gitcomp "diff3 merge" "" "${cur##--conflict=}"
		;;
	--source=*)
		__git_complete_refs --cur="${cur##--source=}"
		;;
	--*)
		__gitcomp_builtin restore
		;;
	esac
}

__git_revert_inprogress_options=$__git_sequencer_inprogress_options

_git_revert ()
{
	__git_find_repo_path
	if [ -f "$__git_repo_path"/REVERT_HEAD ]; then
		__gitcomp "$__git_revert_inprogress_options"
		return
	fi
	__git_complete_strategy && return
	case "$cur" in
	--*)
		__gitcomp_builtin revert "" \
			"$__git_revert_inprogress_options"
		return
		;;
	esac
	__git_complete_refs
}

_git_rm ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin rm
		return
		;;
	esac

	__git_complete_index_file "--cached"
}

_git_shortlog ()
{
	__git_has_doubledash && return

	case "$cur" in
	--*)
		__gitcomp "
			$__git_log_common_options
			$__git_log_shortlog_options
			--numbered --summary --email
			"
		return
		;;
	esac
	__git_complete_revlist
}

_git_show ()
{
	__git_has_doubledash && return

	case "$cur" in
	--pretty=*|--format=*)
		__gitcomp "$__git_log_pretty_formats $(__git_pretty_aliases)
			" "" "${cur#*=}"
		return
		;;
	--diff-algorithm=*)
		__gitcomp "$__git_diff_algorithms" "" "${cur##--diff-algorithm=}"
		return
		;;
	--submodule=*)
		__gitcomp "$__git_diff_submodule_formats" "" "${cur##--submodule=}"
		return
		;;
	--color-moved=*)
		__gitcomp "$__git_color_moved_opts" "" "${cur##--color-moved=}"
		return
		;;
	--color-moved-ws=*)
		__gitcomp "$__git_color_moved_ws_opts" "" "${cur##--color-moved-ws=}"
		return
		;;
	--*)
		__gitcomp "--pretty= --format= --abbrev-commit --no-abbrev-commit
			--oneline --show-signature --patch
			--expand-tabs --expand-tabs= --no-expand-tabs
			$__git_diff_common_options
			"
		return
		;;
	esac
	__git_complete_revlist_file
}

_git_show_branch ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin show-branch
		return
		;;
	esac
	__git_complete_revlist
}

_git_sparse_checkout ()
{
	local subcommands="list init set disable"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand,$cur" in
	init,--*)
		__gitcomp "--cone"
		;;
	set,--*)
		__gitcomp "--stdin"
		;;
	*)
		;;
	esac
}

_git_stash ()
{
	local save_opts='--all --keep-index --no-keep-index --quiet --patch --include-untracked'
	local subcommands='push list show apply clear drop pop create branch'
	local subcommand="$(__git_find_on_cmdline "$subcommands save")"
	if [ -z "$subcommand" -a -n "$(__git_find_on_cmdline "-p")" ]; then
		subcommand="push"
	fi
	if [ -z "$subcommand" ]; then
		case "$cur" in
		--*)
			__gitcomp "$save_opts"
			;;
		sa*)
			if [ -z "$(__git_find_on_cmdline "$save_opts")" ]; then
				__gitcomp "save"
			fi
			;;
		*)
			if [ -z "$(__git_find_on_cmdline "$save_opts")" ]; then
				__gitcomp "$subcommands"
			fi
			;;
		esac
	else
		case "$subcommand,$cur" in
		push,--*)
			__gitcomp "$save_opts --message"
			;;
		save,--*)
			__gitcomp "$save_opts"
			;;
		apply,--*|pop,--*)
			__gitcomp "--index --quiet"
			;;
		drop,--*)
			__gitcomp "--quiet"
			;;
		list,--*)
			__gitcomp "--name-status --oneline --patch-with-stat"
			;;
		show,--*|branch,--*)
			;;
		branch,*)
			if [ $cword -eq 3 ]; then
				__git_complete_refs
			else
				__gitcomp_nl "$(__git stash list \
						| sed -n -e 's/:.*//p')"
			fi
			;;
		show,*|apply,*|drop,*|pop,*)
			__gitcomp_nl "$(__git stash list \
					| sed -n -e 's/:.*//p')"
			;;
		*)
			;;
		esac
	fi
}

_git_submodule ()
{
	__git_has_doubledash && return

	local subcommands="add status init deinit update set-branch set-url summary foreach sync absorbgitdirs"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		case "$cur" in
		--*)
			__gitcomp "--quiet"
			;;
		*)
			__gitcomp "$subcommands"
			;;
		esac
		return
	fi

	case "$subcommand,$cur" in
	add,--*)
		__gitcomp "--branch --force --name --reference --depth"
		;;
	status,--*)
		__gitcomp "--cached --recursive"
		;;
	deinit,--*)
		__gitcomp "--force --all"
		;;
	update,--*)
		__gitcomp "
			--init --remote --no-fetch
			--recommend-shallow --no-recommend-shallow
			--force --rebase --merge --reference --depth --recursive --jobs
		"
		;;
	set-branch,--*)
		__gitcomp "--default --branch"
		;;
	summary,--*)
		__gitcomp "--cached --files --summary-limit"
		;;
	foreach,--*|sync,--*)
		__gitcomp "--recursive"
		;;
	*)
		;;
	esac
}

_git_svn ()
{
	local subcommands="
		init fetch clone rebase dcommit log find-rev
		set-tree commit-diff info create-ignore propget
		proplist show-ignore show-externals branch tag blame
		migrate mkdirs reset gc
		"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
	else
		local remote_opts="--username= --config-dir= --no-auth-cache"
		local fc_opts="
			--follow-parent --authors-file= --repack=
			--no-metadata --use-svm-props --use-svnsync-props
			--log-window-size= --no-checkout --quiet
			--repack-flags --use-log-author --localtime
			--add-author-from
			--recursive
			--ignore-paths= --include-paths= $remote_opts
			"
		local init_opts="
			--template= --shared= --trunk= --tags=
			--branches= --stdlayout --minimize-url
			--no-metadata --use-svm-props --use-svnsync-props
			--rewrite-root= --prefix= $remote_opts
			"
		local cmt_opts="
			--edit --rmdir --find-copies-harder --copy-similarity=
			"

		case "$subcommand,$cur" in
		fetch,--*)
			__gitcomp "--revision= --fetch-all $fc_opts"
			;;
		clone,--*)
			__gitcomp "--revision= $fc_opts $init_opts"
			;;
		init,--*)
			__gitcomp "$init_opts"
			;;
		dcommit,--*)
			__gitcomp "
				--merge --strategy= --verbose --dry-run
				--fetch-all --no-rebase --commit-url
				--revision --interactive $cmt_opts $fc_opts
				"
			;;
		set-tree,--*)
			__gitcomp "--stdin $cmt_opts $fc_opts"
			;;
		create-ignore,--*|propget,--*|proplist,--*|show-ignore,--*|\
		show-externals,--*|mkdirs,--*)
			__gitcomp "--revision="
			;;
		log,--*)
			__gitcomp "
				--limit= --revision= --verbose --incremental
				--oneline --show-commit --non-recursive
				--authors-file= --color
				"
			;;
		rebase,--*)
			__gitcomp "
				--merge --verbose --strategy= --local
				--fetch-all --dry-run $fc_opts
				"
			;;
		commit-diff,--*)
			__gitcomp "--message= --file= --revision= $cmt_opts"
			;;
		info,--*)
			__gitcomp "--url"
			;;
		branch,--*)
			__gitcomp "--dry-run --message --tag"
			;;
		tag,--*)
			__gitcomp "--dry-run --message"
			;;
		blame,--*)
			__gitcomp "--git-format"
			;;
		migrate,--*)
			__gitcomp "
				--config-dir= --ignore-paths= --minimize
				--no-auth-cache --username=
				"
			;;
		reset,--*)
			__gitcomp "--revision= --parent"
			;;
		*)
			;;
		esac
	fi
}

_git_tag ()
{
	local i c=1 f=0
	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		-d|--delete|-v|--verify)
			__gitcomp_direct "$(__git_tags "" "$cur" " ")"
			return
			;;
		-f)
			f=1
			;;
		esac
		((c++))
	done

	case "$prev" in
	-m|-F)
		;;
	-*|tag)
		if [ $f = 1 ]; then
			__gitcomp_direct "$(__git_tags "" "$cur" " ")"
		fi
		;;
	*)
		__git_complete_refs
		;;
	esac

	case "$cur" in
	--*)
		__gitcomp_builtin tag
		;;
	esac
}

_git_whatchanged ()
{
	_git_log
}

__git_complete_worktree_paths ()
{
	local IFS=$'\n'
	__gitcomp_nl "$(git worktree list --porcelain |
		# Skip the first entry: it's the path of the main worktree,
		# which can't be moved, removed, locked, etc.
		sed -n -e '2,$ s/^worktree //p')"
}

_git_worktree ()
{
	local subcommands="add list lock move prune remove unlock"
	local subcommand subcommand_idx

	subcommand="$(__git_find_on_cmdline --show-idx "$subcommands")"
	subcommand_idx="${subcommand% *}"
	subcommand="${subcommand#* }"

	case "$subcommand,$cur" in
	,*)
		__gitcomp "$subcommands"
		;;
	*,--*)
		__gitcomp_builtin worktree_$subcommand
		;;
	add,*)	# usage: git worktree add [<options>] <path> [<commit-ish>]
		# Here we are not completing an --option, it's either the
		# path or a ref.
		case "$prev" in
		-b|-B)	# Complete refs for branch to be created/reseted.
			__git_complete_refs
			;;
		-*)	# The previous word is an -o|--option without an
			# unstuck argument: have to complete the path for
			# the new worktree, so don't list anything, but let
			# Bash fall back to filename completion.
			;;
		*)	# The previous word is not an --option, so it must
			# be either the 'add' subcommand, the unstuck
			# argument of an option (e.g. branch for -b|-B), or
			# the path for the new worktree.
			if [ $cword -eq $((subcommand_idx+1)) ]; then
				# Right after the 'add' subcommand: have to
				# complete the path, so fall back to Bash
				# filename completion.
				:
			else
				case "${words[cword-2]}" in
				-b|-B)	# After '-b <branch>': have to
					# complete the path, so fall back
					# to Bash filename completion.
					;;
				*)	# After the path: have to complete
					# the ref to be checked out.
					__git_complete_refs
					;;
				esac
			fi
			;;
		esac
		;;
	lock,*|remove,*|unlock,*)
		__git_complete_worktree_paths
		;;
	move,*)
		if [ $cword -eq $((subcommand_idx+1)) ]; then
			# The first parameter must be an existing working
			# tree to be moved.
			__git_complete_worktree_paths
		else
			# The second parameter is the destination: it could
			# be any path, so don't list anything, but let Bash
			# fall back to filename completion.
			:
		fi
		;;
	esac
}

__git_complete_common () {
	local command="$1"

	case "$cur" in
	--*)
		__gitcomp_builtin "$command"
		;;
	esac
}

__git_cmds_with_parseopt_helper=
__git_support_parseopt_helper () {
	test -n "$__git_cmds_with_parseopt_helper" ||
		__git_cmds_with_parseopt_helper="$(__git --list-cmds=parseopt)"

	case " $__git_cmds_with_parseopt_helper " in
	*" $1 "*)
		return 0
		;;
	*)
		return 1
		;;
	esac
}

__git_complete_command () {
	local command="$1"
	local completion_func="_git_${command//-/_}"
	if ! declare -f $completion_func >/dev/null 2>/dev/null &&
		declare -f _completion_loader >/dev/null 2>/dev/null
	then
		_completion_loader "git-$command"
	fi
	if declare -f $completion_func >/dev/null 2>/dev/null
	then
		$completion_func
		return 0
	elif __git_support_parseopt_helper "$command"
	then
		__git_complete_common "$command"
		return 0
	else
		return 1
	fi
}

__git_main ()
{
	local i c=1 command __git_dir __git_repo_path
	local __git_C_args C_args_count=0

	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		--git-dir=*) __git_dir="${i#--git-dir=}" ;;
		--git-dir)   ((c++)) ; __git_dir="${words[c]}" ;;
		--bare)      __git_dir="." ;;
		--help) command="help"; break ;;
		-c|--work-tree|--namespace) ((c++)) ;;
		-C)	__git_C_args[C_args_count++]=-C
			((c++))
			__git_C_args[C_args_count++]="${words[c]}"
			;;
		-*) ;;
		*) command="$i"; break ;;
		esac
		((c++))
	done

	if [ -z "${command-}" ]; then
		case "$prev" in
		--git-dir|-C|--work-tree)
			# these need a path argument, let's fall back to
			# Bash filename completion
			return
			;;
		-c)
			__git_complete_config_variable_name_and_value
			return
			;;
		--namespace)
			# we don't support completing these options' arguments
			return
			;;
		esac
		case "$cur" in
		--*)   __gitcomp "
			--paginate
			--no-pager
			--git-dir=
			--bare
			--version
			--exec-path
			--exec-path=
			--html-path
			--man-path
			--info-path
			--work-tree=
			--namespace=
			--no-replace-objects
			--help
			"
			;;
		*)
			if test -n "${GIT_TESTING_PORCELAIN_COMMAND_LIST-}"
			then
				__gitcomp "$GIT_TESTING_PORCELAIN_COMMAND_LIST"
			else
				__gitcomp "$(__git --list-cmds=list-mainporcelain,others,nohelpers,alias,list-complete,config)"
			fi
			;;
		esac
		return
	fi

	__git_complete_command "$command" && return

	local expansion=$(__git_aliased_command "$command")
	if [ -n "$expansion" ]; then
		words[1]=$expansion
		__git_complete_command "$expansion"
	fi
}

__gitk_main ()
{
	__git_has_doubledash && return

	local __git_repo_path
	__git_find_repo_path

	local merge=""
	if [ -f "$__git_repo_path/MERGE_HEAD" ]; then
		merge="--merge"
	fi
	case "$cur" in
	--*)
		__gitcomp "
			$__git_log_common_options
			$__git_log_gitk_options
			$merge
			"
		return
		;;
	esac
	__git_complete_revlist
}

if [[ -n ${ZSH_VERSION-} && -z ${GIT_SOURCING_ZSH_COMPLETION-} ]]; then
	echo "ERROR: this script is obsolete, please see git-completion.zsh" 1>&2
	return
fi

__git_func_wrap ()
{
	local cur words cword prev
	_get_comp_words_by_ref -n =: cur words cword prev
	$1
}

# Setup completion for certain functions defined above by setting common
# variables and workarounds.
# This is NOT a public function; use at your own risk.
__git_complete ()
{
	local wrapper="__git_wrap${2}"
	eval "$wrapper () { __git_func_wrap $2 ; }"
	complete -o bashdefault -o default -o nospace -F $wrapper $1 2>/dev/null \
		|| complete -o default -o nospace -F $wrapper $1
}

if ! git --list-cmds=main >/dev/null 2>&1; then

	declare -A __git_cmds
	__git_cmds[list-complete]="apply blame cherry config difftool fsck help instaweb mergetool prune reflog remote repack replace request-pull send-email show-branch stage whatchanged"
	__git_cmds[list-guide]="attributes cli core-tutorial credentials cvs-migration diffcore everyday faq glossary hooks ignore modules namespaces remote-helpers repository-layout revisions submodules tutorial-2 tutorial workflows"
	__git_cmds[list-mainporcelain]="add am archive bisect branch bundle checkout cherry-pick citool clean clone commit describe diff fetch format-patch gc grep gui init gitk log maintenance merge mv notes pull push range-diff rebase reset restore revert rm shortlog show sparse-checkout stash status submodule switch tag worktree"
	__git_cmds[main]="add add--interactive am annotate apply archimport archive bisect bisect--helper blame branch bugreport bundle cat-file check-attr check-ignore check-mailmap check-ref-format checkout checkout-index cherry cherry-pick citool clean clone column commit commit-graph commit-tree config count-objects credential credential-cache credential-cache--daemon credential-gnome-keyring credential-libsecret credential-store cvsexportcommit cvsimport cvsserver daemon describe diff diff-files diff-index diff-tree difftool difftool--helper env--helper fast-export fast-import fetch fetch-pack filter-branch fmt-merge-msg for-each-ref format-patch fsck fsck-objects gc get-tar-commit-id grep gui gui--askpass hash-object help http-backend http-fetch http-push imap-send index-pack init init-db instaweb interpret-trailers log ls-files ls-remote ls-tree mailinfo mailsplit maintenance merge merge-base merge-file merge-index merge-octopus merge-one-file merge-ours merge-recursive merge-recursive-ours merge-recursive-theirs merge-resolve merge-subtree merge-tree mergetool mktag mktree multi-pack-index mv mw name-rev notes p4 pack-objects pack-redundant pack-refs patch-id pickaxe prune prune-packed pull push quiltimport range-diff read-tree rebase rebase--interactive receive-pack reflog remote remote-ext remote-fd remote-ftp remote-ftps remote-http remote-https remote-mediawiki repack replace request-pull rerere reset restore rev-list rev-parse revert rm send-email send-pack sh-i18n--envsubst shell shortlog show show-branch show-index show-ref sparse-checkout stage stash status stripspace submodule submodule--helper subtree svn switch symbolic-ref tag unpack-file unpack-objects update-index update-ref update-server-info upload-archive upload-archive--writer upload-pack var verify-commit verify-pack verify-tag version web--browse whatchanged worktree write-tree"
	__git_cmds[others]="compare reintegrate related remote-hg remote-sync send-series smartlist"
	__git_cmds[parseopt]="add am apply archive bisect--helper blame branch bugreport cat-file check-attr check-ignore check-mailmap checkout checkout-index cherry cherry-pick clean clone column commit commit-graph config count-objects credential-cache credential-cache--daemon credential-store describe difftool env--helper fast-export fetch fmt-merge-msg for-each-ref format-patch fsck fsck-objects gc grep hash-object help init init-db interpret-trailers log ls-files ls-remote ls-tree merge merge-base merge-file mktree multi-pack-index mv name-rev notes pack-objects pack-refs pickaxe prune prune-packed pull push range-diff read-tree rebase rebase--interactive receive-pack reflog remote repack replace rerere reset restore revert rm send-pack shortlog show show-branch show-index show-ref sparse-checkout stage stash status stripspace switch symbolic-ref tag update-index update-ref update-server-info upload-pack verify-commit verify-pack verify-tag version whatchanged write-tree "

	# Override __git
	__git ()
	{
		case "$1" in
		--list-cmds=*)
			while read -r -d ',' x; do
				case "$x" in
				nohelpers)
					;;
				alias)
					;;
				config)
					;;
				*)
					echo ${__git_cmds[$x]}
					;;
				esac
			done <<< "${1##--list-cmds=},"
			return
			;;
		esac
		git ${__git_C_args:+"${__git_C_args[@]}"} \
			${__git_dir:+--git-dir="$__git_dir"} "$@" 2>/dev/null
	}

fi

__git_complete git __git_main
__git_complete gitk __gitk_main

# The following are necessary only for Cygwin, and only are needed
# when the user has tab-completed the executable name and consequently
# included the '.exe' suffix.
#
# Bash completion for "crystal" command.
# Written by Sergey Potapov <blake131313@gmail.com>.

# Get list of crystal files or directories, that match $pattern
_crystal_compgen_files(){
    local pattern=$1
    compgen -f -o plusdirs -X '!*.cr' -- $pattern
}

_crystal()
{
    local program=${COMP_WORDS[0]}
    local cmd=${COMP_WORDS[1]}
    local cur="${COMP_WORDS[COMP_CWORD]}"
    local prev="${COMP_WORDS[COMP_CWORD-1]}"

    commands="init build docs eval play run spec tool help version --help --version"

    case "${cmd}" in
        init)
            if [[ "${prev}" == "init" ]] ; then
                COMPREPLY=( $(compgen -W "app lib" -- ${cur}) )
            else
                COMPREPLY=( $(compgen -f ${cur}) )
            fi
            ;;
        build)
            if [[ ${cur} == -* ]] ; then
                local opts="--cross-compile --debug --emit --error-on-warnings --exclude-warnings --ll --link-flags --mcpu --no-color --no-codegen --prelude --release --single-module --threads --target --verbose --warnings --help"
                COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
            else
                COMPREPLY=($(_crystal_compgen_files $cur))
            fi
            ;;
        run)
            if [[ ${cur} == -* ]] ; then
                local opts="--debug --define --emit --error-on-warnings --exclude-warnings --format --help --ll --link-flags --mcpu --no-color --no-codegen --prelude --release --stats --single-module --threads --verbose --warnings"
                COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
            else
                COMPREPLY=($(_crystal_compgen_files $cur))
            fi
            ;;
        tool)
            if [[ ${cur} == -* ]] ; then
                local opts="--no-color --prelude --define --format --cursor"
                COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
            else
                if [[ "${prev}" == "tool" ]] ; then
                    local subcommands="context format hierarchy implementations types"
                    COMPREPLY=( $(compgen -W "${subcommands}" -- ${cur}) )
                else
                    COMPREPLY=($(_crystal_compgen_files $cur))
                fi
            fi
            ;;
        play)
            if [[ ${cur} == -* ]] ; then
                local opts="--port --binding --verbose --help"
                COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
            else
                COMPREPLY=($(_crystal_compgen_files $cur))
            fi
            ;;
        docs|eval|spec|version|help)
            # These commands do not accept any options nor subcommands
            COMPREPLY=( $(compgen -f ${cur}) )
            ;;
        *)
            # When any of subcommands matches directly
            if [[ "${prev}" == "${program}" && $(compgen -W "${commands}" -- ${cur})  ]] ; then
                COMPREPLY=( $(compgen -W "${commands}" -- ${cur}) )
            else
                COMPREPLY=($(_crystal_compgen_files $cur))
            fi
    esac
#!/usr/bin/env bash

###############################################################################
# Copyright 2020 The Apollo Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
###############################################################################

cd "$(dirname "${BASH_SOURCE[0]}")"

# usage: source apollo_auto_complete.bash

COMMANDS="config build build_dbg build_opt build_cpu build_gpu build_opt_gpu test coverage lint \
          buildify check build_fe build_teleop build_prof doc clean format usage -h --help"

MODULES="$(find /apollo/modules/* -maxdepth 0 -type d -printf "%f ")"
MODULES="cyber ${MODULES}"

function _complete_apollo_func() {
  COMPREPLY=()
  local cur="${COMP_WORDS[COMP_CWORD]}"
  local prev="${COMP_WORDS[COMP_CWORD - 1]}"

  local cmds="$(echo ${COMMANDS} | xargs)"
  local modules="$(echo ${MODULES} | xargs)"

  if [ "${COMP_CWORD}" -eq 1 ]; then
    COMPREPLY=($(compgen -W "${cmds}" -- ${cur}))
  elif [ "${COMP_CWORD}" -eq 2 ]; then
    case "${prev}" in
      build | build_dbg | build_opt | build_cpu | build_gpu | test | coverage)
        COMPREPLY=($(compgen -W "${modules}" -- ${cur}))
        ;;
      config)
        COMPREPLY=($(compgen -W "--interactive --noninteractive --help" -- ${cur}))
        ;;
      clean)
        COMPREPLY=($(compgen -W "--bazel --core --log --expunge --all --help" -- ${cur}))
        ;;
      lint)
        COMPREPLY=($(compgen -W "--py --sh --cpp --all --help" -- ${cur}))
        ;;
      format)
        COMPREPLY=($(compgen -W "--python --bazel --cpp --shell --markdown --all --help" -- ${cur}))
        ;;
#! /usr/bin/env bash
TOP_DIR="$(cd "$( dirname "${BASH_SOURCE[0]}" )/.." && pwd -P)"
source ${TOP_DIR}/scripts/apollo.bashrc

export CYBER_PATH="${APOLLO_ROOT_DIR}/cyber"

pathprepend "${TOP_DIR}/bin"

export CYBER_DOMAIN_ID=80
export CYBER_IP=127.0.0.1

export GLOG_log_dir="${APOLLO_ROOT_DIR}/data/log"
export GLOG_alsologtostderr=1
export GLOG_colorlogtostderr=1
export GLOG_minloglevel=0
#! /usr/bin/env bash
TOP_DIR="$(cd "$( dirname "${BASH_SOURCE[0]}" )/.." && pwd -P)"
source ${TOP_DIR}/scripts/apollo.bashrc

export APOLLO_BAZEL_DIST_DIR="${APOLLO_CACHE_DIR}/distdir"
export CYBER_PATH="${APOLLO_ROOT_DIR}/cyber"

bazel_bin_path="${APOLLO_ROOT_DIR}/bazel-bin"
mainboard_path="${bazel_bin_path}/cyber/mainboard"
cyber_tool_path="${bazel_bin_path}/cyber/tools"
recorder_path="${cyber_tool_path}/cyber_recorder"
launch_path="${cyber_tool_path}/cyber_launch"
channel_path="${cyber_tool_path}/cyber_channel"
node_path="${cyber_tool_path}/cyber_node"
service_path="${cyber_tool_path}/cyber_service"
monitor_path="${cyber_tool_path}/cyber_monitor"
visualizer_path="${bazel_bin_path}/modules/tools/visualizer"

# TODO(all): place all these in one place and pathprepend
for entry in "${mainboard_path}" \
    "${recorder_path}" "${monitor_path}"  \
    "${channel_path}" "${node_path}" \
    "${service_path}" \
    "${launch_path}" \
    "${visualizer_path}" ; do
    pathprepend "${entry}"
done

pathprepend ${bazel_bin_path}/cyber/python/internal PYTHONPATH

export CYBER_DOMAIN_ID=80
export CYBER_IP=127.0.0.1

export GLOG_log_dir="${APOLLO_ROOT_DIR}/data/log"
export GLOG_alsologtostderr=0
export GLOG_colorlogtostderr=1
export GLOG_minloglevel=0

export sysmo_start=0

# usage: source cyber_tools_auto_complete.bash

function _cyber_launch_complete() {
  COMPREPLY=()
  local word=${COMP_WORDS[COMP_CWORD]}
  local cmd=${COMP_WORDS[COMP_CWORD-1]}
  case $cmd in
  'cyber_launch')
    COMPREPLY=( $(compgen -W "start stop" -- ${word}) )
    ;;
  'start')
    compopt -o nospace
    local files=`ls *.launch 2>/dev/null`
    COMPREPLY=( $(compgen -W "$files" -- ${word}) )
    ;;
  'stop')
    compopt -o nospace
    local files=`ls *.launch 2>/dev/null`
    COMPREPLY=( $(compgen -W "$files" -- ${word}) )
    ;;
  *)
    ;;
  esac
}

function _cyber_recorder_complete() {
  COMPREPLY=()
  local word=${COMP_WORDS[COMP_CWORD]}
  local cmd=${COMP_WORDS[COMP_CWORD-1]}
  case $cmd in
  'cyber_recorder')
    COMPREPLY=( $(compgen -W "play info record split recover" -- ${word}) )
    ;;
  *)
    ;;
  esac
}

function _cyber_channel_complete() {
  COMPREPLY=()
  local word=${COMP_WORDS[COMP_CWORD]}
  local cmd=${COMP_WORDS[COMP_CWORD-1]}
  case $cmd in
  'cyber_channel')
    COMPREPLY=( $(compgen -W "echo list info hz bw type" -- ${word}) )
    ;;
  *)
    ;;
  esac
}

function _cyber_node_complete() {
  COMPREPLY=()
  local word=${COMP_WORDS[COMP_CWORD]}
  local cmd=${COMP_WORDS[COMP_CWORD-1]}
  case $cmd in
  'cyber_node')
    COMPREPLY=( $(compgen -W "list info" -- ${word}) )
    ;;
  *)
    ;;
  esac
}

function _cyber_service_complete() {
  COMPREPLY=()
  local word=${COMP_WORDS[COMP_CWORD]}
  local cmd=${COMP_WORDS[COMP_CWORD-1]}
  case $cmd in
  'cyber_service')
    COMPREPLY=( $(compgen -W "list info" -- ${word}) )
    ;;
  *)
    ;;
  esac
}
complete -F _cyber_launch_complete -o default cyber_launch
complete -F _cyber_recorder_complete -o default cyber_recorder
complete -F _cyber_channel_complete -o default cyber_channel
complete -F _cyber_node_complete -o default cyber_node
# -*- sh -*- (Bash only)
#
# Copyright 2018 The Bazel Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Bash completion of Bazel commands.
#
# Provides command-completion for:
# - bazel prefix options (e.g. --host_jvm_args)
# - blaze command-set (e.g. build, test)
# - blaze command-specific options (e.g. --copts)
# - values for enum-valued options
# - package-names, exploring all package-path roots.
# - targets within packages.

# Environment variables for customizing behavior:
#
# BAZEL_COMPLETION_USE_QUERY - if "true", `bazel query` will be used for
# autocompletion; otherwise, a heuristic grep is used. This is more accurate
# than the heuristic grep, especially for strangely-formatted BUILD files. But
# it can be slower, especially if the Bazel server is busy, and more brittle, if
# the BUILD file contains serious errors. This is an experimental feature.
#
# BAZEL_COMPLETION_ALLOW_TESTS_FOR_RUN - if "true", autocompletion results for
# `bazel run` includes test targets. This is convenient for users who run a lot
# of tests/benchmarks locally with 'bazel run'.

_bazel_completion_use_query() {
  _bazel__is_true "${BAZEL_COMPLETION_USE_QUERY}"
}

_bazel_completion_allow_tests_for_run() {
  _bazel__is_true "${BAZEL_COMPLETION_ALLOW_TESTS_FOR_RUN}"
}
# -*- sh -*- (Bash only)
#
# Copyright 2015 The Bazel Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# The template is expanded at build time using tables of commands/options
# derived from the bazel executable built in the same client; the expansion is
# written to bazel-complete.bash.
#
# Don't use this script directly. Generate the final script with
# bazel build //scripts:bash_completion instead.

# This script expects a header to be prepended to it that defines the following
# nullary functions:
#
# _bazel_completion_use_query - Has a successful exit code if
# BAZEL_COMPLETION_USE_QUERY is "true".
#
# _bazel_completion_allow_tests_for_run - Has a successful exit code if
# BAZEL_COMPLETION_ALLOW_TESTS_FOR_RUN is "true".

# The package path used by the completion routines.  Unfortunately
# this isn't necessarily the same as the actual package path used by
# Bazel, but that's ok.  (It's impossible for us to reliably know what
# the relevant package-path, so this is just a good guess.  Users can
# override it if they want.)
: ${BAZEL_COMPLETION_PACKAGE_PATH:=%workspace%}

# Some commands might interfer with the important one, so don't complete them
: ${BAZEL_IGNORED_COMMAND_REGEX:="__none__"}

# bazel & ibazel commands
: ${BAZEL:=bazel}
: ${IBAZEL:=ibazel}

# Pattern to match for looking for a target
#  BAZEL_BUILD_MATCH_PATTERN__* give the pattern for label-*
#  when looking in the build file.
#  BAZEL_QUERY_MATCH_PATTERN__* give the pattern for label-*
#  when using 'bazel query'.
# _RUNTEST is a special case for _bazel_completion_allow_tests_for_run.
: ${BAZEL_BUILD_MATCH_PATTERN__test:='(.*_test|test_suite)'}
: ${BAZEL_QUERY_MATCH_PATTERN__test:='(test|test_suite)'}
: ${BAZEL_BUILD_MATCH_PATTERN__bin:='.*_binary'}
: ${BAZEL_QUERY_MATCH_PATTERN__bin:='(binary)'}
: ${BAZEL_BUILD_MATCH_PATTERN_RUNTEST__bin:='(.*_(binary|test)|test_suite)'}
: ${BAZEL_QUERY_MATCH_PATTERN_RUNTEST__bin:='(binary|test)'}
: ${BAZEL_BUILD_MATCH_PATTERN__:='.*'}
: ${BAZEL_QUERY_MATCH_PATTERN__:=''}

# Usage: _bazel__get_rule_match_pattern <command>
# Determine what kind of rules to match, based on command.
_bazel__get_rule_match_pattern() {
  local var_name pattern
  if _bazel_completion_use_query; then
    var_name="BAZEL_QUERY_MATCH_PATTERN"
  else
    var_name="BAZEL_BUILD_MATCH_PATTERN"
  fi
  if [[ "$1" =~ ^label-?([a-z]*)$ ]]; then
    pattern=${BASH_REMATCH[1]:-}
    if _bazel_completion_allow_tests_for_run; then
      eval "echo \"\${${var_name}_RUNTEST__${pattern}:-\$${var_name}__${pattern}}\""
    else
      eval "echo \"\$${var_name}__${pattern}\""
    fi
  fi
}

# Compute workspace directory. Search for the innermost
# enclosing directory with a WORKSPACE file.
_bazel__get_workspace_path() {
  local workspace=$PWD
  while true; do
    if [ -f "${workspace}/WORKSPACE" ]; then
      break
    elif [ -z "$workspace" -o "$workspace" = "/" ]; then
      workspace=$PWD
      break;
    fi
    workspace=${workspace%/*}
  done
  echo $workspace
}


# Find the current piece of the line to complete, but only do word breaks at
# certain characters. In particular, ignore these: "':=
# This method also takes into account the current cursor position.
#
# Works with both bash 3 and 4! Bash 3 and 4 perform different word breaks when
# computing the COMP_WORDS array. We need this here because Bazel options are of
# the form --a=b, and labels of the form //some/label:target.
_bazel__get_cword() {
  local cur=${COMP_LINE:0:$COMP_POINT}
  # This expression finds the last word break character, as defined in the
  # COMP_WORDBREAKS variable, but without '=' or ':', which is not preceeded by
  # a slash. Quote characters are also excluded.
  local wordbreaks="$COMP_WORDBREAKS"
  wordbreaks="${wordbreaks//\'/}"
  wordbreaks="${wordbreaks//\"/}"
  wordbreaks="${wordbreaks//:/}"
  wordbreaks="${wordbreaks//=/}"
  local word_start=$(expr "$cur" : '.*[^\]['"${wordbreaks}"']')
  echo "${cur:$word_start}"
}


# Usage: _bazel__package_path <workspace> <displacement>
#
# Prints a list of package-path root directories, displaced using the
# current displacement from the workspace.  All elements have a
# trailing slash.
_bazel__package_path() {
  local workspace=$1 displacement=$2 root
  IFS=:
  for root in ${BAZEL_COMPLETION_PACKAGE_PATH//\%workspace\%/$workspace}; do
    unset IFS
    echo "$root/$displacement"
  done
}

# Usage: _bazel__options_for <command>
#
# Prints the set of options for a given Bazel command, e.g. "build".
_bazel__options_for() {
  local options
  if [[ "${BAZEL_COMMAND_LIST}" =~ ^(.* )?$1( .*)?$ ]]; then
      # assumes option names only use ASCII characters
      local option_name=$(echo $1 | tr a-z A-Z | tr "-" "_")
      eval "echo \${BAZEL_COMMAND_${option_name}_FLAGS}" | tr " " "\n"
  fi
}
# Usage: _bazel__expansion_for <command>
#
# Prints the completion pattern for a given Bazel command, e.g. "build".
_bazel__expansion_for() {
  local options
  if [[ "${BAZEL_COMMAND_LIST}" =~ ^(.* )?$1( .*)?$ ]]; then
      # assumes option names only use ASCII characters
      local option_name=$(echo $1 | tr a-z A-Z | tr "-" "_")
      eval "echo \${BAZEL_COMMAND_${option_name}_ARGUMENT}"
  fi
}

# Usage: _bazel__matching_targets <kind> <prefix>
#
# Prints target names of kind <kind> and starting with <prefix> in the BUILD
# file given as standard input.  <kind> is a basic regex (BRE) used to match the
# bazel rule kind and <prefix> is the prefix of the target name.
_bazel__matching_targets() {
  local kind_pattern="$1"
  local target_prefix="$2"
  # The following commands do respectively:
  #   Remove BUILD file comments
  #   Replace \n by spaces to have the BUILD file in a single line
  #   Extract all rule types and target names
  #   Grep the kind pattern and the target prefix
  #   Returns the target name
  sed 's/#.*$//' \
      | tr "\n" " " \
      | sed 's/\([a-zA-Z0-9_]*\) *(\([^)]* \)\{0,1\}name *= *['\''"]\([a-zA-Z0-9_/.+=,@~-]*\)['\''"][^)]*)/\
type:\1 name:\3\
/g' \
      | "grep" -E "^type:$kind_pattern name:$target_prefix" \
      | cut -d ':' -f 3
}


# Usage: _bazel__is_true <string>
#
# Returns true or false based on the input string. The following are
# valid true values (the rest are false): "1", "true".
_bazel__is_true() {
  local str="$1"
  [[ "$str" == "1" || "$str" == "true" ]]
}

# Usage: _bazel__expand_rules_in_package <workspace> <displacement>
#                                        <current> <label-type>
#
# Expands rules in specified packages, exploring all roots of
# $BAZEL_COMPLETION_PACKAGE_PATH, not just $(pwd).  Only rules
# appropriate to the command are printed.  Sets $COMPREPLY array to
# result.
#
# If _bazel_completion_use_query has a successful exit code, 'bazel query' is
# used instead, with the actual Bazel package path;
# $BAZEL_COMPLETION_PACKAGE_PATH is ignored in this case, since the actual Bazel
# value is likely to be more accurate.
_bazel__expand_rules_in_package() {
  local workspace=$1 displacement=$2 current=$3 label_type=$4
  local package_name=$(echo "$current" | cut -f1 -d:)
  local rule_prefix=$(echo "$current" | cut -f2 -d:)
  local root buildfile rule_pattern r result

  result=
  pattern=$(_bazel__get_rule_match_pattern "$label_type")
  if _bazel_completion_use_query; then
    package_name=$(echo "$package_name" | tr -d "'\"") # remove quotes
    result=$(${BAZEL} --output_base=/tmp/${BAZEL}-completion-$USER query \
                   --keep_going --noshow_progress --output=label \
      "kind('$pattern rule', '$package_name:*')" 2>/dev/null |
      cut -f2 -d: | "grep" "^$rule_prefix")
  else
    for root in $(_bazel__package_path "$workspace" "$displacement"); do
      buildfile="$root/$package_name/BUILD.bazel"
      if [ ! -f "$buildfile" ]; then
        buildfile="$root/$package_name/BUILD"
      fi
      if [ -f "$buildfile" ]; then
        result=$(_bazel__matching_targets \
                   "$pattern" "$rule_prefix" <"$buildfile")
        break
      fi
    done
  fi

  index=$(echo $result | wc -w)
  if [ -n "$result" ]; then
      echo "$result" | tr " " "\n" | sed 's|$| |'
  fi
  # Include ":all" wildcard if there was no unique match.  (The zero
  # case is tricky: we need to include "all" in that case since
  # otherwise we won't expand "a" to "all" in the absence of rules
  # starting with "a".)
  if [ $index -ne 1 ] && expr all : "\\($rule_prefix\\)" >/dev/null; then
    echo "all "
  fi
}

# Usage: _bazel__expand_package_name <workspace> <displacement> <current-word>
#                                    <label-type>
#
# Expands directories, but explores all roots of
# BAZEL_COMPLETION_PACKAGE_PATH, not just $(pwd).  When a directory is
# a bazel package, the completion offers "pkg:" so you can expand
# inside the package.
# Sets $COMPREPLY array to result.
_bazel__expand_package_name() {
  local workspace=$1 displacement=$2 current=$3 type=${4:-} root dir index
  for root in $(_bazel__package_path "$workspace" "$displacement"); do
    found=0
    for dir in $(compgen -d $root$current); do
      [ -L "$dir" ] && continue  # skip symlinks (e.g. bazel-bin)
      [[ "$dir" =~ ^(.*/)?\.[^/]*$ ]] && continue  # skip dotted dir (e.g. .git)
      found=1
      echo "${dir#$root}/"
      if [ -f $dir/BUILD.bazel -o -f $dir/BUILD ]; then
        if [ "${type}" = "label-package" ]; then
          echo "${dir#$root} "
        else
          echo "${dir#$root}:"
        fi
      fi
    done
    [ $found -gt 0 ] && break  # Stop searching package path upon first match.
  done
}

# Usage: _bazel__expand_target_pattern <workspace> <displacement>
#                                      <word> <label-syntax>
#
# Expands "word" to match target patterns, using the current workspace
# and displacement from it.  "command" is used to filter rules.
# Sets $COMPREPLY array to result.
_bazel__expand_target_pattern() {
  local workspace=$1 displacement=$2 current=$3 label_syntax=$4
  case "$current" in
    //*:*) # Expand rule names within package, no displacement.
      if [ "${label_syntax}" = "label-package" ]; then
        compgen -S " " -W "BUILD" "$(echo current | cut -f ':' -d2)"
      else
        _bazel__expand_rules_in_package "$workspace" "" "$current" "$label_syntax"
      fi
      ;;
    *:*) # Expand rule names within package, displaced.
      if [ "${label_syntax}" = "label-package" ]; then
        compgen -S " " -W "BUILD" "$(echo current | cut -f ':' -d2)"
      else
        _bazel__expand_rules_in_package \
          "$workspace" "$displacement" "$current" "$label_syntax"
      fi
      ;;
    //*) # Expand filenames using package-path, no displacement
      _bazel__expand_package_name "$workspace" "" "$current" "$label_syntax"
      ;;
    *) # Expand filenames using package-path, displaced.
      if [ -n "$current" ]; then
        _bazel__expand_package_name "$workspace" "$displacement" "$current" "$label_syntax"
      fi
      ;;
  esac
}

_bazel__get_command() {
  for word in "${COMP_WORDS[@]:1:COMP_CWORD-1}"; do
    if echo "$BAZEL_COMMAND_LIST" | "grep" -wsq -e "$word"; then
      echo $word
      break
    fi
  done
}

# Returns the displacement to the workspace given in $1
_bazel__get_displacement() {
  if [[ "$PWD" =~ ^$1/.*$ ]]; then
    echo ${PWD##$1/}/
  fi
}


# Usage: _bazel__complete_pattern <workspace> <displacement> <current>
#                                 <type>
#
# Expand a word according to a type. The currently supported types are:
#  - {a,b,c}: an enum that can take value a, b or c
#  - label: a label of any kind
#  - label-bin: a label to a runnable rule (basically to a _binary rule)
#  - label-test: a label to a test rule
#  - info-key: an info key as listed by `bazel help info-keys`
#  - command: the name of a command
#  - path: a file path
#  - combinaison of previous type using | as separator
_bazel__complete_pattern() {
  local workspace=$1 displacement=$2 current=$3 types=$4
  for type in $(echo $types | tr "|" "\n"); do
    case "$type" in
      label*)
        _bazel__expand_target_pattern "$workspace" "$displacement" \
            "$current" "$type"
        ;;
      info-key)
    compgen -S " " -W "${BAZEL_INFO_KEYS}" -- "$current"
        ;;
      "command")
        local commands=$(echo "${BAZEL_COMMAND_LIST}" \
          | tr " " "\n" | "grep" -v "^${BAZEL_IGNORED_COMMAND_REGEX}$")
    compgen -S " " -W "${commands}" -- "$current"
        ;;
      path)
        compgen -f -- "$current"
        ;;
      *)
        compgen -S " " -W "$type" -- "$current"
        ;;
    esac
  done
}

# Usage: _bazel__expand_options <workspace> <displacement> <current-word>
#                               <options>
#
# Expands options, making sure that if current-word contains an equals sign,
# it is handled appropriately.
_bazel__expand_options() {
  local workspace="$1" displacement="$2" cur="$3" options="$4"
  if [[ $cur =~ = ]]; then
    # also expands special labels
    current=$(echo "$cur" | cut -f2 -d=)
    _bazel__complete_pattern "$workspace" "$displacement" "$current" \
    "$(compgen -W "$options" -- "$cur" | cut -f2 -d=)" \
        | sort -u
  else
    compgen -W "$(echo "$options" | sed 's|=.*$|=|')" -- "$cur" \
    | sed 's|\([^=]\)$|\1 |'
  fi
}

# Usage: _bazel__abspath <file>
#
#
# Returns the absolute path to a file
_bazel__abspath() {
    echo "$(cd "$(dirname "$1")"; pwd)/$(basename "$1")"
 }

# Usage: _bazel__rc_imports <workspace> <rc-file>
#
#
# Returns the list of other RC imported (or try-imported) by a given RC file
# Only return files we can actually find, and only return absolute paths
_bazel__rc_imports() {
  local workspace="$1" rc_dir rc_file="$2" import_files
  rc_dir=$(dirname $rc_file)
  import_files=$(cat $rc_file \
      | sed 's/#.*//' \
      | sed -E "/^(try-){0,1}import/!d" \
      | sed -E "s/^(try-){0,1}import ([^ ]*).*$/\2/" \
      | sort -u)

  local confirmed_import_files=()
  for import in $import_files; do
    # rc imports can use %workspace% to refer to the workspace, and we need to substitute that here
    import=${import//\%workspace\%/$workspace}
    if [[ "${import:0:1}" != "/" ]] ; then
      import="$rc_dir/$import"
    fi
    import=$(_bazel__abspath $import)
    # Don't bother dealing with it further if we can't find it
    if [ -f "$import" ] ; then
      confirmed_import_files+=($import)
    fi
  done
  echo "${confirmed_import_files[@]}"
}

# Usage: _bazel__rc_expand_imports <workspace> <processed-rc-files ...> __new__ <new-rc-files ...>
#
#
# Function that receives a workspace and two lists. The first list is a list of RC files that have
# already been processed, and the second list contains new RC files that need processing. Each new file will be
# processed for "{try-}import" lines to discover more RC files that need parsing.
# Any lines we find in "{try-}import" will be checked against known files (and not processed again if known).
_bazel__rc_expand_imports() {
  local workspace="$1" rc_file new_found="no" processed_files=() to_process_files=() discovered_files=()
  # We've consumed workspace
  shift
  # Now grab everything else
  local all_files=($@)
  for rc_file in ${all_files[@]} ; do
    if [ "$rc_file" == "__new__" ] ; then
      new_found="yes"
      continue
    elif [ "$new_found" == "no" ] ; then
      processed_files+=($rc_file)
    else
      to_process_files+=($rc_file)
    fi
  done

  # For all the non-processed files, get the list of imports out of each of those files
  for rc_file in "${to_process_files[@]}"; do
    local potential_new_files+=($(_bazel__rc_imports "$workspace" "$rc_file"))
    processed_files+=($rc_file)
    for potential_new_file in ${potential_new_files[@]} ; do
      if [[ ! " ${processed_files[@]} " =~ " ${potential_new_file} " ]] ; then
        discovered_files+=($potential_new_file)
      fi
    done
  done

  # Finally, return two lists (separated by __new__) of the files that have been fully processed, and
  # the files that need processing.
  echo "${processed_files[@]}" "__new__" "${discovered_files[@]}"
}

# Usage: _bazel__rc_files <workspace>
#
#
# Returns the list of RC files to examine, given the current command-line args.
_bazel__rc_files() {
  local workspace="$1" new_files=() processed_files=()
  # Handle the workspace RC unless --noworkspace_rc says not to.
  if [[ ! "${COMP_LINE}" =~ "--noworkspace_rc" ]]; then
    local workspacerc="$workspace/.bazelrc"
    if [ -f "$workspacerc" ] ; then
      new_files+=($(_bazel__abspath $workspacerc))
    fi
  fi
  # Handle the $HOME RC unless --nohome_rc says not to.
  if [[ ! "${COMP_LINE}" =~ "--nohome_rc" ]]; then
    local homerc="$HOME/.bazelrc"
    if [ -f "$homerc" ] ; then
      new_files+=($(_bazel__abspath $homerc))
    fi
  fi
  # Handle the system level RC unless --nosystem_rc says not to.
  if [[ ! "${COMP_LINE}" =~ "--nosystem_rc" ]]; then
    local systemrc="/etc/bazel.bazelrc"
    if [ -f "$systemrc" ] ; then
      new_files+=($(_bazel__abspath $systemrc))
    fi
  fi
  # Finally, if the user specified any on the command-line, then grab those
  # keeping in mind that there may be several.
  if [[ "${COMP_LINE}" =~ "--bazelrc=" ]]; then
    # There's got to be a better way to do this, but... it gets the job done,
    # even if there are multiple --bazelrc on the command line. The sed command
    # SHOULD be simpler, but capturing several instances of the same pattern
    # from the same line is tricky because of the greedy nature of .*
    # Instead we transform it to multiple lines, and then back.
    local cmdlnrcs=$(echo ${COMP_LINE} | sed -E "s/--bazelrc=/\n--bazelrc=/g" | sed -E "/--bazelrc/!d;s/^--bazelrc=([^ ]*).*$/\1/g" | tr "\n" " ")
    for rc_file in $cmdlnrcs; do
      if [ -f "$rc_file" ] ; then
        new_files+=($(_bazel__abspath $rc_file))
      fi
    done
  fi

  # Each time we call _bazel__rc_expand_imports, it may find new files which then need to be expanded as well,
  # so we loop until we've processed all new files.
  while (( ${#new_files[@]} > 0 )) ; do
    local all_files=($(_bazel__rc_expand_imports "$workspace" "${processed_files[@]}" "__new__" "${new_files[@]}"))
    local new_found="no"
    new_files=()
    processed_files=()
    for file in ${all_files[@]} ; do
      if [ "$file" == "__new__" ] ; then
        new_found="yes"
        continue
      elif [ "$new_found" == "no" ] ; then
        processed_files+=($file)
      else
        new_files+=($file)
      fi
    done
  done

  echo "${processed_files[@]}"
}

# Usage: _bazel__all_configs <workspace> <command>
#
#
# Gets contents of all RC files and searches them for config names
# that could be used for expansion.
_bazel__all_configs() {
  local workspace="$1" command="$2" rc_files

  # Start out getting a list of all RC files that we can look for configs in
  # This respects the various command line options documented at
  # https://docs.bazel.build/versions/2.0.0/guide.html#bazelrc
  rc_files=$(_bazel__rc_files "$workspace")

  # Commands can inherit configs from other commands, so build up command_match, which is
  # a match list of the various commands that we can match against, given the command
  # specified by the user
  local build_inherit=("aquery" "clean" "coverage" "cquery" "info" "mobile-install" "print_action" "run" "test")
  local test_inherit=("coverage")
  local command_match="$command"
  if [[ "${build_inherit[@]}" =~ "$command" ]]; then
    command_match="$command_match|build"
  fi
  if [[ "${test_inherit[@]}" =~ "$command" ]]; then
    command_match="$command_match|test"
  fi

  # The following commands do respectively:
  #   Gets the contents of all relevant/allowed RC files
  #   Remove file comments
  #   Filter only the configs relevant to the current command
  #   Extract the config names
  #   Filters out redundant names and returns the results
  cat $rc_files \
      | sed 's/#.*//' \
      | sed -E "/^($command_match):/!d" \
      | sed -E "s/^($command_match):([^ ]*).*$/\2/" \
      | sort -u
}

# Usage: _bazel__expand_config <workspace> <command> <current-word>
#
#
# Expands configs, checking through the allowed rc files and parsing for configs
# relevant to the current command
_bazel__expand_config() {
  local workspace="$1" command="$2" cur="$3" rc_files all_configs
  all_configs=$(_bazel__all_configs "$workspace" "$command")
  compgen -S " " -W "$all_configs" -- "$cur"
}

_bazel__complete_stdout() {
  local cur=$(_bazel__get_cword) word command displacement workspace

  # Determine command: "" (startup-options) or one of $BAZEL_COMMAND_LIST.
  command="$(_bazel__get_command)"

  workspace="$(_bazel__get_workspace_path)"
  displacement="$(_bazel__get_displacement ${workspace})"

  case "$command" in
    "") # Expand startup-options or commands
      local commands=$(echo "${BAZEL_COMMAND_LIST}" \
        | tr " " "\n" | "grep" -v "^${BAZEL_IGNORED_COMMAND_REGEX}$")
      _bazel__expand_options  "$workspace" "$displacement" "$cur" \
          "${commands}\
          ${BAZEL_STARTUP_OPTIONS}"
      ;;

    *)
      case "$cur" in
        --config=*) # Expand options:
          _bazel__expand_config  "$workspace" "$command" "${cur#"--config="}"
          ;;
        -*) # Expand options:
          _bazel__expand_options  "$workspace" "$displacement" "$cur" \
              "$(_bazel__options_for $command)"
          ;;
        *)  # Expand target pattern
      expansion_pattern="$(_bazel__expansion_for $command)"
          NON_QUOTE_REGEX="^[\"']"
          if [[ $command = query && $cur =~ $NON_QUOTE_REGEX ]]; then
            : # Ideally we would expand query expressions---it's not
              # that hard, conceptually---but readline is just too
              # damn complex when it comes to quotation.  Instead,
              # for query, we just expand target patterns, unless
              # the first char is a quote.
          elif [ -n "$expansion_pattern" ]; then
            _bazel__complete_pattern \
        "$workspace" "$displacement" "$cur" "$expansion_pattern"
          fi
          ;;
      esac
      ;;
  esac
}

_bazel__to_compreply() {
  local replies="$1"
  COMPREPLY=()
  # Trick to preserve whitespaces
  while IFS="" read -r reply; do
    COMPREPLY+=("${reply}")
  done < <(echo "${replies}")
  # Null may be set despite there being no completions
  if [ ${#COMPREPLY[@]} -eq 1 ] && [ -z ${COMPREPLY[0]} ]; then
    COMPREPLY=()
  fi
}

_bazel__complete() {
  _bazel__to_compreply "$(_bazel__complete_stdout)"
}

# Some users have aliases such as bt="bazel test" or bb="bazel build", this
# completion function allows them to have auto-completion for these aliases.
_bazel__complete_target_stdout() {
  local cur=$(_bazel__get_cword) word command displacement workspace

  # Determine command: "" (startup-options) or one of $BAZEL_COMMAND_LIST.
  command="$1"

  workspace="$(_bazel__get_workspace_path)"
  displacement="$(_bazel__get_displacement ${workspace})"

  _bazel__to_compreply "$(_bazel__expand_target_pattern "$workspace" "$displacement" \
      "$cur" "$(_bazel__expansion_for $command)")"
}

# default completion for bazel
complete -F _bazel__complete -o nospace "${BAZEL}"
complete -F _bazel__complete -o nospace "${IBAZEL}"
BAZEL_COMMAND_LIST="analyze-profile aquery build canonicalize-flags clean config coverage cquery dump fetch help info license mobile-install print_action query run shutdown sync test version"
BAZEL_INFO_KEYS="
workspace
install_base
output_base
execution_root
output_path
client-env
bazel-bin
bazel-genfiles
bazel-testlogs
release
server_pid
server_log
package_path
used-heap-size
used-heap-size-after-gc
committed-heap-size
max-heap-size
gc-time
gc-count
java-runtime
java-vm
java-home
character-encoding
defaults-package
build-language
default-package-path
starlark-semantics
"
BAZEL_STARTUP_OPTIONS="
--batch
--nobatch
--batch_cpu_scheduling
--nobatch_cpu_scheduling
--bazelrc=
--block_for_lock
--noblock_for_lock
--client_debug
--noclient_debug
--connect_timeout_secs=
--deep_execroot
--nodeep_execroot
--expand_configs_in_place
--noexpand_configs_in_place
--failure_detail_out=path
--home_rc
--nohome_rc
--host_jvm_args=
--host_jvm_debug
--host_jvm_profile=
--idle_server_tasks
--noidle_server_tasks
--ignore_all_rc_files
--noignore_all_rc_files
--incompatible_enable_execution_transition
--noincompatible_enable_execution_transition
--io_nice_level=
--macos_qos_class=
--max_idle_secs=
--output_base=path
--output_user_root=path
--server_javabase=
--server_jvm_out=path
--shutdown_on_low_sys_mem
--noshutdown_on_low_sys_mem
--system_rc
--nosystem_rc
--unlimit_coredumps
--nounlimit_coredumps
--watchfs
--nowatchfs
--windows_enable_symlinks
--nowindows_enable_symlinks
--workspace_rc
--noworkspace_rc
"
BAZEL_COMMAND_ANALYZE_PROFILE_ARGUMENT="path"
BAZEL_COMMAND_ANALYZE_PROFILE_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--distdir=
--dump=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--override_repository=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--repository_cache=path
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--watchfs
--nowatchfs
"
BAZEL_COMMAND_AQUERY_ARGUMENT="label"
BAZEL_COMMAND_AQUERY_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspect_deps={off,conservative,precise}
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--implicit_deps
--noimplicit_deps
--include_artifacts
--noinclude_artifacts
--include_aspects
--noinclude_aspects
--include_commandline
--noinclude_commandline
--include_param_files
--noinclude_param_files
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_proto_output_v2
--noincompatible_proto_output_v2
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--infer_universe_scope
--noinfer_universe_scope
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--nodep_deps
--nonodep_deps
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto:default_values
--noproto:default_values
--proto:definition_stack
--noproto:definition_stack
--proto:flatten_selects
--noproto:flatten_selects
--proto:include_synthetic_attribute_hash
--noproto:include_synthetic_attribute_hash
--proto:instantiation_stack
--noproto:instantiation_stack
--proto:locations
--noproto:locations
--proto:output_rule_attrs=
--proto:rule_inputs_and_outputs
--noproto:rule_inputs_and_outputs
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--relative_locations
--norelative_locations
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--skyframe_state
--noskyframe_state
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_deps
--notool_deps
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--universe_scope=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_BUILD_ARGUMENT="label"
BAZEL_COMMAND_BUILD_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_CANONICALIZE_FLAGS_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--aspect_deps={off,conservative,precise}
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--canonicalize_policy
--nocanonicalize_policy
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--deleted_packages=
--disk_cache=path
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_graphless_genquery_force_sort
--noexperimental_graphless_genquery_force_sort
--experimental_graphless_query={auto,yes,no}
--noexperimental_graphless_query
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--for_command=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--graph:conditional_edges_limit=
--graph:factored
--nograph:factored
--graph:node_limit=
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--implicit_deps
--noimplicit_deps
--include_aspects
--noinclude_aspects
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prefer_unordered_output
--noincompatible_prefer_unordered_output
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--infer_universe_scope
--noinfer_universe_scope
--invocation_policy=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--line_terminator_null
--noline_terminator_null
--loading_phase_threads=
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--nodep_deps
--nonodep_deps
--noorder_results
--null
--order_output={no,deps,auto,full}
--order_results
--output=
--override_repository=
--package_path=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--proto:default_values
--noproto:default_values
--proto:definition_stack
--noproto:definition_stack
--proto:flatten_selects
--noproto:flatten_selects
--proto:include_synthetic_attribute_hash
--noproto:include_synthetic_attribute_hash
--proto:instantiation_stack
--noproto:instantiation_stack
--proto:locations
--noproto:locations
--proto:output_rule_attrs=
--proto:rule_inputs_and_outputs
--noproto:rule_inputs_and_outputs
--query_file=
--relative_locations
--norelative_locations
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repository_cache=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--show_warnings
--noshow_warnings
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--strict_test_suite
--nostrict_test_suite
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_deps
--notool_deps
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--universe_scope=
--watchfs
--nowatchfs
--xml:default_values
--noxml:default_values
--xml:line_numbers
--noxml:line_numbers
"
BAZEL_COMMAND_CLEAN_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--async
--noasync
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--expunge
--noexpunge
--expunge_async
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_CONFIG_ARGUMENT="string"
BAZEL_COMMAND_CONFIG_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dump_all
--nodump_all
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output={text,json}
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_COVERAGE_ARGUMENT="label-test"
BAZEL_COMMAND_COVERAGE_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--print_relative_test_log_paths
--noprint_relative_test_log_paths
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--test_verbose_timeout_warnings
--notest_verbose_timeout_warnings
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--verbose_test_summary
--noverbose_test_summary
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_CQUERY_ARGUMENT="label"
BAZEL_COMMAND_CQUERY_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspect_deps={off,conservative,precise}
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--implicit_deps
--noimplicit_deps
--include_aspects
--noinclude_aspects
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--infer_universe_scope
--noinfer_universe_scope
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--nodep_deps
--nonodep_deps
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto:default_values
--noproto:default_values
--proto:definition_stack
--noproto:definition_stack
--proto:flatten_selects
--noproto:flatten_selects
--proto:include_configurations
--noproto:include_configurations
--proto:include_synthetic_attribute_hash
--noproto:include_synthetic_attribute_hash
--proto:instantiation_stack
--noproto:instantiation_stack
--proto:locations
--noproto:locations
--proto:output_rule_attrs=
--proto:rule_inputs_and_outputs
--noproto:rule_inputs_and_outputs
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--relative_locations
--norelative_locations
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_config_fragments={off,direct_host_only,direct,transitive}
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark:expr=
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_deps
--notool_deps
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--transitions={full,lite,none}
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--universe_scope=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_DUMP_FLAGS="
--action_cache
--noaction_cache
--action_graph=
--action_graph:include_artifacts
--noaction_graph:include_artifacts
--action_graph:include_cmdline
--noaction_graph:include_cmdline
--action_graph:targets=
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--override_repository=
--packages
--nopackages
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--repository_cache=path
--rule_classes
--norule_classes
--rules
--norules
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--skyframe={off,summary,detailed}
--skylark_memory=
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--watchfs
--nowatchfs
"
BAZEL_COMMAND_FETCH_ARGUMENT="label"
BAZEL_COMMAND_FETCH_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--deleted_packages=
--disk_cache=path
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--loading_phase_threads=
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--override_repository=
--package_path=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repository_cache=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--watchfs
--nowatchfs
"
BAZEL_COMMAND_HELP_ARGUMENT="command|{startup_options,target-syntax,info-keys}"
BAZEL_COMMAND_HELP_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--help_verbosity={long,medium,short}
--http_timeout_scaling=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--logging=
--long
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--override_repository=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--repository_cache=path
--short
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--watchfs
--nowatchfs
"
BAZEL_COMMAND_INFO_ARGUMENT="info-key"
BAZEL_COMMAND_INFO_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_make_env
--noshow_make_env
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_LICENSE_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--override_repository=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--repository_cache=path
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--watchfs
--nowatchfs
"
BAZEL_COMMAND_MOBILE_INSTALL_ARGUMENT="label"
BAZEL_COMMAND_MOBILE_INSTALL_FLAGS="
--action_env=
--adb=
--adb_arg=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--debug_app
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device=
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental
--noincremental
--incremental_dexing
--noincremental_dexing
--incremental_install_verbosity=
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--mode={classic,classic_internal_test_do_not_use,skylark}
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--split_apks
--nosplit_apks
--stamp
--nostamp
--starlark_cpu_profile=
--start={no,cold,warm,debug}
--start_app
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_PRINT_ACTION_ARGUMENT="label"
BAZEL_COMMAND_PRINT_ACTION_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--print_action_mnemonics=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_QUERY_ARGUMENT="label"
BAZEL_COMMAND_QUERY_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--aspect_deps={off,conservative,precise}
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--deleted_packages=
--disk_cache=path
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_graphless_genquery_force_sort
--noexperimental_graphless_genquery_force_sort
--experimental_graphless_query={auto,yes,no}
--noexperimental_graphless_query
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--graph:conditional_edges_limit=
--graph:factored
--nograph:factored
--graph:node_limit=
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--implicit_deps
--noimplicit_deps
--include_aspects
--noinclude_aspects
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prefer_unordered_output
--noincompatible_prefer_unordered_output
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--infer_universe_scope
--noinfer_universe_scope
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--line_terminator_null
--noline_terminator_null
--loading_phase_threads=
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--nodep_deps
--nonodep_deps
--noorder_results
--null
--order_output={no,deps,auto,full}
--order_results
--output=
--override_repository=
--package_path=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--proto:default_values
--noproto:default_values
--proto:definition_stack
--noproto:definition_stack
--proto:flatten_selects
--noproto:flatten_selects
--proto:include_synthetic_attribute_hash
--noproto:include_synthetic_attribute_hash
--proto:instantiation_stack
--noproto:instantiation_stack
--proto:locations
--noproto:locations
--proto:output_rule_attrs=
--proto:rule_inputs_and_outputs
--noproto:rule_inputs_and_outputs
--query_file=
--relative_locations
--norelative_locations
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repository_cache=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--strict_test_suite
--nostrict_test_suite
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_deps
--notool_deps
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--universe_scope=
--watchfs
--nowatchfs
--xml:default_values
--noxml:default_values
--xml:line_numbers
--noxml:line_numbers
"
BAZEL_COMMAND_RUN_ARGUMENT="label-bin"
BAZEL_COMMAND_RUN_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--script_path=path
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_SHUTDOWN_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--iff_heap_size_greater_than=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--override_repository=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--repository_cache=path
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--watchfs
--nowatchfs
"
BAZEL_COMMAND_SYNC_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--configure
--noconfigure
--curses={yes,no,auto}
--deleted_packages=
--disk_cache=path
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--loading_phase_threads=
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--only=
--override_repository=
--package_path=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repository_cache=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
--ui_actions_shown=
--ui_event_filters=
--watchfs
--nowatchfs
"
BAZEL_COMMAND_TEST_ARGUMENT="label-test"
BAZEL_COMMAND_TEST_FLAGS="
--action_env=
--all_incompatible_changes
--allow_analysis_failures
--noallow_analysis_failures
--analysis_testing_deps_limit=
--android_compiler=
--android_cpu=
--android_crosstool_top=label
--android_databinding_use_v3_4_args
--noandroid_databinding_use_v3_4_args
--android_dynamic_mode={off,default,fully}
--android_grte_top=label
--android_manifest_merger={legacy,android,force_android}
--android_manifest_merger_order={alphabetical,alphabetical_by_configuration,dependency}
--android_resource_shrinking
--noandroid_resource_shrinking
--android_sdk=label
--announce
--noannounce
--announce_rc
--noannounce_rc
--apk_signing_method={v1,v2,v1_v2}
--apple_bitcode=
--apple_compiler=
--apple_crosstool_top=label
--apple_enable_auto_dsym_dbg
--noapple_enable_auto_dsym_dbg
--apple_generate_dsym
--noapple_generate_dsym
--apple_grte_top=label
--apple_sdk=label
--aspects=
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--auto_cpu_environment_group=label
--auto_output_filter={none,all,packages,subpackages}
--bep_publish_used_heap_size_post_build
--nobep_publish_used_heap_size_post_build
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--break_build_on_parallel_dex2oat_failure
--nobreak_build_on_parallel_dex2oat_failure
--build
--nobuild
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_manual_tests
--nobuild_manual_tests
--build_metadata=
--build_python_zip={auto,yes,no}
--nobuild_python_zip
--build_runfile_links
--nobuild_runfile_links
--build_runfile_manifests
--nobuild_runfile_manifests
--build_tag_filters=
--build_test_dwp
--nobuild_test_dwp
--build_tests_only
--nobuild_tests_only
--cache_test_results={auto,yes,no}
--nocache_test_results
--catalyst_cpus=
--cc_output_directory_tag=
--cc_proto_library_header_suffixes=
--cc_proto_library_source_suffixes=
--check_constraint=
--check_licenses
--nocheck_licenses
--check_tests_up_to_date
--nocheck_tests_up_to_date
--check_up_to_date
--nocheck_up_to_date
--check_visibility
--nocheck_visibility
--collapse_duplicate_defines
--nocollapse_duplicate_defines
--collect_code_coverage
--nocollect_code_coverage
--color={yes,no,auto}
--combined_report={none,lcov}
--compilation_mode={fastbuild,dbg,opt}
--compile_one_dependency
--nocompile_one_dependency
--compiler=
--config=
--conlyopt=
--copt=
--coverage_report_generator=label
--coverage_support=label
--cpu=
--crosstool_top=label
--cs_fdo_absolute_path=
--cs_fdo_instrument=
--cs_fdo_profile=label
--curses={yes,no,auto}
--custom_malloc=label
--cxxopt=
--default_ios_provisioning_profile=label
--define=
--deleted_packages=
--desugar_for_android
--nodesugar_for_android
--device_debug_entitlements
--nodevice_debug_entitlements
--discard_analysis_cache
--nodiscard_analysis_cache
--disk_cache=path
--distdir=
--distinct_host_configuration
--nodistinct_host_configuration
--dynamic_mode={off,default,fully}
--embed_label=
--enable_apple_binary_native_protos
--noenable_apple_binary_native_protos
--enable_fdo_profile_absolute_path
--noenable_fdo_profile_absolute_path
--enable_platform_specific_config
--noenable_platform_specific_config
--enable_runfiles={auto,yes,no}
--noenable_runfiles
--enforce_constraints
--noenforce_constraints
--execution_log_binary_file=path
--execution_log_json_file=path
--expand_test_suites
--noexpand_test_suites
--experimental_action_listener=
--experimental_add_exec_constraints_to_targets=
--experimental_allow_android_library_deps_without_srcs
--noexperimental_allow_android_library_deps_without_srcs
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_android_compress_java_resources
--noexperimental_android_compress_java_resources
--experimental_android_databinding_v2
--noexperimental_android_databinding_v2
--experimental_android_resource_shrinking
--noexperimental_android_resource_shrinking
--experimental_android_rewrite_dexes_with_rex
--noexperimental_android_rewrite_dexes_with_rex
--experimental_android_use_parallel_dex2oat
--noexperimental_android_use_parallel_dex2oat
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cancel_concurrent_tests
--noexperimental_cancel_concurrent_tests
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_check_desugar_deps
--noexperimental_check_desugar_deps
--experimental_convenience_symlinks={normal,clean,ignore,log_only}
--experimental_convenience_symlinks_bep_event
--noexperimental_convenience_symlinks_bep_event
--experimental_delay_virtual_input_materialization
--noexperimental_delay_virtual_input_materialization
--experimental_desugar_java8_libs
--noexperimental_desugar_java8_libs
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_docker_image=
--experimental_docker_privileged
--noexperimental_docker_privileged
--experimental_docker_use_customized_images
--noexperimental_docker_use_customized_images
--experimental_docker_verbose
--noexperimental_docker_verbose
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_enable_docker_sandbox
--noexperimental_enable_docker_sandbox
--experimental_enable_flag_alias
--noexperimental_enable_flag_alias
--experimental_enable_objc_cc_deps
--noexperimental_enable_objc_cc_deps
--experimental_execution_log_file=path
--experimental_extra_action_filter=
--experimental_extra_action_top_level_only
--noexperimental_extra_action_top_level_only
--experimental_fetch_all_coverage_outputs
--noexperimental_fetch_all_coverage_outputs
--experimental_filter_library_jar_with_program_jar
--noexperimental_filter_library_jar_with_program_jar
--experimental_forward_instrumented_files_info_by_default
--noexperimental_forward_instrumented_files_info_by_default
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_guard_against_concurrent_changes
--noexperimental_guard_against_concurrent_changes
--experimental_import_deps_checking={off,warning,error}
--experimental_inmemory_dotd_files
--noexperimental_inmemory_dotd_files
--experimental_inmemory_jdeps_files
--noexperimental_inmemory_jdeps_files
--experimental_inprocess_symlink_creation
--noexperimental_inprocess_symlink_creation
--experimental_interleave_loading_and_analysis
--noexperimental_interleave_loading_and_analysis
--experimental_j2objc_header_map
--noexperimental_j2objc_header_map
--experimental_j2objc_shorter_header_path
--noexperimental_j2objc_shorter_header_path
--experimental_java_classpath={off,javabuilder,bazel}
--experimental_java_proto_add_allowed_public_imports
--noexperimental_java_proto_add_allowed_public_imports
--experimental_local_execution_delay=
--experimental_local_memory_estimate
--noexperimental_local_memory_estimate
--experimental_materialize_param_files_directly
--noexperimental_materialize_param_files_directly
--experimental_multi_cpu=
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_objc_enable_module_maps
--noexperimental_objc_enable_module_maps
--experimental_objc_fastbuild_options=
--experimental_objc_include_scanning
--noexperimental_objc_include_scanning
--experimental_omitfp
--noexperimental_omitfp
--experimental_oom_more_eagerly_threshold=
--experimental_persistent_javac
--experimental_persistent_test_runner
--noexperimental_persistent_test_runner
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_prefer_mutual_xcode
--noexperimental_prefer_mutual_xcode
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_proto_descriptor_sets_include_source_info
--noexperimental_proto_descriptor_sets_include_source_info
--experimental_proto_extra_actions
--noexperimental_proto_extra_actions
--experimental_remotable_source_manifests
--noexperimental_remotable_source_manifests
--experimental_remote_downloader=
--experimental_remote_grpc_log=path
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_repository_resolved_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_run_validations
--noexperimental_run_validations
--experimental_sandbox_async_tree_delete_idle_threads=
--experimental_sandboxfs_map_symlink_targets
--noexperimental_sandboxfs_map_symlink_targets
--experimental_sandboxfs_path=
--experimental_save_feature_state
--noexperimental_save_feature_state
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_spawn_scheduler
--experimental_split_xml_generation
--noexperimental_split_xml_generation
--experimental_starlark_cc_import
--noexperimental_starlark_cc_import
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_strict_fileset_output
--noexperimental_strict_fileset_output
--experimental_strict_java_deps={off,warn,error,strict,default}
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_use_llvm_covmap
--noexperimental_use_llvm_covmap
--experimental_use_sandboxfs={auto,yes,no}
--noexperimental_use_sandboxfs
--experimental_use_windows_sandbox={auto,yes,no}
--noexperimental_use_windows_sandbox
--experimental_verify_repository_rules=
--experimental_windows_sandbox_path=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_worker_max_multiplex_instances=
--experimental_worker_multiplex
--noexperimental_worker_multiplex
--experimental_workspace_rules_log_file=path
--explain=path
--explicit_java_test_deps
--noexplicit_java_test_deps
--extra_execution_platforms=
--extra_toolchains=
--fat_apk_cpu=
--fat_apk_hwasan
--nofat_apk_hwasan
--fdo_instrument=
--fdo_optimize=
--fdo_prefetch_hints=label
--fdo_profile=label
--features=
--fission=
--flag_alias=
--flaky_test_attempts=
--force_pic
--noforce_pic
--genrule_strategy=
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--grte_top=label
--high_priority_workers=
--host_action_env=
--host_compilation_mode={fastbuild,dbg,opt}
--host_compiler=
--host_conlyopt=
--host_copt=
--host_cpu=
--host_crosstool_top=label
--host_cxxopt=
--host_force_python={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--host_grte_top=label
--host_java_launcher=label
--host_java_toolchain=label
--host_javabase=label
--host_javacopt=
--host_linkopt=
--host_platform=label
--host_swiftcopt=
--http_timeout_scaling=
--ignore_unsupported_sandboxing
--noignore_unsupported_sandboxing
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_avoid_conflict_dlls
--noincompatible_avoid_conflict_dlls
--incompatible_default_to_explicit_init_py
--noincompatible_default_to_explicit_init_py
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_expand_if_all_available_in_flag_set
--noincompatible_disable_expand_if_all_available_in_flag_set
--incompatible_disable_native_android_rules
--noincompatible_disable_native_android_rules
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_legacy_py_provider
--noincompatible_disallow_legacy_py_provider
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_dont_enable_host_nonhost_crosstool_features
--noincompatible_dont_enable_host_nonhost_crosstool_features
--incompatible_enable_android_toolchain_resolution
--noincompatible_enable_android_toolchain_resolution
--incompatible_force_strict_header_check_from_starlark
--noincompatible_force_strict_header_check_from_starlark
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_make_thinlto_command_lines_standalone
--noincompatible_make_thinlto_command_lines_standalone
--incompatible_merge_genfiles_directory
--noincompatible_merge_genfiles_directory
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_compile_info_migration
--noincompatible_objc_compile_info_migration
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_prohibit_aapt1
--noincompatible_prohibit_aapt1
--incompatible_py2_outputs_are_suffixed
--noincompatible_py2_outputs_are_suffixed
--incompatible_py3_is_default
--noincompatible_py3_is_default
--incompatible_remote_results_ignore_disk
--noincompatible_remote_results_ignore_disk
--incompatible_remote_symlinks
--noincompatible_remote_symlinks
--incompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--noincompatible_remove_cpu_and_compiler_attributes_from_cc_toolchain
--incompatible_remove_legacy_whole_archive
--noincompatible_remove_legacy_whole_archive
--incompatible_remove_local_resources
--noincompatible_remove_local_resources
--incompatible_require_ctx_in_configure_features
--noincompatible_require_ctx_in_configure_features
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_strict_action_env
--noincompatible_strict_action_env
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_use_platforms_repo_for_constraints
--noincompatible_use_platforms_repo_for_constraints
--incompatible_use_python_toolchains
--noincompatible_use_python_toolchains
--incompatible_validate_top_level_header_inclusions
--noincompatible_validate_top_level_header_inclusions
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--incremental_dexing
--noincremental_dexing
--instrument_test_targets
--noinstrument_test_targets
--instrumentation_filter=
--interface_shared_objects
--nointerface_shared_objects
--ios_cpu=
--ios_memleaks
--noios_memleaks
--ios_minimum_os=
--ios_multi_cpus=
--ios_sdk_version=
--ios_signing_cert_name=
--ios_simulator_device=
--ios_simulator_version=
--j2objc_translation_flags=
--java_debug
--java_deps
--nojava_deps
--java_header_compilation
--nojava_header_compilation
--java_launcher=label
--java_toolchain=label
--javabase=label
--javacopt=
--jobs=
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--jvmopt=
--keep_going
--nokeep_going
--keep_state_after_build
--nokeep_state_after_build
--legacy_external_runfiles
--nolegacy_external_runfiles
--legacy_important_outputs
--nolegacy_important_outputs
--legacy_main_dex_list_generator=label
--legacy_whole_archive
--nolegacy_whole_archive
--linkopt=
--loading_phase_threads=
--local_cpu_resources=
--local_ram_resources=
--local_resources=
--local_termination_grace_seconds=
--local_test_jobs=
--logging=
--ltobackendopt=
--ltoindexopt=
--macos_cpus=
--macos_minimum_os=
--macos_sdk_version=
--materialize_param_files
--nomaterialize_param_files
--max_computation_steps=
--max_config_changes_to_show=
--max_test_output_bytes=
--memory_profile_stable_heap_parameters=
--message_translations=
--minimum_os_version=
--modify_execution_info=
--nested_set_depth_limit=
--objc_debug_with_GLIBCXX
--noobjc_debug_with_GLIBCXX
--objc_enable_binary_stripping
--noobjc_enable_binary_stripping
--objc_generate_linkmap
--noobjc_generate_linkmap
--objc_use_dotd_pruning
--noobjc_use_dotd_pruning
--objccopt=
--output_filter=
--output_groups=
--override_repository=
--package_path=
--parse_headers_verifies_modules
--noparse_headers_verifies_modules
--per_file_copt=
--per_file_ltobackendopt=
--persistent_android_resource_processor
--platform_mappings=path
--platform_suffix=
--platforms=
--plugin=
--print_relative_test_log_paths
--noprint_relative_test_log_paths
--process_headers_in_dependencies
--noprocess_headers_in_dependencies
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--progress_report_interval=
--proguard_top=label
--project_id=
--propeller_optimize=label
--proto_compiler=label
--proto_toolchain_for_cc=label
--proto_toolchain_for_j2objc=label
--proto_toolchain_for_java=label
--proto_toolchain_for_javalite=label
--protocopt=
--python2_path=
--python3_path=
--python_path=
--python_top=label
--python_version={py2,py3,py2and3,py2only,py3only,_internal_sentinel}
--remote_accept_cached
--noremote_accept_cached
--remote_allow_symlink_upload
--noremote_allow_symlink_upload
--remote_cache=
--remote_cache_header=
--remote_default_exec_properties=
--remote_default_platform_properties=
--remote_download_minimal
--remote_download_outputs={all,minimal,toplevel}
--remote_download_symlink_template=
--remote_download_toplevel
--remote_downloader_header=
--remote_exec_header=
--remote_execution_priority=
--remote_executor=
--remote_header=
--remote_instance_name=
--remote_local_fallback
--noremote_local_fallback
--remote_local_fallback_strategy=
--remote_max_connections=
--remote_proxy=
--remote_result_cache_priority=
--remote_retries=
--remote_timeout=
--remote_upload_local_results
--noremote_upload_local_results
--remote_verify_downloads
--noremote_verify_downloads
--repo_env=
--repository_cache=path
--run_under=
--runs_per_test=
--runs_per_test_detects_flakes
--noruns_per_test_detects_flakes
--sandbox_add_mount_pair=
--sandbox_base=
--sandbox_block_path=
--sandbox_debug
--nosandbox_debug
--sandbox_default_allow_network
--nosandbox_default_allow_network
--sandbox_fake_hostname
--nosandbox_fake_hostname
--sandbox_fake_username
--nosandbox_fake_username
--sandbox_tmpfs_path=
--sandbox_writable_path=
--save_temps
--nosave_temps
--share_native_deps
--noshare_native_deps
--shell_executable=path
--show_loading_progress
--noshow_loading_progress
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_result=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--spawn_strategy=
--stamp
--nostamp
--starlark_cpu_profile=
--strategy=
--strategy_regexp=
--strict_filesets
--nostrict_filesets
--strict_proto_deps={off,warn,error,strict,default}
--strict_system_includes
--nostrict_system_includes
--strip={always,sometimes,never}
--stripopt=
--subcommands={true,pretty_print,false}
--swiftcopt=
--symlink_prefix=
--target_environment=
--target_pattern_file=
--target_platform_fallback=label
--test_arg=
--test_env=
--test_filter=
--test_keep_going
--notest_keep_going
--test_lang_filters=
--test_output={summary,errors,all,streamed}
--test_result_expiration=
--test_runner_fail_fast
--notest_runner_fail_fast
--test_sharding_strategy={explicit,disabled}
--test_size_filters=
--test_strategy=
--test_summary={short,terse,detailed,none,testcase}
--test_tag_filters=
--test_timeout=
--test_timeout_filters=
--test_tmpdir=path
--test_verbose_timeout_warnings
--notest_verbose_timeout_warnings
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--toolchain_resolution_debug
--notoolchain_resolution_debug
--track_incremental_state
--notrack_incremental_state
--translations={auto,yes,no}
--notranslations
--trim_test_configuration
--notrim_test_configuration
--tvos_cpus=
--tvos_minimum_os=
--tvos_sdk_version=
--tvos_simulator_device=
--tvos_simulator_version=
--ui_actions_shown=
--ui_event_filters=
--use_ijars
--nouse_ijars
--use_singlejar_apkbuilder
--nouse_singlejar_apkbuilder
--verbose_explanations
--noverbose_explanations
--verbose_failures
--noverbose_failures
--verbose_test_summary
--noverbose_test_summary
--watchfs
--nowatchfs
--watchos_cpus=
--watchos_minimum_os=
--watchos_sdk_version=
--watchos_simulator_device=
--watchos_simulator_version=
--worker_extra_flag=
--worker_max_instances=
--worker_quit_after_build
--noworker_quit_after_build
--worker_sandboxing
--noworker_sandboxing
--worker_verbose
--noworker_verbose
--workspace_status_command=path
--xbinary_fdo=label
--xcode_version=
--xcode_version_config=label
"
BAZEL_COMMAND_VERSION_FLAGS="
--all_incompatible_changes
--announce_rc
--noannounce_rc
--attempt_to_print_relative_paths
--noattempt_to_print_relative_paths
--bes_backend=
--bes_best_effort
--nobes_best_effort
--bes_keywords=
--bes_lifecycle_events
--nobes_lifecycle_events
--bes_outerr_buffer_size=
--bes_outerr_chunk_size=
--bes_proxy=
--bes_results_url=
--bes_timeout=
--build_event_binary_file=
--build_event_binary_file_path_conversion
--nobuild_event_binary_file_path_conversion
--build_event_json_file=
--build_event_json_file_path_conversion
--nobuild_event_json_file_path_conversion
--build_event_max_named_set_of_file_entries=
--build_event_publish_all_actions
--nobuild_event_publish_all_actions
--build_event_text_file=
--build_event_text_file_path_conversion
--nobuild_event_text_file_path_conversion
--build_metadata=
--color={yes,no,auto}
--config=
--curses={yes,no,auto}
--distdir=
--enable_platform_specific_config
--noenable_platform_specific_config
--experimental_allow_tags_propagation
--noexperimental_allow_tags_propagation
--experimental_announce_profile_path
--noexperimental_announce_profile_path
--experimental_build_event_expand_filesets
--noexperimental_build_event_expand_filesets
--experimental_build_event_fully_resolve_fileset_symlinks
--noexperimental_build_event_fully_resolve_fileset_symlinks
--experimental_build_event_upload_strategy=
--experimental_cc_shared_library
--noexperimental_cc_shared_library
--experimental_disable_external_package
--noexperimental_disable_external_package
--experimental_enable_android_migration_apis
--noexperimental_enable_android_migration_apis
--experimental_generate_json_trace_profile
--noexperimental_generate_json_trace_profile
--experimental_google_legacy_api
--noexperimental_google_legacy_api
--experimental_multi_threaded_digest
--noexperimental_multi_threaded_digest
--experimental_ninja_actions
--noexperimental_ninja_actions
--experimental_oom_more_eagerly_threshold=
--experimental_platforms_api
--noexperimental_platforms_api
--experimental_profile_additional_tasks=
--experimental_profile_cpu_usage
--noexperimental_profile_cpu_usage
--experimental_profile_include_primary_output
--noexperimental_profile_include_primary_output
--experimental_profile_include_target_label
--noexperimental_profile_include_target_label
--experimental_repo_remote_exec
--noexperimental_repo_remote_exec
--experimental_repository_cache_hardlinks
--noexperimental_repository_cache_hardlinks
--experimental_repository_hash_file=
--experimental_resolved_file_instead_of_workspace=
--experimental_scale_timeouts=
--experimental_sibling_repository_layout
--noexperimental_sibling_repository_layout
--experimental_starlark_config_transitions
--noexperimental_starlark_config_transitions
--experimental_stream_log_file_uploads
--noexperimental_stream_log_file_uploads
--experimental_ui_max_stdouterr_bytes=
--experimental_ui_mode={oldest_actions,mnemonic_histogram}
--experimental_verify_repository_rules=
--experimental_windows_watchfs
--noexperimental_windows_watchfs
--experimental_workspace_rules_log_file=path
--gnu_format
--nognu_format
--google_auth_scopes=
--google_credentials=
--google_default_credentials
--nogoogle_default_credentials
--grpc_keepalive_time=
--grpc_keepalive_timeout=
--http_timeout_scaling=
--incompatible_always_check_depset_elements
--noincompatible_always_check_depset_elements
--incompatible_depset_for_libraries_to_link_getter
--noincompatible_depset_for_libraries_to_link_getter
--incompatible_disable_depset_items
--noincompatible_disable_depset_items
--incompatible_disable_target_provider_fields
--noincompatible_disable_target_provider_fields
--incompatible_disable_third_party_license_checking
--noincompatible_disable_third_party_license_checking
--incompatible_disallow_empty_glob
--noincompatible_disallow_empty_glob
--incompatible_disallow_legacy_javainfo
--noincompatible_disallow_legacy_javainfo
--incompatible_disallow_struct_provider_syntax
--noincompatible_disallow_struct_provider_syntax
--incompatible_do_not_split_linking_cmdline
--noincompatible_do_not_split_linking_cmdline
--incompatible_java_common_parameters
--noincompatible_java_common_parameters
--incompatible_linkopts_to_linklibs
--noincompatible_linkopts_to_linklibs
--incompatible_new_actions_api
--noincompatible_new_actions_api
--incompatible_no_attr_license
--noincompatible_no_attr_license
--incompatible_no_implicit_file_export
--noincompatible_no_implicit_file_export
--incompatible_no_rule_outputs_param
--noincompatible_no_rule_outputs_param
--incompatible_objc_provider_remove_compile_info
--noincompatible_objc_provider_remove_compile_info
--incompatible_require_linker_input_cc_api
--noincompatible_require_linker_input_cc_api
--incompatible_restrict_string_escapes
--noincompatible_restrict_string_escapes
--incompatible_run_shell_command_string
--noincompatible_run_shell_command_string
--incompatible_string_replace_count
--noincompatible_string_replace_count
--incompatible_use_cc_configure_from_rules_cc
--noincompatible_use_cc_configure_from_rules_cc
--incompatible_visibility_private_attributes_at_definition
--noincompatible_visibility_private_attributes_at_definition
--json_trace_compression={auto,yes,no}
--nojson_trace_compression
--keep_state_after_build
--nokeep_state_after_build
--legacy_important_outputs
--nolegacy_important_outputs
--logging=
--max_computation_steps=
--memory_profile_stable_heap_parameters=
--nested_set_depth_limit=
--override_repository=
--profile=path
--progress_in_terminal_title
--noprogress_in_terminal_title
--project_id=
--repository_cache=path
--show_progress
--noshow_progress
--show_progress_rate_limit=
--show_task_finish
--noshow_task_finish
--show_timestamps
--noshow_timestamps
--slim_profile
--noslim_profile
--starlark_cpu_profile=
--tls_certificate=
--tls_client_certificate=
--tls_client_key=
--tool_tag=
--track_incremental_state
--notrack_incremental_state
#!/usr/bin/env bash
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

setup() {

  RELTMP="${BATS_TEST_DIRNAME}/../../../target/test-dir/bats.$$.${RANDOM}"
  mkdir -p ${RELTMP}
  TMP=$(cd -P -- "${RELTMP}" >/dev/null && pwd -P)
  export TMP
  TESTBINDIR=$(cd -P -- "$(pwd)" >/dev/null && pwd -P)
  HADOOP_LIBEXEC_DIR=${TESTBINDIR}/../../main/bin
  HADOOP_LIBEXEC_DIR=$(cd -P -- "${HADOOP_LIBEXEC_DIR}" >/dev/null && pwd -P)

  # shellcheck disable=SC2034
  HADOOP_SHELL_SCRIPT_DEBUG=true
  unset HADOOP_CONF_DIR
  # we unset both of these for bw compat
  unset HADOOP_HOME
  unset HADOOP_PREFIX

  echo "bindir: ${TESTBINDIR}" 2>&1

  mkdir -p "${TMP}"

  # shellcheck disable=SC2034
  QATESTMODE=true

  . "${BATS_TEST_DIRNAME}/../../main/bin/hadoop-functions.sh"
  pushd "${TMP}" >/dev/null
}

teardown() {
  popd >/dev/null
  rm -rf "${TMP}"
}


strstr() {
  if [ "${1#*$2}" != "${1}" ]; then
    echo true
  else
    echo false
#!/usr/bin/env bash
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

setup() {

  TMP="${BATS_TEST_DIRNAME}/../../../target/test-dir/bats.$$.${RANDOM}"
  mkdir -p "${TMP}"
  TMP=$(cd -P -- "${TMP}" >/dev/null && pwd -P)
  export TMP
  TESTBINDIR="${BATS_TEST_DIRNAME}"
  HADOOP_LIBEXEC_DIR=${TESTBINDIR}/../../main/bin
  HADOOP_LIBEXEC_DIR=$(cd -P -- "${HADOOP_LIBEXEC_DIR}" >/dev/null && pwd -P)

  # shellcheck disable=SC2034
  HADOOP_SHELL_SCRIPT_DEBUG=true
  unset HADOOP_CONF_DIR
  # we unset both of these for bw compat
  unset HADOOP_HOME
  unset HADOOP_PREFIX

  echo "bindir: ${TESTBINDIR}" 2>&1

  mkdir -p "${TMP}"

  # shellcheck disable=SC2034
  QATESTMODE=true

  # shellcheck disable=SC1090
  . "${BATS_TEST_DIRNAME}/../../../../../hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh"
  pushd "${TMP}" >/dev/null
}

teardown() {
  popd >/dev/null
  rm -rf "${TMP}"
}


strstr() {
  if [ "${1#*$2}" != "${1}" ]; then
    echo true
  else
#!/usr/bin/env bash
#

# A library to simplify using the SBT launcher from other packages.
# Note: This should be used by tools like giter8/conscript etc.

# TODO - Should we merge the main SBT script with this library?

if test -z "$HOME"; then
  declare -r script_dir="$(dirname "$script_path")"
else
  declare -r script_dir="$HOME/.sbt"
fi

declare -a residual_args
declare -a java_args
declare -a scalac_args
declare -a sbt_commands
declare -a maven_profiles
declare sbt_default_mem=2048

if test -x "$JAVA_HOME/bin/java"; then
    echo -e "Using $JAVA_HOME as default JAVA_HOME."
    echo "Note, this will be overridden by -java-home if it is set."
    declare java_cmd="$JAVA_HOME/bin/java"
else
    declare java_cmd=java
fi

echoerr () {
  echo 1>&2 "$@"
}
vlog () {
  [[ $verbose || $debug ]] && echoerr "$@"
}
dlog () {
  [[ $debug ]] && echoerr "$@"
}

acquire_sbt_jar () {
  SBT_VERSION=`awk -F "=" '/sbt\.version/ {print $2}' ./project/build.properties`
  # DEFAULT_ARTIFACT_REPOSITORY env variable can be used to only fetch
  # artifacts from internal repos only.
  # Ex:
  #   DEFAULT_ARTIFACT_REPOSITORY=https://artifacts.internal.com/libs-release/
  URL1=${DEFAULT_ARTIFACT_REPOSITORY:-https://repo1.maven.org/maven2/}org/scala-sbt/sbt-launch/${SBT_VERSION}/sbt-launch-${SBT_VERSION}.jar
  JAR=build/sbt-launch-${SBT_VERSION}.jar

  sbt_jar=$JAR

  if [[ ! -f "$sbt_jar" ]]; then
    # Download sbt launch jar if it hasn't been downloaded yet
    if [ ! -f "${JAR}" ]; then
    # Download
    printf "Attempting to fetch sbt\n"
    JAR_DL="${JAR}.part"
    if [ $(command -v curl) ]; then
      curl --fail --location --silent ${URL1} > "${JAR_DL}" &&\
        mv "${JAR_DL}" "${JAR}"
    elif [ $(command -v wget) ]; then
      wget --quiet ${URL1} -O "${JAR_DL}" &&\
        mv "${JAR_DL}" "${JAR}"
    else
      printf "You do not have curl or wget installed, please install sbt manually from https://www.scala-sbt.org/\n"
      exit -1
    fi
    fi
    if [ ! -f "${JAR}" ]; then
    # We failed to download
    printf "Our attempt to download sbt locally to ${JAR} failed. Please install sbt manually from https://www.scala-sbt.org/\n"
    exit -1
    fi
    printf "Launching sbt from ${JAR}\n"
  fi
}

execRunner () {
  # print the arguments one to a line, quoting any containing spaces
  [[ $verbose || $debug ]] && echo "# Executing command line:" && {
    for arg; do
      if printf "%s\n" "$arg" | grep -q ' '; then
        printf "\"%s\"\n" "$arg"
      else
        printf "%s\n" "$arg"
      fi
    done
    echo ""
  }

  "$@"
}

addJava () {
  dlog "[addJava] arg = '$1'"
  java_args=( "${java_args[@]}" "$1" )
}

enableProfile () {
  dlog "[enableProfile] arg = '$1'"
  maven_profiles=( "${maven_profiles[@]}" "$1" )
  export SBT_MAVEN_PROFILES="${maven_profiles[@]}"
}

addSbt () {
  dlog "[addSbt] arg = '$1'"
  sbt_commands=( "${sbt_commands[@]}" "$1" )
}
addResidual () {
  dlog "[residual] arg = '$1'"
  residual_args=( "${residual_args[@]}" "$1" )
}
addDebugger () {
  addJava "-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=$1"
}

# a ham-fisted attempt to move some memory settings in concert
# so they need not be dicked around with individually.
get_mem_opts () {
  local mem=${1:-$sbt_default_mem}
  local codecache=$(( $mem / 8 ))
  (( $codecache > 128 )) || codecache=128
  (( $codecache < 2048 )) || codecache=2048

  echo "-Xms${mem}m -Xmx${mem}m -XX:ReservedCodeCacheSize=${codecache}m"
}

require_arg () {
  local type="$1"
  local opt="$2"
  local arg="$3"
  if [[ -z "$arg" ]] || [[ "${arg:0:1}" == "-" ]]; then
    echo "$opt requires <$type> argument" 1>&2
    exit 1
  fi
}

is_function_defined() {
  declare -f "$1" > /dev/null
}

process_args () {
  while [[ $# -gt 0 ]]; do
    case "$1" in
       -h|-help) usage; exit 1 ;;
    -v|-verbose) verbose=1 && shift ;;
      -d|-debug) debug=1 && shift ;;

           -ivy) require_arg path "$1" "$2" && addJava "-Dsbt.ivy.home=$2" && shift 2 ;;
           -mem) require_arg integer "$1" "$2" && sbt_mem="$2" && shift 2 ;;
     -jvm-debug) require_arg port "$1" "$2" && addDebugger $2 && shift 2 ;;
         -batch) exec </dev/null && shift ;;

       -sbt-jar) require_arg path "$1" "$2" && sbt_jar="$2" && shift 2 ;;
   -sbt-version) require_arg version "$1" "$2" && sbt_version="$2" && shift 2 ;;
     -java-home) require_arg path "$1" "$2" && java_cmd="$2/bin/java" && export JAVA_HOME=$2 && shift 2 ;;

            -D*) addJava "$1" && shift ;;
            -J*) addJava "${1:2}" && shift ;;
            -P*) enableProfile "$1" && shift ;;
              *) addResidual "$1" && shift ;;
    esac
  done

  is_function_defined process_my_args && {
    myargs=("${residual_args[@]}")
    residual_args=()
    process_my_args "${myargs[@]}"
  }
}

run() {
  # no jar? download it.
  [[ -f "$sbt_jar" ]] || acquire_sbt_jar "$sbt_version" || {
    # still no jar? uh-oh.
    echo "Download failed. Obtain the sbt-launch.jar manually and place it at $sbt_jar"
    exit 1
  }

  # process the combined args, then reset "$@" to the residuals
  process_args "$@"
  set -- "${residual_args[@]}"
  argumentCount=$#

  # run sbt
  execRunner "$java_cmd" \
    ${SBT_OPTS:-$default_sbt_opts} \
    $(get_mem_opts $sbt_mem) \
    ${java_opts} \
    ${java_args[@]} \
    -jar "$sbt_jar" \
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
# shellcheck disable=SC1091
source "/opt/bats/lib/bats-support/load.bash"
# shellcheck disable=SC1091
source "/opt/bats/lib/bats-assert/load.bash"
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
# shellcheck disable=SC1091
source "/opt/bats/lib/bats-support/load.bash"
# shellcheck disable=SC1091
source "/opt/bats/lib/bats-assert/load.bash"
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

AIRFLOW_SOURCES=$(pwd)
export AIRFLOW_SOURCES
readonly AIRFLOW_SOURCES

export DOCKER_BINARY_PATH=${AIRFLOW_SOURCES}/tests/bats/mock/docker.sh
export KUBECTL_BINARY_PATH=${AIRFLOW_SOURCES}/tests/bats/mock/kubectl.sh
export KIND_BINARY_PATH=${AIRFLOW_SOURCES}/tests/bats/mock/kind.sh
export HELM_BINARY_PATH=${AIRFLOW_SOURCES}/tests/bats/mock/helm.sh
export SKIP_IN_CONTAINER_CHECK="true"

# shellcheck source=scripts/ci/libraries/_all_libs.sh
source "scripts/ci/libraries/_all_libs.sh"

_exa()
{
    cur=${COMP_WORDS[COMP_CWORD]}
    prev=${COMP_WORDS[COMP_CWORD-1]}

    case "$prev" in
        -'?'|--help|-v|--version)
            return
            ;;

        -L|--level)
            COMPREPLY=( $( compgen -W '{0..9}' -- "$cur" ) )
            return
            ;;

        -s|--sort)
            COMPREPLY=( $( compgen -W 'name filename Name Filename size filesize extension Extension date time modified changed accessed created type inode oldest newest age none --' -- "$cur" ) )
            return
            ;;

        -t|--time)
            COMPREPLY=( $( compgen -W 'modified changed accessed created --' -- $cur ) )
            return
            ;;

        --time-style)
            COMPREPLY=( $( compgen -W 'default iso long-iso full-iso --' -- $cur ) )
            return
            ;;
    esac

    case "$cur" in
        -*)
            COMPREPLY=( $( compgen -W '$( _parse_help "$1" )' -- "$cur" ) )
            ;;

        *)
            _filedir
            ;;
    esac
#!/bin/bash

# start an "rclone serve" server

PIDFILE=/tmp/${NAME}.pid
DATADIR=/tmp/${NAME}-data

stop() {
    if status ; then
        pid=$(cat "$PIDFILE")
        kill "$pid"
        rm "$PIDFILE"
        echo "$NAME stopped"
    fi
}

status() {
    if [ -e "$PIDFILE" ]; then
        pid=$(cat "$PIDFILE")
        if kill -0 "$pid" >/dev/null 2>&1; then
            # echo "$NAME running"
            return 0
        else
            rm "$PIDFILE"
        fi
    fi
    # echo "$NAME not running"
    return 1
}

run() {
    if ! status ; then
        mkdir -p "$DATADIR"
        nohup "$@" >> "/tmp/${NAME}.log" 2>&1 </dev/null &
        pid=$!
        echo $pid > "$PIDFILE"
        disown "$pid"
    fi
}

#!/bin/bash

stop() {
    if status ; then
        docker stop "$NAME"
        echo "$NAME stopped"
    fi
}

status() {
    if docker ps --format '{{.Names}}' | grep -q "^${NAME}$" ; then
        echo "$NAME running"
    else
        echo "$NAME not running"
        return 1
    fi
    return 0
}

docker_ip() {
#!/bin/bash

case "$1" in 
    start)
	start
	;;
    stop)
	stop
	;;
    status)
	status
	;;
    *)
	echo "usage: $0 start|stop|status" >&2
	exit 1
#     ____      ____
#    / __/___  / __/
#   / /_/_  / / /_
#  / __/ / /_/ __/
# /_/   /___/_/ key-bindings.bash
#
# - $FZF_TMUX_OPTS
# - $FZF_CTRL_T_COMMAND
# - $FZF_CTRL_T_OPTS
# - $FZF_CTRL_R_OPTS
# - $FZF_ALT_C_COMMAND
# - $FZF_ALT_C_OPTS

# Key bindings
# ------------
__fzf_select__() {
  local cmd="${FZF_CTRL_T_COMMAND:-"command find -L . -mindepth 1 \\( -path '*/\\.*' -o -fstype 'sysfs' -o -fstype 'devfs' -o -fstype 'devtmpfs' -o -fstype 'proc' \\) -prune \
    -o -type f -print \
    -o -type d -print \
    -o -type l -print 2> /dev/null | cut -b3-"}"
  eval "$cmd" | FZF_DEFAULT_OPTS="--height ${FZF_TMUX_HEIGHT:-40%} --reverse --bind=ctrl-z:ignore $FZF_DEFAULT_OPTS $FZF_CTRL_T_OPTS" $(__fzfcmd) -m "$@" | while read -r item; do
    printf '%q ' "$item"
  done
  echo
}

if [[ $- =~ i ]]; then

__fzfcmd() {
  [ -n "$TMUX_PANE" ] && { [ "${FZF_TMUX:-0}" != 0 ] || [ -n "$FZF_TMUX_OPTS" ]; } &&
    echo "fzf-tmux ${FZF_TMUX_OPTS:--d${FZF_TMUX_HEIGHT:-40%}} -- " || echo "fzf"
}

fzf-file-widget() {
  local selected="$(__fzf_select__)"
  READLINE_LINE="${READLINE_LINE:0:$READLINE_POINT}$selected${READLINE_LINE:$READLINE_POINT}"
  READLINE_POINT=$(( READLINE_POINT + ${#selected} ))
}

__fzf_cd__() {
  local cmd dir
  cmd="${FZF_ALT_C_COMMAND:-"command find -L . -mindepth 1 \\( -path '*/\\.*' -o -fstype 'sysfs' -o -fstype 'devfs' -o -fstype 'devtmpfs' -o -fstype 'proc' \\) -prune \
    -o -type d -print 2> /dev/null | cut -b3-"}"
  dir=$(eval "$cmd" | FZF_DEFAULT_OPTS="--height ${FZF_TMUX_HEIGHT:-40%} --reverse --bind=ctrl-z:ignore $FZF_DEFAULT_OPTS $FZF_ALT_C_OPTS" $(__fzfcmd) +m) && printf 'cd %q' "$dir"
}

__fzf_history__() {
  local output
  output=$(
    builtin fc -lnr -2147483648 |
      last_hist=$(HISTTIMEFORMAT='' builtin history 1) perl -n -l0 -e 'BEGIN { getc; $/ = "\n\t"; $HISTCMD = $ENV{last_hist} + 1 } s/^[ *]//; print $HISTCMD - $. . "\t$_" if !$seen{$_}++' |
      FZF_DEFAULT_OPTS="--height ${FZF_TMUX_HEIGHT:-40%} $FZF_DEFAULT_OPTS -n2..,.. --tiebreak=index --bind=ctrl-r:toggle-sort,ctrl-z:ignore $FZF_CTRL_R_OPTS +m --read0" $(__fzfcmd) --query "$READLINE_LINE"
  ) || return
  READLINE_LINE=${output#*$'\t'}
  if [ -z "$READLINE_POINT" ]; then
    echo "$READLINE_LINE"
  else
    READLINE_POINT=0x7fffffff
  fi
}

# Required to refresh the prompt after fzf
bind -m emacs-standard '"\er": redraw-current-line'

bind -m vi-command '"\C-z": emacs-editing-mode'
bind -m vi-insert '"\C-z": emacs-editing-mode'
bind -m emacs-standard '"\C-z": vi-editing-mode'

if [ "${BASH_VERSINFO[0]}" -lt 4 ]; then
  # CTRL-T - Paste the selected file path into the command line
  bind -m emacs-standard '"\C-t": " \C-b\C-k \C-u`__fzf_select__`\e\C-e\er\C-a\C-y\C-h\C-e\e \C-y\ey\C-x\C-x\C-f"'
  bind -m vi-command '"\C-t": "\C-z\C-t\C-z"'
  bind -m vi-insert '"\C-t": "\C-z\C-t\C-z"'

  # CTRL-R - Paste the selected command from history into the command line
  bind -m emacs-standard '"\C-r": "\C-e \C-u\C-y\ey\C-u"$(__fzf_history__)"\e\C-e\er"'
  bind -m vi-command '"\C-r": "\C-z\C-r\C-z"'
  bind -m vi-insert '"\C-r": "\C-z\C-r\C-z"'
else
  # CTRL-T - Paste the selected file path into the command line
  bind -m emacs-standard -x '"\C-t": fzf-file-widget'
  bind -m vi-command -x '"\C-t": fzf-file-widget'
  bind -m vi-insert -x '"\C-t": fzf-file-widget'

  # CTRL-R - Paste the selected command from history into the command line
  bind -m emacs-standard -x '"\C-r": __fzf_history__'
  bind -m vi-command -x '"\C-r": __fzf_history__'
  bind -m vi-insert -x '"\C-r": __fzf_history__'
fi

# ALT-C - cd into the selected directory
bind -m emacs-standard '"\ec": " \C-b\C-k \C-u`__fzf_cd__`\e\C-e\er\C-m\C-y\C-h\e \C-y\ey\C-x\C-x\C-d"'
bind -m vi-command '"\ec": "\C-z\ec\C-z"'
bind -m vi-insert '"\ec": "\C-z\ec\C-z"'

#     ____      ____
#    / __/___  / __/
#   / /_/_  / / /_
#  / __/ / /_/ __/
# /_/   /___/_/ completion.bash
#
# - $FZF_TMUX               (default: 0)
# - $FZF_TMUX_OPTS          (default: empty)
# - $FZF_COMPLETION_TRIGGER (default: '**')
# - $FZF_COMPLETION_OPTS    (default: empty)

if [[ $- =~ i ]]; then

# To use custom commands instead of find, override _fzf_compgen_{path,dir}
if ! declare -f _fzf_compgen_path > /dev/null; then
  _fzf_compgen_path() {
    echo "$1"
    command find -L "$1" \
      -name .git -prune -o -name .hg -prune -o -name .svn -prune -o \( -type d -o -type f -o -type l \) \
      -a -not -path "$1" -print 2> /dev/null | sed 's@^\./@@'
  }
fi

if ! declare -f _fzf_compgen_dir > /dev/null; then
  _fzf_compgen_dir() {
    command find -L "$1" \
      -name .git -prune -o -name .hg -prune -o -name .svn -prune -o -type d \
      -a -not -path "$1" -print 2> /dev/null | sed 's@^\./@@'
  }
fi

###########################################################

# To redraw line after fzf closes (printf '\e[5n')
bind '"\e[0n": redraw-current-line'

__fzf_comprun() {
  if [ "$(type -t _fzf_comprun 2>&1)" = function ]; then
    _fzf_comprun "$@"
  elif [ -n "$TMUX_PANE" ] && { [ "${FZF_TMUX:-0}" != 0 ] || [ -n "$FZF_TMUX_OPTS" ]; }; then
    shift
    fzf-tmux ${FZF_TMUX_OPTS:--d${FZF_TMUX_HEIGHT:-40%}} -- "$@"
  else
    shift
    fzf "$@"
  fi
}

__fzf_orig_completion() {
  local l comp f cmd
  while read -r l; do
    if [[ "$l" =~ ^(.*\ -F)\ *([^ ]*).*\ ([^ ]*)$ ]]; then
      comp="${BASH_REMATCH[1]}"
      f="${BASH_REMATCH[2]}"
      cmd="${BASH_REMATCH[3]}"
      [[ "$f" = _fzf_* ]] && continue
      printf -v "_fzf_orig_completion_${cmd//[^A-Za-z0-9_]/_}" "%s" "${comp} %s ${cmd} #${f}"
      if [[ "$l" = *" -o nospace "* ]] && [[ ! "$__fzf_nospace_commands" = *" $cmd "* ]]; then
        __fzf_nospace_commands="$__fzf_nospace_commands $cmd "
      fi
    fi
  done
}

_fzf_opts_completion() {
  local cur prev opts
  COMPREPLY=()
  cur="${COMP_WORDS[COMP_CWORD]}"
  prev="${COMP_WORDS[COMP_CWORD-1]}"
  opts="
    -x --extended
    -e --exact
    --algo
    -i +i
    -n --nth
    --with-nth
    -d --delimiter
    +s --no-sort
    --tac
    --tiebreak
    -m --multi
    --no-mouse
    --bind
    --cycle
    --no-hscroll
    --jump-labels
    --height
    --literal
    --reverse
    --margin
    --inline-info
    --prompt
    --pointer
    --marker
    --header
    --header-lines
    --ansi
    --tabstop
    --color
    --no-bold
    --history
    --history-size
    --preview
    --preview-window
    -q --query
    -1 --select-1
    -0 --exit-0
    -f --filter
    --print-query
    --expect
    --sync"

  case "${prev}" in
  --tiebreak)
    COMPREPLY=( $(compgen -W "length begin end index" -- "$cur") )
    return 0
    ;;
  --color)
    COMPREPLY=( $(compgen -W "dark light 16 bw" -- "$cur") )
    return 0
    ;;
  --history)
    COMPREPLY=()
    return 0
    ;;
  esac

  if [[ "$cur" =~ ^-|\+ ]]; then
    COMPREPLY=( $(compgen -W "${opts}" -- "$cur") )
    return 0
  fi

  return 0
}

_fzf_handle_dynamic_completion() {
  local cmd orig_var orig ret orig_cmd orig_complete
  cmd="$1"
  shift
  orig_cmd="$1"
  orig_var="_fzf_orig_completion_$cmd"
  orig="${!orig_var##*#}"
  if [ -n "$orig" ] && type "$orig" > /dev/null 2>&1; then
    $orig "$@"
  elif [ -n "$_fzf_completion_loader" ]; then
    orig_complete=$(complete -p "$orig_cmd" 2> /dev/null)
    _completion_loader "$@"
    ret=$?
    # _completion_loader may not have updated completion for the command
    if [ "$(complete -p "$orig_cmd" 2> /dev/null)" != "$orig_complete" ]; then
      __fzf_orig_completion < <(complete -p "$orig_cmd" 2> /dev/null)
      if [[ "$__fzf_nospace_commands" = *" $orig_cmd "* ]]; then
        eval "${orig_complete/ -F / -o nospace -F }"
      else
        eval "$orig_complete"
      fi
    fi
    return $ret
  fi
}

__fzf_generic_path_completion() {
  local cur base dir leftover matches trigger cmd
  cmd="${COMP_WORDS[0]//[^A-Za-z0-9_=]/_}"
  COMPREPLY=()
  trigger=${FZF_COMPLETION_TRIGGER-'**'}
  cur="${COMP_WORDS[COMP_CWORD]}"
  if [[ "$cur" == *"$trigger" ]]; then
    base=${cur:0:${#cur}-${#trigger}}
    eval "base=$base"

    [[ $base = *"/"* ]] && dir="$base"
    while true; do
      if [ -z "$dir" ] || [ -d "$dir" ]; then
        leftover=${base/#"$dir"}
        leftover=${leftover/#\/}
        [ -z "$dir" ] && dir='.'
        [ "$dir" != "/" ] && dir="${dir/%\//}"
        matches=$(eval "$1 $(printf %q "$dir")" | FZF_DEFAULT_OPTS="--height ${FZF_TMUX_HEIGHT:-40%} --reverse --bind=ctrl-z:ignore $FZF_DEFAULT_OPTS $FZF_COMPLETION_OPTS $2" __fzf_comprun "$4" -q "$leftover" | while read -r item; do
          printf "%q$3 " "$item"
        done)
        matches=${matches% }
        [[ -z "$3" ]] && [[ "$__fzf_nospace_commands" = *" ${COMP_WORDS[0]} "* ]] && matches="$matches "
        if [ -n "$matches" ]; then
          COMPREPLY=( "$matches" )
        else
          COMPREPLY=( "$cur" )
        fi
        printf '\e[5n'
        return 0
      fi
      dir=$(dirname "$dir")
      [[ "$dir" =~ /$ ]] || dir="$dir"/
    done
  else
    shift
    shift
    shift
    _fzf_handle_dynamic_completion "$cmd" "$@"
  fi
}

_fzf_complete() {
  # Split arguments around --
  local args rest str_arg i sep
  args=("$@")
  sep=
  for i in "${!args[@]}"; do
    if [[ "${args[$i]}" = -- ]]; then
      sep=$i
      break
    fi
  done
  if [[ -n "$sep" ]]; then
    str_arg=
    rest=("${args[@]:$((sep + 1)):${#args[@]}}")
    args=("${args[@]:0:$sep}")
  else
    str_arg=$1
    args=()
    shift
    rest=("$@")
  fi

  local cur selected trigger cmd post
  post="$(caller 0 | awk '{print $2}')_post"
  type -t "$post" > /dev/null 2>&1 || post=cat

  cmd="${COMP_WORDS[0]//[^A-Za-z0-9_=]/_}"
  trigger=${FZF_COMPLETION_TRIGGER-'**'}
  cur="${COMP_WORDS[COMP_CWORD]}"
  if [[ "$cur" == *"$trigger" ]]; then
    cur=${cur:0:${#cur}-${#trigger}}

    selected=$(FZF_DEFAULT_OPTS="--height ${FZF_TMUX_HEIGHT:-40%} --reverse --bind=ctrl-z:ignore $FZF_DEFAULT_OPTS $FZF_COMPLETION_OPTS $str_arg" __fzf_comprun "${rest[0]}" "${args[@]}" -q "$cur" | $post | tr '\n' ' ')
    selected=${selected% } # Strip trailing space not to repeat "-o nospace"
    if [ -n "$selected" ]; then
      COMPREPLY=("$selected")
    else
      COMPREPLY=("$cur")
    fi
    printf '\e[5n'
    return 0
  else
    _fzf_handle_dynamic_completion "$cmd" "${rest[@]}"
  fi
}

_fzf_path_completion() {
  __fzf_generic_path_completion _fzf_compgen_path "-m" "" "$@"
}

# Deprecated. No file only completion.
_fzf_file_completion() {
  _fzf_path_completion "$@"
}

_fzf_dir_completion() {
  __fzf_generic_path_completion _fzf_compgen_dir "" "/" "$@"
}

_fzf_complete_kill() {
  local trigger=${FZF_COMPLETION_TRIGGER-'**'}
  local cur="${COMP_WORDS[COMP_CWORD]}"
  if [[ -z "$cur" ]]; then
    COMP_WORDS[$COMP_CWORD]=$trigger
  elif [[ "$cur" != *"$trigger" ]]; then
    return 1
  fi

  _fzf_proc_completion "$@"
}

_fzf_proc_completion() {
  _fzf_complete -m --preview 'echo {}' --preview-window down:3:wrap --min-height 15 -- "$@" < <(
    command ps -ef | sed 1d
  )
}

_fzf_proc_completion_post() {
  awk '{print $2}'
}

_fzf_host_completion() {
  _fzf_complete +m -- "$@" < <(
    command cat <(command tail -n +1 ~/.ssh/config ~/.ssh/config.d/* /etc/ssh/ssh_config 2> /dev/null | command grep -i '^\s*host\(name\)\? ' | awk '{for (i = 2; i <= NF; i++) print $1 " " $i}' | command grep -v '[*?]') \
        <(command grep -oE '^[[a-z0-9.,:-]+' ~/.ssh/known_hosts | tr ',' '\n' | tr -d '[' | awk '{ print $1 " " $1 }') \
        <(command grep -v '^\s*\(#\|$\)' /etc/hosts | command grep -Fv '0.0.0.0') |
        awk '{if (length($2) > 0) {print $2}}' | sort -u
  )
}

_fzf_var_completion() {
  _fzf_complete -m -- "$@" < <(
    declare -xp | sed 's/=.*//' | sed 's/.* //'
  )
}

_fzf_alias_completion() {
  _fzf_complete -m -- "$@" < <(
    alias | sed 's/=.*//' | sed 's/.* //'
  )
}

# fzf options
complete -o default -F _fzf_opts_completion fzf

d_cmds="${FZF_COMPLETION_DIR_COMMANDS:-cd pushd rmdir}"
a_cmds="
  awk cat diff diff3
  emacs emacsclient ex file ftp g++ gcc gvim head hg java
  javac ld less more mvim nvim patch perl python ruby
  sed sftp sort source tail tee uniq vi view vim wc xdg-open
  basename bunzip2 bzip2 chmod chown curl cp dirname du
  find git grep gunzip gzip hg jar
  ln ls mv open rm rsync scp
  svn tar unzip zip"

# Preserve existing completion
__fzf_orig_completion < <(complete -p $d_cmds $a_cmds 2> /dev/null)

if type _completion_loader > /dev/null 2>&1; then
  _fzf_completion_loader=1
fi

__fzf_defc() {
  local cmd func opts orig_var orig def
  cmd="$1"
  func="$2"
  opts="$3"
  orig_var="_fzf_orig_completion_${cmd//[^A-Za-z0-9_]/_}"
  orig="${!orig_var}"
  if [ -n "$orig" ]; then
    printf -v def "$orig" "$func"
    eval "$def"
  else
    complete -F "$func" $opts "$cmd"
  fi
}

# Anything
for cmd in $a_cmds; do
  __fzf_defc "$cmd" _fzf_path_completion "-o default -o bashdefault"
done

# Directory
for cmd in $d_cmds; do
  __fzf_defc "$cmd" _fzf_dir_completion "-o nospace -o dirnames"
done

# Kill completion (supports empty completion trigger)
complete -F _fzf_complete_kill -o default -o bashdefault kill

unset cmd d_cmds a_cmds

_fzf_setup_completion() {
  local kind fn cmd
  kind=$1
  fn=_fzf_${1}_completion
  if [[ $# -lt 2 ]] || ! type -t "$fn" > /dev/null; then
    echo "usage: ${FUNCNAME[0]} path|dir|var|alias|host|proc COMMANDS..."
    return 1
  fi
  shift
  __fzf_orig_completion < <(complete -p "$@" 2> /dev/null)
  for cmd in "$@"; do
    case "$kind" in
      dir)   __fzf_defc "$cmd" "$fn" "-o nospace -o dirnames" ;;
      var)   __fzf_defc "$cmd" "$fn" "-o default -o nospace -v" ;;
      alias) __fzf_defc "$cmd" "$fn" "-a" ;;
      *)     __fzf_defc "$cmd" "$fn" "-o default -o bashdefault" ;;
    esac
  done
}

# Environment variables / Aliases / Hosts
_fzf_setup_completion 'var'   export unset
_fzf_setup_completion 'alias' unalias
_fzf_setup_completion 'host'  ssh telnet

#!/usr/bin/env bash

set -ex

if [ "$TRAVIS_OS_NAME" != linux ]; then
    exit 0
fi

sudo apt-get update

# needed to build deb packages
sudo apt-get install -y fakeroot

# needed for i686 linux gnu target
if [[ $TARGET == i686-unknown-linux-gnu ]]; then
    sudo apt-get install -y gcc-multilib
fi

# needed for cross-compiling for arm
if [[ $TARGET == arm-unknown-linux-* ]]; then
    sudo apt-get install -y \
        gcc-4.8-arm-linux-gnueabihf \
        binutils-arm-linux-gnueabihf \
        libc6-armhf-cross \
        libc6-dev-armhf-cross
#!/usr/bin/env bash

set -ex

# Incorporate TARGET env var to the build and test process
cargo build --target "$TARGET" --verbose

# We cannot run arm executables on linux
if [[ $TARGET != arm-unknown-linux-* ]]; then
    cargo test --target "$TARGET" --verbose
#!/usr/bin/env bash
# Building and packaging for release

set -ex

build() {
    cargo build --target "$TARGET" --release --verbose
}

pack() {
    local tempdir
    local out_dir
    local package_name
    local gcc_prefix

    tempdir=$(mktemp -d 2>/dev/null || mktemp -d -t tmp)
    out_dir=$(pwd)
    package_name="$PROJECT_NAME-$TRAVIS_TAG-$TARGET"

    if [[ $TARGET == arm-unknown-linux-* ]]; then
        gcc_prefix="arm-linux-gnueabihf-"
    else
        gcc_prefix=""
    fi

    # create a "staging" directory
    mkdir "$tempdir/$package_name"
    mkdir "$tempdir/$package_name/autocomplete"

    # copying the main binary
    cp "target/$TARGET/release/$PROJECT_NAME" "$tempdir/$package_name/"
    "${gcc_prefix}"strip "$tempdir/$package_name/$PROJECT_NAME"

    # manpage, readme and license
    cp "doc/$PROJECT_NAME.1" "$tempdir/$package_name"
    cp README.md "$tempdir/$package_name"
    cp LICENSE-MIT "$tempdir/$package_name"
    cp LICENSE-APACHE "$tempdir/$package_name"

    # various autocomplete
    cp target/"$TARGET"/release/build/"$PROJECT_NAME"-*/out/"$PROJECT_NAME".bash "$tempdir/$package_name/autocomplete/${PROJECT_NAME}.bash-completion"
    cp target/"$TARGET"/release/build/"$PROJECT_NAME"-*/out/"$PROJECT_NAME".fish "$tempdir/$package_name/autocomplete"
    cp contrib/completion/_"$PROJECT_NAME" "$tempdir/$package_name/autocomplete"

    # archiving
    pushd "$tempdir"
    tar czf "$out_dir/$package_name.tar.gz" "$package_name"/*
    popd
    rm -r "$tempdir"
}

make_deb() {
    local tempdir
    local architecture
    local version
    local dpkgname
    local conflictname
    local homepage
    local maintainer
    local gcc_prefix

    homepage="https://github.com/sharkdp/fd"
    maintainer="David Peter <mail@david-peter.de>"

    case $TARGET in
        x86_64*)
            architecture=amd64
            gcc_prefix=""
            ;;
        i686*)
            architecture=i386
            gcc_prefix=""
            ;;
        arm*hf)
            architecture=armhf
            gcc_prefix="arm-linux-gnueabihf-"
            ;;
        *)
            echo "make_deb: skipping target '${TARGET}'" >&2
            return 0
            ;;
    esac
    version=${TRAVIS_TAG#v}
    if [[ $TARGET = *musl* ]]; then
      dpkgname=$PROJECT_NAME-musl
      conflictname=$PROJECT_NAME
    else
      dpkgname=$PROJECT_NAME
      conflictname=$PROJECT_NAME-musl
    fi

    tempdir=$(mktemp -d 2>/dev/null || mktemp -d -t tmp)

    # copy the main binary
    install -Dm755 "target/$TARGET/release/$PROJECT_NAME" "$tempdir/usr/bin/$PROJECT_NAME"
    "${gcc_prefix}"strip "$tempdir/usr/bin/$PROJECT_NAME"

    # manpage
    install -Dm644 "doc/$PROJECT_NAME.1" "$tempdir/usr/share/man/man1/$PROJECT_NAME.1"
    gzip --best "$tempdir/usr/share/man/man1/$PROJECT_NAME.1"

    # readme and license
    install -Dm644 README.md "$tempdir/usr/share/doc/$PROJECT_NAME/README.md"
    install -Dm644 LICENSE-MIT "$tempdir/usr/share/doc/$PROJECT_NAME/LICENSE-MIT"
    install -Dm644 LICENSE-APACHE "$tempdir/usr/share/doc/$PROJECT_NAME/LICENSE-APACHE"
    cat > "$tempdir/usr/share/doc/$PROJECT_NAME/copyright" <<EOF
Format: http://www.debian.org/doc/packaging-manuals/copyright-format/1.0/
Upstream-Name: $PROJECT_NAME
Source: $homepage

Files: *
Copyright: $maintainer
License: Apache-2.0 or MIT

License: Apache-2.0
 On Debian systems, the complete text of the Apache-2.0 can be found in the
 file /usr/share/common-licenses/Apache-2.0.

License: MIT
 Permission is hereby granted, free of charge, to any
 person obtaining a copy of this software and associated
 documentation files (the "Software"), to deal in the
 Software without restriction, including without
 limitation the rights to use, copy, modify, merge,
 publish, distribute, sublicense, and/or sell copies of
 the Software, and to permit persons to whom the Software
 is furnished to do so, subject to the following
 conditions:
 .
 The above copyright notice and this permission notice
 shall be included in all copies or substantial portions
 of the Software.
 .
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF
 ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED
 TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
 PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT
 SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR
 IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 DEALINGS IN THE SOFTWARE.
EOF

    # completions
    install -Dm644 target/$TARGET/release/build/$PROJECT_NAME-*/out/$PROJECT_NAME.bash "$tempdir/usr/share/bash-completion/completions/${PROJECT_NAME}"
    install -Dm644 target/$TARGET/release/build/$PROJECT_NAME-*/out/$PROJECT_NAME.fish "$tempdir/usr/share/fish/completions/$PROJECT_NAME.fish"
    install -Dm644 contrib/completion/_"$PROJECT_NAME" "$tempdir/usr/share/zsh/vendor-completions/_$PROJECT_NAME"

    # Control file
    mkdir "$tempdir/DEBIAN"
    cat > "$tempdir/DEBIAN/control" <<EOF
Package: $dpkgname
Version: $version
Section: utils
Priority: optional
Maintainer: $maintainer
Architecture: $architecture
Provides: $PROJECT_NAME
Conflicts: $conflictname
Homepage: $homepage
Description: Simple, fast and user-friendly alternative to find
 While fd does not seek to mirror all of find's powerful functionality, it
 provides sensible (opinionated) defaults for 80% of the use cases.
EOF

    fakeroot dpkg-deb --build "$tempdir" "${dpkgname}_${version}_${architecture}.deb"
}


main() {
    build
    pack
    if [[ $TARGET = *linux* ]]; then
      make_deb
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/usr/bin/env bash

GOOSARCH="${GOOS}_${GOARCH}"
case "$GOOSARCH" in
_* | *_ | _)
	echo 'undefined $GOOS_$GOARCH:' "$GOOSARCH" 1>&2
	exit 1
	;;
esac

GODEFS="go tool cgo -godefs"

$GODEFS types.go |gofmt > ztypes_$GOARCH.go

case $GOOS in
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#/usr/bin/env bash

# Load completion function
complete -F _alacritty alacritty

# Completion function
_alacritty()
{
    local cur prev prevprev opts
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    prevprev="${COMP_WORDS[COMP_CWORD-2]}"
    opts="-h --help -V --version --print-events -q -qq -v -vv -vvv --ref-test --hold -e --command --config-file -o --option -t --title --embed --class --working-directory"

    # If `--command` or `-e` is used, stop completing
    for i in "${!COMP_WORDS[@]}"; do
        if [[ "${COMP_WORDS[i]}" == "--command" ]] \
            || [[ "${COMP_WORDS[i]}" == "-e" ]] \
            && [[ "${#COMP_WORDS[@]}" -gt "$(($i + 2))" ]]
        then
            return 0
        fi
    done

    # Match the previous word
    case "${prev}" in
        --command | -e)
            # Complete all commands in $PATH
            COMPREPLY=( $(compgen -c -- "${cur}") )
            return 0;;
        --config-file)
            # Path based completion
            local IFS=$'\n'
            compopt -o filenames
            COMPREPLY=( $(compgen -f -- "${cur}") )
            return 0;;
        --class | --title | -t)
            # Don't complete here
            return 0;;
        --working-directory)
            # Directory completion
            local IFS=$'\n'
            compopt -o filenames
            COMPREPLY=( $(compgen -d -- "${cur}") )
            return 0;;
    esac

    # Show all flags if there was no previous word
    COMPREPLY=( $(compgen -W "${opts}" -- "${cur}") )
#/usr/bin/env bash

_vcpkg_completions()
{
  local vcpkg_executable=${COMP_WORDS[0]}
  local remaining_command_line=${COMP_LINE:(${#vcpkg_executable}+1)}
  COMPREPLY=($(${vcpkg_executable} autocomplete "${remaining_command_line}" -- 2>/dev/null))

  # Colon is treated as a delimiter in bash. The following workaround
  # allows triplet completion to work correctly in the syntax:
  # zlib:x64-windows
  local cur
  _get_comp_words_by_ref -n : cur
  __ltrim_colon_completions "$cur"
}
#!/usr/bin/env bash

# This script updates each non-stdlib, non-Go-kit dependency to its most recent
# commit. It can be invoked to aid in debugging after a dependency-related
# failure on continuous integration.

function deps {
	go list -deps -f '{{if and .DepOnly (not .Standard)}}{{.ImportPath}}{{end}}' ./...
}

function unique_repos {
	cut -d '/' -f-3 | sort | uniq
}

function not_gokit {
	grep -v 'go-kit/kit'
}

function go_get_update {
	while read d
	do
		echo $d
		go get -u $d/... || echo "failed, trying again with master" && cd $GOPATH/src/$d && git checkout master && go get -u $d
	done
}
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/usr/bin/env bash

GOOSARCH="${GOOS}_${GOARCH}"
case "$GOOSARCH" in
_* | *_ | _)
	echo 'undefined $GOOS_$GOARCH:' "$GOOSARCH" 1>&2
	exit 1
	;;
esac

GODEFS="go tool cgo -godefs"

$GODEFS types.go |gofmt > ztypes_$GOARCH.go

case $GOOS in

diff_so_fancy="$BATS_TEST_DIRNAME/../diff-so-fancy"

load_fixture() {
  local name="$1"
  cat "$BATS_TEST_DIRNAME/fixtures/${name}.diff"
}

set_env() {
  export LC_CTYPE="en_US.UTF-8"
}


# applying colors so ANSI color values will match
# FIXME: not everyone will have these set, so we need to test for that.
git config color.diff.meta "227"
git config color.diff.frag "magenta bold"
git config color.diff.commit "227 bold"
git config color.diff.old "red bold"
git config color.diff.new "green bold"
git config color.diff.whitespace "red reverse"

git config color.diff-highlight.oldNormal "red bold"
git config color.diff-highlight.oldHighlight "red bold 52"
git config color.diff-highlight.newNormal "green bold"
#!/usr/bin/env bats

load "Utilities/git-commit"

extract-test-frameworks-one-and-two() {
	unzip ${BATS_TEST_DIRNAME:?}/../Tests/CarthageKitTests/fixtures/DependencyTest.zip 'DependencyTest/SourceRepos/TestFramework[12]/*' -d "${BATS_TMPDIR:?}"
}

branch-test-frameworks-one-and-two() {
	directory_to_return_into="${PWD:?}"
	branch="${1:?}" # parameter 1: branch name used in git repositories for both `TestFramework`s.

	# - - - - - - -

	cd ${extracted_directory:?}/SourceRepos/TestFramework2
	git checkout -b ${branch} master

	rm -v Cartfile Cartfile.resolved
	git-commit 'Remove dependencies.'

	# - - - - - - -

	cd ${extracted_directory:?}/SourceRepos/TestFramework1
	git checkout -b ${branch} master

	# overwrite Cartfile
	cat >| Cartfile <<-EOF
		git "file://${extracted_directory:?}/SourceRepos/TestFramework2" "${branch}"
	EOF

	rm -v Cartfile.resolved
	git-commit 'Set Cartfile based on file URLs and branch.'

	# - - - - - - -

# load with: . ipython-completion.bash

if [[ -n ${ZSH_VERSION-} ]]; then
    autoload -Uz bashcompinit && bashcompinit
fi

_ipython_get_flags()
{
    local url=$1
    local var=$2
    local dash=$3
    if [[ "$url $var" == $__ipython_complete_last ]]; then
        opts=$__ipython_complete_last_res
        return
    fi
    # matplotlib and profile don't need the = and the
    # version without simplifies the special cased completion
    opts=$(ipython ${url} --help-all | grep -E "^-{1,2}[^-]" | sed -e "s/<.*//" -e "s/[^=]$/& /" -e "s/^--matplotlib=$//" -e "s/^--profile=$/--profile /"  -e "$ s/^/\n-h\n--help\n--help-all\n/")
    __ipython_complete_last="$url $var"
    __ipython_complete_last_res="$opts"
}

_ipython()
{
    local cur=${COMP_WORDS[COMP_CWORD]}
    local prev=${COMP_WORDS[COMP_CWORD - 1]}
    local subcommands="kernel profile locate history"
    local opts="help"
    if [ -z "$__ipython_complete_baseopts" ]; then
        _ipython_get_flags baseopts
        __ipython_complete_baseopts="${opts}"
    fi
    local baseopts="$__ipython_complete_baseopts"
    local mode=""
    for i in "${COMP_WORDS[@]}"; do
        [ "$cur" = "$i" ] && break
        if [[ ${subcommands} == *${i}* ]]; then
            mode="$i"
            break
        elif [[ ${i} == "--"* ]]; then
            mode="nosubcommand"
            break
        fi
    done


    if [[ ${cur} == -* ]]; then
        case $mode in
             "kernel")
                _ipython_get_flags $mode
                opts=$"${opts} ${baseopts}"
                ;;
            "locate" | "profile")
                _ipython_get_flags $mode
                ;;
            "history")
                if [[ $COMP_CWORD -ge 3 ]]; then
                    # 'history trim' and 'history clear' covered by next line
                    _ipython_get_flags $mode\ "${COMP_WORDS[2]}"
                else
                    _ipython_get_flags $mode

                fi
                opts=$"${opts}"
                ;;
            *)
                opts=$baseopts
        esac
        # don't drop the trailing space
        local IFS=$'\t\n'
        COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
        return 0
    elif [[ $mode == "profile" ]]; then
        opts="list 	create 	locate "
        local IFS=$'\t\n'
        COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
    elif [[ $mode == "history" ]]; then
        if [[ $COMP_CWORD -ge 3 ]]; then
            # drop into flags
            opts="--"
        else
            opts="trim 	clear "
        fi
        local IFS=$'\t\n'
        COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
    elif [[ $mode == "locate" ]]; then
        if [[ $COMP_CWORD -ge 3 ]]; then
            # drop into flags
            opts="--"
        else
            opts="profile "
        fi
        local IFS=$'\t\n'
        COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
    elif [[ ${prev} == "--matplotlib"* ]] || [[ ${prev} == "--gui"* ]]; then
        if [ -z "$__ipython_complete_matplotlib" ]; then
            __ipython_complete_matplotlib=`cat <<EOF | python -
try:
    import IPython.core.shellapp as mod;
    for k in mod.InteractiveShellApp.matplotlib.values:
        print "%s " % k
except:
    pass
EOF
        `
        fi
        local IFS=$'\t\n'
        COMPREPLY=( $(compgen -W "${__ipython_complete_matplotlib}" -- ${cur}) )
    elif [[ ${prev} == "--profile"* ]]; then
        if [ -z  "$__ipython_complete_profiles" ]; then
        __ipython_complete_profiles=`cat <<EOF | python -
try:
    import IPython.core.profileapp
    for k in IPython.core.profileapp.list_bundled_profiles():
        print "%s " % k
    p = IPython.core.profileapp.ProfileList()
    for k in IPython.core.profileapp.list_profiles_in(p.ipython_dir):
        print "%s " % k
except:
    pass
EOF
        `
        fi
        local IFS=$'\t\n'
        COMPREPLY=( $(compgen -W "${__ipython_complete_profiles}" -- ${cur}) )
    else
        if [ "$COMP_CWORD" == 1 ]; then
            local IFS=$'\t\n'
            local sub=$(echo $subcommands | sed -e "s/ / \t/g")
            COMPREPLY=( $(compgen -W "${sub}" -- ${cur}) )
        else
            COMPREPLY=( $(compgen -f -- ${cur}) )
        fi
    fi

#!/bin/bash
# Copyright 2012 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# This script rebuilds the time zone files using files
# downloaded from the ICANN/IANA distribution.
# Consult https://www.iana.org/time-zones for the latest versions.

# Versions to use.
CODE=2021a
DATA=2021a

set -e
rm -rf work
mkdir work
cd work
mkdir zoneinfo
curl -L -O https://www.iana.org/time-zones/repository/releases/tzcode$CODE.tar.gz
curl -L -O https://www.iana.org/time-zones/repository/releases/tzdata$DATA.tar.gz
tar xzf tzcode$CODE.tar.gz
tar xzf tzdata$DATA.tar.gz

make CFLAGS=-DSTD_INSPIRED AWK=awk TZDIR=zoneinfo posix_only

cd zoneinfo
rm -f ../../zoneinfo.zip
zip -0 -r ../../zoneinfo.zip *
cd ../..

go generate time/tzdata

echo
if [ "$1" = "-work" ]; then
	echo Left workspace behind in work/.
#!/usr/bin/env bash
# Copyright 2016 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# This directory is intended to test the use of Fortran with cgo.

set -e

FC=$1

goos=$(go env GOOS)

libext="so"
if [ "$goos" = "darwin" ]; then
	libext="dylib"
elif [ "$goos" = "aix" ]; then
	libtext="a"
fi

case "$FC" in
*gfortran*)
  libpath=$(dirname $($FC -print-file-name=libgfortran.$libext))
  if [ "$goos" != "aix" ]; then
	  RPATH_FLAG="-Wl,-rpath,$libpath"
  fi
  export CGO_LDFLAGS="$CGO_LDFLAGS $RPATH_FLAG -L $libpath"
  ;;
esac

if ! $FC helloworld/helloworld.f90 -o /dev/null >& /dev/null; then
  echo "skipping Fortran test: could not build helloworld.f90 with $FC"
  exit 0
fi
rm -f main.exe

status=0

if ! go test; then
  echo "FAIL: go test"
#!/usr/bin/env bash
# Copyright 2016 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# mkcanned.bash creates canned traces for the trace test suite using
# the current Go version.

set -e

if [ $# != 1 ]; then
    echo "usage: $0 <label>" >&2
    exit 1
fi

#!/usr/bin/env bash

# Copyright 2016 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# A simple script to compare differences between
# assembly listings for packages built with different
# compiler flags. It is useful to inspect the impact
# of a compiler change across all std lib packages.
#
# The script builds the std library (make.bash) once
# with FLAGS1 and once with FLAGS2 and compares the
# "go build <pkg>" assembly output for each package
# and lists the packages with differences.
#
# It leaves and old.txt and new.txt file in the package
# directories for the packages with differences.

FLAGS1="-newexport=0"
FLAGS2="-newexport=1"

echo
echo
echo "1a) clean build using $FLAGS1"
(export GO_GCFLAGS="$FLAGS1"; sh make.bash)

echo
echo
echo "1b) save go build output for all packages"
for pkg in `go list std`; do
	echo $pkg
	DIR=$GOROOT/src/$pkg
	go build -gcflags "$FLAGS1 -S" -o /dev/null $pkg &> $DIR/old.txt
done

echo
echo
echo "2a) clean build using $FLAGS2"
(export GO_GCFLAGS="$FLAGS2"; sh make.bash)

echo
echo
echo "2b) save go build output for all packages"
for pkg in `go list std`; do
	echo $pkg
	DIR=$GOROOT/src/$pkg
	go build -gcflags "$FLAGS2 -S" -o /dev/null $pkg &> $DIR/new.txt
done

echo
echo
echo "3) compare assembly files"
for pkg in `go list std`; do
	DIR=$GOROOT/src/$pkg

	if cmp $DIR/old.txt $DIR/new.txt &> /dev/null
	then rm $DIR/old.txt $DIR/new.txt
	else echo "==> $DIR"
	fi
#!/usr/bin/env bash
# Copyright 2015 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# When run as (for example)
#
#	GOOS=linux GOARCH=ppc64 bootstrap.bash
#
# this script cross-compiles a toolchain for that GOOS/GOARCH
# combination, leaving the resulting tree in ../../go-${GOOS}-${GOARCH}-bootstrap.
# That tree can be copied to a machine of the given target type
# and used as $GOROOT_BOOTSTRAP to bootstrap a local build.
#
# Only changes that have been committed to Git (at least locally,
# not necessary reviewed and submitted to master) are included in the tree.
#
# As a special case for Go's internal use only, if the
# BOOTSTRAP_FORMAT environment variable is set to "mintgz", the
# resulting archive is intended for use by the Go build system and
# differs in that the mintgz file:
#   * is a tar.gz file instead of bz2
#   * has many unnecessary files deleted to reduce its size
#   * does not have a shared directory component for each tar entry
# Do not depend on the mintgz format.

set -e

if [ "$GOOS" = "" -o "$GOARCH" = "" ]; then
	echo "usage: GOOS=os GOARCH=arch ./bootstrap.bash" >&2
	exit 2
fi

targ="../../go-${GOOS}-${GOARCH}-bootstrap"
if [ -e $targ ]; then
	echo "$targ already exists; remove before continuing"
	exit 2
fi

if [ "$BOOTSTRAP_FORMAT" != "mintgz" -a "$BOOTSTRAP_FORMAT" != "" ]; then
	echo "unknown BOOTSTRAP_FORMAT format"
	exit 2
fi

unset GOROOT
src=$(cd .. && pwd)
echo "#### Copying to $targ"
cp -Rp "$src" "$targ"
cd "$targ"
echo
echo "#### Cleaning $targ"
chmod -R +w .
rm -f .gitignore
if [ -e .git ]; then
	git clean -f -d
fi
echo
echo "#### Building $targ"
echo
cd src
./make.bash --no-banner
gohostos="$(../bin/go env GOHOSTOS)"
gohostarch="$(../bin/go env GOHOSTARCH)"
goos="$(../bin/go env GOOS)"
goarch="$(../bin/go env GOARCH)"

# NOTE: Cannot invoke go command after this point.
# We're about to delete all but the cross-compiled binaries.
cd ..
if [ "$goos" = "$gohostos" -a "$goarch" = "$gohostarch" ]; then
	# cross-compile for local system. nothing to copy.
	# useful if you've bootstrapped yourself but want to
	# prepare a clean toolchain for others.
	true
else
	rm -f bin/go_${goos}_${goarch}_exec
	mv bin/*_*/* bin
	rmdir bin/*_*
	rm -rf "pkg/${gohostos}_${gohostarch}" "pkg/tool/${gohostos}_${gohostarch}"
fi

if [ "$BOOTSTRAP_FORMAT" = "mintgz" ]; then
	# Fetch git revision before rm -rf .git.
	GITREV=$(git rev-parse --short HEAD)
fi

rm -rf pkg/bootstrap pkg/obj .git

# Support for building minimal tar.gz for the builders.
# The build system doesn't support bzip2, and by deleting more stuff,
# they start faster, especially on machines without fast filesystems
# and things like tmpfs configures.
# Do not depend on this format. It's for internal use only.
if [ "$BOOTSTRAP_FORMAT" = "mintgz" ]; then
	OUTGZ="gobootstrap-${GOOS}-${GOARCH}-${GITREV}.tar.gz"
	echo "Preparing to generate build system's ${OUTGZ}; cleaning ..."
	rm -rf bin/gofmt
	rm -rf src/runtime/race/race_*.syso
	rm -rf api test doc misc/cgo/test misc/trace
	rm -rf pkg/tool/*_*/{addr2line,api,cgo,cover,doc,fix,nm,objdump,pack,pprof,test2json,trace,vet}
	rm -rf pkg/*_*/{image,database,cmd}
	rm -rf $(find . -type d -name testdata)
	find . -type f -name '*_test.go' -exec rm {} \;
	# git clean doesn't clean symlinks apparently, and the buildlet
	# rejects them, so:
	find . -type l -exec rm {} \;

	echo "Writing ${OUTGZ} ..."
	tar cf - . | gzip -9 > ../$OUTGZ
	cd ..
	ls -l "$(pwd)/$OUTGZ"
	exit 0
fi

echo ----
echo Bootstrap toolchain for "$GOOS/$GOARCH" installed in "$(pwd)".
echo Building tbz.
cd ..
tar cf - "go-${GOOS}-${GOARCH}-bootstrap" | bzip2 -9 >"go-${GOOS}-${GOARCH}-bootstrap.tbz"
ls -l "$(pwd)/go-${GOOS}-${GOARCH}-bootstrap.tbz"
#!/usr/bin/env bash
# Copyright 2009 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e

if [ ! -f run.bash ]; then
	echo 'clean.bash must be run from $GOROOT/src' 1>&2
	exit 1
fi
export GOROOT="$(cd .. && pwd)"

gobin="${GOROOT}"/bin
if ! "$gobin"/go help >/dev/null 2>&1; then
	echo 'cannot find go command; nothing to clean' >&2
	exit 1
fi

"$gobin/go" clean -i std
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/usr/bin/env bash 
# Copyright 2020 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# A quick and dirty way to obtain code coverage from rulegen's main func. For
# example:
#
#     ./cover.bash && go tool cover -html=cover.out
#
# This script is needed to set up a temporary test file, so that we don't break
# regular 'go run *.go' usage to run the generator.

cat >main_test.go <<-EOF
	// +build ignore

	package main

	import "testing"

	func TestCoverage(t *testing.T) { main() }
EOF

go test -run='^TestCoverage$' -coverprofile=cover.out "$@" *.go

#!/usr/bin/env bash
# Copyright 2009 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
if [ ! -f make.bash ]; then
	echo 'all.bash must be run from $GOROOT/src' 1>&2
	exit 1
fi
#!/usr/bin/env bash
# Copyright 2013 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# race.bash tests the standard library under the race detector.
# https://golang.org/doc/articles/race_detector.html

set -e

function usage {
	echo 'race detector is only supported on linux/amd64, linux/ppc64le, linux/arm64, freebsd/amd64, netbsd/amd64, openbsd/amd64, darwin/amd64, and darwin/arm64' 1>&2
	exit 1
}

case $(uname) in
"Darwin")
	if [ $(uname -m) != "x86_64" ] && [ $(uname -m) != "arm64" ]; then
		usage
	fi
	;;
"Linux")
	if [ $(uname -m) != "x86_64" ] && [ $(uname -m) != "ppc64le" ] && [ $(uname -m) != "aarch64" ]; then
		usage
	fi
	;;
"FreeBSD")
	if [ $(uname -m) != "amd64" ]; then
		usage
	fi
	;;
"NetBSD")
	if [ $(uname -m) != "amd64" ]; then
		usage
	fi
	;;
"OpenBSD")
	if [ $(uname -m) != "amd64" ]; then
		usage
	fi
	;;
*)
	usage
	;;
esac

if [ ! -f make.bash ]; then
	echo 'race.bash must be run from $GOROOT/src' 1>&2
	exit 1
fi
#!/usr/bin/env bash
# Copyright 2009 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# Environment variables that control run.bash:
#
# GO_TEST_SHARDS: number of "dist test" test shards that the
# $GOROOT/test directory will be sliced up into for parallel
# execution. Defaults to 1, unless GO_BUILDER_NAME is also specified,
# in which case it defaults to 10.
#
# GO_BUILDER_NAME: the name of the Go builder that's running the tests.
# Some tests are conditionally enabled or disabled based on the builder
# name or the builder name being non-empty.

set -e

if [ ! -f ../bin/go ]; then
	echo 'run.bash must be run from $GOROOT/src after installing cmd/go' 1>&2
	exit 1
fi

eval $(../bin/go env)
export GOROOT   # The api test requires GOROOT to be set, so set it to match ../bin/go.
export GOPATH=/nonexist-gopath

unset CDPATH	# in case user has it set
export GOBIN=$GOROOT/bin  # Issue 14340
unset GOFLAGS
unset GO111MODULE

export GOHOSTOS
export CC

# no core files, please
ulimit -c 0

# Raise soft limits to hard limits for NetBSD/OpenBSD.
# We need at least 256 files and ~300 MB of bss.
# On OS X ulimit -S -n rejects 'unlimited'.
#
# Note that ulimit -S -n may fail if ulimit -H -n is set higher than a
# non-root process is allowed to set the high limit.
# This is a system misconfiguration and should be fixed on the
# broken system, not "fixed" by ignoring the failure here.
# See longer discussion on golang.org/issue/7381.
[ "$(ulimit -H -n)" = "unlimited" ] || ulimit -S -n $(ulimit -H -n)
[ "$(ulimit -H -d)" = "unlimited" ] || ulimit -S -d $(ulimit -H -d)

# Thread count limit on NetBSD 7.
if ulimit -T &> /dev/null; then
	[ "$(ulimit -H -T)" = "unlimited" ] || ulimit -S -T $(ulimit -H -T)
fi

#!/usr/bin/env bash
# Copyright 2009 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# See golang.org/s/go15bootstrap for an overview of the build process.

# Environment variables that control make.bash:
#
# GOROOT_FINAL: The expected final Go root, baked into binaries.
# The default is the location of the Go tree during the build.
#
# GOHOSTARCH: The architecture for host tools (compilers and
# binaries).  Binaries of this type must be executable on the current
# system, so the only common reason to set this is to set
# GOHOSTARCH=386 on an amd64 machine.
#
# GOARCH: The target architecture for installed packages and tools.
#
# GOOS: The target operating system for installed packages and tools.
#
# GO_GCFLAGS: Additional go tool compile arguments to use when
# building the packages and commands.
#
# GO_LDFLAGS: Additional go tool link arguments to use when
# building the commands.
#
# CGO_ENABLED: Controls cgo usage during the build. Set it to 1
# to include all cgo related files, .c and .go file with "cgo"
# build directive, in the build. Set it to 0 to ignore them.
#
# GO_EXTLINK_ENABLED: Set to 1 to invoke the host linker when building
# packages that use cgo.  Set to 0 to do all linking internally.  This
# controls the default behavior of the linker's -linkmode option.  The
# default value depends on the system.
#
# GO_LDSO: Sets the default dynamic linker/loader (ld.so) to be used
# by the internal linker.
#
# CC: Command line to run to compile C code for GOHOSTARCH.
# Default is "gcc". Also supported: "clang".
#
# CC_FOR_TARGET: Command line to run to compile C code for GOARCH.
# This is used by cgo.  Default is CC.
#
# CXX_FOR_TARGET: Command line to run to compile C++ code for GOARCH.
# This is used by cgo. Default is CXX, or, if that is not set,
# "g++" or "clang++".
#
# FC: Command line to run to compile Fortran code for GOARCH.
# This is used by cgo. Default is "gfortran".
#
# PKG_CONFIG: Path to pkg-config tool. Default is "pkg-config".
#
# GO_DISTFLAGS: extra flags to provide to "dist bootstrap".
# (Or just pass them to the make.bash command line.)
#
# GOBUILDTIMELOGFILE: If set, make.bash and all.bash write
# timing information to this file. Useful for profiling where the
# time goes when these scripts run.
#
# GOROOT_BOOTSTRAP: A working Go tree >= Go 1.4 for bootstrap.
# If $GOROOT_BOOTSTRAP/bin/go is missing, $(go env GOROOT) is
# tried for all "go" in $PATH. $HOME/go1.4 by default.

set -e

export GOENV=off
unset GOBIN # Issue 14340
unset GOFLAGS
unset GO111MODULE

if [ ! -f run.bash ]; then
	echo 'make.bash must be run from $GOROOT/src' 1>&2
	exit 1
fi

if [ "$GOBUILDTIMELOGFILE" != "" ]; then
	echo $(LC_TIME=C date) start make.bash >"$GOBUILDTIMELOGFILE"
fi

# Test for Windows.
case "$(uname)" in
*MINGW* | *WIN32* | *CYGWIN*)
	echo 'ERROR: Do not use make.bash to build on Windows.'
	echo 'Use make.bat instead.'
	echo
	exit 1
	;;
esac

# Test for bad ld.
if ld --version 2>&1 | grep 'gold.* 2\.20' >/dev/null; then
	echo 'ERROR: Your system has gold 2.20 installed.'
	echo 'This version is shipped by Ubuntu even though'
	echo 'it is known not to work on Ubuntu.'
	echo 'Binaries built with this linker are likely to fail in mysterious ways.'
	echo
	echo 'Run sudo apt-get remove binutils-gold.'
	echo
	exit 1
fi

# Test for bad SELinux.
# On Fedora 16 the selinux filesystem is mounted at /sys/fs/selinux,
# so loop through the possible selinux mount points.
for se_mount in /selinux /sys/fs/selinux
do
	if [ -d $se_mount -a -f $se_mount/booleans/allow_execstack -a -x /usr/sbin/selinuxenabled ] && /usr/sbin/selinuxenabled; then
		if ! cat $se_mount/booleans/allow_execstack | grep -c '^1 1$' >> /dev/null ; then
			echo "WARNING: the default SELinux policy on, at least, Fedora 12 breaks "
			echo "Go. You can enable the features that Go needs via the following "
			echo "command (as root):"
			echo "  # setsebool -P allow_execstack 1"
			echo
			echo "Note that this affects your system globally! "
			echo
			echo "The build will continue in five seconds in case we "
			echo "misdiagnosed the issue..."

			sleep 5
		fi
	fi
done

# Test for debian/kFreeBSD.
# cmd/dist will detect kFreeBSD as freebsd/$GOARCH, but we need to
# disable cgo manually.
if [ "$(uname -s)" = "GNU/kFreeBSD" ]; then
	export CGO_ENABLED=0
fi

# On Alpine Linux, use the musl dynamic linker/loader
if [ -f "/etc/alpine-release" ]; then
	if type readelf >/dev/null 2>&1; then
		echo "int main() { return 0; }" | ${CC:-gcc} -o ./test-alpine-ldso -x c -
		export GO_LDSO=$(readelf -l ./test-alpine-ldso | grep 'interpreter:' | sed -e 's/^.*interpreter: \(.*\)[]]/\1/')
		rm -f ./test-alpine-ldso
	fi
fi

# Clean old generated file that will cause problems in the build.
rm -f ./runtime/runtime_defs.go

# Finally!  Run the build.

verbose=false
vflag=""
if [ "$1" = "-v" ]; then
	verbose=true
	vflag=-v
	shift
fi

export GOROOT_BOOTSTRAP=${GOROOT_BOOTSTRAP:-$HOME/go1.4}
export GOROOT="$(cd .. && pwd)"
IFS=$'\n'; for go_exe in $(type -ap go); do
	if [ ! -x "$GOROOT_BOOTSTRAP/bin/go" ]; then
		goroot=$(GOROOT='' GOOS='' GOARCH='' "$go_exe" env GOROOT)
		if [ "$goroot" != "$GOROOT" ]; then
			GOROOT_BOOTSTRAP=$goroot
		fi
	fi
done; unset IFS
if [ ! -x "$GOROOT_BOOTSTRAP/bin/go" ]; then
	echo "ERROR: Cannot find $GOROOT_BOOTSTRAP/bin/go." >&2
	echo "Set \$GOROOT_BOOTSTRAP to a working Go tree >= Go 1.4." >&2
	exit 1
fi
# Get the exact bootstrap toolchain version to help with debugging.
# We clear GOOS and GOARCH to avoid an ominous but harmless warning if
# the bootstrap doesn't support them.
GOROOT_BOOTSTRAP_VERSION=$(GOOS= GOARCH= $GOROOT_BOOTSTRAP/bin/go version | sed 's/go version //')
echo "Building Go cmd/dist using $GOROOT_BOOTSTRAP. ($GOROOT_BOOTSTRAP_VERSION)"
if $verbose; then
	echo cmd/dist
fi
if [ "$GOROOT_BOOTSTRAP" = "$GOROOT" ]; then
	echo "ERROR: \$GOROOT_BOOTSTRAP must not be set to \$GOROOT" >&2
	echo "Set \$GOROOT_BOOTSTRAP to a working Go tree >= Go 1.4." >&2
	exit 1
fi
rm -f cmd/dist/dist
GOROOT="$GOROOT_BOOTSTRAP" GOOS="" GOARCH="" GO111MODULE=off "$GOROOT_BOOTSTRAP/bin/go" build -o cmd/dist/dist ./cmd/dist

# -e doesn't propagate out of eval, so check success by hand.
eval $(./cmd/dist/dist env -p || echo FAIL=true)
if [ "$FAIL" = true ]; then
	exit 1
fi

if $verbose; then
	echo
fi

if [ "$1" = "--dist-tool" ]; then
	# Stop after building dist tool.
	mkdir -p "$GOTOOLDIR"
	if [ "$2" != "" ]; then
		cp cmd/dist/dist "$2"
	fi
	mv cmd/dist/dist "$GOTOOLDIR"/dist
	exit 0
fi

buildall="-a"
if [ "$1" = "--no-clean" ]; then
	buildall=""
	shift
fi

# Run dist bootstrap to complete make.bash.
# Bootstrap installs a proper cmd/dist, built with the new toolchain.
# Throw ours, built with Go 1.4, away after bootstrap.
./cmd/dist/dist bootstrap $buildall $vflag $GO_DISTFLAGS "$@"
rm -f ./cmd/dist/dist

# DO NOT ADD ANY NEW CODE HERE.
# The bootstrap+rm above are the final step of make.bash.
# If something must be added, add it to cmd/dist's cmdbootstrap,
#!/usr/bin/env bash
# Copyright 2015 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# Usage: buildall.bash [-e] [pattern]
#
# buildall.bash builds the standard library for all Go-supported
# architectures. It is used by the "misc-compile" trybot builders,
# as a smoke test to quickly flag portability issues.
#
# Options:
#   -e: stop at first failure

if [ ! -f run.bash ]; then
	echo 'buildall.bash must be run from $GOROOT/src' 1>&2
	exit 1
fi

sete=false
if [ "$1" = "-e" ]; then
	sete=true
	shift
fi

if [ "$sete" = true ]; then
	set -e
fi

pattern="$1"
if [ "$pattern" = "" ]; then
	pattern=.
fi

./make.bash || exit 1
GOROOT="$(cd .. && pwd)"

gettargets() {
	../bin/go tool dist list | sed -e 's|/|-|'
	echo linux-arm-arm5
}

selectedtargets() {
	gettargets | egrep "$pattern"
}

# put linux first in the target list to get all the architectures up front.
linux_targets() {
	selectedtargets | grep 'linux' | sort
}

non_linux_targets() {
	selectedtargets | grep -v 'linux' | sort
}

# Note words in $targets are separated by both newlines and spaces.
targets="$(linux_targets) $(non_linux_targets)"

failed=false
for target in $targets
do
	echo ""
	echo "### Building $target"
	export GOOS=$(echo $target | sed 's/-.*//')
	export GOARCH=$(echo $target | sed 's/.*-//')
	unset GOARM
	if [ "$GOARCH" = "arm5" ]; then
		export GOARCH=arm
		export GOARM=5
	fi

	# Build and vet everything.
	# cmd/go/internal/work/exec.go enables the same vet flags during go test of std cmd
	# and should be kept in sync with any vet flag changes here.
	if ! "$GOROOT/bin/go" build std cmd || ! "$GOROOT/bin/go" vet -unsafeptr=false std cmd; then
		failed=true
		if $sete; then
			exit 1
		fi
	fi
done

if [ "$failed" = "true" ]; then
	echo "" 1>&2
	echo "Build(s) failed." 1>&2
#!/usr/bin/env bash
# Copyright 2017 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.
#
# This script will generate coverage.txt.

set -e

PKGS=$(go list ./... | grep -v /vendor/)
for pkg in $PKGS; do
  go test -timeout=300s -race -coverprofile=profile.out -covermode=atomic $pkg
  if [[ -f profile.out ]]; then
    cat profile.out >> coverage.txt
    rm profile.out
#!/usr/bin/env bash
# Copyright 2017 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.
#
# This script will build licenseok and run it on all
# source files to check licence
set -e

go build -o licenseok ./hack/licenseok/main.go
#!/usr/bin/env bash
# Copyright 2017 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.
#
# This script will validate code with various linters
set -e

PKGS=$(go list ./... | grep -vF /vendor/)
go vet $PKGS
#!/usr/bin/env bash
# Copyright 2017 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.
#
# This script will validate that `go fmt` has been ran
# and is passing for certain directories in the project.
#
# Here we use `go list` to help determine which packages
# we need to check for `go fmt`
#
# EXIT 0 - The check is successful
# EXIT 1 - The check has failed

PKGS=$(go list ./... | grep -v /vendor/)
REPO_TLD="github.com/golang/dep"
IGNORE_PKGS=". ./gps"

for PKG in $PKGS; do
    RELATIVE_PATH="${PKG/$REPO_TLD/.}"
    i=0
    for IGNORE_PKG in $IGNORE_PKGS; do
        if [ "${IGNORE_PKG}" == $RELATIVE_PATH ]; then
            i=1
        fi
    done;
    if [ $i -eq 1 ]; then
        continue
    fi

    echo "Processing gofmt for: ${PKG}"
    gofmt -s -l $RELATIVE_PATH
    if [ $? -ne 0 ]; then
        echo "GO FMT FAILURE: ${PKG}"
        exit 1
#!/usr/bin/env bash
# Copyright 2017 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.
#
# This script will build dep and calculate hash for each
# (DEP_BUILD_PLATFORMS, DEP_BUILD_ARCHS) pair.
# DEP_BUILD_PLATFORMS="linux" DEP_BUILD_ARCHS="amd64" ./hack/build-all.bash
# can be called to build only for linux-amd64

set -e

IMPORT_DURING_SOLVE=${IMPORT_DURING_SOLVE:-false}

go test -timeout=300s -race \
    -ldflags '-X github.com/golang/dep/cmd/dep.flagImportDuringSolve=${IMPORT_DURING_SOLVE}' \
    ./...

if ! ./dep status -out .dep.status.file.output; then exit 1; fi
if ! ./dep status > .dep.status.stdout.output; then
   rm -f .dep.status.file.output
   exit 1
fi
if ! diff .dep.status.file.output .dep.status.stdout.output; then
  diffResult=1
else
  diffResult=0
fi
rm -f .dep.status.file.output .dep.status.stdout.output
if [ "$diffResult" -eq "1" ]; then
#!/usr/bin/env bash
# Copyright 2017 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.
#
# This script will build dep and calculate hash for each
# (DEP_BUILD_PLATFORMS, DEP_BUILD_ARCHS) pair.
# DEP_BUILD_PLATFORMS="linux" DEP_BUILD_ARCHS="amd64" ./hack/build-all.bash
# can be called to build only for linux-amd64

set -e

DEP_ROOT=$(git rev-parse --show-toplevel)
VERSION=$(git describe --tags --dirty)
COMMIT_HASH=$(git rev-parse --short HEAD 2>/dev/null)
DATE=$(date "+%Y-%m-%d")
BUILD_PLATFORM=$(uname -a | awk '{print tolower($1);}')
IMPORT_DURING_SOLVE=${IMPORT_DURING_SOLVE:-false}

if [[ "$(pwd)" != "${DEP_ROOT}" ]]; then
  echo "you are not in the root of the repo" 1>&2
  echo "please cd to ${DEP_ROOT} before running this script" 1>&2
  exit 1
fi

GO_BUILD_CMD="go build -a -installsuffix cgo"
GO_BUILD_LDFLAGS="-s -w -X main.commitHash=${COMMIT_HASH} -X main.buildDate=${DATE} -X main.version=${VERSION} -X main.flagImportDuringSolve=${IMPORT_DURING_SOLVE}"

if [[ -z "${DEP_BUILD_PLATFORMS}" ]]; then
    DEP_BUILD_PLATFORMS="linux windows darwin freebsd"
fi

if [[ -z "${DEP_BUILD_ARCHS}" ]]; then
    DEP_BUILD_ARCHS="amd64 386 ppc64 ppc64le s390x arm arm64"
fi

mkdir -p "${DEP_ROOT}/release"

for OS in ${DEP_BUILD_PLATFORMS[@]}; do
  for ARCH in ${DEP_BUILD_ARCHS[@]}; do
    NAME="dep-${OS}-${ARCH}"
    if [[ "${OS}" == "windows" ]]; then
      NAME="${NAME}.exe"
    fi

    # Enable CGO if building for OS X on OS X; see
    # https://github.com/golang/dep/issues/1838 for details.
    if [[ "${OS}" == "darwin" && "${BUILD_PLATFORM}" == "darwin" ]]; then
      CGO_ENABLED=1
    else
      CGO_ENABLED=0
    fi
    if [[ "${ARCH}" == "ppc64" || "${ARCH}" == "ppc64le" || "${ARCH}" == "s390x" || "${ARCH}" == "arm" || "${ARCH}" == "arm64" ]] && [[ "${OS}" != "linux" ]]; then
        # ppc64, ppc64le, s390x, arm and arm64 are only supported on Linux.
        echo "Building for ${OS}/${ARCH} not supported."
    else
        echo "Building for ${OS}/${ARCH} with CGO_ENABLED=${CGO_ENABLED}"
        GOARCH=${ARCH} GOOS=${OS} CGO_ENABLED=${CGO_ENABLED} ${GO_BUILD_CMD} -ldflags "${GO_BUILD_LDFLAGS}"\
            -o "${DEP_ROOT}/release/${NAME}" ./cmd/dep/
        pushd "${DEP_ROOT}/release" > /dev/null
#!/usr/bin/env bash

# Copyright ©2017 The Gonum Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

# Generate code for blas32.
echo Generating blas32/conv.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv.go
cat blas64/conv.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
\
>> blas32/conv.go

echo Generating blas32/conv_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv_test.go
cat blas64/conv_test.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
\
>> blas32/conv_test.go

echo Generating blas32/conv_symmetric.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv_symmetric.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
\
>> blas32/conv_symmetric.go

echo Generating blas32/conv_symmetric_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > blas32/conv_symmetric_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> float32' \
\
| sed -e 's/blas64/blas32/' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
\
>> blas32/conv_symmetric_test.go


# Generate code for cblas128.
echo Generating cblas128/conv.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv.go
cat blas64/conv.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
\
>> cblas128/conv.go

echo Generating cblas128/conv_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_test.go
cat blas64/conv_test.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's_"math"_math "math/cmplx"_' \
\
>> cblas128/conv_test.go

echo Generating cblas128/conv_symmetric.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_symmetric.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
\
>> cblas128/conv_symmetric.go

echo Generating cblas128/conv_symmetric_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_symmetric_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's_"math"_math "math/cmplx"_' \
\
>> cblas128/conv_symmetric_test.go

echo Generating cblas128/conv_hermitian.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_hermitian.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
      -e 's/Sym/Herm/g' \
\
>> cblas128/conv_hermitian.go

echo Generating cblas128/conv_hermitian_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas128/conv_hermitian_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> complex128' \
\
| sed -e 's/blas64/cblas128/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
      -e 's/Sym/Herm/g' \
      -e 's_"math"_math "math/cmplx"_' \
\
>> cblas128/conv_hermitian_test.go


# Generate code for cblas64.
echo Generating cblas64/conv.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv.go
cat blas64/conv.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
\
>> cblas64/conv.go

echo Generating cblas64/conv_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv_test.go
cat blas64/conv_test.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/cmplx64"_' \
\
>> cblas64/conv_test.go

echo Generating cblas64/conv_hermitian.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv_hermitian.go
cat blas64/conv_symmetric.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
      -e 's/Sym/Herm/g' \
\
>> cblas64/conv_hermitian.go

echo Generating cblas64/conv_hermitian_test.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas”; DO NOT EDIT.\n' > cblas64/conv_hermitian_test.go
cat blas64/conv_symmetric_test.go \
| gofmt -r 'float64 -> complex64' \
\
| sed -e 's/blas64/cblas64/' \
      -e 's/Symmetric/Hermitian/g' \
      -e 's/a symmetric/an Hermitian/g' \
      -e 's/symmetric/hermitian/g' \
#!/usr/bin/env bash

# Copyright ©2015 The Gonum Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

WARNINGF32='//\
// Float32 implementations are autogenerated and not directly tested.\
'
WARNINGC64='//\
// Complex64 implementations are autogenerated and not directly tested.\
'

# Level1 routines.

echo Generating level1float32.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32.go
cat level1float64.go \
| gofmt -r 'blas.Float64Level1 -> blas.Float32Level1' \
\
| gofmt -r 'float64 -> float32' \
| gofmt -r 'blas.DrotmParams -> blas.SrotmParams' \
\
| gofmt -r 'f64.AxpyInc -> f32.AxpyInc' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
| gofmt -r 'f64.ScalInc -> f32.ScalInc' \
| gofmt -r 'f64.ScalUnitary -> f32.ScalUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e "s_^\(func (Implementation) \)Id\(.*\)\$_$WARNINGF32\1Is\2_" \
      -e 's_^// Id_// Is_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
>> level1float32.go

echo Generating level1cmplx64.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1cmplx64.go
cat level1cmplx128.go \
| gofmt -r 'blas.Complex128Level1 -> blas.Complex64Level1' \
\
| gofmt -r 'float64 -> float32' \
| gofmt -r 'complex128 -> complex64' \
\
| gofmt -r 'c128.AxpyInc -> c64.AxpyInc' \
| gofmt -r 'c128.AxpyUnitary -> c64.AxpyUnitary' \
| gofmt -r 'c128.DotcInc -> c64.DotcInc' \
| gofmt -r 'c128.DotcUnitary -> c64.DotcUnitary' \
| gofmt -r 'c128.DotuInc -> c64.DotuInc' \
| gofmt -r 'c128.DotuUnitary -> c64.DotuUnitary' \
| gofmt -r 'c128.ScalInc -> c64.ScalInc' \
| gofmt -r 'c128.ScalUnitary -> c64.ScalUnitary' \
| gofmt -r 'dcabs1 -> scabs1' \
\
| sed -e "s_^\(func (Implementation) \)Zdot\(.*\)\$_$WARNINGC64\1Cdot\2_" \
      -e 's_^// Zdot_// Cdot_' \
      -e "s_^\(func (Implementation) \)Zdscal\(.*\)\$_$WARNINGC64\1Csscal\2_" \
      -e 's_^// Zdscal_// Csscal_' \
      -e "s_^\(func (Implementation) \)Z\(.*\)\$_$WARNINGC64\1C\2_" \
      -e 's_^// Z_// C_' \
      -e "s_^\(func (Implementation) \)Iz\(.*\)\$_$WARNINGC64\1Ic\2_" \
      -e 's_^// Iz_// Ic_' \
      -e "s_^\(func (Implementation) \)Dz\(.*\)\$_$WARNINGC64\1Sc\2_" \
      -e 's_^// Dz_// Sc_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/c128"_"gonum.org/v1/gonum/internal/asm/c64"_' \
      -e 's_"math"_math "gonum.org/v1/gonum/internal/math32"_' \
>> level1cmplx64.go

echo Generating level1float32_sdot.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32_sdot.go
cat level1float64_ddot.go \
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.DotInc -> f32.DotInc' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level1float32_sdot.go

echo Generating level1float32_dsdot.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32_dsdot.go
cat level1float64_ddot.go \
| gofmt -r '[]float64 -> []float32' \
\
| gofmt -r 'f64.DotInc -> f32.DdotInc' \
| gofmt -r 'f64.DotUnitary -> f32.DdotUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1Ds\2_" \
      -e 's_^// D_// Ds_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level1float32_dsdot.go

echo Generating level1float32_sdsdot.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level1float32_sdsdot.go
cat level1float64_ddot.go \
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.DotInc(x, y, f(n), f(incX), f(incY), f(ix), f(iy)) -> alpha + float32(f32.DdotInc(x, y, f(n), f(incX), f(incY), f(ix), f(iy)))' \
| gofmt -r 'f64.DotUnitary(a, b) -> alpha + float32(f32.DdotUnitary(a, b))' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1Sds\2_" \
      -e 's_^// D\(.*\)$_// Sds\1 plus a constant_' \
      -e 's_\\sum_alpha + \\sum_' \
      -e 's/n int/n int, alpha float32/' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level1float32_sdsdot.go


# Level2 routines.

echo Generating level2float32.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level2float32.go
cat level2float64.go \
| gofmt -r 'blas.Float64Level2 -> blas.Float32Level2' \
\
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.AxpyInc -> f32.AxpyInc' \
| gofmt -r 'f64.AxpyIncTo -> f32.AxpyIncTo' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.AxpyUnitaryTo -> f32.AxpyUnitaryTo' \
| gofmt -r 'f64.DotInc -> f32.DotInc' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
| gofmt -r 'f64.ScalInc -> f32.ScalInc' \
| gofmt -r 'f64.ScalUnitary -> f32.ScalUnitary' \
| gofmt -r 'f64.Ger -> f32.Ger' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level2float32.go

echo Generating level2cmplx64.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level2cmplx64.go
cat level2cmplx128.go \
| gofmt -r 'blas.Complex128Level2 -> blas.Complex64Level2' \
\
| gofmt -r 'complex128 -> complex64' \
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'c128.AxpyInc -> c64.AxpyInc' \
| gofmt -r 'c128.AxpyUnitary -> c64.AxpyUnitary' \
| gofmt -r 'c128.DotuInc -> c64.DotuInc' \
| gofmt -r 'c128.DotuUnitary -> c64.DotuUnitary' \
| gofmt -r 'c128.ScalInc -> c64.ScalInc' \
| gofmt -r 'c128.ScalUnitary -> c64.ScalUnitary' \
\
| sed -e "s_^\(func (Implementation) \)Z\(.*\)\$_$WARNINGC64\1C\2_" \
      -e 's_^// Z_// C_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/c128"_"gonum.org/v1/gonum/internal/asm/c64"_' \
      -e 's_"math/cmplx"_cmplx "gonum.org/v1/gonum/internal/cmplx64"_' \
>> level2cmplx64.go

# Level3 routines.

echo Generating level3float32.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level3float32.go
cat level3float64.go \
| gofmt -r 'blas.Float64Level3 -> blas.Float32Level3' \
\
| gofmt -r 'float64 -> float32' \
\
| gofmt -r 'f64.AxpyUnitaryTo -> f32.AxpyUnitaryTo' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
| gofmt -r 'f64.ScalUnitary -> f32.ScalUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> level3float32.go

echo Generating sgemm.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > sgemm.go
cat dgemm.go \
| gofmt -r 'float64 -> float32' \
| gofmt -r 'sliceView64 -> sliceView32' \
\
| gofmt -r 'dgemmParallel -> sgemmParallel' \
| gofmt -r 'computeNumBlocks64 -> computeNumBlocks32' \
| gofmt -r 'dgemmSerial -> sgemmSerial' \
| gofmt -r 'dgemmSerialNotNot -> sgemmSerialNotNot' \
| gofmt -r 'dgemmSerialTransNot -> sgemmSerialTransNot' \
| gofmt -r 'dgemmSerialNotTrans -> sgemmSerialNotTrans' \
| gofmt -r 'dgemmSerialTransTrans -> sgemmSerialTransTrans' \
\
| gofmt -r 'f64.AxpyInc -> f32.AxpyInc' \
| gofmt -r 'f64.AxpyUnitary -> f32.AxpyUnitary' \
| gofmt -r 'f64.DotUnitary -> f32.DotUnitary' \
\
| sed -e "s_^\(func (Implementation) \)D\(.*\)\$_$WARNINGF32\1S\2_" \
      -e 's_^// D_// S_' \
      -e 's_^// d_// s_' \
      -e 's_"gonum.org/v1/gonum/internal/asm/f64"_"gonum.org/v1/gonum/internal/asm/f32"_' \
>> sgemm.go

echo Generating level3cmplx64.go
echo -e '// Code generated by "go generate gonum.org/v1/gonum/blas/gonum”; DO NOT EDIT.\n' > level3cmplx64.go
cat level3cmplx128.go \
| gofmt -r 'blas.Complex128Level3 -> blas.Complex64Level3' \
\
| gofmt -r 'float64 -> float32' \
| gofmt -r 'complex128 -> complex64' \
\
| gofmt -r 'c128.ScalUnitary -> c64.ScalUnitary' \
| gofmt -r 'c128.DscalUnitary -> c64.SscalUnitary' \
| gofmt -r 'c128.DotcUnitary -> c64.DotcUnitary' \
| gofmt -r 'c128.AxpyUnitary -> c64.AxpyUnitary' \
| gofmt -r 'c128.DotuUnitary -> c64.DotuUnitary' \
\
| sed -e "s_^\(func (Implementation) \)Z\(.*\)\$_$WARNINGC64\1C\2_" \
      -e 's_^// Z_// C_' \
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/bin/bash

# Copyright (c) The Diem Core Contributors
# SPDX-License-Identifier: Apache-2.0

TRACE_PATH=$HOME/trace

[ ! -e  "$TRACE_PATH" ] || rm -f "$TRACE_PATH"

export MOVE_VM_TRACE=$TRACE_PATH

echo "Rebuilding stdlib..."
pushd ../../diem-framework || exit 1
cargo run
popd || exit 1

#cargo test -p ir-testsuite -p language-e2e-tests -p move-lang-functional-tests

echo "---------------------------------------------------------------------------"
echo "Running IR testsuite..."
echo "---------------------------------------------------------------------------"
pushd ../../ir-testsuite || exit 1
cargo test
popd || exit 1

echo "---------------------------------------------------------------------------"
echo "Running e2e testsuite..."
echo "---------------------------------------------------------------------------"
pushd ../../e2e-testsuite || exit 1
cargo test -- --skip account_universe --skip fuzz_scripts
popd || exit 1

echo "---------------------------------------------------------------------------"
echo "Running Move testsuite..."
echo "---------------------------------------------------------------------------"
pushd ../../move-lang/functional-tests/tests || exit 1
cargo test
popd || exit 1

echo "---------------------------------------------------------------------------"
echo "Building Move modules and source maps.."
echo "---------------------------------------------------------------------------"
pushd ../../move-lang || exit 1
rm -rf build
cargo run --bin move-build -- ../diem-framework/modules -m
popd || exit 1

echo "---------------------------------------------------------------------------"
echo "Converting trace file..."
echo "---------------------------------------------------------------------------"
cargo run --bin move-trace-conversion -- -f "$TRACE_PATH" -o trace.mvcov

echo "---------------------------------------------------------------------------"
echo "Producing coverage summaries..."
echo "---------------------------------------------------------------------------"
cargo run --bin coverage-summaries -- -t trace.mvcov -s ../../diem-framework/compiled/stdlib

echo "==========================================================================="
echo "You can check source coverage for a module by running:"
echo "> cargo run --bin source-coverage -- -t trace.mvcov -b ../../move-lang/build/modules/<LOOK_FOR_MODULE_HERE>.mv -s ../../diem-framework/modules/<SOURCE_MODULE>.move"
echo "---------------------------------------------------------------------------"
echo "You can can also get a finer-grained coverage summary for each function by running:"
echo "> cargo run --bin coverage-summaries -- -t trace.mvcov -s ../../diem-framework/compiled/stdlib.mv"
echo "==========================================================================="

#! /bin/bash
# Completion for bash:
#
# (1) install this file,
#
# (2) load the script, and
#      . ~/.profile.d/rb_optparse.bash
#
# (3) define completions in your .bashrc,
#      rb_optparse command_using_optparse_1
#      rb_optparse command_using_optparse_2

_rb_optparse() {
  COMPREPLY=($("${COMP_WORDS[0]}" "--*-completion-bash=${COMP_WORDS[COMP_CWORD]}"))
  return 0
_do_comp()
{
  if [[ $(type compopt) == *"builtin" ]]; then
    compopt $@
  else
    complete $@
  fi
}

_ipfs_comp()
{
    COMPREPLY=( $(compgen -W "$1" -- ${word}) )
    if [[ ${#COMPREPLY[@]} == 1 && ${COMPREPLY[0]} == "--"*"=" ]] ; then
        # If there's only one option, with =, then discard space
        _do_comp -o nospace
    fi
}

_ipfs_help_only()
{
    _ipfs_comp "--help"
}

_ipfs_add()
{
    if [[ "${prev}" == "--chunker" ]] ; then
        _ipfs_comp "placeholder1 placeholder2 placeholder3" # TODO: a) Give real options, b) Solve autocomplete bug for "="
    elif [ "${prev}" == "--pin" ] ; then
        _ipfs_comp "true false"
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive --dereference-args --stdin-name= --hidden --ignore= --ignore-rules-path= --quiet --quieter --silent --progress --trickle --only-hash --wrap-with-directory --chunker= --pin= --raw-leaves --nocopy --fscache --cid-version= --hash= --inline --inline-limit= --help "
    else
        _ipfs_filesystem_complete
    fi
}

_ipfs_bitswap()
{
    ipfs_comp "ledger stat wantlist --help"
}

_ipfs_bitswap_ledger()
{
    _ipfs_help_only
}

_ipfs_bitswap_stat()
{
    _ipfs_help_only
}

_ipfs_bitswap_wantlist()
{
    ipfs_comp "--peer= --help"
}

_ipfs_block()
{
    _ipfs_comp "get put rm stat --help"
}

_ipfs_block_get()
{
    _ipfs_hash_complete
}

_ipfs_block_put()
{
    if [ "${prev}" == "--format" ] ; then
        _ipfs_comp "v0 placeholder2 placeholder3" # TODO: a) Give real options, b) Solve autocomplete bug for "="
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--format= --help"
    else
        _ipfs_filesystem_complete
    fi
}

_ipfs_block_rm()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--force --quiet --help"
    else
        _ipfs_hash_complete
    fi
}

_ipfs_block_stat()
{
    _ipfs_hash_complete
}

_ipfs_bootstrap()
{
    _ipfs_comp "add list rm --help"
}

_ipfs_bootstrap_add()
{
    _ipfs_comp "default --help"
}

_ipfs_bootstrap_list()
{
    _ipfs_help_only
}

_ipfs_bootstrap_rm()
{
    _ipfs_comp "all --help"
}

_ipfs_cat()
{
    if [[ ${prev} == */* ]] ; then
        COMPREPLY=() # Only one argument allowed
    elif [[ ${word} == */* ]] ; then
        _ipfs_hash_complete
    else
        _ipfs_pinned_complete
    fi
}

_ipfs_commands()
{
    _ipfs_comp "--flags --help"
}

_ipfs_config()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--bool --json"
    elif [[ ${prev} == *.* ]] ; then
        COMPREPLY=() # Only one subheader of the config can be shown or edited.
    else
        _ipfs_comp "show edit replace"
    fi
}

_ipfs_config_edit()
{
    _ipfs_help_only
}

_ipfs_config_replace()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--help"
    else
        _ipfs_filesystem_complete
    fi
}

_ipfs_config_show()
{
    _ipfs_help_only
}

_ipfs_daemon()
{
    if [[ ${prev} == "--routing" ]] ; then
        _ipfs_comp "dht dhtclient none" # TODO: Solve autocomplete bug for "="
    elif [[ ${prev} == "--mount-ipfs" ]] || [[ ${prev} == "--mount-ipns" ]] || [[ ${prev} == "=" ]]; then
        _ipfs_filesystem_complete
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--init --routing= --mount --writable --mount-ipfs= \
            --mount-ipns= --unrestricted-api --disable-transport-encryption \
            -- enable-gc --manage-fdlimit --offline --migrate --help"
    fi
}

_ipfs_dag()
{
    _ipfs_comp "get put --help"
}

_ipfs_dag_get()
{
    _ipfs_help_only
}

_ipfs_dag_put()
{
    if [[ ${prev} == "--format" ]] ; then
        _ipfs_comp "cbor placeholder1" # TODO: a) Which format more than cbor is valid? b) Solve autocomplete bug for "="
    elif [[ ${prev} == "--input-enc" ]] ; then
        _ipfs_comp "json placeholder1" # TODO: a) Which format more than json is valid? b) Solve autocomplete bug for "="
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--format= --input-enc= --help"
    else
        _ipfs_filesystem_complete
    fi
}

_ipfs_dht()
{
    _ipfs_comp "findpeer findprovs get provide put query --help"
}

_ipfs_dht_findpeer()
{
    _ipfs_comp "--verbose --help"
}

_ipfs_dht_findprovs()
{
    _ipfs_comp "--verbose --help"
}

_ipfs_dht_get()
{
    _ipfs_comp "--verbose --help"
}

_ipfs_dht_provide()
{
    _ipfs_comp "--recursive --verbose --help"
}

_ipfs_dht_put()
{
    _ipfs_comp "--verbose --help"
}

_ipfs_dht_query()
{
    _ipfs_comp "--verbose --help"
}

_ipfs_diag()
{
    _ipfs_comp "sys cmds net --help"
}

_ipfs_diag_cmds()
{
    if [[ ${prev} == "clear" ]] ; then
        return 0
    elif [[ ${prev} =~ ^-?[0-9]+$ ]] ; then
        _ipfs_comp "ns us µs ms s m h" # TODO: Trigger without space, eg. "ipfs diag set-time 10ns" not "... set-time 10 ns"
    elif [[ ${prev} == "set-time" ]] ; then
        _ipfs_help_only
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--verbose --help"
    else
        _ipfs_comp "clear set-time"
    fi
}

_ipfs_diag_sys()
{
    _ipfs_help_only
}

_ipfs_diag_net()
{
    if [[ ${prev} == "--vis" ]] ; then
        _ipfs_comp "d3 dot text" # TODO: Solve autocomplete bug for "="
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--timeout= --vis= --help"
    fi
}

_ipfs_dns()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive --help"
    fi
}

_ipfs_files()
{
    _ipfs_comp "mv rm flush read write cp ls mkdir stat"
}

_ipfs_files_mv()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive --flush"
    elif [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_files_rm()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive --flush"
    elif [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}
_ipfs_files_flush()
{
    if [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_files_read()
{
    if [[ ${prev} == "--count" ]] || [[ ${prev} == "--offset" ]] ; then
        COMPREPLY=() # Numbers, just keep it empty
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--offset --count --help"
    elif [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_files_write()
{
    if [[ ${prev} == "--count" ]] || [[ ${prev} == "--offset" ]] ; then # Dirty check
        COMPREPLY=() # Numbers, just keep it empty
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--offset --count --create --truncate --help"
    elif [[ ${prev} == /* ]] ; then
        _ipfs_filesystem_complete
    elif [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_files_cp()
{
    if [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_files_ls()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "-l --help"
    elif [[ ${prev} == /* ]] ; then
        COMPREPLY=() # Path exist
    elif [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_files_mkdir()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--parents --help"

    elif [[ ${prev} == /* ]] ; then
        COMPREPLY=() # Path exist
    elif [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_files_stat()
{
    if [[ ${prev} == /* ]] ; then
        COMPREPLY=() # Path exist
    elif [[ ${word} == /* ]] ; then
        _ipfs_files_complete
    else
        COMPREPLY=( / )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_file()
{
    if [[ ${prev} == "ls" ]] ; then
        _ipfs_hash_complete
    else
        _ipfs_comp "ls --help"
    fi
}

_ipfs_file_ls()
{
    _ipfs_help_only
}

_ipfs_get()
{
    if [ "${prev}" == "--output" ] ; then
        _do_comp -o default # Re-enable default file read
        COMPREPLY=()
    elif [ "${prev}" == "--compression-level" ] ; then
        _ipfs_comp "-1 1 2 3 4 5 6 7 8 9" # TODO: Solve autocomplete bug for "="
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--output= --archive --compress --compression-level= --help"
    else
        _ipfs_hash_complete
    fi
}

_ipfs_id()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--format= --help"
    fi
}

_ipfs_init()
{
    _ipfs_comp "--bits --force --empty-repo --help"
}

_ipfs_log()
{
    _ipfs_comp "level ls tail --help"
}

_ipfs_log_level()
{
    # TODO: auto-complete subsystem and level
    _ipfs_help_only
}

_ipfs_log_ls()
{
    _ipfs_help_only
}

_ipfs_log_tail()
{
    _ipfs_help_only
}

_ipfs_ls()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--headers --resolve-type=false --help"
    else
        _ipfs_hash_complete
    fi
}

_ipfs_mount()
{
    if [[ ${prev} == "--ipfs-path" ]] || [[ ${prev} == "--ipns-path" ]] || [[ ${prev} == "=" ]] ; then
        _ipfs_filesystem_complete
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--ipfs-path= --ipns-path= --help"
    fi
}

_ipfs_name()
{
    _ipfs_comp "publish resolve --help"
}

_ipfs_name_publish()
{
    if [[ ${prev} == "--lifetime" ]] || [[ ${prev} == "--ttl" ]] ; then
        COMPREPLY=() # Accept only numbers
    elif [[ ${prev} =~ ^-?[0-9]+$ ]] ; then
        _ipfs_comp "ns us µs ms s m h" # TODO: Trigger without space, eg. "ipfs diag set-time 10ns" not "... set-time 10 ns"
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--resolve --lifetime --ttl --help"
    elif [[ ${word} == */ ]]; then
        _ipfs_hash_complete
    else
        _ipfs_pinned_complete
    fi
}

_ipfs_name_resolve()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive --nocache --help"
    fi
}

_ipfs_object()
{
    _ipfs_comp "data diff get links new patch put stat --help"
}

_ipfs_object_data()
{
    _ipfs_hash_complete
}

_ipfs_object_diff()
{
  if [[ ${word} == -* ]] ; then
      _ipfs_comp "--verbose --help"
  else
      _ipfs_hash_complete
  fi
}


_ipfs_object_get()
{
    if [ "${prev}" == "--encoding" ] ; then
        _ipfs_comp "protobuf json xml"
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--encoding --help"
    else
        _ipfs_hash_complete
    fi
}

_ipfs_object_links()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--headers --help"
    else
        _ipfs_hash_complete
    fi
}

_ipfs_object_new()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--help"
    else
        _ipfs_comp "unixfs-dir"
    fi
}

_ipfs_object_patch()
{
    if [[ -n "${COMP_WORDS[3]}" ]] ; then # Root merkledag object exist
        case "${COMP_WORDS[4]}" in
        append-data)
            _ipfs_help_only
            ;;
        add-link)
            if [[ ${word} == -* ]] && [[ ${prev} == "add-link" ]] ; then # Dirty check
                _ipfs_comp "--create"
            #else
                # TODO: Hash path autocomplete. This is tricky, can be hash or a name.
            fi
            ;;
        rm-link)
            _ipfs_hash_complete
            ;;
        set-data)
            _ipfs_filesystem_complete
            ;;
        *)
            _ipfs_comp "append-data add-link rm-link set-data"
            ;;
        esac
    else
        _ipfs_hash_complete
    fi
}

_ipfs_object_put()
{
    if [ "${prev}" == "--inputenc" ] ; then
        _ipfs_comp "protobuf json"
    elif [ "${prev}" == "--datafieldenc" ] ; then
        _ipfs_comp "text base64"
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--inputenc --datafieldenc --help"
    else
        _ipfs_hash_complete
    fi
}

_ipfs_object_stat()
{
    _ipfs_hash_complete
}

_ipfs_pin()
{
    _ipfs_comp "rm ls add --help"
}

_ipfs_pin_add()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive=  --help"
    elif [[ ${word} == */ ]] && [[ ${word} != "/ipfs/" ]] ; then
        _ipfs_hash_complete
    fi
}

_ipfs_pin_ls()
{
    if [[ ${prev} == "--type" ]] || [[ ${prev} == "-t" ]] ; then
        _ipfs_comp "direct indirect recursive all" # TODO: Solve autocomplete bug for
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--count --quiet --type= --help"
    elif [[ ${word} == */ ]] && [[ ${word} != "/ipfs/" ]] ; then
        _ipfs_hash_complete
    fi
}

_ipfs_pin_rm()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive  --help"
    elif [[ ${word} == */ ]] && [[ ${word} != "/ipfs/" ]] ; then
        COMPREPLY=() # TODO: _ipfs_hash_complete() + List local pinned hashes as default?
    fi
}

_ipfs_ping()
{
    _ipfs_comp "--count=  --help"
}

_ipfs_pubsub()
{
    _ipfs_comp "ls peers pub sub --help"
}

_ipfs_pubsub_ls()
{
    _ipfs_help_only
}

_ipfs_pubsub_peers()
{
    _ipfs_help_only
}

_ipfs_pubsub_pub()
{
    _ipfs_help_only
}

_ipfs_pubsub_sub()
{
    _ipfs_comp "--discover --help"
}

_ipfs_refs()
{
    if [ "${prev}" == "--format" ] ; then
        _ipfs_comp "src dst linkname"
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "local --format= --edges --unique --recursive --help"
    #else
        # TODO: Use "ipfs ref" and combine it with autocomplete, see _ipfs_hash_complete
    fi
}

_ipfs_refs_local()
{
    _ipfs_help_only
}

_ipfs_repo()
{
    _ipfs_comp "fsck gc stat verify version --help"
}

_ipfs_repo_version()
{
    _ipfs_comp "--quiet --help"
}

_ipfs_repo_verify()
{
    _ipfs_help_only
}

_ipfs_repo_gc()
{
    _ipfs_comp "--quiet --help"
}

_ipfs_repo_stat()
{
    _ipfs_comp "--human --help"
}

_ipfs_repo_fsck()
{
    _ipfs_help_only
}

_ipfs_resolve()
{
    if [[ ${word} == /ipfs/* ]] ; then
        _ipfs_hash_complete
    elif [[ ${word} == /ipns/* ]] ; then
        COMPREPLY=() # Can't autocomplete ipns
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--recursive --help"
    else
        opts="/ipns/ /ipfs/"
        COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace
    fi
}

_ipfs_stats()
{
    _ipfs_comp "bitswap bw repo --help"
}

_ipfs_stats_bitswap()
{
    _ipfs_help_only
}

_ipfs_stats_bw()
{
    # TODO: Which protocol is valid?
    _ipfs_comp "--peer= --proto= --poll --interval= --help"
}

_ipfs_stats_repo()
{
    _ipfs_comp "--human= --help"
}

_ipfs_swarm()
{
    _ipfs_comp "addrs connect disconnect filters peers --help"
}

_ipfs_swarm_addrs()
{
    _ipfs_comp "local --help"
}

_ipfs_swarm_addrs_local()
{
    _ipfs_comp "--id --help"
}

_ipfs_swarm_connect()
{
    _ipfs_multiaddr_complete
}

_ipfs_swarm_disconnect()
{
    local OLDIFS="$IFS" ; local IFS=$'\n' # Change divider for iterator one line below
    opts=$(for x in `ipfs swarm peers`; do echo ${x} ; done)
    IFS="$OLDIFS" # Reset divider to space, ' '
    COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
    [[ $COMPREPLY = */ ]] && _do_comp -o nospace -o filenames
}

_ipfs_swarm_filters()
{
    if [[ ${prev} == "add" ]] || [[ ${prev} == "rm" ]]; then
        _ipfs_multiaddr_complete
    else
        _ipfs_comp "add rm --help"
    fi
}

_ipfs_swarm_filters_add()
{
    _ipfs_help_only
}

_ipfs_swarm_filters_rm()
{
    _ipfs_help_only
}

_ipfs_swarm_peers()
{
    _ipfs_help_only
}

_ipfs_tar()
{
    _ipfs_comp "add cat --help"
}

_ipfs_tar_add()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--help"
    else
        _ipfs_filesystem_complete
    fi
}

_ipfs_tar_cat()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--help"
    else
        _ipfs_filesystem_complete
    fi
}

_ipfs_update()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--version" # TODO: How does "--verbose" option work?
    else
        _ipfs_comp "versions version install stash revert fetch"
    fi
}

_ipfs_update_install()
{
    if   [[ ${prev} == v*.*.* ]] ; then
        COMPREPLY=()
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--version"
    else
        local OLDIFS="$IFS" ; local IFS=$'\n' # Change divider for iterator one line below
        opts=$(for x in `ipfs update versions`; do echo ${x} ; done)
        IFS="$OLDIFS" # Reset divider to space, ' '
        COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
    fi
}

_ipfs_update_stash()
{
    if [[ ${word} == -* ]] ; then
        _ipfs_comp "--tag --help"
    fi
}
_ipfs_update_fetch()
{
    if [[ ${prev} == "--output" ]] ; then
        _ipfs_filesystem_complete
    elif [[ ${word} == -* ]] ; then
        _ipfs_comp "--output --help"
    fi
}

_ipfs_version()
{
    _ipfs_comp "--number --commit --repo"
}

_ipfs_hash_complete()
{
    local lastDir=${word%/*}/
    echo "LastDir: ${lastDir}" >> ~/Downloads/debug-ipfs.txt
    local OLDIFS="$IFS" ; local IFS=$'\n' # Change divider for iterator one line below
    opts=$(for x in `ipfs file ls ${lastDir}`; do echo ${lastDir}${x}/ ; done) # TODO: Implement "ipfs file ls -F" to get rid of frontslash after files. This take long time to run first time on a new shell.
    echo "Options: ${opts}" >> ~/Downloads/debug-ipfs.txt
    IFS="$OLDIFS" # Reset divider to space, ' '
    echo "Current: ${word}" >> ~/Downloads/debug-ipfs.txt
    COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
    echo "Suggestion: ${COMPREPLY}" >> ~/Downloads/debug-ipfs.txt
    [[ $COMPREPLY = */ ]] && _do_comp -o nospace -o filenames # Removing whitespace after output & handle output as filenames. (Only printing the latest folder of files.)
    return 0
}

_ipfs_files_complete()
{
    local lastDir=${word%/*}/
    local OLDIFS="$IFS" ; local IFS=$'\n' # Change divider for iterator one line below
    opts=$(for x in `ipfs files ls ${lastDir}`; do echo ${lastDir}${x}/ ; done) # TODO: Implement "ipfs files ls -F" to get rid of frontslash after files. This does currently throw "Error: /cats/foo/ is not a directory"
    IFS="$OLDIFS" # Reset divider to space, ' '
    COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
    [[ $COMPREPLY = */ ]] && _do_comp -o nospace -o filenames
    return 0
}

_ipfs_multiaddr_complete()
{
    local lastDir=${word%/*}/
    # Special case
    if [[ ${word} == */"ipcidr"* ]] ; then # TODO: Broken, fix it.
        opts="1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32" # TODO: IPv6?
        COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
    # "Loop"
    elif [[ ${word} == /*/ ]] || [[ ${word} == /*/* ]] ; then
        if [[ ${word} == /*/*/*/*/*/ ]] ; then
            COMPREPLY=()
        elif [[ ${word} == /*/*/*/*/ ]] ; then
            word=${word##*/}
            opts="ipfs/ "
            COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
        elif [[ ${word} == /*/*/*/ ]] ; then
            word=${word##*/}
            opts="4001/ "
            COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
        elif [[ ${word} == /*/*/ ]] ; then
            word=${word##*/}
            opts="udp/ tcp/ ipcidr/"
            COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
        elif [[ ${word} == /*/ ]] ; then
            COMPREPLY=() # TODO: This need to return something to NOT break the function. Maybe a "/" in the end as well due to -o filename option.
        fi
        COMPREPLY=${lastDir}${COMPREPLY}
    else # start case
        opts="/ip4/ /ip6/"
        COMPREPLY=( $(compgen -W "${opts}" -- ${word}) )
    fi
    [[ $COMPREPLY = */ ]] && _do_comp -o nospace -o filenames
    return 0
}

_ipfs_pinned_complete()
{
    local OLDIFS="$IFS" ; local IFS=$'\n'
    local pinned=$(ipfs pin ls)
    COMPREPLY=( $(compgen -W "${pinned}" -- ${word}) )
    IFS="$OLDIFS"
    if [[ ${#COMPREPLY[*]} -eq 1 ]]; then # Only one completion, remove pretty output
        COMPREPLY=( ${COMPREPLY[0]/ *//} ) #Remove ' ' and everything after
        [[ $COMPREPLY = */ ]] && _do_comp -o nospace  # Removing whitespace after output
    fi
}
_ipfs_filesystem_complete()
{
    _do_comp -o default # Re-enable default file read
    COMPREPLY=()
}

_ipfs()
{
    COMPREPLY=()
    _do_comp +o default # Disable default to not deny completion, see: http://stackoverflow.com/a/19062943/1216348

    local word="${COMP_WORDS[COMP_CWORD]}"
    local prev="${COMP_WORDS[COMP_CWORD-1]}"

    case "${COMP_CWORD}" in
        1)
            local opts="add bitswap block bootstrap cat commands config daemon dag dht \
                        diag dns file files get id init log ls mount name object pin ping pubsub \
                        refs repo resolve stats swarm tar update version"
            COMPREPLY=( $(compgen -W "${opts}" -- ${word}) );;
        2)
            local command="${COMP_WORDS[1]}"
            eval "_ipfs_$command" 2> /dev/null ;;
        *)
            local command="${COMP_WORDS[1]}"
            local subcommand="${COMP_WORDS[2]}"
            eval "_ipfs_${command}_${subcommand}" 2> /dev/null && return
            eval "_ipfs_$command" 2> /dev/null ;;
# -*- sh -*- (Bash only)
#
# Copyright 2018 The Bazel Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Bash completion of Bazel commands.
#
# Provides command-completion for:
# - bazel prefix options (e.g. --host_jvm_args)
# - blaze command-set (e.g. build, test)
# - blaze command-specific options (e.g. --copts)
# - values for enum-valued options
# - package-names, exploring all package-path roots.
# - targets within packages.

# Environment variables for customizing behavior:
#
# BAZEL_COMPLETION_USE_QUERY - if "true", `bazel query` will be used for
# autocompletion; otherwise, a heuristic grep is used. This is more accurate
# than the heuristic grep, especially for strangely-formatted BUILD files. But
# it can be slower, especially if the Bazel server is busy, and more brittle, if
# the BUILD file contains serious errors. This is an experimental feature.
#
# BAZEL_COMPLETION_ALLOW_TESTS_FOR_RUN - if "true", autocompletion results for
# `bazel run` includes test targets. This is convenient for users who run a lot
# of tests/benchmarks locally with 'bazel run'.

_bazel_completion_use_query() {
  _bazel__is_true "${BAZEL_COMPLETION_USE_QUERY}"
# -*- sh -*- (Bash only)
#
# Copyright 2015 The Bazel Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# The template is expanded at build time using tables of commands/options
# derived from the bazel executable built in the same client; the expansion is
# written to bazel-complete.bash.
#
# Don't use this script directly. Generate the final script with
# bazel build //scripts:bash_completion instead.

# This script expects a header to be prepended to it that defines the following
# nullary functions:
#
# _bazel_completion_use_query - Has a successful exit code if
# BAZEL_COMPLETION_USE_QUERY is "true".
#
# _bazel_completion_allow_tests_for_run - Has a successful exit code if
# BAZEL_COMPLETION_ALLOW_TESTS_FOR_RUN is "true".

# The package path used by the completion routines.  Unfortunately
# this isn't necessarily the same as the actual package path used by
# Bazel, but that's ok.  (It's impossible for us to reliably know what
# the relevant package-path, so this is just a good guess.  Users can
# override it if they want.)
: ${BAZEL_COMPLETION_PACKAGE_PATH:=%workspace%}

# Some commands might interfer with the important one, so don't complete them
: ${BAZEL_IGNORED_COMMAND_REGEX:="__none__"}

# bazel & ibazel commands
: ${BAZEL:=bazel}
: ${IBAZEL:=ibazel}

# Pattern to match for looking for a target
#  BAZEL_BUILD_MATCH_PATTERN__* give the pattern for label-*
#  when looking in the build file.
#  BAZEL_QUERY_MATCH_PATTERN__* give the pattern for label-*
#  when using 'bazel query'.
# _RUNTEST is a special case for _bazel_completion_allow_tests_for_run.
: ${BAZEL_BUILD_MATCH_PATTERN__test:='(.*_test|test_suite)'}
: ${BAZEL_QUERY_MATCH_PATTERN__test:='(test|test_suite)'}
: ${BAZEL_BUILD_MATCH_PATTERN__bin:='.*_binary'}
: ${BAZEL_QUERY_MATCH_PATTERN__bin:='(binary)'}
: ${BAZEL_BUILD_MATCH_PATTERN_RUNTEST__bin:='(.*_(binary|test)|test_suite)'}
: ${BAZEL_QUERY_MATCH_PATTERN_RUNTEST__bin:='(binary|test)'}
: ${BAZEL_BUILD_MATCH_PATTERN__:='.*'}
: ${BAZEL_QUERY_MATCH_PATTERN__:=''}

# Usage: _bazel__get_rule_match_pattern <command>
# Determine what kind of rules to match, based on command.
_bazel__get_rule_match_pattern() {
  local var_name pattern
  if _bazel_completion_use_query; then
    var_name="BAZEL_QUERY_MATCH_PATTERN"
  else
    var_name="BAZEL_BUILD_MATCH_PATTERN"
  fi
  if [[ "$1" =~ ^label-?([a-z]*)$ ]]; then
    pattern=${BASH_REMATCH[1]:-}
    if _bazel_completion_allow_tests_for_run; then
      eval "echo \"\${${var_name}_RUNTEST__${pattern}:-\$${var_name}__${pattern}}\""
    else
      eval "echo \"\$${var_name}__${pattern}\""
    fi
  fi
}

# Compute workspace directory. Search for the innermost
# enclosing directory with a WORKSPACE file.
_bazel__get_workspace_path() {
  local workspace=$PWD
  while true; do
    if [ -f "${workspace}/WORKSPACE" ]; then
      break
    elif [ -z "$workspace" -o "$workspace" = "/" ]; then
      workspace=$PWD
      break;
    fi
    workspace=${workspace%/*}
  done
  echo $workspace
}


# Find the current piece of the line to complete, but only do word breaks at
# certain characters. In particular, ignore these: "':=
# This method also takes into account the current cursor position.
#
# Works with both bash 3 and 4! Bash 3 and 4 perform different word breaks when
# computing the COMP_WORDS array. We need this here because Bazel options are of
# the form --a=b, and labels of the form //some/label:target.
_bazel__get_cword() {
  local cur=${COMP_LINE:0:$COMP_POINT}
  # This expression finds the last word break character, as defined in the
  # COMP_WORDBREAKS variable, but without '=' or ':', which is not preceeded by
  # a slash. Quote characters are also excluded.
  local wordbreaks="$COMP_WORDBREAKS"
  wordbreaks="${wordbreaks//\'/}"
  wordbreaks="${wordbreaks//\"/}"
  wordbreaks="${wordbreaks//:/}"
  wordbreaks="${wordbreaks//=/}"
  local word_start=$(expr "$cur" : '.*[^\]['"${wordbreaks}"']')
  echo "${cur:$word_start}"
}


# Usage: _bazel__package_path <workspace> <displacement>
#
# Prints a list of package-path root directories, displaced using the
# current displacement from the workspace.  All elements have a
# trailing slash.
_bazel__package_path() {
  local workspace=$1 displacement=$2 root
  IFS=:
  for root in ${BAZEL_COMPLETION_PACKAGE_PATH//\%workspace\%/$workspace}; do
    unset IFS
    echo "$root/$displacement"
  done
}

# Usage: _bazel__options_for <command>
#
# Prints the set of options for a given Bazel command, e.g. "build".
_bazel__options_for() {
  local options
  if [[ "${BAZEL_COMMAND_LIST}" =~ ^(.* )?$1( .*)?$ ]]; then
      # assumes option names only use ASCII characters
      local option_name=$(echo $1 | tr a-z A-Z | tr "-" "_")
      eval "echo \${BAZEL_COMMAND_${option_name}_FLAGS}" | tr " " "\n"
  fi
}
# Usage: _bazel__expansion_for <command>
#
# Prints the completion pattern for a given Bazel command, e.g. "build".
_bazel__expansion_for() {
  local options
  if [[ "${BAZEL_COMMAND_LIST}" =~ ^(.* )?$1( .*)?$ ]]; then
      # assumes option names only use ASCII characters
      local option_name=$(echo $1 | tr a-z A-Z | tr "-" "_")
      eval "echo \${BAZEL_COMMAND_${option_name}_ARGUMENT}"
  fi
}

# Usage: _bazel__matching_targets <kind> <prefix>
#
# Prints target names of kind <kind> and starting with <prefix> in the BUILD
# file given as standard input.  <kind> is a basic regex (BRE) used to match the
# bazel rule kind and <prefix> is the prefix of the target name.
_bazel__matching_targets() {
  local kind_pattern="$1"
  local target_prefix="$2"
  # The following commands do respectively:
  #   Remove BUILD file comments
  #   Replace \n by spaces to have the BUILD file in a single line
  #   Extract all rule types and target names
  #   Grep the kind pattern and the target prefix
  #   Returns the target name
  sed 's/#.*$//' \
      | tr "\n" " " \
      | sed 's/\([a-zA-Z0-9_]*\) *(\([^)]* \)\{0,1\}name *= *['\''"]\([a-zA-Z0-9_/.+=,@~-]*\)['\''"][^)]*)/\
type:\1 name:\3\
/g' \
      | "grep" -E "^type:$kind_pattern name:$target_prefix" \
      | cut -d ':' -f 3
}


# Usage: _bazel__is_true <string>
#
# Returns true or false based on the input string. The following are
# valid true values (the rest are false): "1", "true".
_bazel__is_true() {
  local str="$1"
  [[ "$str" == "1" || "$str" == "true" ]]
}

# Usage: _bazel__expand_rules_in_package <workspace> <displacement>
#                                        <current> <label-type>
#
# Expands rules in specified packages, exploring all roots of
# $BAZEL_COMPLETION_PACKAGE_PATH, not just $(pwd).  Only rules
# appropriate to the command are printed.  Sets $COMPREPLY array to
# result.
#
# If _bazel_completion_use_query has a successful exit code, 'bazel query' is
# used instead, with the actual Bazel package path;
# $BAZEL_COMPLETION_PACKAGE_PATH is ignored in this case, since the actual Bazel
# value is likely to be more accurate.
_bazel__expand_rules_in_package() {
  local workspace=$1 displacement=$2 current=$3 label_type=$4
  local package_name=$(echo "$current" | cut -f1 -d:)
  local rule_prefix=$(echo "$current" | cut -f2 -d:)
  local root buildfile rule_pattern r result

  result=
  pattern=$(_bazel__get_rule_match_pattern "$label_type")
  if _bazel_completion_use_query; then
    package_name=$(echo "$package_name" | tr -d "'\"") # remove quotes
    result=$(${BAZEL} --output_base=/tmp/${BAZEL}-completion-$USER query \
                   --keep_going --noshow_progress --output=label \
      "kind('$pattern rule', '$package_name:*')" 2>/dev/null |
      cut -f2 -d: | "grep" "^$rule_prefix")
  else
    for root in $(_bazel__package_path "$workspace" "$displacement"); do
      buildfile="$root/$package_name/BUILD.bazel"
      if [ ! -f "$buildfile" ]; then
        buildfile="$root/$package_name/BUILD"
      fi
      if [ -f "$buildfile" ]; then
        result=$(_bazel__matching_targets \
                   "$pattern" "$rule_prefix" <"$buildfile")
        break
      fi
    done
  fi

  index=$(echo $result | wc -w)
  if [ -n "$result" ]; then
      echo "$result" | tr " " "\n" | sed 's|$| |'
  fi
  # Include ":all" wildcard if there was no unique match.  (The zero
  # case is tricky: we need to include "all" in that case since
  # otherwise we won't expand "a" to "all" in the absence of rules
  # starting with "a".)
  if [ $index -ne 1 ] && expr all : "\\($rule_prefix\\)" >/dev/null; then
    echo "all "
  fi
}

# Usage: _bazel__expand_package_name <workspace> <displacement> <current-word>
#                                    <label-type>
#
# Expands directories, but explores all roots of
# BAZEL_COMPLETION_PACKAGE_PATH, not just $(pwd).  When a directory is
# a bazel package, the completion offers "pkg:" so you can expand
# inside the package.
# Sets $COMPREPLY array to result.
_bazel__expand_package_name() {
  local workspace=$1 displacement=$2 current=$3 type=${4:-} root dir index
  for root in $(_bazel__package_path "$workspace" "$displacement"); do
    found=0
    for dir in $(compgen -d $root$current); do
      [ -L "$dir" ] && continue  # skip symlinks (e.g. bazel-bin)
      [[ "$dir" =~ ^(.*/)?\.[^/]*$ ]] && continue  # skip dotted dir (e.g. .git)
      found=1
      echo "${dir#$root}/"
      if [ -f $dir/BUILD.bazel -o -f $dir/BUILD ]; then
        if [ "${type}" = "label-package" ]; then
          echo "${dir#$root} "
        else
          echo "${dir#$root}:"
        fi
      fi
    done
    [ $found -gt 0 ] && break  # Stop searching package path upon first match.
  done
}

# Usage: _bazel__expand_target_pattern <workspace> <displacement>
#                                      <word> <label-syntax>
#
# Expands "word" to match target patterns, using the current workspace
# and displacement from it.  "command" is used to filter rules.
# Sets $COMPREPLY array to result.
_bazel__expand_target_pattern() {
  local workspace=$1 displacement=$2 current=$3 label_syntax=$4
  case "$current" in
    //*:*) # Expand rule names within package, no displacement.
      if [ "${label_syntax}" = "label-package" ]; then
        compgen -S " " -W "BUILD" "$(echo current | cut -f ':' -d2)"
      else
        _bazel__expand_rules_in_package "$workspace" "" "$current" "$label_syntax"
      fi
      ;;
    *:*) # Expand rule names within package, displaced.
      if [ "${label_syntax}" = "label-package" ]; then
        compgen -S " " -W "BUILD" "$(echo current | cut -f ':' -d2)"
      else
        _bazel__expand_rules_in_package \
          "$workspace" "$displacement" "$current" "$label_syntax"
      fi
      ;;
    //*) # Expand filenames using package-path, no displacement
      _bazel__expand_package_name "$workspace" "" "$current" "$label_syntax"
      ;;
    *) # Expand filenames using package-path, displaced.
      if [ -n "$current" ]; then
        _bazel__expand_package_name "$workspace" "$displacement" "$current" "$label_syntax"
      fi
      ;;
  esac
}

_bazel__get_command() {
  for word in "${COMP_WORDS[@]:1:COMP_CWORD-1}"; do
    if echo "$BAZEL_COMMAND_LIST" | "grep" -wsq -e "$word"; then
      echo $word
      break
    fi
  done
}

# Returns the displacement to the workspace given in $1
_bazel__get_displacement() {
  if [[ "$PWD" =~ ^$1/.*$ ]]; then
    echo ${PWD##$1/}/
  fi
}


# Usage: _bazel__complete_pattern <workspace> <displacement> <current>
#                                 <type>
#
# Expand a word according to a type. The currently supported types are:
#  - {a,b,c}: an enum that can take value a, b or c
#  - label: a label of any kind
#  - label-bin: a label to a runnable rule (basically to a _binary rule)
#  - label-test: a label to a test rule
#  - info-key: an info key as listed by `bazel help info-keys`
#  - command: the name of a command
#  - path: a file path
#  - combinaison of previous type using | as separator
_bazel__complete_pattern() {
  local workspace=$1 displacement=$2 current=$3 types=$4
  for type in $(echo $types | tr "|" "\n"); do
    case "$type" in
      label*)
        _bazel__expand_target_pattern "$workspace" "$displacement" \
            "$current" "$type"
        ;;
      info-key)
    compgen -S " " -W "${BAZEL_INFO_KEYS}" -- "$current"
        ;;
      "command")
        local commands=$(echo "${BAZEL_COMMAND_LIST}" \
          | tr " " "\n" | "grep" -v "^${BAZEL_IGNORED_COMMAND_REGEX}$")
    compgen -S " " -W "${commands}" -- "$current"
        ;;
      path)
        compgen -f -- "$current"
        ;;
      *)
        compgen -S " " -W "$type" -- "$current"
        ;;
    esac
  done
}

# Usage: _bazel__expand_options <workspace> <displacement> <current-word>
#                               <options>
#
# Expands options, making sure that if current-word contains an equals sign,
# it is handled appropriately.
_bazel__expand_options() {
  local workspace="$1" displacement="$2" cur="$3" options="$4"
  if [[ $cur =~ = ]]; then
    # also expands special labels
    current=$(echo "$cur" | cut -f2 -d=)
    _bazel__complete_pattern "$workspace" "$displacement" "$current" \
    "$(compgen -W "$options" -- "$cur" | cut -f2 -d=)" \
        | sort -u
  else
    compgen -W "$(echo "$options" | sed 's|=.*$|=|')" -- "$cur" \
    | sed 's|\([^=]\)$|\1 |'
  fi
}

# Usage: _bazel__abspath <file>
#
#
# Returns the absolute path to a file
_bazel__abspath() {
    echo "$(cd "$(dirname "$1")"; pwd)/$(basename "$1")"
 }

# Usage: _bazel__rc_imports <workspace> <rc-file>
#
#
# Returns the list of other RC imported (or try-imported) by a given RC file
# Only return files we can actually find, and only return absolute paths
_bazel__rc_imports() {
  local workspace="$1" rc_dir rc_file="$2" import_files
  rc_dir=$(dirname $rc_file)
  import_files=$(cat $rc_file \
      | sed 's/#.*//' \
      | sed -E "/^(try-){0,1}import/!d" \
      | sed -E "s/^(try-){0,1}import ([^ ]*).*$/\2/" \
      | sort -u)

  local confirmed_import_files=()
  for import in $import_files; do
    # rc imports can use %workspace% to refer to the workspace, and we need to substitute that here
    import=${import//\%workspace\%/$workspace}
    if [[ "${import:0:1}" != "/" ]] ; then
      import="$rc_dir/$import"
    fi
    import=$(_bazel__abspath $import)
    # Don't bother dealing with it further if we can't find it
    if [ -f "$import" ] ; then
      confirmed_import_files+=($import)
    fi
  done
  echo "${confirmed_import_files[@]}"
}

# Usage: _bazel__rc_expand_imports <workspace> <processed-rc-files ...> __new__ <new-rc-files ...>
#
#
# Function that receives a workspace and two lists. The first list is a list of RC files that have
# already been processed, and the second list contains new RC files that need processing. Each new file will be
# processed for "{try-}import" lines to discover more RC files that need parsing.
# Any lines we find in "{try-}import" will be checked against known files (and not processed again if known).
_bazel__rc_expand_imports() {
  local workspace="$1" rc_file new_found="no" processed_files=() to_process_files=() discovered_files=()
  # We've consumed workspace
  shift
  # Now grab everything else
  local all_files=($@)
  for rc_file in ${all_files[@]} ; do
    if [ "$rc_file" == "__new__" ] ; then
      new_found="yes"
      continue
    elif [ "$new_found" == "no" ] ; then
      processed_files+=($rc_file)
    else
      to_process_files+=($rc_file)
    fi
  done

  # For all the non-processed files, get the list of imports out of each of those files
  for rc_file in "${to_process_files[@]}"; do
    local potential_new_files+=($(_bazel__rc_imports "$workspace" "$rc_file"))
    processed_files+=($rc_file)
    for potential_new_file in ${potential_new_files[@]} ; do
      if [[ ! " ${processed_files[@]} " =~ " ${potential_new_file} " ]] ; then
        discovered_files+=($potential_new_file)
      fi
    done
  done

  # Finally, return two lists (separated by __new__) of the files that have been fully processed, and
  # the files that need processing.
  echo "${processed_files[@]}" "__new__" "${discovered_files[@]}"
}

# Usage: _bazel__rc_files <workspace>
#
#
# Returns the list of RC files to examine, given the current command-line args.
_bazel__rc_files() {
  local workspace="$1" new_files=() processed_files=()
  # Handle the workspace RC unless --noworkspace_rc says not to.
  if [[ ! "${COMP_LINE}" =~ "--noworkspace_rc" ]]; then
    local workspacerc="$workspace/.bazelrc"
    if [ -f "$workspacerc" ] ; then
      new_files+=($(_bazel__abspath $workspacerc))
    fi
  fi
  # Handle the $HOME RC unless --nohome_rc says not to.
  if [[ ! "${COMP_LINE}" =~ "--nohome_rc" ]]; then
    local homerc="$HOME/.bazelrc"
    if [ -f "$homerc" ] ; then
      new_files+=($(_bazel__abspath $homerc))
    fi
  fi
  # Handle the system level RC unless --nosystem_rc says not to.
  if [[ ! "${COMP_LINE}" =~ "--nosystem_rc" ]]; then
    local systemrc="/etc/bazel.bazelrc"
    if [ -f "$systemrc" ] ; then
      new_files+=($(_bazel__abspath $systemrc))
    fi
  fi
  # Finally, if the user specified any on the command-line, then grab those
  # keeping in mind that there may be several.
  if [[ "${COMP_LINE}" =~ "--bazelrc=" ]]; then
    # There's got to be a better way to do this, but... it gets the job done,
    # even if there are multiple --bazelrc on the command line. The sed command
    # SHOULD be simpler, but capturing several instances of the same pattern
    # from the same line is tricky because of the greedy nature of .*
    # Instead we transform it to multiple lines, and then back.
    local cmdlnrcs=$(echo ${COMP_LINE} | sed -E "s/--bazelrc=/\n--bazelrc=/g" | sed -E "/--bazelrc/!d;s/^--bazelrc=([^ ]*).*$/\1/g" | tr "\n" " ")
    for rc_file in $cmdlnrcs; do
      if [ -f "$rc_file" ] ; then
        new_files+=($(_bazel__abspath $rc_file))
      fi
    done
  fi

  # Each time we call _bazel__rc_expand_imports, it may find new files which then need to be expanded as well,
  # so we loop until we've processed all new files.
  while (( ${#new_files[@]} > 0 )) ; do
    local all_files=($(_bazel__rc_expand_imports "$workspace" "${processed_files[@]}" "__new__" "${new_files[@]}"))
    local new_found="no"
    new_files=()
    processed_files=()
    for file in ${all_files[@]} ; do
      if [ "$file" == "__new__" ] ; then
        new_found="yes"
        continue
      elif [ "$new_found" == "no" ] ; then
        processed_files+=($file)
      else
        new_files+=($file)
      fi
    done
  done

  echo "${processed_files[@]}"
}

# Usage: _bazel__all_configs <workspace> <command>
#
#
# Gets contents of all RC files and searches them for config names
# that could be used for expansion.
_bazel__all_configs() {
  local workspace="$1" command="$2" rc_files

  # Start out getting a list of all RC files that we can look for configs in
  # This respects the various command line options documented at
  # https://docs.bazel.build/versions/2.0.0/guide.html#bazelrc
  rc_files=$(_bazel__rc_files "$workspace")

  # Commands can inherit configs from other commands, so build up command_match, which is
  # a match list of the various commands that we can match against, given the command
  # specified by the user
  local build_inherit=("aquery" "clean" "coverage" "cquery" "info" "mobile-install" "print_action" "run" "test")
  local test_inherit=("coverage")
  local command_match="$command"
  if [[ "${build_inherit[@]}" =~ "$command" ]]; then
    command_match="$command_match|build"
  fi
  if [[ "${test_inherit[@]}" =~ "$command" ]]; then
    command_match="$command_match|test"
  fi

  # The following commands do respectively:
  #   Gets the contents of all relevant/allowed RC files
  #   Remove file comments
  #   Filter only the configs relevant to the current command
  #   Extract the config names
  #   Filters out redundant names and returns the results
  cat $rc_files \
      | sed 's/#.*//' \
      | sed -E "/^($command_match):/!d" \
      | sed -E "s/^($command_match):([^ ]*).*$/\2/" \
      | sort -u
}

# Usage: _bazel__expand_config <workspace> <command> <current-word>
#
#
# Expands configs, checking through the allowed rc files and parsing for configs
# relevant to the current command
_bazel__expand_config() {
  local workspace="$1" command="$2" cur="$3" rc_files all_configs
  all_configs=$(_bazel__all_configs "$workspace" "$command")
  compgen -S " " -W "$all_configs" -- "$cur"
}

_bazel__complete_stdout() {
  local cur=$(_bazel__get_cword) word command displacement workspace

  # Determine command: "" (startup-options) or one of $BAZEL_COMMAND_LIST.
  command="$(_bazel__get_command)"

  workspace="$(_bazel__get_workspace_path)"
  displacement="$(_bazel__get_displacement ${workspace})"

  case "$command" in
    "") # Expand startup-options or commands
      local commands=$(echo "${BAZEL_COMMAND_LIST}" \
        | tr " " "\n" | "grep" -v "^${BAZEL_IGNORED_COMMAND_REGEX}$")
      _bazel__expand_options  "$workspace" "$displacement" "$cur" \
          "${commands}\
          ${BAZEL_STARTUP_OPTIONS}"
      ;;

    *)
      case "$cur" in
        --config=*) # Expand options:
          _bazel__expand_config  "$workspace" "$command" "${cur#"--config="}"
          ;;
        -*) # Expand options:
          _bazel__expand_options  "$workspace" "$displacement" "$cur" \
              "$(_bazel__options_for $command)"
          ;;
        *)  # Expand target pattern
      expansion_pattern="$(_bazel__expansion_for $command)"
          NON_QUOTE_REGEX="^[\"']"
          if [[ $command = query && $cur =~ $NON_QUOTE_REGEX ]]; then
            : # Ideally we would expand query expressions---it's not
              # that hard, conceptually---but readline is just too
              # damn complex when it comes to quotation.  Instead,
              # for query, we just expand target patterns, unless
              # the first char is a quote.
          elif [ -n "$expansion_pattern" ]; then
            _bazel__complete_pattern \
        "$workspace" "$displacement" "$cur" "$expansion_pattern"
          fi
          ;;
      esac
      ;;
  esac
}

_bazel__to_compreply() {
  local replies="$1"
  COMPREPLY=()
  # Trick to preserve whitespaces
  while IFS="" read -r reply; do
    COMPREPLY+=("${reply}")
  done < <(echo "${replies}")
  # Null may be set despite there being no completions
  if [ ${#COMPREPLY[@]} -eq 1 ] && [ -z ${COMPREPLY[0]} ]; then
    COMPREPLY=()
  fi
}

_bazel__complete() {
  _bazel__to_compreply "$(_bazel__complete_stdout)"
}

# Some users have aliases such as bt="bazel test" or bb="bazel build", this
# completion function allows them to have auto-completion for these aliases.
_bazel__complete_target_stdout() {
  local cur=$(_bazel__get_cword) word command displacement workspace

  # Determine command: "" (startup-options) or one of $BAZEL_COMMAND_LIST.
  command="$1"

  workspace="$(_bazel__get_workspace_path)"
  displacement="$(_bazel__get_displacement ${workspace})"

  _bazel__to_compreply "$(_bazel__expand_target_pattern "$workspace" "$displacement" \
      "$cur" "$(_bazel__expansion_for $command)")"
}
#!/bin/bash
#
# Copyright 2015 The Bazel Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Common utility file for Bazel shell tests
#
# unittest.bash: a unit test framework in Bash.
#
# A typical test suite looks like so:
#
#   ------------------------------------------------------------------------
#   #!/bin/bash
#
#   source path/to/unittest.bash || exit 1
#
#   # Test that foo works.
#   function test_foo() {
#     foo >$TEST_log || fail "foo failed";
#     expect_log "blah" "Expected to see 'blah' in output of 'foo'."
#   }
#
#   # Test that bar works.
#   function test_bar() {
#     bar 2>$TEST_log || fail "bar failed";
#     expect_not_log "ERROR" "Unexpected error from 'bar'."
#     ...
#     assert_equals $x $y
#   }
#
#   run_suite "Test suite for blah"
#   ------------------------------------------------------------------------
#
# Each test function is considered to pass iff fail() is not called
# while it is active.  fail() may be called directly, or indirectly
# via other assertions such as expect_log().  run_suite must be called
# at the very end.
#
# A test suite may redefine functions "set_up" and/or "tear_down";
# these functions are executed before and after each test function,
# respectively.  Similarly, "cleanup" and "timeout" may be redefined,
# and these function are called upon exit (of any kind) or a timeout.
#
# The user can pass --test_arg to blaze test to select specific tests
# to run. Specifying --test_arg multiple times allows to select several
# tests to be run in the given order. Additionally the user may define
# TESTS=(test_foo test_bar ...) to specify a subset of test functions to
# execute, for example, a working set during debugging. By default, all
# functions called test_* will be executed.
#
# This file provides utilities for assertions over the output of a
# command.  The output of the command under test is directed to the
# file $TEST_log, and then the expect_log* assertions can be used to
# test for the presence of certain regular expressions in that file.
#
# The test framework is responsible for restoring the original working
# directory before each test.
#
# The order in which test functions are run is not defined, so it is
# important that tests clean up after themselves.
#
# Each test will be run in a new subshell.
#
# Functions named __* are not intended for use by clients.
#
# This framework implements the "test sharding protocol".
#

[ -n "$BASH_VERSION" ] ||
  { echo "unittest.bash only works with bash!" >&2; exit 1; }

export BAZEL_SHELL_TEST=1

DIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)

#### Configuration variables (may be overridden by testenv.sh or the suite):

# This function may be called by testenv.sh or a test suite to enable errexit
# in a way that enables us to print pretty stack traces when something fails.
function enable_errexit() {
  set -o errtrace
  set -eu
  trap __test_terminated_err ERR
}

function disable_errexit() {
  set +o errtrace
  set +eu
  trap - ERR
}

# Load the environment support utilities.
source "${DIR}/unittest_utils.sh" || { echo "unittest_utils.sh not found" >&2; exit 1; }

#### Global variables:

TEST_name=""                    # The name of the current test.

TEST_log=$TEST_TMPDIR/log       # The log file over which the
                                # expect_log* assertions work.  Must
                                # be absolute to be robust against
                                # tests invoking 'cd'!

TEST_passed="true"              # The result of the current test;
                                # failed assertions cause this to
                                # become false.

# These variables may be overridden by the test suite:

TESTS=()                        # A subset or "working set" of test
                                # functions that should be run.  By
                                # default, all tests called test_* are
                                # run.
if [ $# -gt 0 ]; then
  # Legacy behavior is to ignore missing regexp, but with errexit
  # the following line fails without || true.
  # TODO(dmarting): maybe we should revisit the way of selecting
  # test with that framework (use Bazel's environment variable instead).
  TESTS=($(for i in $@; do echo $i; done | grep ^test_ || true))
  if (( ${#TESTS[@]} == 0 )); then
    echo "WARNING: Arguments do not specify tests!" >&2
  fi
fi
# TESTBRIDGE_TEST_ONLY contains the value of --test_filter, if any. We want to
# preferentially use that instead of $@ to determine which tests to run.
if [[ ${TESTBRIDGE_TEST_ONLY:-} != "" ]]; then
  # Split TESTBRIDGE_TEST_ONLY on comma and put the results into an array.
  IFS=',' read -r -a TESTS <<< "$TESTBRIDGE_TEST_ONLY"
fi

TEST_verbose="true"             # Whether or not to be verbose.  A
                                # command; "true" or "false" are
                                # acceptable.  The default is: true.

TEST_script="$0"                # Full path to test script
# Check if the script path is absolute, if not prefix the PWD.
if [[ ! "$TEST_script" = /* ]]; then
  TEST_script="$(pwd)/$0"
fi


#### Internal functions

function __show_log() {
    echo "-- Test log: -----------------------------------------------------------"
    [[ -e $TEST_log ]] && cat $TEST_log || echo "(Log file did not exist.)"
    echo "------------------------------------------------------------------------"
}

# Usage: __pad <title> <pad-char>
# Print $title padded to 80 columns with $pad_char.
function __pad() {
    local title=$1
    local pad=$2
    {
        echo -n "$pad$pad $title "
        printf "%80s" " " | tr ' ' "$pad"
    } | head -c 80
    echo
}

#### Exported functions

# Usage: init_test ...
# Deprecated.  Has no effect.
function init_test() {
    :
}


# Usage: set_up
# Called before every test function.  May be redefined by the test suite.
function set_up() {
    :
}

# Usage: tear_down
# Called after every test function.  May be redefined by the test suite.
function tear_down() {
    :
}

# Usage: cleanup
# Called upon eventual exit of the test suite.  May be redefined by
# the test suite.
function cleanup() {
    :
}

# Usage: timeout
# Called upon early exit from a test due to timeout.
function timeout() {
    :
}

# Usage: testenv_set_up
# Called prior to set_up. For use by testenv.sh.
function testenv_set_up() {
    :
}

# Usage: testenv_tear_down
# Called after tear_down. For use by testenv.sh.
function testenv_tear_down() {
    :
}

# Usage: fail <message> [<message> ...]
# Print failure message with context information, and mark the test as
# a failure.  The context includes a stacktrace including the longest sequence
# of calls outside this module.  (We exclude the top and bottom portions of
# the stack because they just add noise.)  Also prints the contents of
# $TEST_log.
function fail() {
    __show_log >&2
    echo "$TEST_name FAILED:" "$@" "." >&2
    echo "$@" >$TEST_TMPDIR/__fail
    TEST_passed="false"
    __show_stack
    # Cleanup as we are leaving the subshell now
    tear_down
    testenv_tear_down
    exit 1
}

# Usage: warn <message>
# Print a test warning with context information.
# The context includes a stacktrace including the longest sequence
# of calls outside this module.  (We exclude the top and bottom portions of
# the stack because they just add noise.)
function warn() {
    __show_log >&2
    echo "$TEST_name WARNING: $1." >&2
    __show_stack

    if [ -n "${TEST_WARNINGS_OUTPUT_FILE:-}" ]; then
      echo "$TEST_name WARNING: $1." >> "$TEST_WARNINGS_OUTPUT_FILE"
    fi
}

# Usage: show_stack
# Prints the portion of the stack that does not belong to this module,
# i.e. the user's code that called a failing assertion.  Stack may not
# be available if Bash is reading commands from stdin; an error is
# printed in that case.
__show_stack() {
    local i=0
    local trace_found=0

    # Skip over active calls within this module:
    while (( i < ${#FUNCNAME[@]} )) && [[ ${BASH_SOURCE[i]:-} == ${BASH_SOURCE[0]} ]]; do
       (( ++i ))
    done

    # Show all calls until the next one within this module (typically run_suite):
    while (( i < ${#FUNCNAME[@]} )) && [[ ${BASH_SOURCE[i]:-} != ${BASH_SOURCE[0]} ]]; do
        # Read online docs for BASH_LINENO to understand the strange offset.
        # Undefined can occur in the BASH_SOURCE stack apparently when one exits from a subshell
        echo "${BASH_SOURCE[i]:-"Unknown"}:${BASH_LINENO[i - 1]:-"Unknown"}: in call to ${FUNCNAME[i]:-"Unknown"}" >&2
        (( ++i ))
        trace_found=1
    done

    [ $trace_found = 1 ] || echo "[Stack trace not available]" >&2
}

# Usage: expect_log <regexp> [error-message]
# Asserts that $TEST_log matches regexp.  Prints the contents of
# $TEST_log and the specified (optional) error message otherwise, and
# returns non-zero.
function expect_log() {
    local pattern=$1
    local message=${2:-Expected regexp "$pattern" not found}
    grep -sq -- "$pattern" $TEST_log && return 0

    fail "$message"
    return 1
}

# Usage: expect_log_warn <regexp> [error-message]
# Warns if $TEST_log does not match regexp.  Prints the contents of
# $TEST_log and the specified (optional) error message on mismatch.
function expect_log_warn() {
    local pattern=$1
    local message=${2:-Expected regexp "$pattern" not found}
    grep -sq -- "$pattern" $TEST_log && return 0

    warn "$message"
    return 1
}

# Usage: expect_log_once <regexp> [error-message]
# Asserts that $TEST_log contains one line matching <regexp>.
# Prints the contents of $TEST_log and the specified (optional)
# error message otherwise, and returns non-zero.
function expect_log_once() {
    local pattern=$1
    local message=${2:-Expected regexp "$pattern" not found exactly once}
    expect_log_n "$pattern" 1 "$message"
}

# Usage: expect_log_n <regexp> <count> [error-message]
# Asserts that $TEST_log contains <count> lines matching <regexp>.
# Prints the contents of $TEST_log and the specified (optional)
# error message otherwise, and returns non-zero.
function expect_log_n() {
    local pattern=$1
    local expectednum=${2:-1}
    local message=${3:-Expected regexp "$pattern" not found exactly $expectednum times}
    local count=$(grep -sc -- "$pattern" $TEST_log)
    [[ $count = $expectednum ]] && return 0
    fail "$message"
    return 1
}

# Usage: expect_not_log <regexp> [error-message]
# Asserts that $TEST_log does not match regexp.  Prints the contents
# of $TEST_log and the specified (optional) error message otherwise, and
# returns non-zero.
function expect_not_log() {
    local pattern=$1
    local message=${2:-Unexpected regexp "$pattern" found}
    grep -sq -- "$pattern" $TEST_log || return 0

    fail "$message"
    return 1
}

# Usage: expect_query_targets <arguments>
# Checks that log file contains exactly the targets in the argument list.
function expect_query_targets() {
  for arg in $@; do
    expect_log_once "^$arg$"
  done

# Checks that the number of lines started with '//' equals to the number of
# arguments provided.
  expect_log_n "^//[^ ]*$" $#
}

# Usage: expect_log_with_timeout <regexp> <timeout> [error-message]
# Waits for the given regexp in the $TEST_log for up to timeout seconds.
# Prints the contents of $TEST_log and the specified (optional)
# error message otherwise, and returns non-zero.
function expect_log_with_timeout() {
    local pattern=$1
    local timeout=$2
    local message=${3:-Regexp "$pattern" not found in "$timeout" seconds}
    local count=0
    while [ $count -lt $timeout ]; do
      grep -sq -- "$pattern" $TEST_log && return 0
      let count=count+1
      sleep 1
    done

    grep -sq -- "$pattern" $TEST_log && return 0
    fail "$message"
    return 1
}

# Usage: expect_cmd_with_timeout <expected> <cmd> [timeout]
# Repeats the command once a second for up to timeout seconds (10s by default),
# until the output matches the expected value. Fails and returns 1 if
# the command does not return the expected value in the end.
function expect_cmd_with_timeout() {
    local expected="$1"
    local cmd="$2"
    local timeout=${3:-10}
    local count=0
    while [ $count -lt $timeout ]; do
      local actual="$($cmd)"
      [ "$expected" = "$actual" ] && return 0
      let count=count+1
      sleep 1
    done

    [ "$expected" = "$actual" ] && return 0
    fail "Expected '$expected' within ${timeout}s, was '$actual'"
    return 1
}

# Usage: assert_one_of <expected_list>... <actual>
# Asserts that actual is one of the items in expected_list
#
# Example:
#     local expected=( "foo", "bar", "baz" )
#     assert_one_of $expected $actual
function assert_one_of() {
    local args=("$@")
    local last_arg_index=$((${#args[@]} - 1))
    local actual=${args[last_arg_index]}
    unset args[last_arg_index]
    for expected_item in "${args[@]}"; do
      [ "$expected_item" = "$actual" ] && return 0
    done;

    fail "Expected one of '${args[*]}', was '$actual'"
    return 1
}

# Usage: assert_not_one_of <expected_list>... <actual>
# Asserts that actual is not one of the items in expected_list
#
# Example:
#     local unexpected=( "foo", "bar", "baz" )
#     assert_not_one_of $unexpected $actual
function assert_not_one_of() {
    local args=("$@")
    local last_arg_index=$((${#args[@]} - 1))
    local actual=${args[last_arg_index]}
    unset args[last_arg_index]
    for expected_item in "${args[@]}"; do
      if [ "$expected_item" = "$actual" ]; then
        fail "'${args[*]}' contains '$actual'"
        return 1
      fi
    done;

    return 0
}

# Usage: assert_equals <expected> <actual>
# Asserts [ expected = actual ].
function assert_equals() {
    local expected=$1 actual=$2
    [ "$expected" = "$actual" ] && return 0

    fail "Expected '$expected', was '$actual'"
    return 1
}

# Usage: assert_not_equals <unexpected> <actual>
# Asserts [ unexpected != actual ].
function assert_not_equals() {
    local unexpected=$1 actual=$2
    [ "$unexpected" != "$actual" ] && return 0;

    fail "Expected not '$unexpected', was '$actual'"
    return 1
}

# Usage: assert_contains <regexp> <file> [error-message]
# Asserts that file matches regexp.  Prints the contents of
# file and the specified (optional) error message otherwise, and
# returns non-zero.
function assert_contains() {
    local pattern=$1
    local file=$2
    local message=${3:-Expected regexp "$pattern" not found in "$file"}
    grep -sq -- "$pattern" "$file" && return 0

    cat "$file" >&2
    fail "$message"
    return 1
}

# Usage: assert_not_contains <regexp> <file> [error-message]
# Asserts that file does not match regexp.  Prints the contents of
# file and the specified (optional) error message otherwise, and
# returns non-zero.
function assert_not_contains() {
    local pattern=$1
    local file=$2
    local message=${3:-Expected regexp "$pattern" found in "$file"}

    if [[ -f "$file" ]]; then
      grep -sq -- "$pattern" "$file" || return 0
    else
      fail "$file is not a file: $message"
      return 1
    fi

    cat "$file" >&2
    fail "$message"
    return 1
}

function assert_contains_n() {
    local pattern=$1
    local expectednum=${2:-1}
    local file=$3
    local message=${4:-Expected regexp "$pattern" not found exactly $expectednum times}
    local count
    if [[ -f "$file" ]]; then
      count=$(grep -sc -- "$pattern" "$file")
    else
      fail "$file is not a file: $message"
      return 1
    fi
    [[ $count = $expectednum ]] && return 0

    cat "$file" >&2
    fail "$message"
    return 1
}

# Updates the global variables TESTS if
# sharding is enabled, i.e. ($TEST_TOTAL_SHARDS > 0).
function __update_shards() {
    [ -z "${TEST_TOTAL_SHARDS-}" ] && return 0

    [ "$TEST_TOTAL_SHARDS" -gt 0 ] ||
      { echo "Invalid total shards $TEST_TOTAL_SHARDS" >&2; exit 1; }

    [ "$TEST_SHARD_INDEX" -lt 0 -o "$TEST_SHARD_INDEX" -ge  "$TEST_TOTAL_SHARDS" ] &&
      { echo "Invalid shard $shard_index" >&2; exit 1; }

    TESTS=$(for test in "${TESTS[@]}"; do echo "$test"; done |
      awk "NR % $TEST_TOTAL_SHARDS == $TEST_SHARD_INDEX")

    [ -z "${TEST_SHARD_STATUS_FILE-}" ] || touch "$TEST_SHARD_STATUS_FILE"
}

# Usage: __test_terminated <signal-number>
# Handler that is called when the test terminated unexpectedly
function __test_terminated() {
    __show_log >&2
    echo "$TEST_name FAILED: terminated by signal $1." >&2
    TEST_passed="false"
    __show_stack
    timeout
    exit 1
}

# Usage: __test_terminated_err
# Handler that is called when the test terminated unexpectedly due to "errexit".
function __test_terminated_err() {
    # When a subshell exits due to signal ERR, its parent shell also exits,
    # thus the signal handler is called recursively and we print out the
    # error message and stack trace multiple times. We're only interested
    # in the first one though, as it contains the most information, so ignore
    # all following.
    if [[ -f $TEST_TMPDIR/__err_handled ]]; then
      exit 1
    fi
    __show_log >&2
    if [[ ! -z "$TEST_name" ]]; then
      echo -n "$TEST_name " >&2
    fi
    echo "FAILED: terminated because this command returned a non-zero status:" >&2
    touch $TEST_TMPDIR/__err_handled
    TEST_passed="false"
    __show_stack
    # If $TEST_name is still empty, the test suite failed before we even started
    # to run tests, so we shouldn't call tear_down.
    if [[ ! -z "$TEST_name" ]]; then
      tear_down
      testenv_tear_down
    fi
    exit 1
}

# Usage: __trap_with_arg <handler> <signals ...>
# Helper to install a trap handler for several signals preserving the signal
# number, so that the signal number is available to the trap handler.
function __trap_with_arg() {
    func="$1" ; shift
    for sig ; do
        trap "$func $sig" "$sig"
    done
}

# Usage: <node> <block>
# Adds the block to the given node in the report file. Quotes in the in
# arguments need to be escaped.
function __log_to_test_report() {
    local node="$1"
    local block="$2"
    if [[ ! -e "$XML_OUTPUT_FILE" ]]; then
        local xml_header='<?xml version="1.0" encoding="UTF-8"?>'
        echo "$xml_header<testsuites></testsuites>" > $XML_OUTPUT_FILE
    fi

    # replace match on node with block and match
    # replacement expression only needs escaping for quotes
    perl -e "\
\$input = @ARGV[0]; \
\$/=undef; \
open FILE, '+<$XML_OUTPUT_FILE'; \
\$content = <FILE>; \
if (\$content =~ /($node.*)\$/) { \
  seek FILE, 0, 0; \
  print FILE \$\` . \$input . \$1; \
}; \
close FILE" "$block"
}

# Usage: <total> <passed>
# Adds the test summaries to the xml nodes.
function __finish_test_report() {
    local suite_name="$1"
    local total="$2"
    local passed="$3"
    local failed=$((total - passed))

    # Update the xml output with the suite name and total number of
    # passed/failed tests.
    cat $XML_OUTPUT_FILE | \
      sed \
        "s/<testsuites>/<testsuites tests=\"$total\" failures=\"0\" errors=\"$failed\">/" | \
      sed \
        "s/<testsuite>/<testsuite name=\"${suite_name}\" tests=\"$total\" failures=\"0\" errors=\"$failed\">/" \
        > $XML_OUTPUT_FILE.bak

    rm -f $XML_OUTPUT_FILE
    mv $XML_OUTPUT_FILE.bak $XML_OUTPUT_FILE
}

# Multi-platform timestamp function
UNAME=$(uname -s | tr 'A-Z' 'a-z')
if [ "$UNAME" = "linux" ] || [[ "$UNAME" =~ msys_nt* ]]; then
    function timestamp() {
      echo $(($(date +%s%N)/1000000))
    }
elif [[ "$UNAME" = "openbsd" ]]; then
    function timestamp() {
      # OpenBSD does not have %N, so Python is the best we can do.
      python3 -c 'import time; print(int(round(time.time() * 1000)))'
    }
else
    function timestamp() {
      # OS X and FreeBSD do not have %N, so Python is the best we can do.
      python -c 'import time; print(int(round(time.time() * 1000)))'
    }
fi

function get_run_time() {
  local ts_start=$1
  local ts_end=$2
  run_time_ms=$((${ts_end}-${ts_start}))
  echo $(($run_time_ms/1000)).${run_time_ms: -3}
}

# Usage: run_tests <suite-comment>
# Must be called from the end of the user's test suite.
# Calls exit with zero on success, non-zero otherwise.
function run_suite() {
  local message="$1"
  # The name of the suite should be the script being run, which
  # will be the filename with the ".sh" extension removed.
  local suite_name="$(basename $0)"

  echo >&2
  echo "$message" >&2
  echo >&2

  __log_to_test_report "<\/testsuites>" "<testsuite></testsuite>"

  local total=0
  local passed=0

  atexit "cleanup"

  # If the user didn't specify an explicit list of tests (e.g. a
  # working set), use them all.
  if [ ${#TESTS[@]} -eq 0 ]; then
    # Even if there aren't any tests, this needs to succeed.
    TESTS=$(declare -F | awk '{print $3}' | grep ^test_ || true)
  elif [ -n "${TEST_WARNINGS_OUTPUT_FILE:-}" ]; then
    if grep -q "TESTS=" "$TEST_script" ; then
      echo "TESTS variable overridden in sh_test. Please remove before submitting" \
        >> "$TEST_WARNINGS_OUTPUT_FILE"
    fi
  fi

  # Reset TESTS in the common case where it contains a single empty string.
  if [ -z "${TESTS[*]}" ]; then
    TESTS=()
  fi
  local original_tests_size=${#TESTS[@]}

  __update_shards

  if [[ "${#TESTS[@]}" -ne 0 ]]; then
    for TEST_name in ${TESTS[@]}; do
      >$TEST_log # Reset the log.
      TEST_passed="true"

      total=$(($total + 1))
      if [[ "$TEST_verbose" == "true" ]]; then
          date >&2
          __pad $TEST_name '*' >&2
      fi

      local run_time="0.0"
      rm -f $TEST_TMPDIR/{__ts_start,__ts_end}

      if [ "$(type -t $TEST_name)" = function ]; then
        # Save exit handlers eventually set.
        local SAVED_ATEXIT="$ATEXIT";
        ATEXIT=

        # Run test in a subshell.
        rm -f $TEST_TMPDIR/__err_handled
        __trap_with_arg __test_terminated INT KILL PIPE TERM ABRT FPE ILL QUIT SEGV
        (
          timestamp >$TEST_TMPDIR/__ts_start
          testenv_set_up
          set_up
          eval $TEST_name
          tear_down
          testenv_tear_down
          timestamp >$TEST_TMPDIR/__ts_end
          test $TEST_passed == "true"
        ) 2>&1 | tee $TEST_TMPDIR/__log
        # Note that tee will prevent the control flow continuing if the test
        # spawned any processes which are still running and have not closed
        # their stdout.

        test_subshell_status=${PIPESTATUS[0]}
        if [ "$test_subshell_status" != 0 ]; then
          TEST_passed="false"
          # Ensure that an end time is recorded in case the test subshell
          # terminated prematurely.
          [ -f $TEST_TMPDIR/__ts_end ] || timestamp >$TEST_TMPDIR/__ts_end
        fi

        # Calculate run time for the testcase.
        local ts_start=$(cat $TEST_TMPDIR/__ts_start)
        local ts_end=$(cat $TEST_TMPDIR/__ts_end)
        run_time=$(get_run_time $ts_start $ts_end)

        # Eventually restore exit handlers.
        if [ -n "$SAVED_ATEXIT" ]; then
          ATEXIT="$SAVED_ATEXIT"
          trap "$ATEXIT" EXIT
        fi
      else # Bad test explicitly specified in $TESTS.
        fail "Not a function: '$TEST_name'"
      fi

      local testcase_tag=""

      local red='\033[0;31m'
      local green='\033[0;32m'
      local no_color='\033[0m'

      if [[ "$TEST_verbose" == "true" ]]; then
          echo >&2
      fi

      if [[ "$TEST_passed" == "true" ]]; then
        if [[ "$TEST_verbose" == "true" ]]; then
          echo -e "${green}PASSED${no_color}: $TEST_name" >&2
        fi
        passed=$(($passed + 1))
        testcase_tag="<testcase name=\"$TEST_name\" status=\"run\" time=\"$run_time\" classname=\"\"></testcase>"
      else
        echo -e "${red}FAILED${no_color}: $TEST_name" >&2
        # end marker in CDATA cannot be escaped, we need to split the CDATA sections
        log=$(cat $TEST_TMPDIR/__log | sed 's/]]>/]]>]]&gt;<![CDATA[/g')
        fail_msg=$(cat $TEST_TMPDIR/__fail 2> /dev/null || echo "No failure message")
        # Replacing '&' with '&amp;', '<' with '&lt;', '>' with '&gt;', and '"' with '&quot;'
        escaped_fail_msg=$(echo $fail_msg | sed 's/&/\&amp;/g' | sed 's/</\&lt;/g' | sed 's/>/\&gt;/g' | sed 's/"/\&quot;/g')
        testcase_tag="<testcase name=\"$TEST_name\" status=\"run\" time=\"$run_time\" classname=\"\"><error message=\"$escaped_fail_msg\"><![CDATA[$log]]></error></testcase>"
      fi

      if [[ "$TEST_verbose" == "true" ]]; then
          echo >&2
      fi
      __log_to_test_report "<\/testsuite>" "$testcase_tag"
    done
  fi

  __finish_test_report "$suite_name" $total $passed
  __pad "$passed / $total tests passed." '*' >&2
  if [ $original_tests_size -eq 0 ]; then
    __pad "No tests found." '*'
    exit 1
  elif [ $total -eq 0 ]; then
    __pad "No tests executed due to sharding. Check your test's shard_count." '*'
    __pad "Succeeding anyway." '*'
  fi
  [ $total = $passed ] || {
    __pad "There were errors." '*'
    exit 1
  } >&2

  exit 0
#!/bin/bash
#
# Copyright 2018 The Bazel Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
set -euo pipefail

function _log_base() {
  prefix=$1
  shift
  echo >&2 "${prefix}[$(basename "${BASH_SOURCE[0]}"):${BASH_LINENO[1]} ($(date "+%H:%M:%S %z"))] $*"
}

function fail() {
  _log_base "FAILED" "$@"
  exit 1
}

function log_fail() {
  # non-fatal version of fail()
  _log_base "FAILED" $*
}

function log_info() {
  _log_base "INFO" $*
}

which uname >&/dev/null || fail "cannot locate GNU coreutils"

case "$(uname -s | tr [:upper:] [:lower:])" in
msys*|mingw*|cygwin*)
  function is_windows() { true; }
  ;;
*)
  function is_windows() { false; }
  ;;
esac

function find_runfiles_lib() {
  # Unset existing definitions of the functions we want to test.
  if type rlocation >&/dev/null; then
    unset rlocation
    unset runfiles_export_envvars
  fi

  if [[ ! -d "${RUNFILES_DIR:-/dev/null}" && ! -f "${RUNFILES_MANIFEST_FILE:-/dev/null}" ]]; then
    if [[ -f "$0.runfiles_manifest" ]]; then
      export RUNFILES_MANIFEST_FILE="$0.runfiles_manifest"
    elif [[ -f "$0.runfiles/MANIFEST" ]]; then
      export RUNFILES_MANIFEST_FILE="$0.runfiles/MANIFEST"
    elif [[ -f "$0.runfiles/io_bazel/tools/bash/runfiles/runfiles.bash" ]]; then
      export RUNFILES_DIR="$0.runfiles"
    fi
  fi
  if [[ -f "${RUNFILES_DIR:-/dev/null}/io_bazel/tools/bash/runfiles/runfiles.bash" ]]; then
    echo "${RUNFILES_DIR}/io_bazel/tools/bash/runfiles/runfiles.bash"
  elif [[ -f "${RUNFILES_MANIFEST_FILE:-/dev/null}" ]]; then
    grep -m1 "^io_bazel/tools/bash/runfiles/runfiles.bash " \
        "$RUNFILES_MANIFEST_FILE" | cut -d ' ' -f 2-
  else
    echo >&2 "ERROR: cannot find //tools/bash/runfiles:runfiles.bash"
    exit 1
  fi
}

function test_rlocation_call_requires_no_envvars() {
  export RUNFILES_DIR=mock/runfiles
  export RUNFILES_MANIFEST_FILE=
  export RUNFILES_MANIFEST_ONLY=
  source "$runfiles_lib_path" || fail
}

function test_rlocation_argument_validation() {
  export RUNFILES_DIR=
  export RUNFILES_MANIFEST_FILE=
  export RUNFILES_MANIFEST_ONLY=
  source "$runfiles_lib_path"

  # Test invalid inputs to make sure rlocation catches these.
  if rlocation "../foo" >&/dev/null; then
    fail
  fi
  if rlocation "foo/.." >&/dev/null; then
    fail
  fi
  if rlocation "foo/../bar" >&/dev/null; then
    fail
  fi
  if rlocation "./foo" >&/dev/null; then
    fail
  fi
  if rlocation "foo/." >&/dev/null; then
    fail
  fi
  if rlocation "foo/./bar" >&/dev/null; then
    fail
  fi
  if rlocation "//foo" >&/dev/null; then
    fail
  fi
  if rlocation "foo//" >&/dev/null; then
    fail
  fi
  if rlocation "foo//bar" >&/dev/null; then
    fail
  fi
  if rlocation "\\foo" >&/dev/null; then
    fail
  fi
}

function test_rlocation_abs_path() {
  export RUNFILES_DIR=
  export RUNFILES_MANIFEST_FILE=
  export RUNFILES_MANIFEST_ONLY=
  source "$runfiles_lib_path"

  if is_windows; then
    [[ "$(rlocation "c:/Foo")" == "c:/Foo" ]] || fail
    [[ "$(rlocation "c:\\Foo")" == "c:\\Foo" ]] || fail
  else
    [[ "$(rlocation "/Foo")" == "/Foo" ]] || fail
  fi
}

function test_init_manifest_based_runfiles() {
  local tmpdir="$(mktemp -d $TEST_TMPDIR/tmp.XXXXXXXX)"
  cat > $tmpdir/foo.runfiles_manifest << EOF
a/b $tmpdir/c/d
e/f $tmpdir/g h
y $tmpdir/y
EOF
  mkdir "${tmpdir}/c"
  mkdir "${tmpdir}/y"
  touch "${tmpdir}/c/d" "${tmpdir}/g h"

  export RUNFILES_DIR=
  export RUNFILES_MANIFEST_FILE=$tmpdir/foo.runfiles_manifest
  source "$runfiles_lib_path"

  [[ -z "$(rlocation a)" ]] || fail
  [[ -z "$(rlocation c/d)" ]] || fail
  [[ "$(rlocation a/b)" == "$tmpdir/c/d" ]] || fail
  [[ "$(rlocation e/f)" == "$tmpdir/g h" ]] || fail
  [[ "$(rlocation y)" == "$tmpdir/y" ]] || fail
  rm -r "$tmpdir/c/d" "$tmpdir/g h" "$tmpdir/y"
  [[ -z "$(rlocation a/b)" ]] || fail
  [[ -z "$(rlocation e/f)" ]] || fail
  [[ -z "$(rlocation y)" ]] || fail
}

function test_manifest_based_envvars() {
  local tmpdir="$(mktemp -d $TEST_TMPDIR/tmp.XXXXXXXX)"
  echo "a b" > $tmpdir/foo.runfiles_manifest

  export RUNFILES_DIR=
  export RUNFILES_MANIFEST_FILE=$tmpdir/foo.runfiles_manifest
  mkdir -p $tmpdir/foo.runfiles
  source "$runfiles_lib_path"

  runfiles_export_envvars
  [[ "${RUNFILES_DIR:-}" == "$tmpdir/foo.runfiles" ]] || fail
  [[ "${RUNFILES_MANIFEST_FILE:-}" == "$tmpdir/foo.runfiles_manifest" ]] || fail
}

function test_init_directory_based_runfiles() {
  local tmpdir="$(mktemp -d $TEST_TMPDIR/tmp.XXXXXXXX)"

  export RUNFILES_DIR=${tmpdir}/mock/runfiles
  export RUNFILES_MANIFEST_FILE=
  source "$runfiles_lib_path"

  mkdir -p "$RUNFILES_DIR/a"
  touch "$RUNFILES_DIR/a/b" "$RUNFILES_DIR/c d"
  [[ "$(rlocation a)" == "$RUNFILES_DIR/a" ]] || fail
  [[ -z "$(rlocation c/d)" ]] || fail
  [[ "$(rlocation a/b)" == "$RUNFILES_DIR/a/b" ]] || fail
  [[ "$(rlocation "c d")" == "$RUNFILES_DIR/c d" ]] || fail
  [[ -z "$(rlocation "c")" ]] || fail
  rm -r "$RUNFILES_DIR/a" "$RUNFILES_DIR/c d"
  [[ -z "$(rlocation a)" ]] || fail
  [[ -z "$(rlocation a/b)" ]] || fail
  [[ -z "$(rlocation "c d")" ]] || fail
}

function test_directory_based_envvars() {
  export RUNFILES_DIR=mock/runfiles
  export RUNFILES_MANIFEST_FILE=
  source "$runfiles_lib_path"

  runfiles_export_envvars
  [[ "${RUNFILES_DIR:-}" == "mock/runfiles" ]] || fail
  [[ -z "${RUNFILES_MANIFEST_FILE:-}" ]] || fail
}

function main() {
  local -r manifest_file="${RUNFILES_MANIFEST_FILE:-}"
  local -r dir="${RUNFILES_DIR:-}"
  local -r runfiles_lib_path=$(find_runfiles_lib)

  local -r tests=$(declare -F | grep " -f test" | awk '{print $3}')
  local failure=0
  for t in $tests; do
    export RUNFILES_MANIFEST_FILE="$manifest_file"
    export RUNFILES_DIR="$dir"
    if ! ($t); then
      failure=1
    fi
  done
  return $failure
# Copyright 2018 The Bazel Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Runfiles lookup library for Bazel-built Bash binaries and tests, version 2.
#
# VERSION HISTORY:
# - version 2: Shorter init code.
#   Features:
#     - "set -euo pipefail" only at end of init code.
#       "set -e" breaks the source <path1> || source <path2> || ... scheme on
#       macOS, because it terminates if path1 does not exist.
#     - Not exporting any environment variables in init code.
#       This is now done in runfiles.bash itself.
#   Compatibility:
#     - The v1 init code can load the v2 library, i.e. if you have older source
#       code (still using v1 init) then you can build it with newer Bazel (which
#       contains the v2 library).
#     - The reverse is not true: the v2 init code CANNOT load the v1 library,
#       i.e. if your project (or any of its external dependencies) use v2 init
#       code, then you need a newer Bazel version (which contains the v2
#       library).
# - version 1: Original Bash runfiles library.
#
# ENVIRONMENT:
# - If RUNFILES_LIB_DEBUG=1 is set, the script will print diagnostic messages to
#   stderr.
#
# USAGE:
# 1.  Depend on this runfiles library from your build rule:
#
#       sh_binary(
#           name = "my_binary",
#           ...
#           deps = ["@bazel_tools//tools/bash/runfiles"],
#       )
#
# 2.  Source the runfiles library.
#
#     The runfiles library itself defines rlocation which you would need to look
#     up the library's runtime location, thus we have a chicken-and-egg problem.
#     Insert the following code snippet to the top of your main script:
#
#       # --- begin runfiles.bash initialization v2 ---
#       # Copy-pasted from the Bazel Bash runfiles library v2.
#       set -uo pipefail; f=bazel_tools/tools/bash/runfiles/runfiles.bash
#       source "${RUNFILES_DIR:-/dev/null}/$f" 2>/dev/null || \
#         source "$(grep -sm1 "^$f " "${RUNFILES_MANIFEST_FILE:-/dev/null}" | cut -f2- -d' ')" 2>/dev/null || \
#         source "$0.runfiles/$f" 2>/dev/null || \
#         source "$(grep -sm1 "^$f " "$0.runfiles_manifest" | cut -f2- -d' ')" 2>/dev/null || \
#         source "$(grep -sm1 "^$f " "$0.exe.runfiles_manifest" | cut -f2- -d' ')" 2>/dev/null || \
#         { echo>&2 "ERROR: cannot find $f"; exit 1; }; f=; set -e
#       # --- end runfiles.bash initialization v2 ---
#
#
# 3.  Use rlocation to look up runfile paths.
#
#       cat "$(rlocation my_workspace/path/to/my/data.txt)"
#

if [[ ! -d "${RUNFILES_DIR:-/dev/null}" && ! -f "${RUNFILES_MANIFEST_FILE:-/dev/null}" ]]; then
  if [[ -f "$0.runfiles_manifest" ]]; then
    export RUNFILES_MANIFEST_FILE="$0.runfiles_manifest"
  elif [[ -f "$0.runfiles/MANIFEST" ]]; then
    export RUNFILES_MANIFEST_FILE="$0.runfiles/MANIFEST"
  elif [[ -f "$0.runfiles/bazel_tools/tools/bash/runfiles/runfiles.bash" ]]; then
    export RUNFILES_DIR="$0.runfiles"
  fi
fi

case "$(uname -s | tr [:upper:] [:lower:])" in
msys*|mingw*|cygwin*)
  # matches an absolute Windows path
  export _RLOCATION_ISABS_PATTERN="^[a-zA-Z]:[/\\]"
  ;;
*)
  # matches an absolute Unix path
  export _RLOCATION_ISABS_PATTERN="^/[^/].*"
  ;;
esac

# Prints to stdout the runtime location of a data-dependency.
function rlocation() {
  if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
    echo >&2 "INFO[runfiles.bash]: rlocation($1): start"
  fi
  if [[ "$1" =~ $_RLOCATION_ISABS_PATTERN ]]; then
    if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
      echo >&2 "INFO[runfiles.bash]: rlocation($1): absolute path, return"
    fi
    # If the path is absolute, print it as-is.
    echo "$1"
  elif [[ "$1" == ../* || "$1" == */.. || "$1" == ./* || "$1" == */./* || "$1" == "*/." || "$1" == *//* ]]; then
    if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
      echo >&2 "ERROR[runfiles.bash]: rlocation($1): path is not normalized"
    fi
    return 1
  elif [[ "$1" == \\* ]]; then
    if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
      echo >&2 "ERROR[runfiles.bash]: rlocation($1): absolute path without" \
               "drive name"
    fi
    return 1
  else
    if [[ -e "${RUNFILES_DIR:-/dev/null}/$1" ]]; then
      if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
        echo >&2 "INFO[runfiles.bash]: rlocation($1): found under RUNFILES_DIR ($RUNFILES_DIR), return"
      fi
      echo "${RUNFILES_DIR}/$1"
    elif [[ -f "${RUNFILES_MANIFEST_FILE:-/dev/null}" ]]; then
      if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
        echo >&2 "INFO[runfiles.bash]: rlocation($1): looking in RUNFILES_MANIFEST_FILE ($RUNFILES_MANIFEST_FILE)"
      fi
      local -r result=$(grep -m1 "^$1 " "${RUNFILES_MANIFEST_FILE}" | cut -d ' ' -f 2-)
      if [[ -e "${result:-/dev/null}" ]]; then
        if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
          echo >&2 "INFO[runfiles.bash]: rlocation($1): found in manifest as ($result)"
        fi
        echo "$result"
      else
        if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
          echo >&2 "INFO[runfiles.bash]: rlocation($1): not found in manifest"
        fi
        echo ""
      fi
    else
      if [[ "${RUNFILES_LIB_DEBUG:-}" == 1 ]]; then
        echo >&2 "ERROR[runfiles.bash]: cannot look up runfile \"$1\" " \
                 "(RUNFILES_DIR=\"${RUNFILES_DIR:-}\"," \
                 "RUNFILES_MANIFEST_FILE=\"${RUNFILES_MANIFEST_FILE:-}\")"
      fi
      return 1
    fi
  fi
}
export -f rlocation

# Exports the environment variables that subprocesses need in order to use
# runfiles.
# If a subprocess is a Bazel-built binary rule that also uses the runfiles
# libraries under @bazel_tools//tools/<lang>/runfiles, then that binary needs
# these envvars in order to initialize its own runfiles library.
function runfiles_export_envvars() {
  if [[ ! -f "${RUNFILES_MANIFEST_FILE:-/dev/null}" \
        && ! -d "${RUNFILES_DIR:-/dev/null}" ]]; then
    return 1
  fi

  if [[ ! -f "${RUNFILES_MANIFEST_FILE:-/dev/null}" ]]; then
    if [[ -f "$RUNFILES_DIR/MANIFEST" ]]; then
      export RUNFILES_MANIFEST_FILE="$RUNFILES_DIR/MANIFEST"
    elif [[ -f "${RUNFILES_DIR}_manifest" ]]; then
      export RUNFILES_MANIFEST_FILE="${RUNFILES_DIR}_manifest"
    else
      export RUNFILES_MANIFEST_FILE=
    fi
  elif [[ ! -d "${RUNFILES_DIR:-/dev/null}" ]]; then
    if [[ "$RUNFILES_MANIFEST_FILE" == */MANIFEST \
          && -d "${RUNFILES_MANIFEST_FILE%/MANIFEST}" ]]; then
      export RUNFILES_DIR="${RUNFILES_MANIFEST_FILE%/MANIFEST}"
      export JAVA_RUNFILES="$RUNFILES_DIR"
    elif [[ "$RUNFILES_MANIFEST_FILE" == *_manifest \
          && -d "${RUNFILES_MANIFEST_FILE%_manifest}" ]]; then
      export RUNFILES_DIR="${RUNFILES_MANIFEST_FILE%_manifest}"
      export JAVA_RUNFILES="$RUNFILES_DIR"
    else
      export RUNFILES_DIR=
    fi
  fi
}
#!/usr/bin/env bash

if ! [[ "$0" =~ "tests/semaphore.test.bash" ]]; then
  echo "must be run from repository root"
  exit 255
fi

<<COMMENT
# amd64-e2e
tests/semaphore.test.bash
sudo HOST_TMP_DIR=/tmp TEST_OPTS="PASSES='build release e2e' MANUAL_VER=v3.4.7" make docker-test

# 386-e2e
sudo HOST_TMP_DIR=/tmp TEST_OPTS="GOARCH=386 PASSES='build e2e'" make docker-test
COMMENT
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/bin/bash

# Get full user name of current user
# E.g. "Robbie Hanson"
full1=$(osascript -e "tell application \"System Events\"" -e "get the full name of the current user" -e "end tell")
#echo $full1

# Convert to lower case
# E.g. "robbie hanson"
full2=$(echo $full1 | awk '{print tolower($0)}')
#echo $full2

# Replace spaces with underscores
# E.g. "robbie_hanson"
full3=$(echo ${full2// /_})
#echo $full3

# Remove any characters that are illegal in a macro name
full4=$(echo $full3 | sed 's/[^0-9a-zA-Z_]*//g')
#echo $full4

# If blank, set the name to an anonymous user
if [ "$full4" == "" ]
then
	full4='anonymous_user'
fi

# If we output directly to our intended file, even when nothing has changed,
# then we'll essentially be doing a touch on the file.
# The compiler will see this, and recompile any files that include the header.
# This may mean recompiling every single source file, every single time we do a build!
# So instead we're going to output to a temporary file, and use diff to detect changes.

temp_filepath="${SRCROOT}/PerUserLogLevels/LumberjackUser.temp.h"
final_filepath="${SRCROOT}/PerUserLogLevels/LumberjackUser.h"

echo "// This file is automatically generated" > ${temp_filepath}
echo "#define $full4 1" >> ${temp_filepath}

if [ -a ${final_filepath} ]
then
	DIFF=$(diff ${temp_filepath} ${final_filepath}) 
	if [ "$DIFF" != "" ] 
	then
		cp -f ${temp_filepath} ${final_filepath}
#!/usr/bin/env bash

export BASH_IT_LOG_LEVEL_ERROR=1
export BASH_IT_LOG_LEVEL_WARNING=2
export BASH_IT_LOG_LEVEL_ALL=3

function _has_colors()
{
  # Check that stdout is a terminal
  test -t 1 || return 1

  ncolors=$(tput colors)
  test -n "$ncolors" && test "$ncolors" -ge 8 || return 1
  return 0
}

function _log_general()
{
  about 'Internal function used for logging, uses BASH_IT_LOG_PREFIX as a prefix'
  param '1: color of the message'
  param '2: log level to print before the prefix'
  param '3: message to log'
  group 'log'

  message=$2${BASH_IT_LOG_PREFIX}$3
  _has_colors && echo -e "$1${message}${echo_normal}" || echo -e "${message}"
}

function _log_debug()
{
  about 'log a debug message by echoing to the screen. needs BASH_IT_LOG_LEVEL >= BASH_IT_LOG_LEVEL_ALL'
  param '1: message to log'
  example '$ _log_debug "Loading plugin git..."'
  group 'log'

  [[ "$BASH_IT_LOG_LEVEL" -ge $BASH_IT_LOG_LEVEL_ALL ]] || return 0
  _log_general "${echo_green}" "DEBUG: " "$1"
}

function _log_warning()
{
  about 'log a message by echoing to the screen. needs BASH_IT_LOG_LEVEL >= BASH_IT_LOG_LEVEL_WARNING'
  param '1: message to log'
  example '$ _log_warning "git binary not found, disabling git plugin..."'
  group 'log'

  [[ "$BASH_IT_LOG_LEVEL" -ge $BASH_IT_LOG_LEVEL_WARNING ]] || return 0
  _log_general "${echo_yellow}" " WARN: " "$1"
}

function _log_error()
{
  about 'log a message by echoing to the screen. needs BASH_IT_LOG_LEVEL >= BASH_IT_LOG_LEVEL_ERROR'
  param '1: message to log'
  example '$ _log_error "Failed to load git plugin..."'
#!/usr/bin/env bash

# colored ls
export LSCOLORS='Gxfxcxdxdxegedabagacad'

if [[ -z "$CUSTOM_THEME_DIR" ]]; then
    CUSTOM_THEME_DIR="${BASH_IT_CUSTOM:=${BASH_IT}/custom}/themes"
fi

# Load the theme
if [[ $BASH_IT_THEME ]]; then
    if [[ -f $BASH_IT_THEME ]]; then
        source $BASH_IT_THEME
    elif [[ -f "$CUSTOM_THEME_DIR/$BASH_IT_THEME/$BASH_IT_THEME.theme.bash" ]]; then
        source "$CUSTOM_THEME_DIR/$BASH_IT_THEME/$BASH_IT_THEME.theme.bash"
#!/usr/bin/env bash
#
# Search by Konstantin Gredeskoul «github.com/kigster»
#———————————————————————————————————————————————————————————————————————————————
# This function returns list of aliases, plugins and completions in bash-it,
# whose name or description matches one of the search terms provided as arguments.
#
# Usage:
#    ❯ bash-it search [-|@]term1 [-|@]term2 ... \
#       [ --enable   | -e ] \
#       [ --disable  | -d ] \
#       [ --no-color | -c ] \
#       [ --refresh  | -r ] \
#       [ --help     | -h ]
#
#    Single dash, as in "-chruby", indicates a negative search term.
#    Double dash indicates a command that is to be applied to the search result.
#    At the moment only --help, --enable and --disable are supported.
#    An '@' sign indicates an exact (not partial) match.
#
# Examples:
#    ❯ bash-it search ruby rbenv rvm gem rake
#          aliases:  bundler
#          plugins:  chruby chruby-auto ruby rbenv rvm ruby
#      completions:  rvm gem rake
#
#    ❯ bash-it search ruby rbenv rvm gem rake -chruby
#          aliases:  bundler
#          plugins:  ruby rbenv rvm ruby
#      completions:  rvm gem rake
#
# Examples of enabling or disabling results of the search:
#
#    ❯ bash-it search ruby
#          aliases:  bundler
#          plugins:  chruby chruby-auto ruby
#
#    ❯ bash-it search ruby -chruby --enable
#          aliases:  bundler
#          plugins:  ruby
#
# Examples of using exact match:

#    ❯ bash-it search @git @ruby
#          aliases:  git
#          plugins:  git ruby
#      completions:  git
#

_bash-it-search() {
  _about 'searches for given terms amongst bash-it plugins, aliases and completions'
  _param '1: term1'
  _param '2: [ term2 ]...'
  _example '$ _bash-it-search @git ruby -rvm rake bundler'

  [[ -z "$(type _bash-it-array-contains-element 2>/dev/null)" ]] && source "${BASH_IT}/lib/utilities.bash"

  local component
  export BASH_IT_SEARCH_USE_COLOR=true
  export BASH_IT_GREP=${BASH_IT_GREP:-$(which egrep)}
  declare -a BASH_IT_COMPONENTS=(aliases plugins completions)

  if [[ -z "$*" ]] ; then
    _bash-it-search-help
    return 0
  fi

  local -a args=()
  for word in $@; do
    if [[ ${word} == "--help" || ${word} == "-h" ]]; then
      _bash-it-search-help
      return 0
    elif [[ ${word} == "--refresh" || ${word} == "-r" ]]; then
      _bash-it-clean-component-cache
    elif [[ ${word} == "--no-color" || ${word} == '-c' ]]; then
      export BASH_IT_SEARCH_USE_COLOR=false
    else
      args=(${args[@]} ${word})
    fi
  done

  if [[ ${#args} -gt 0 ]]; then
    for component in "${BASH_IT_COMPONENTS[@]}" ; do
      _bash-it-search-component "${component}" "${args[@]}"
    done
  fi

  return 0
}

_bash-it-search-help() {
  printf "${echo_normal}
${echo_underline_yellow}USAGE${echo_normal}

   bash-it search [-|@]term1 [-|@]term2 ... \\
     [ --enable   | -e ] \\
     [ --disable  | -d ] \\
     [ --no-color | -c ] \\
     [ --refresh  | -r ] \\
     [ --help     | -h ]

${echo_underline_yellow}DESCRIPTION${echo_normal}

   Use ${echo_bold_green}search${echo_normal} bash-it command to search for a list of terms or term negations
   across all components: aliases, completions and plugins. Components that are
   enabled are shown in green (or with a check box if --no-color option is used).

   In addition to simply finding the right component, you can use the results
   of the search to enable or disable all components that the search returns.

   When search is used to enable/disable components it becomes clear that
   you must be able to perform not just a partial match, but an exact match,
   as well as be able to exclude some components.

      * To exclude a component (or all components matching a substring) use
        a search term with minus as a prefix, eg '-flow'

      * To perform an exact match, use character '@' in front of the term,
        eg. '@git' would only match aliases, plugins and completions named 'git'.

${echo_underline_yellow}FLAGS${echo_normal}
   --enable   | -e    ${echo_purple}Enable all matching componenents.${echo_normal}
   --disable  | -d    ${echo_purple}Disable all matching componenents.${echo_normal}
   --help     | -h    ${echo_purple}Print this help.${echo_normal}
   --refresh  | -r    ${echo_purple}Force a refresh of the search cache.${echo_normal}
   --no-color | -c    ${echo_purple}Disable color output and use monochrome text.${echo_normal}

${echo_underline_yellow}EXAMPLES${echo_normal}

   For example, ${echo_bold_green}bash-it search git${echo_normal} would match any alias, completion
   or plugin that has the word 'git' in either the module name or
   it's description. You should see something like this when you run this
   command:

         ${echo_bold_green}❯ bash-it search git${echo_bold_blue}
               ${echo_bold_yellow}aliases:  ${echo_bold_green}git ${echo_normal}gitsvn
               ${echo_bold_yellow}plugins:  ${echo_normal}autojump ${echo_bold_green}git ${echo_normal}git-subrepo jgitflow jump
           ${echo_bold_yellow}completions:  ${echo_bold_green}git ${echo_normal}git_flow git_flow_avh${echo_normal}

   You can exclude some terms by prefixing a term with a minus, eg:

         ${echo_bold_green}❯ bash-it search git -flow -svn${echo_bold_blue}
               ${echo_bold_yellow}aliases:  ${echo_normal}git
               ${echo_bold_yellow}plugins:  ${echo_normal}autojump git git-subrepo jump
           ${echo_bold_yellow}completions:  ${echo_normal}git${echo_normal}

   Finally, if you prefix a term with '@' symbol, that indicates an exact
   match. Note, that we also pass the '--enable' flag, which would ensure
   that all matches are automatically enabled. The example is below:

         ${echo_bold_green}❯ bash-it search @git --enable${echo_bold_blue}
               ${echo_bold_yellow}aliases:  ${echo_normal}git
               ${echo_bold_yellow}plugins:  ${echo_normal}git
           ${echo_bold_yellow}completions:  ${echo_normal}git${echo_normal}

${echo_underline_yellow}SUMMARY${echo_normal}

   Take advantage of the search functionality to discover what Bash-It can do
   for you. Try searching for partial term matches, mix and match with the
   negative terms, or specify an exact matches of any number of terms. Once
   you created the search command that returns ONLY the modules you need,
   simply append '--enable' or '--disable' at the end to activate/deactivate
   each module.

"
}

_bash-it-is-partial-match() {
  local component="$1"
  local term="$2"
  _bash-it-component-help "${component}" | $(_bash-it-grep) -E -i -q -- "${term}"
}

_bash-it-component-term-matches-negation() {
  local match="$1"; shift
  local negative
  for negative in "$@"; do
    [[ "${match}" =~ "${negative}" ]] && return 0
  done

  return 1
}

_bash-it-search-component() {
  local component="$1"
  shift

  _about 'searches for given terms amongst a given component'
  _param '1: component type, one of: [ aliases | plugins | completions ]'
  _param '2: term1 term2 @term3'
  _param '3: [-]term4 [-]term5 ...'
  _example '$ _bash-it-search-component aliases @git rake bundler -chruby'

  # if one of the search terms is --enable or --disable, we will apply
  # this action to the matches further  ` down.
  local component_singular action action_func
  local -a search_commands=(enable disable)
  for search_command in "${search_commands[@]}"; do
    if $(_bash-it-array-contains-element "--${search_command}" "$@"); then
      component_singular=${component}
      component_singular=${component_singular/es/}  # aliases -> alias
      component_singular=${component_singular/ns/n} # plugins -> plugin

      action="${search_command}"
      action_func="_${action}-${component_singular}"
      break
    fi
  done

  local -a terms=($@)           # passed on the command line

  unset exact_terms
  unset partial_terms
  unset negative_terms

  local -a exact_terms=()       # terms that should be included only if they match exactly
  local -a partial_terms=()     # terms that should be included if they match partially
  local -a negative_terms=()    # negated partial terms that should be excluded

  unset component_list
  local -a component_list=( $(_bash-it-component-list "${component}") )
  local term

  for term in "${terms[@]}"; do
    local search_term="${term:1}"
    if [[ "${term:0:2}" == "--" ]] ; then
      continue
    elif [[ "${term:0:1}" == "-"  ]] ; then
      negative_terms=(${negative_terms[@]} "${search_term}")
    elif [[ "${term:0:1}" == "@"  ]] ; then
      if $(_bash-it-array-contains-element "${search_term}" "${component_list[@]}"); then
        exact_terms=(${exact_terms[@]} "${search_term}")
      fi
    else
      partial_terms=(${partial_terms[@]} $(_bash-it-component-list-matching "${component}" "${term}") )
    fi
  done

  local -a total_matches=( $(_bash-it-array-dedup ${exact_terms[@]} ${partial_terms[@]}) )

  unset matches
  declare -a matches=()
  for match in ${total_matches[@]}; do
    local include_match=true
    if  [[ ${#negative_terms[@]} -gt 0 ]]; then
      ( _bash-it-component-term-matches-negation "${match}" "${negative_terms[@]}" ) && include_match=false
    fi
    ( ${include_match} ) && matches=(${matches[@]} "${match}")
  done
  _bash-it-search-result "${component}" "${action}" "${action_func}" "${matches[@]}"
  unset matches final_matches terms
}

_bash-it-search-result() {
  local component="$1"; shift
  local action="$1"; shift
  local action_func="$1"; shift
  local -a matches=($@)

  local color_component color_enable color_disable color_off

  color_sep=':'

  ( ${BASH_IT_SEARCH_USE_COLOR} ) && {
    color_component='\e[1;34m'
    color_enable='\e[1;32m'
    suffix_enable=''
    suffix_disable=''
    color_disable='\e[0;0m'
    color_off='\e[0;0m'
  }

  ( ${BASH_IT_SEARCH_USE_COLOR} ) || {
    color_component=''
    suffix_enable=' ✓ ︎'
    suffix_disable='  '
    color_enable=''
    color_disable=''
    color_off=''
  }

  local match
  local modified=0

  if [[ "${#matches[@]}" -gt 0 ]] ; then
    printf "${color_component}%13s${color_sep} ${color_off}" "${component}"

    for match in "${matches[@]}"; do
      local enabled=0
      ( _bash-it-component-item-is-enabled "${component}" "${match}" ) && enabled=1

      local match_color compatible_action suffix opposite_suffix

      (( ${enabled} )) && {
        match_color=${color_enable}
        suffix=${suffix_enable}
        opposite_suffix=${suffix_disable}
        compatible_action="disable"
      }

      (( ${enabled} )) || {
        match_color=${color_disable}
        suffix=${suffix_disable}
        opposite_suffix=${suffix_enable}
        compatible_action="enable"
      }

      local m="${match}${suffix}"
      local len
      len=${#m}

      printf " ${match_color}${match}${suffix}"  # print current state
      if [[ "${action}" == "${compatible_action}" ]]; then
        if [[ ${action} == "enable" && ${BASH_IT_SEARCH_USE_COLOR} == false ]]; then
          _bash-it-flash-term ${len} "${match}${suffix}"
        else
          _bash-it-erase-term ${len}
        fi
        modified=1
        result=$(${action_func} ${match})
        local temp="color_${compatible_action}"
        match_color=${!temp}
        _bash-it-rewind ${len}
        printf "${match_color}${match}${opposite_suffix}"
      fi

      printf "${color_off}"
    done

    [[ ${modified} -gt 0 ]] && _bash-it-clean-component-cache ${component}
    printf "\n"
  fi
}

_bash-it-rewind() {
  local len="$1"
  printf "\033[${len}D"
}

_bash-it-flash-term() {
  local len="$1"
  local match="$2"
  local delay=0.1
  local color

  for color in ${text_black} ${echo_bold_blue} ${bold_yellow} ${bold_red} ${echo_bold_green} ; do
    sleep ${delay}
    _bash-it-rewind "${len}"
    printf "${color}${match}"
  done
}

_bash-it-erase-term() {
  local len="$1"
  _bash-it-rewind ${len}
  for a in {0..30}; do
    [[ ${a} -gt ${len} ]] && break
    printf "%.*s" $a " "
    sleep 0.05
  done
if [[ $BASH_PREVIEW ]];
then
  unset BASH_PREVIEW #Prevent infinite looping
  echo "

  Previewing Bash-it Themes

  "

  THEMES="$BASH_IT/themes/*/*.theme.bash"
  for theme in $THEMES
  do
    BASH_IT_THEME=${theme%.theme.bash}
    BASH_IT_THEME=${BASH_IT_THEME##*/}
    echo "
#!/usr/bin/env bash
#
# A collection of reusable functions.

###########################################################################
# Generic utilies
###########################################################################

_bash-it-get-component-name-from-path() {
  # filename without path
  filename=${1##*/}
  # filename without path or priority
  filename=${filename##*---}
  # filename without path, priority or extension
  echo ${filename%.*.bash}
}

_bash-it-get-component-type-from-path() {
  # filename without path
  filename=${1##*/}
  # filename without path or priority
  filename=${filename##*---}
  # extension
  echo ${filename} | cut -d '.' -f 2
}

# This function searches an array for an exact match against the term passed
# as the first argument to the function. This function exits as soon as
# a match is found.
#
# Returns:
#   0 when a match is found, otherwise 1.
#
# Examples:
#   $ declare -a fruits=(apple orange pear mandarin)
#
#   $ _bash-it-array-contains-element apple "@{fruits[@]}" && echo 'contains apple'
#   contains apple
#
#   $ if $(_bash-it-array-contains-element pear "${fruits[@]}"); then
#       echo "contains pear!"
#     fi
#   contains pear!
#
#
_bash-it-array-contains-element() {
  local e
  for e in "${@:2}"; do
    [[ "$e" == "$1" ]] && return 0
  done
  return 1
}

# Dedupe a simple array of words without spaces.
_bash-it-array-dedup() {
  echo "$*" | tr ' ' '\n' | sort -u | tr '\n' ' '
}

# Outputs a full path of the grep found on the filesystem
_bash-it-grep() {
  if [[ -z "${BASH_IT_GREP}" ]] ; then
    export BASH_IT_GREP="$(which egrep || which grep || '/usr/bin/grep')"
  fi
  printf "%s " "${BASH_IT_GREP}"
}


###########################################################################
# Component-specific functions (component is either an alias, a plugin, or a
# completion).
###########################################################################

_bash-it-component-help() {
  local component=$(_bash-it-pluralize-component "${1}")
  local file=$(_bash-it-component-cache-file ${component})
  if [[ ! -s "${file}" || -z $(find "${file}" -mmin -300) ]] ; then
    rm -f "${file}" 2>/dev/null
    local func="_bash-it-${component}"
    ${func} | $(_bash-it-grep) -E '   \[' | cat > ${file}
  fi
  cat "${file}"
}

_bash-it-component-cache-file() {
  local component=$(_bash-it-pluralize-component "${1}")
  local file="${BASH_IT}/tmp/cache/${component}"
  [[ -f ${file} ]] || mkdir -p $(dirname ${file})
  printf "${file}"
}

_bash-it-pluralize-component() {
  local component="${1}"
  local len=$(( ${#component} - 1 ))
  # pluralize component name for consistency
  [[ ${component:${len}:1} != 's' ]] && component="${component}s"
  [[ ${component} == "alias" ]] && component="aliases"
  printf ${component}
}

_bash-it-clean-component-cache() {
  local component="$1"
  local cache
  local -a BASH_IT_COMPONENTS=(aliases plugins completions)
  if [[ -z ${component} ]] ; then
    for component in "${BASH_IT_COMPONENTS[@]}" ; do
      _bash-it-clean-component-cache "${component}"
    done
  else
    cache="$(_bash-it-component-cache-file ${component})"
    if [[ -f "${cache}" ]] ; then
      rm -f "${cache}"
    fi
  fi
}

# Returns an array of items within each compoenent.
_bash-it-component-list() {
  local component="$1"
  _bash-it-component-help "${component}" | awk '{print $1}' | uniq | sort | tr '\n' ' '
}

_bash-it-component-list-matching() {
  local component="$1"; shift
  local term="$1"
  _bash-it-component-help "${component}" | $(_bash-it-grep) -E -- "${term}" | awk '{print $1}' | sort | uniq
}

_bash-it-component-list-enabled() {
  local component="$1"
  _bash-it-component-help "${component}" | $(_bash-it-grep) -E  '\[x\]' | awk '{print $1}' | uniq | sort | tr '\n' ' '
}

_bash-it-component-list-disabled() {
  local component="$1"
  _bash-it-component-help "${component}" | $(_bash-it-grep) -E -v '\[x\]' | awk '{print $1}' | uniq | sort | tr '\n' ' '
}

# Checks if a given item is enabled for a particular component/file-type.
# Uses the component cache if available.
#
# Returns:
#    0 if an item of the component is enabled, 1 otherwise.
#
# Examples:
#    _bash-it-component-item-is-enabled alias git && echo "git alias is enabled"
_bash-it-component-item-is-enabled() {
  local component="$1"
  local item="$2"
  _bash-it-component-help "${component}" | $(_bash-it-grep) -E '\[x\]' |  $(_bash-it-grep) -E -q -- "^${item}\s"
}

# Checks if a given item is disabled for a particular component/file-type.
# Uses the component cache if available.
#
# Returns:
#    0 if an item of the component is enabled, 1 otherwise.
#
# Examples:
#    _bash-it-component-item-is-disabled alias git && echo "git aliases are disabled"
_bash-it-component-item-is-disabled() {
#!/usr/bin/env bash

BASH_IT_LOAD_PRIORITY_DEFAULT_ALIAS=${BASH_IT_LOAD_PRIORITY_DEFAULT_ALIAS:-150}
BASH_IT_LOAD_PRIORITY_DEFAULT_PLUGIN=${BASH_IT_LOAD_PRIORITY_DEFAULT_PLUGIN:-250}
BASH_IT_LOAD_PRIORITY_DEFAULT_COMPLETION=${BASH_IT_LOAD_PRIORITY_DEFAULT_COMPLETION:-350}
BASH_IT_LOAD_PRIORITY_SEPARATOR="---"

# Handle the different ways of running `sed` without generating a backup file based on OS
# - GNU sed (Linux) uses `-i`
# - BSD sed (macOS) uses `-i ''`
# To use this in Bash-it for inline replacements with `sed`, use the following syntax:
# sed "${BASH_IT_SED_I_PARAMETERS[@]}" -e "..." file
BASH_IT_SED_I_PARAMETERS=(-i)
case "$(uname)" in
  Darwin*) BASH_IT_SED_I_PARAMETERS=(-i "")
esac

function _command_exists ()
{
  _about 'checks for existence of a command'
  _param '1: command to check'
  _param '2: (optional) log message to include when command not found'
  _example '$ _command_exists ls && echo exists'
  _group 'lib'
  local msg="${2:-Command '$1' does not exist!}"
  type "$1" &> /dev/null || (_log_warning "$msg" && return 1) ;
}

function _binary_exists ()
{
  _about 'checks for existence of a binary'
  _param '1: binary to check'
  _param '2: (optional) log message to include when binary not found'
  _example '$ _binary_exists ls && echo exists'
  _group 'lib'
  local msg="${2:-Binary '$1' does not exist!}"
  type -P "$1" &> /dev/null || (_log_warning "$msg" && return 1) ;
}

function _completion_exists ()
{
  _about 'checks for existence of a completion'
  _param '1: command to check'
  _param '2: (optional) log message to include when completion is found'
  _example '$ _completion_exists gh && echo exists'
  _group 'lib'
  local msg="${2:-Completion for '$1' already exists!}"
  complete -p "$1" &> /dev/null && _log_warning "$msg" ;
}

function _make_reload_alias() {
  echo "source \${BASH_IT}/scripts/reloader.bash ${1} ${2}"
}

# Alias for reloading aliases
# shellcheck disable=SC2139
alias reload_aliases="$(_make_reload_alias alias aliases)"

# Alias for reloading auto-completion
# shellcheck disable=SC2139
alias reload_completion="$(_make_reload_alias completion completion)"

# Alias for reloading plugins
# shellcheck disable=SC2139
alias reload_plugins="$(_make_reload_alias plugin plugins)"

bash-it ()
{
    about 'Bash-it help and maintenance'
    param '1: verb [one of: help | show | enable | disable | migrate | update | search | version | reload | restart | doctor ] '
    param '2: component type [one of: alias(es) | completion(s) | plugin(s) ] or search term(s)'
    param '3: specific component [optional]'
    example '$ bash-it show plugins'
    example '$ bash-it help aliases'
    example '$ bash-it enable plugin git [tmux]...'
    example '$ bash-it disable alias hg [tmux]...'
    example '$ bash-it migrate'
    example '$ bash-it update'
    example '$ bash-it search [-|@]term1 [-|@]term2 ... [ -e/--enable ] [ -d/--disable ] [ -r/--refresh ] [ -c/--no-color ]'
    example '$ bash-it version'
    example '$ bash-it reload'
    example '$ bash-it restart'
    example '$ bash-it doctor errors|warnings|all'
    typeset verb=${1:-}
    shift
    typeset component=${1:-}
    shift
    typeset func

    case $verb in
      show)
        func=_bash-it-$component;;
      enable)
        func=_enable-$component;;
      disable)
        func=_disable-$component;;
      help)
        func=_help-$component;;
      doctor)
        func=_bash-it-doctor-$component;;
      search)
        _bash-it-search $component "$@"
        return;;
      update)
        func=_bash-it-update-$component;;
      migrate)
        func=_bash-it-migrate;;
      version)
        func=_bash-it-version;;
      restart)
        func=_bash-it-restart;;
      reload)
        func=_bash-it-reload;;
      *)
        reference bash-it
        return;;
    esac

    # pluralize component if necessary
    if ! _is_function $func; then
        if _is_function ${func}s; then
            func=${func}s
        else
            if _is_function ${func}es; then
                func=${func}es
            else
                echo "oops! $component is not a valid option!"
                reference bash-it
                return
            fi
        fi
    fi

    if [ x"$verb" == x"enable" ] || [ x"$verb" == x"disable" ]; then
        # Automatically run a migration if required
        _bash-it-migrate

        for arg in "$@"
        do
            $func $arg
        done

        if [ -n "$BASH_IT_AUTOMATIC_RELOAD_AFTER_CONFIG_CHANGE" ]; then
          _bash-it-reload
        fi
    else
        $func "$@"
    fi
}

_is_function ()
{
    _about 'sets $? to true if parameter is the name of a function'
    _param '1: name of alleged function'
    _group 'lib'
    [ -n "$(LANG=C type -t $1 2>/dev/null | grep 'function')" ]
}

_bash-it-aliases ()
{
    _about 'summarizes available bash_it aliases'
    _group 'lib'

    _bash-it-describe "aliases" "an" "alias" "Alias"
}

_bash-it-completions ()
{
    _about 'summarizes available bash_it completions'
    _group 'lib'

    _bash-it-describe "completion" "a" "completion" "Completion"
}

_bash-it-plugins ()
{
    _about 'summarizes available bash_it plugins'
    _group 'lib'

    _bash-it-describe "plugins" "a" "plugin" "Plugin"
}

_bash-it-update-dev() {
  _about 'updates Bash-it to the latest master'
  _group 'lib'

  _bash-it-update- dev "$@"
}

_bash-it-update-stable() {
  _about 'updates Bash-it to the latest tag'
  _group 'lib'

  _bash-it-update- stable "$@"
}

_bash-it_pull_and_update_inner() {
  git checkout "$1" &> /dev/null
  if [[ $? -eq 0 ]]; then
    echo "Bash-it successfully updated."
    echo ""
    echo "Migrating your installation to the latest $2 version now..."
    _bash-it-migrate
    echo ""
    echo "All done, enjoy!"
    bash-it reload
  else
    echo "Error updating Bash-it, please, check if your Bash-it installation folder (${BASH_IT}) is clean."
  fi
}

_bash-it-update-() {
  _about 'updates Bash-it'
  _param '1: What kind of update to do (stable|dev)'
  _group 'lib'

  declare silent
  for word in $@; do
    if [[ ${word} == "--silent" || ${word} == "-s" ]]; then
      silent=true
    fi
  done
  local old_pwd="${PWD}"

  cd "${BASH_IT}" || return

  if [ -z "$BASH_IT_REMOTE" ]; then
    BASH_IT_REMOTE="origin"
  fi

  git fetch $BASH_IT_REMOTE --tags &> /dev/null

  if [ -z "$BASH_IT_DEVELOPMENT_BRANCH" ]; then
    BASH_IT_DEVELOPMENT_BRANCH="master"
  fi
  # Defaults to stable update
  if [ -z "$1" ] || [ "$1" == "stable" ]; then
    version="stable"
    TARGET=$(git describe --tags "$(git rev-list --tags --max-count=1)" 2> /dev/null)

    if [[ -z "$TARGET" ]]; then
      echo "Can not find tags, so can not update to latest stable version..."
      return
    fi
  else
    version="dev"
    TARGET=${BASH_IT_REMOTE}/${BASH_IT_DEVELOPMENT_BRANCH}
  fi

  declare revision
  revision="HEAD..${TARGET}"
  declare status
  status="$(git rev-list ${revision} 2> /dev/null)"
  declare revert

  if [[ -z "${status}" && ${version} == "stable" ]]; then
    revision="${TARGET}..HEAD"
    status="$(git rev-list ${revision} 2> /dev/null)"
    revert=true
  fi

  if [[ -n "${status}" ]]; then
    if [[ $revert ]]; then
      echo "Your version is a more recent development version ($(git log -1 --format=%h HEAD))"
      echo "You can continue in order to revert and update to the latest stable version"
      echo ""
      log_color="%Cred"
    fi

    for i in $(git rev-list --merges --first-parent ${revision}); do
      num_of_lines=$(git log -1 --format=%B $i | awk 'NF' | wc -l)
      if [ $num_of_lines -eq 1 ]; then
        description="%s"
      else
        description="%b"
      fi
      git log --format="${log_color}%h: $description (%an)" -1 $i
    done
    echo ""

    if [[ $silent ]]; then
      echo "Updating to ${TARGET}($(git log -1 --format=%h "${TARGET}"))..."
      _bash-it_pull_and_update_inner $TARGET $version
    else
      read -e -n 1 -p "Would you like to update to ${TARGET}($(git log -1 --format=%h "${TARGET}"))? [Y/n] " RESP
      case $RESP in
        [yY]|"")
          _bash-it_pull_and_update_inner $TARGET $version
          ;;
        [nN])
          echo "Not updating…"
          ;;
        *)
          echo -e "\033[91mPlease choose y or n.\033[m"
          ;;
        esac
    fi
  else
    if [[ ${version} == "stable" ]]; then
      echo "You're on the latest stable version. If you want to check out the latest 'dev' version, please run \"bash-it update dev\""
    else
      echo "Bash-it is up to date, nothing to do!"
    fi
  fi
  cd "${old_pwd}" &> /dev/null || return
}

_bash-it-migrate() {
  _about 'migrates Bash-it configuration from a previous format to the current one'
  _group 'lib'

  declare migrated_something
  migrated_something=false

  for file_type in "aliases" "plugins" "completion"
  do
    for f in `sort <(compgen -G "${BASH_IT}/$file_type/enabled/*.bash")`
    do
      typeset ff=$(basename $f)

      # Get the type of component from the extension
      typeset single_type=$(echo $ff | sed -e 's/.*\.\(.*\)\.bash/\1/g' | sed 's/aliases/alias/g')
      # Cut off the optional "250---" prefix and the suffix
      typeset component_name=$(echo $ff | sed -e 's/[0-9]*[-]*\(.*\)\..*\.bash/\1/g')

      migrated_something=true

      echo "Migrating $single_type $component_name."

      disable_func="_disable-$single_type"
      enable_func="_enable-$single_type"

      $disable_func $component_name
      $enable_func $component_name
    done
  done

  if [ -n "$BASH_IT_AUTOMATIC_RELOAD_AFTER_CONFIG_CHANGE" ]; then
    _bash-it-reload
  fi

  if [ "$migrated_something" = "true" ]; then
    echo ""
    echo "If any migration errors were reported, please try the following: reload && bash-it migrate"
  fi
}

_bash-it-version() {
  _about 'shows current Bash-it version'
  _group 'lib'

  cd "${BASH_IT}" || return

  if [ -z $BASH_IT_REMOTE ]; then
    BASH_IT_REMOTE="origin"
  fi

  BASH_IT_GIT_REMOTE=$(git remote get-url $BASH_IT_REMOTE)
  BASH_IT_GIT_URL=${BASH_IT_GIT_REMOTE%.git}
  if [[ "$BASH_IT_GIT_URL" == *"git@"* ]]; then
    # Fix URL in case it is ssh based URL
    BASH_IT_GIT_URL=${BASH_IT_GIT_URL/://}
    BASH_IT_GIT_URL=${BASH_IT_GIT_URL/git@/https://}
  fi

  current_tag=$(git describe --exact-match --tags 2> /dev/null)

  if [[ -z $current_tag ]]; then
    BASH_IT_GIT_VERSION_INFO="$(git log --pretty=format:'%h on %aI' -n 1)"
    TARGET=${BASH_IT_GIT_VERSION_INFO%% *}
    echo "Version type: dev"
    echo "Current git SHA: $BASH_IT_GIT_VERSION_INFO"
    echo "Commit info: $BASH_IT_GIT_URL/commit/$TARGET"
  else
    TARGET=$current_tag
    echo "Version type: stable"
    echo "Current tag: $current_tag"
    echo "Tag information: $BASH_IT_GIT_URL/releases/tag/$current_tag"
  fi

  echo "Compare to latest: $BASH_IT_GIT_URL/compare/$TARGET...master"

  cd - &> /dev/null || return
}

_bash-it-doctor() {
  _about 'reloads a profile file with a BASH_IT_LOG_LEVEL set'
  _param '1: BASH_IT_LOG_LEVEL argument: "errors" "warnings" "all"'
  _group 'lib'

  BASH_IT_LOG_LEVEL=$1
  _bash-it-reload
  unset BASH_IT_LOG_LEVEL
}

_bash-it-doctor-all() {
  _about 'reloads a profile file with error, warning and debug logs'
  _group 'lib'

  _bash-it-doctor $BASH_IT_LOG_LEVEL_ALL
}

_bash-it-doctor-warnings() {
  _about 'reloads a profile file with error and warning logs'
  _group 'lib'

  _bash-it-doctor $BASH_IT_LOG_LEVEL_WARNING
}

_bash-it-doctor-errors() {
  _about 'reloads a profile file with error logs'
  _group 'lib'

  _bash-it-doctor $BASH_IT_LOG_LEVEL_ERROR
}

_bash-it-doctor-() {
  _about 'default bash-it doctor behavior, behaves like bash-it doctor all'
  _group 'lib'

  _bash-it-doctor-all
}

_bash-it-restart() {
  _about 'restarts the shell in order to fully reload it'
  _group 'lib'

  saved_pwd=$(pwd)

  case $OSTYPE in
    darwin*)
      init_file=.bash_profile
      ;;
    *)
      init_file=.bashrc
      ;;
  esac
  exec "${0/-/}" --rcfile <(echo "source \"$HOME/$init_file\"; cd \"$saved_pwd\"")
}

_bash-it-reload() {
  _about 'reloads a profile file'
  _group 'lib'

  pushd "${BASH_IT}" &> /dev/null || return

  case $OSTYPE in
    darwin*)
      source ~/.bash_profile
      ;;
    *)
      source ~/.bashrc
      ;;
  esac

  popd &> /dev/null || return
}

_bash-it-describe ()
{
    _about 'summarizes available bash_it components'
    _param '1: subdirectory'
    _param '2: preposition'
    _param '3: file_type'
    _param '4: column_header'
    _example '$ _bash-it-describe "plugins" "a" "plugin" "Plugin"'

    subdirectory="$1"
    preposition="$2"
    file_type="$3"
    column_header="$4"

    typeset f
    typeset enabled
    printf "%-20s%-10s%s\n" "$column_header" 'Enabled?' 'Description'
    for f in "${BASH_IT}/$subdirectory/available/"*.bash
    do
        # Check for both the old format without the load priority, and the extended format with the priority
        declare enabled_files enabled_file
        enabled_file=$(basename $f)
        enabled_files=$(sort <(compgen -G "${BASH_IT}/enabled/*$BASH_IT_LOAD_PRIORITY_SEPARATOR${enabled_file}") <(compgen -G "${BASH_IT}/$subdirectory/enabled/${enabled_file}") <(compgen -G "${BASH_IT}/$subdirectory/enabled/*$BASH_IT_LOAD_PRIORITY_SEPARATOR${enabled_file}") | wc -l)

        if [ $enabled_files -gt 0 ]; then
            enabled='x'
        else
            enabled=' '
        fi
        printf "%-20s%-10s%s\n" "$(basename $f | sed -e 's/\(.*\)\..*\.bash/\1/g')" "  [$enabled]" "$(cat $f | metafor about-$file_type)"
    done
    printf '\n%s\n' "to enable $preposition $file_type, do:"
    printf '%s\n' "$ bash-it enable $file_type  <$file_type name> [$file_type name]... -or- $ bash-it enable $file_type all"
    printf '\n%s\n' "to disable $preposition $file_type, do:"
    printf '%s\n' "$ bash-it disable $file_type <$file_type name> [$file_type name]... -or- $ bash-it disable $file_type all"
}

_on-disable-callback()
{
    _about 'Calls the disabled plugin destructor, if present'
    _param '1: plugin name'
    _example '$ _on-disable-callback gitstatus'
    _group 'lib'

    callback=$1_on_disable
    _command_exists $callback && $callback
}

_disable-plugin ()
{
    _about 'disables bash_it plugin'
    _param '1: plugin name'
    _example '$ disable-plugin rvm'
    _group 'lib'

    _disable-thing "plugins" "plugin" $1
    _on-disable-callback $1
}

_disable-alias ()
{
    _about 'disables bash_it alias'
    _param '1: alias name'
    _example '$ disable-alias git'
    _group 'lib'

    _disable-thing "aliases" "alias" $1
}

_disable-completion ()
{
    _about 'disables bash_it completion'
    _param '1: completion name'
    _example '$ disable-completion git'
    _group 'lib'

    _disable-thing "completion" "completion" $1
}

_disable-thing ()
{
    _about 'disables a bash_it component'
    _param '1: subdirectory'
    _param '2: file_type'
    _param '3: file_entity'
    _example '$ _disable-thing "plugins" "plugin" "ssh"'

    subdirectory="$1"
    file_type="$2"
    file_entity="$3"

    if [ -z "$file_entity" ]; then
        reference "disable-$file_type"
        return
    fi

    typeset f suffix
    suffix=$(echo "$subdirectory" | sed -e 's/plugins/plugin/g')

    if [ "$file_entity" = "all" ]; then
        # Disable everything that's using the old structure
        for f in `compgen -G "${BASH_IT}/$subdirectory/enabled/*.${suffix}.bash"`
        do
          rm "$f"
        done

        # Disable everything in the global "enabled" directory
        for f in `compgen -G "${BASH_IT}/enabled/*.${suffix}.bash"`
        do
          rm "$f"
        done
    else
        typeset plugin_global=$(command ls $ "${BASH_IT}/enabled/"[0-9]*$BASH_IT_LOAD_PRIORITY_SEPARATOR$file_entity.$suffix.bash 2>/dev/null | head -1)
        if [ -z "$plugin_global" ]; then
          # Use a glob to search for both possible patterns
          # 250---node.plugin.bash
          # node.plugin.bash
          # Either one will be matched by this glob
          typeset plugin=$(command ls $ "${BASH_IT}/$subdirectory/enabled/"{[0-9]*$BASH_IT_LOAD_PRIORITY_SEPARATOR$file_entity.$suffix.bash,$file_entity.$suffix.bash} 2>/dev/null | head -1)
          if [ -z "$plugin" ]; then
              printf '%s\n' "sorry, $file_entity does not appear to be an enabled $file_type."
              return
          fi
          rm "${BASH_IT}/$subdirectory/enabled/$(basename $plugin)"
        else
          rm "${BASH_IT}/enabled/$(basename $plugin_global)"
        fi
    fi

    _bash-it-clean-component-cache "${file_type}"

    printf '%s\n' "$file_entity disabled."
}

_enable-plugin ()
{
    _about 'enables bash_it plugin'
    _param '1: plugin name'
    _example '$ enable-plugin rvm'
    _group 'lib'

    _enable-thing "plugins" "plugin" $1 $BASH_IT_LOAD_PRIORITY_DEFAULT_PLUGIN
}

_enable-alias ()
{
    _about 'enables bash_it alias'
    _param '1: alias name'
    _example '$ enable-alias git'
    _group 'lib'

    _enable-thing "aliases" "alias" $1 $BASH_IT_LOAD_PRIORITY_DEFAULT_ALIAS
}

_enable-completion ()
{
    _about 'enables bash_it completion'
    _param '1: completion name'
    _example '$ enable-completion git'
    _group 'lib'

    _enable-thing "completion" "completion" $1 $BASH_IT_LOAD_PRIORITY_DEFAULT_COMPLETION
}

_enable-thing ()
{
    cite _about _param _example
    _about 'enables a bash_it component'
    _param '1: subdirectory'
    _param '2: file_type'
    _param '3: file_entity'
    _param '4: load priority'
    _example '$ _enable-thing "plugins" "plugin" "ssh" "150"'

    subdirectory="$1"
    file_type="$2"
    file_entity="$3"
    load_priority="$4"

    if [ -z "$file_entity" ]; then
        reference "enable-$file_type"
        return
    fi

    if [ "$file_entity" = "all" ]; then
        typeset f $file_type
        for f in "${BASH_IT}/$subdirectory/available/"*.bash
        do
            to_enable=$(basename $f .$file_type.bash)
            if [ "$file_type" = "alias" ]; then
              to_enable=$(basename $f ".aliases.bash")
            fi
            _enable-thing $subdirectory $file_type $to_enable $load_priority
        done
    else
        typeset to_enable=$(command ls "${BASH_IT}/$subdirectory/available/"$file_entity.*bash 2>/dev/null | head -1)
        if [ -z "$to_enable" ]; then
            printf '%s\n' "sorry, $file_entity does not appear to be an available $file_type."
            return
        fi

        to_enable=$(basename $to_enable)
        # Check for existence of the file using a wildcard, since we don't know which priority might have been used when enabling it.
        typeset enabled_plugin=$(command ls "${BASH_IT}/$subdirectory/enabled/"{[0-9][0-9][0-9]$BASH_IT_LOAD_PRIORITY_SEPARATOR$to_enable,$to_enable} 2>/dev/null | head -1)
        if [ ! -z "$enabled_plugin" ] ; then
          printf '%s\n' "$file_entity is already enabled."
          return
        fi

        typeset enabled_plugin_global=$(command compgen -G "${BASH_IT}/enabled/[0-9][0-9][0-9]$BASH_IT_LOAD_PRIORITY_SEPARATOR$to_enable" 2>/dev/null | head -1)
        if [ ! -z "$enabled_plugin_global" ] ; then
          printf '%s\n' "$file_entity is already enabled."
          return
        fi

        mkdir -p "${BASH_IT}/enabled"

        # Load the priority from the file if it present there
        declare local_file_priority use_load_priority
        local_file_priority=$(grep -E "^# BASH_IT_LOAD_PRIORITY:" "${BASH_IT}/$subdirectory/available/$to_enable" | awk -F': ' '{ print $2 }')
        use_load_priority=${local_file_priority:-$load_priority}

        ln -s ../$subdirectory/available/$to_enable "${BASH_IT}/enabled/${use_load_priority}${BASH_IT_LOAD_PRIORITY_SEPARATOR}${to_enable}"
    fi

    _bash-it-clean-component-cache "${file_type}"

    printf '%s\n' "$file_entity enabled with priority $use_load_priority."
}

_help-completions()
{
  _about 'summarize all completions available in bash-it'
  _group 'lib'

  _bash-it-completions
}

_help-aliases()
{
    _about 'shows help for all aliases, or a specific alias group'
    _param '1: optional alias group'
    _example '$ alias-help'
    _example '$ alias-help git'

    if [ -n "$1" ]; then
        case $1 in
            custom)
                alias_path='custom.aliases.bash'
            ;;
            *)
                alias_path="available/$1.aliases.bash"
            ;;
        esac
        cat "${BASH_IT}/aliases/$alias_path" | metafor alias | sed "s/$/'/"
    else
        typeset f

        for f in `sort <(compgen -G "${BASH_IT}/aliases/enabled/*") <(compgen -G "${BASH_IT}/enabled/*.aliases.bash")`
        do
            _help-list-aliases $f
        done

        if [ -e "${BASH_IT}/aliases/custom.aliases.bash" ]; then
          _help-list-aliases "${BASH_IT}/aliases/custom.aliases.bash"
        fi
    fi
}

_help-list-aliases ()
{
    typeset file=$(basename $1 | sed -e 's/[0-9]*[-]*\(.*\)\.aliases\.bash/\1/g')
    printf '\n\n%s:\n' "${file}"
    # metafor() strips trailing quotes, restore them with sed..
    cat $1 | metafor alias | sed "s/$/'/"
}

_help-plugins()
{
    _about 'summarize all functions defined by enabled bash-it plugins'
    _group 'lib'

    # display a brief progress message...
    printf '%s' 'please wait, building help...'
    typeset grouplist=$(mktemp -t grouplist.XXXXXX)
    typeset func
    for func in $(typeset_functions)
    do
        typeset group="$(typeset -f $func | metafor group)"
        if [ -z "$group" ]; then
            group='misc'
        fi
        typeset about="$(typeset -f $func | metafor about)"
        letterpress "$about" $func >> $grouplist.$group
        echo $grouplist.$group >> $grouplist
    done
    # clear progress message
    printf '\r%s\n' '                              '
    typeset group
    typeset gfile
    for gfile in $(cat $grouplist | sort | uniq)
    do
        printf '%s\n' "${gfile##*.}:"
        cat $gfile
        printf '\n'
        rm $gfile 2> /dev/null
    done | less
    rm $grouplist 2> /dev/null
}

_help-update () {
  _about 'help message for update command'
  _group 'lib'

  echo "Check for a new version of Bash-it and update it."
}

_help-migrate () {
  _about 'help message for migrate command'
  _group 'lib'

  echo "Migrates internal Bash-it structure to the latest version in case of changes."
  echo "The 'migrate' command is run automatically when calling 'update', 'enable' or 'disable'."
}

all_groups ()
{
    about 'displays all unique metadata groups'
    group 'lib'

    typeset func
    typeset file=$(mktemp -t composure.XXXX)
    for func in $(typeset_functions)
    do
        typeset -f $func | metafor group >> $file
    done
    cat $file | sort | uniq
    rm $file
}

if ! type pathmunge > /dev/null 2>&1
then
  function pathmunge () {
    about 'prevent duplicate directories in you PATH variable'
    group 'helpers'
    example 'pathmunge /path/to/dir is equivalent to PATH=/path/to/dir:$PATH'
    example 'pathmunge /path/to/dir after is equivalent to PATH=$PATH:/path/to/dir'

    if ! [[ $PATH =~ (^|:)$1($|:) ]] ; then
      if [ "$2" = "after" ] ; then
        export PATH=$PATH:$1
      else
#!/usr/bin/env bats
load "${BASH_IT}/vendor/github.com/erichs/composure/composure.sh"

unset BASH_IT_THEME
unset GIT_HOSTING
unset NGINX_PATH
unset IRC_CLIENT
unset TODO
unset SCM_CHECK
unset BASH_IT_AUTOMATIC_RELOAD_AFTER_CONFIG_CHANGE

export TEST_MAIN_DIR="${BATS_TEST_DIRNAME}/.."
export TEST_DEPS_DIR="${TEST_DEPS_DIR-${TEST_MAIN_DIR}/../test_lib}"

# be independent of git's system configuration
export GIT_CONFIG_NOSYSTEM

load "${TEST_DEPS_DIR}/bats-support/load.bash"
load "${TEST_DEPS_DIR}/bats-assert/load.bash"
load "${TEST_DEPS_DIR}/bats-file/load.bash"

# support 'plumbing' metadata
cite _about _param _example _group _author _version

local_setup() {
	true
}

local_teardown() {
	true
}

# This function sets up a local test fixture, i.e. a completely
# fresh and isolated Bash-it directory. This is done to avoid
# messing with your own Bash-it source directory.
# If you need this, call it in your .bats file's `local_setup` function.
setup_test_fixture() {
	mkdir -p "$BASH_IT"
	lib_directory="$(cd "$(dirname "$0")" && pwd)"
	local src_topdir="$lib_directory/../../../.."

	if command -v rsync &> /dev/null; then
		# Use rsync to copy Bash-it to the temp folder
		rsync -qavrKL -d --delete-excluded --exclude=.git --exclude=enabled "$src_topdir" "$BASH_IT"
	else
		rm -rf "$BASH_IT"
		mkdir -p "$BASH_IT"

		find "$src_topdir" \
			-mindepth 1 -maxdepth 1 \
			-not -name .git \
			-exec cp -r {} "$BASH_IT" \;
	fi

	rm -rf "$BASH_IT"/enabled
	rm -rf "$BASH_IT"/aliases/enabled
	rm -rf "$BASH_IT"/completion/enabled
	rm -rf "$BASH_IT"/plugins/enabled

	mkdir -p "$BASH_IT"/enabled
	mkdir -p "$BASH_IT"/aliases/enabled
	mkdir -p "$BASH_IT"/completion/enabled
	mkdir -p "$BASH_IT"/plugins/enabled

	# Some tests use the BASH_IT_TEST_HOME variable, e.g. install/uninstall
	export BASH_IT_TEST_HOME="$TEST_TEMP_DIR"
}

setup() {
	# The `temp_make` function from "bats-file" requires the tralston/bats-file fork,
	# since the original ztombol/bats-file's `temp_make` does not work on macOS.
	TEST_TEMP_DIR="$(temp_make --prefix 'bash-it-test-')"
	export TEST_TEMP_DIR

	export BASH_IT_TEST_DIR="${TEST_TEMP_DIR}/.bash_it"

	export BASH_IT_ROOT="${BASH_IT_TEST_DIR}/root"
	export BASH_IT=$BASH_IT_TEST_DIR

	mkdir -p -- "${BASH_IT_ROOT}"

	# Some tools, e.g. `git` use configuration files from the $HOME directory,
	# which interferes with our tests. The only way to keep `git` from doing this
	# seems to set HOME explicitly to a separate location.
	# Refer to https://git-scm.com/docs/git-config#FILES.
	unset XDG_CONFIG_HOME
	export HOME="${TEST_TEMP_DIR}"
	mkdir -p "${HOME}"

	# For `git` tests to run well, user name and email need to be set.
	# Refer to https://git-scm.com/docs/git-commit#_commit_information.
	# This goes to the test-specific config, due to the $HOME overridden above.
	git config --global user.name "John Doe"
	git config --global user.email "johndoe@example.com"

	local_setup
}

teardown() {
	local_teardown
#!/bin/bash
BASH_IT_LOG_PREFIX="core: reloader: "

function _set-prefix-based-on-path()
{
  filename=$(_bash-it-get-component-name-from-path "$1")
  extension=$(_bash-it-get-component-type-from-path "$1")
  BASH_IT_LOG_PREFIX="$extension: $filename: "
}

if [[ "$1" != "skip" ]] && [[ -d "$BASH_IT/enabled" ]]; then
  _bash_it_config_type=""

  case $1 in
    alias|completion|plugin)
      _bash_it_config_type=$1
      _log_debug "Loading enabled $1 components..." ;;
    *|'')
      _log_debug "Loading all enabled components..." ;;
  esac

  for _bash_it_config_file in $(sort <(compgen -G "$BASH_IT/enabled/*${_bash_it_config_type}.bash")); do
    if [ -e "${_bash_it_config_file}" ]; then
      _set-prefix-based-on-path "${_bash_it_config_file}"
      _log_debug "Loading component..."
      # shellcheck source=/dev/null
      source $_bash_it_config_file
    else
      echo "Unable to read ${_bash_it_config_file}" > /dev/stderr
    fi
  done
fi

if [[ -n "${2}" ]] && [[ -d "$BASH_IT/${2}/enabled" ]]; then
  case $2 in
    aliases|completion|plugins)
      _log_warning "Using legacy enabling for $2, please update your bash-it version and migrate"
      for _bash_it_config_file in $(sort <(compgen -G "$BASH_IT/${2}/enabled/*.bash")); do
        if [[ -e "$_bash_it_config_file" ]]; then
          _set-prefix-based-on-path "${_bash_it_config_file}"
          _log_debug "Loading component..."
          # shellcheck source=/dev/null
          source "$_bash_it_config_file"
        else
          echo "Unable to locate ${_bash_it_config_file}" > /dev/stderr
        fi
      done ;;
  esac
fi

#!/usr/bin/env bash

# If not running interactively, don't do anything
case $- in
  *i*) ;;
    *) return;;
esac

# Path to the bash it configuration
export BASH_IT="{{BASH_IT}}"

# Lock and Load a custom theme file.
# Leave empty to disable theming.
# location /.bash_it/themes/
export BASH_IT_THEME='bobby'

# (Advanced): Change this to the name of your remote repo if you
# cloned bash-it with a remote other than origin such as `bash-it`.
# export BASH_IT_REMOTE='bash-it'

# (Advanced): Change this to the name of the main development branch if
# you renamed it or if it was changed for some reason
# export BASH_IT_DEVELOPMENT_BRANCH='master'

# Your place for hosting Git repos. I use this for private repos.
export GIT_HOSTING='git@git.domain.com'

# Don't check mail when opening terminal.
unset MAILCHECK

# Change this to your console based IRC client of choice.
export IRC_CLIENT='irssi'

# Set this to the command you use for todo.txt-cli
export TODO="t"

# Set this to false to turn off version control status checking within the prompt for all themes
export SCM_CHECK=true
# Set to actual location of gitstatus directory if installed
#export SCM_GIT_GITSTATUS_DIR="$HOME/gitstatus"
# per default gitstatus uses 2 times as many threads as CPU cores, you can change this here if you must
#export GITSTATUS_NUM_THREADS=8

# Set Xterm/screen/Tmux title with only a short hostname.
# Uncomment this (or set SHORT_HOSTNAME to something else),
# Will otherwise fall back on $HOSTNAME.
#export SHORT_HOSTNAME=$(hostname -s)

# Set Xterm/screen/Tmux title with only a short username.
# Uncomment this (or set SHORT_USER to something else),
# Will otherwise fall back on $USER.
#export SHORT_USER=${USER:0:8}

# If your theme use command duration, uncomment this to
# enable display of last command duration.
#export BASH_IT_COMMAND_DURATION=true
# You can choose the minimum time in seconds before
# command duration is displayed.
#export COMMAND_DURATION_MIN_SECONDS=1

# Set Xterm/screen/Tmux title with shortened command and directory.
# Uncomment this to set.
#export SHORT_TERM_LINE=true

# Set vcprompt executable path for scm advance info in prompt (demula theme)
# https://github.com/djl/vcprompt
#export VCPROMPT_EXECUTABLE=~/.vcprompt/bin/vcprompt

# (Advanced): Uncomment this to make Bash-it reload itself automatically
# after enabling or disabling aliases, plugins, and completions.
# export BASH_IT_AUTOMATIC_RELOAD_AFTER_CONFIG_CHANGE=1

# Uncomment this to make Bash-it create alias reload.
# export BASH_IT_RELOAD_LEGACY=1

#!/bin/bash
#
# -binaryanomaly

cite 'about-alias'
about-alias 'kubectl aliases'

function _set_pkg_aliases()
{
  if _command_exists kubectl; then
    alias kc='kubectl'
    alias kcgp='kubectl get pods'
    alias kcgd='kubectl get deployments'
    alias kcgn='kubectl get nodes'
    alias kcdp='kubectl describe pod'
    alias kcdd='kubectl describe deployment'
    alias kcdn='kubectl describe node'
    alias kcgpan='kubectl get pods --all-namespaces'
    alias kcgdan='kubectl get deployments --all-namespaces'
    # launches a disposable netshoot pod in the k8s cluster
cite 'uuid-alias'
about-alias 'uuidgen aliases'

if _command_exists uuid; then # Linux
  alias uuidu="uuid | tr '[:lower:]' '[:upper:]'"
  alias uuidl=uuid
elif _command_exists uuidgen; then # macOS/BSD
  alias uuidu="uuidgen"
  alias uuid="uuidgen | tr '[:upper:]' '[:lower:]'" # because upper case is like YELLING
  alias uuidl=uuid
cite 'about-alias'
about-alias 'heroku task abbreviations'

# heroku
alias h='heroku'
alias hl='heroku list'
alias hi='heroku info'
alias ho='heroku open'

# dynos and workers
alias hd='heroku dynos'
alias hw='heroku workers'

# rake console
alias hr='heroku rake'
alias hcon='heroku console'

# new and restart
alias hnew='heroku create'
alias hrestart='heroku restart'

# logs
alias hlog='heroku logs'
alias hlogs='heroku logs'

# maint
alias hon='heroku maintenance:on'
alias hoff='heroku maintenance:off'

# heroku configs
cite 'about-alias'
about-alias 'rails abbreviations'

# Rails Commands
alias r='rails'
alias rg='rails g'
alias rs='rails s'
alias rc='rails c'
alias rn='rails new'
alias rb='rails dbconsole'
alias rp='rails plugin'
alias ra='rails application'
alias rd='rails destroy'
alias dbm='rake db:migrate'

alias ss='script/server'
alias ts="thin start"     # thin server
alias sc='script/console'
alias restartapp='touch tmp/restart.txt'
alias restart='touch tmp/restart.txt'  # restart passenger
cite 'about-alias'
about-alias 'vault aliases'

# Aliases
alias vad="vault delete"
alias val="vault list"
alias var="vault read"
alias varn="vault renew"
alias varv="vault revoke"
alias vasrv="vault server"
cite 'about-alias'
about-alias 'docker-compose abbreviations'

alias dco="docker-compose"

cite 'about-alias'
about-alias 'todo.txt-cli abbreviations'

alias tls="$TODO ls"
alias ta="$TODO a"
cite about-alias
about-alias 'Aliases for the bash-it command (these aliases are automatically included with the "general" aliases)'

# Common misspellings of bash-it
alias shit='bash-it'
alias batshit='bash-it'
alias bashit='bash-it'
alias batbsh='bash-it'
alias babsh='bash-it'
alias bash_it='bash-it'
alias bash_ti='bash-it'

# Additional bash-it aliases for help/show
alias bshsa='bash-it show aliases'
alias bshsc='bash-it show completions'
alias bshsp='bash-it show plugins'
alias bshha='bash-it help aliases'
alias bshhc='bash-it help completions'
alias bshhp='bash-it help plugins'
alias bshsch="bash-it search"
cite 'about-alias'
about-alias 'common git-svn abbreviations'

# Aliases
alias gsr='git svn rebase'
cite 'about-alias'
about-alias 'Atom.io editor abbreviations'

alias a='atom'
alias ah='atom .'
# shellcheck shell=bash
cite 'about-alias'
about-alias 'xclip shortcuts'

alias pbcopy="xclip -selection clipboard"
alias pbpaste="xclip -selection clipboard -o"

alias xcpy="xclip -selection clipboard"
alias xpst="xclip -selection clipboard -o"
# to use it just install xclip on your distribution and it would work like:
# $ echo "hello" | xcpy
# $ xpst
# hello

# very useful for things like:
cite 'about-alias'
about-alias 'systemd service'

case $OSTYPE in
    linux*)
# Improve aliases by bringing the common root `sc|scd` + `sre` for action + `u` for user
	alias sc='systemctl'
	alias scu='systemctl --user'
	alias scdr='systemctl daemon-reload'
	alias scdru='systemctl --user daemon-reload'
	alias scr='systemctl restart'
	alias scru='systemctl --user restart'
	alias sce='systemctl stop'
	alias sceu='systemctl --user stop'
	alias scs='systemctl start'
	alias scsu='systemctl --user start'
# Keeping previous aliases for a non-breaking change.
	alias scue='sceu'
	alias scus='scsu'
	alias scur='scdru'
cite 'about-alias'
about-alias 'maven abbreviations'

alias mci='mvn clean install'
alias mi='mvn install'
alias mcp='mvn clean package'
alias mp='mvn package'
alias mrprep='mvn release:prepare'
alias mrperf='mvn release:perform'
alias mrrb='mvn release:rollback'
cite 'about-alias'
about-alias 'vagrant aliases'

# Aliases
alias vhl='vagrant hosts list'
alias vscp='vagrant scp'
alias vsl='vagrant snapshot list'
alias vst='vagrant snapshot take'
alias vup="vagrant up"
alias vupl="vagrant up 2>&1 | tee vagrant.log"
alias vh="vagrant halt"
alias vs="vagrant suspend"
alias vr="vagrant resume"
alias vrl="vagrant reload"
alias vssh="vagrant ssh"
alias vst="vagrant status"
alias vp="vagrant provision"
alias vdstr="vagrant destroy"
# requires vagrant-list plugin
alias vl="vagrant list"
cite 'about-alias'
about-alias 'textmate abbreviations'

case $OSTYPE in
  darwin*)
cite 'about-alias'
about-alias 'laravel artisan abbreviations'

# A list of useful laravel aliases

alias laravel="${HOME}/.composer/vendor/bin/laravel"
# asset
alias a:apub='php artisan asset:publish'

# auth
alias a:remclear='php artisan auth:clear-reminders'
alias a:remcontroller='php artisan auth:reminders-controller'
alias a:remtable='php artisan auth:reminders-table'

# cache
alias a:cacheclear='php artisan cache:clear'

# command
alias a:command='php artisan command:make'

# config
alias a:confpub='php artisan config:publish'

# controller
alias a:controller='php artisan make:controller'

# db
alias a:seed='php artisan db:seed'

# key
alias a:key='php artisan key:generate'

# migrate
alias a:migrate='php artisan migrate'
alias a:mig='a:migrate'
alias a:miginstall='php artisan migrate:install'
alias a:migmake='php artisan migrate:make'
alias a:migcreate='php artisan migrate:create'
alias a:migpublish='php artisan migrate:publish'
alias a:migrefresh='php artisan migrate:refresh'
alias a:migreset='php artisan migrate:reset'
alias a:migrollback='php artisan migrate:rollback'
alias a:rollback='a:migrollback'

# queue
alias a:qfailed='php artisan queue:failed'
alias a:qfailedtable='php artisan queue:failed-table'
alias a:qflush='php artisan queue:flush'
alias a:qforget='php artisan queue:forget'
alias a:qlisten='php artisan queue:listen'
alias a:qretry='php artisan queue:retry'
alias a:qsubscribe='php artisan queue:subscribe'
alias a:qwork='php artisan queue:work'

# session
alias a:stable='php artisan session:table'

# view
alias a:vpub='php artisan view:publish'

# misc
alias a:='php artisan'
alias a:changes='php artisan changes'
alias a:down='php artisan down'
alias a:env='php artisan env'
alias a:help='php artisan help'
alias a:list='php artisan list'
alias a:optimize='php artisan optimize'
alias a:routes='php artisan routes'
alias a:serve='php artisan serve'
cite 'about-alias'
about-alias 'docker abbreviations'

alias dk='docker'
alias dklc='docker ps -l'  # List last Docker container
alias dklcid='docker ps -l -q'  # List last Docker container ID
alias dklcip='docker inspect -f "{{.NetworkSettings.IPAddress}}" $(docker ps -l -q)'  # Get IP of last Docker container
alias dkps='docker ps'  # List running Docker containers
alias dkpsa='docker ps -a'  # List all Docker containers
alias dki='docker images'  # List Docker images
alias dkrmac='docker rm $(docker ps -a -q)'  # Delete all Docker containers

case $OSTYPE in
  darwin*|*bsd*|*BSD*)
    alias dkrmui='docker images -q -f dangling=true | xargs docker rmi'  # Delete all untagged Docker images
    ;;
  *)
    alias dkrmui='docker images -q -f dangling=true | xargs -r docker rmi'  # Delete all untagged Docker images
    ;;
esac

if [ ! -z "$(command ls "${BASH_IT}/enabled/"{[0-9][0-9][0-9]${BASH_IT_LOAD_PRIORITY_SEPARATOR}docker,docker}.plugin.bash 2>/dev/null | head -1)" ]; then
# Function aliases from docker plugin:
    alias dkrmlc='docker-remove-most-recent-container'  # Delete most recent (i.e., last) Docker container
    alias dkrmall='docker-remove-stale-assets'  # Delete all untagged images and exited containers
    alias dkrmli='docker-remove-most-recent-image'  # Delete most recent (i.e., last) Docker image
    alias dkrmi='docker-remove-images'  # Delete images for supplied IDs or all if no IDs are passed as arguments
    alias dkideps='docker-image-dependencies'  # Output a graph of image dependencies using Graphiz
    alias dkre='docker-runtime-environment'  # List environmental variables of the supplied image ID
fi
alias dkelc='docker exec -it $(dklcid) bash --login' # Enter last container (works with Docker 1.3 and above)
alias dkrmflast='docker rm -f $(dklcid)'
alias dkbash='dkelc'
alias dkex='docker exec -it ' # Useful to run any commands into container without leaving host
alias dkri='docker run --rm -i '
alias dkric='docker run --rm -i -v $PWD:/cwd -w /cwd '
alias dkrit='docker run --rm -it '
alias dkritc='docker run --rm -it -v $PWD:/cwd -w /cwd '

# Added more recent cleanup options from newer docker versions
cite 'about-alias'
about-alias 'phoenix abbreviations'

# Phoenix Commands
alias i='iex'
alias ips='iex -S mix phx.server'
alias ism='iex -S mix'
alias m='mix'
alias mab='mix archive.build'
alias mai='mix archive.install'
alias mat='mix app.tree'
alias mc='mix compile'
alias mcv='mix compile --verbose'
alias mcx='mix compile.xref'
alias mdc='mix deps.compile'
alias mdg='mix deps.get'
alias mdgc='mix do deps.get, deps.compile'
alias mdu='mix deps.update'
alias mdt='mix deps.tree'
alias mdua='mix deps.update --all'
alias mdun='mix deps.unlock'
alias mduu='mix deps.unlock --unused'
alias meb='mix escript.build'
alias mec='mix ecto.create'
alias mecm='mix do ecto.create, ecto.migrate'
alias med='mix ecto.drop'
alias mem='mix ecto.migrate'
alias megm='mix ecto.gen.migration'
alias merb='mix ecto.rollback'
alias mers='mix ecto.reset'
alias mho='mix hex.outdated'
alias mlh='mix local.hex'
alias mn='mix new'
alias mns='mix new --sup'
alias mpgc='mix phx.gen.channel'
alias mpgh='mix phx.gen.html'
alias mpgj='mix phx.gen.json'
alias mpgm='mix phx.gen.model'
alias mpgs='mix phx.gen.secret'
alias mpn='mix phx.new'
alias mpr='mix phx.routes'
alias mps='mix phx.server'
alias mr='mix run'
alias mrnh='mix run --no-halt'
alias mrl='mix release'
cite 'about-alias'
about-alias 'Tmux terminal multiplexer'

alias txl='tmux ls'
alias txn='tmux new -s'
cite 'about-alias'
about-alias 'osx-specific aliases'

# Desktop Programs
alias fireworks="open -a '/Applications/Adobe Fireworks CS3/Adobe Fireworks CS3.app'"
alias photoshop="open -a '/Applications/Adobe Photoshop CS3/Adobe Photoshop.app'"
alias preview="open -a '$PREVIEW'"
alias xcode="open -a '/Applications/XCode.app'"
alias filemerge="open -a '/Developer/Applications/Utilities/FileMerge.app'"
alias safari="open -a safari"
alias firefox="open -a firefox"
alias chrome="open -a google\ chrome"
alias chromium="open -a chromium"
alias dashcode="open -a dashcode"
alias f='open -a Finder '
alias fh='open -a Finder .'
alias textedit='open -a TextEdit'
alias hex='open -a "Hex Fiend"'
alias skype='open -a Skype'
alias mou='open -a Mou'
alias subl='open -a Sublime\ Text'

if [ -s /usr/bin/firefox ] ; then
  unalias firefox
fi

# Requires growlnotify, which can be found in the Growl DMG under "Extras"
alias grnot='growlnotify -s -t Terminal -m "Done"'

# Get rid of those pesky .DS_Store files recursively
alias dsclean='find . -type f -name .DS_Store -delete'

# Track who is listening to your iTunes music
alias whotunes='lsof -r 2 -n -P -F n -c iTunes -a -i TCP@`hostname`:3689'

# Flush your dns cache
alias flush='dscacheutil -flushcache'

# Show/hide hidden files (for Mac OS X Mavericks)
alias showhidden="defaults write com.apple.finder AppleShowAllFiles TRUE"
alias hidehidden="defaults write com.apple.finder AppleShowAllFiles FALSE"

# From http://apple.stackexchange.com/questions/110343/copy-last-command-in-terminal
alias copyLastCmd='fc -ln -1 | awk '\''{$1=$1}1'\'' ORS='\'''\'' | pbcopy'

# Use Finder's Quick Look on a file (^C or space to close)
alias ql='qlmanage -p 2>/dev/null'

# Mute/Unmute the system volume. Plays nice with all other volume settings.
alias mute="osascript -e 'set volume output muted true'"
cite 'about-alias'
about-alias 'pyrocms abbreviations'

###
## PyroCMS 3.4 bash aliases
## @author Denis Efremov <efremov.a.denis@gmail.com>
###

# general
alias a:cl="php artisan clear-compiled"          # Remove the compiled class file
alias a:d="php artisan down"                     # Put the application into maintenance mode
alias a:e="php artisan env"                      # Display the current framework environment
alias a:h="php artisan help"                     # Displays help for a command
alias a:i="php artisan install"                  # Install the Streams Platform.
alias a:ls="php artisan list"                    # Lists commands
alias a:mg="php artisan migrate"                 # Run the database migrations
alias a:op="php artisan optimize"                # Optimize the framework for better performance (deprecated)
alias a:pr="php artisan preset"                  # Swap the front-end scaffolding for the application
alias a:s="php artisan serve"                    # Serve the application on the PHP development server
alias a:u="php artisan up"                       # Bring the application out of maintenance mode

# addon
alias a:ad:i="php artisan addon:install"         # Install an addon.
alias a:ad:p="php artisan addon:publish"         # Publish an the configuration and translations for an addon.
alias a:ad:r="php artisan addon:reinstall"       # Reinstall an addon.
alias a:ad:u="php artisan addon:uninstall"       # Uninstall an addon.

# app
alias a:ap:n="php artisan app:name"              # Set the application namespace
alias a:ap:p="php artisan app:publish"           # Publish general application override files.

# assets
alias a:as:cl="php artisan assets:clear"         # Clear compiled public assets.

# auth
alias a:au:clrs="php artisan auth:clear-resets"  # Flush expired password reset tokens

# cache
alias a:ca:cl="php artisan cache:clear"          # Flush the application cache
alias a:ca:f="php artisan cache:forget"          # Remove an item from the cache
alias a:ca:t="php artisan cache:table"           # Create a migration for the cache database table

# config
alias a:co:ca="php artisan config:cache"         # Create a cache file for faster configuration loading
alias a:co:cl="php artisan config:clear"         # Remove the configuration cache file

# db
alias a:db:s="php artisan db:seed"               # Seed the database with records

# env
alias a:en:s="php artisan env:set"               # Set an environmental value.

# event
alias a:ev:g="php artisan event:generate"        # Generate the missing events and listeners based on registration

# extension
alias a:ex:i="php artisan extension:install"     # Install a extension.
alias a:ex:r="php artisan extension:reinstall"   # Reinstall a extension.
alias a:ex:u="php artisan extension:uninstall"   # Uninstall a extension.

# files
alias a:fi:cl="php artisan files:clean"          # Clean missing files from the files table.

# key
alias a:ke:g="php artisan key:generate"          # Set the application key

# make
alias a:mk:ad="php artisan make:addon"           # Create a new addon.
alias a:mk:au="php artisan make:auth"            # Scaffold basic login and registration views and routes
alias a:mk:cm="php artisan make:command"         # Create a new Artisan command
alias a:mk:ct="php artisan make:controller"      # Create a new controller class
alias a:mk:ev="php artisan make:event"           # Create a new event class
alias a:mk:fa="php artisan make:factory"         # Create a new model factory
alias a:mk:j="php artisan make:job"              # Create a new job class
alias a:mk:li="php artisan make:listener"        # Create a new event listener class
alias a:mk:ma="php artisan make:mail"            # Create a new email class
alias a:mk:mw="php artisan make:middleware"      # Create a new middleware class
alias a:mk:mg="php artisan make:migration"       # Create a new migration file
alias a:mk:md="php artisan make:model"           # Create a new Eloquent model class
alias a:mk:no="php artisan make:notification"    # Create a new notification class
alias a:mk:po="php artisan make:policy"          # Create a new policy class
alias a:mk:pr="php artisan make:provider"        # Create a new service provider class
alias a:mk:rq="php artisan make:request"         # Create a new form request class
alias a:mk:rs="php artisan make:resource"        # Create a new resource
alias a:mk:rl="php artisan make:rule"            # Create a new validation rule
alias a:mk:sd="php artisan make:seeder"          # Create a new seeder class
alias a:mk:st="php artisan make:stream"          # Make a streams entity namespace.
alias a:mk:ts="php artisan make:test"            # Create a new test class

# migrate
alias a:mg:fr="php artisan migrate:fresh"        # Drop all tables and re-run all migrations
alias a:mg:i="php artisan migrate:install"       # Create the migration repository
alias a:mg:rf="php artisan migrate:refresh"      # Reset and re-run all migrations
alias a:mg:rs="php artisan migrate:reset"        # Rollback all database migrations
alias a:mg:rl="php artisan migrate:rollback"     # Rollback the last database migration
alias a:mg:st="php artisan migrate:status"       # Show the status of each migration

# module
alias a:mo:i="php artisan module:install"        # Install a module.
alias a:mo:r="php artisan module:reinstall"      # Reinstall a module.
alias a:mo:u="php artisan module:uninstall"      # Uninstall a module.

# notifications
alias a:no:tb="php artisan notifications:table"  # Create a migration for the notifications table

# package
alias a:pk:d="php artisan package:discover"      # Rebuild the cached package manifest

# queue
alias a:qu:fa="php artisan queue:failed"         # List all of the failed queue jobs
alias a:qu:ft="php artisan queue:failed-table"   # Create a migration for the failed queue jobs database table
alias a:qu:fl="php artisan queue:flush"          # Flush all of the failed queue jobs
alias a:qu:fg="php artisan queue:forget"         # Delete a failed queue job
alias a:qu:li="php artisan queue:listen"         # Listen to a given queue
alias a:qu:rs="php artisan queue:restart"        # Restart queue worker daemons after their current job
alias a:qu:rt="php artisan queue:retry"          # Retry a failed queue job
alias a:qu:tb="php artisan queue:table"          # Create a migration for the queue jobs database table
alias a:qu:w="php artisan queue:work"            # Start processing jobs on the queue as a daemon

# route
alias a:ro:ca="php artisan route:cache"          # Create a route cache file for faster route registration
alias a:ro:cl="php artisan route:clear"          # Remove the route cache file
alias a:ro:ls="php artisan route:list"           # List all registered routes

# schedule
alias a:sc:r="php artisan schedule:run"          # Run the scheduled commands

# scout
alias a:su:fl="php artisan scout:flush"          # Flush all of the model's records from the index
alias a:su:im="php artisan scout:import"         # Import the given model into the search index

# session
alias a:se:tb="php artisan session:table"        # Create a migration for the session database table

# storage
alias a:sg:l="php artisan storage:link"          # Create a symbolic link from "public/storage" to "storage/app/public"

# streams
alias a:st:cl="php artisan streams:cleanup"      # Cleanup streams entry models.
alias a:st:co="php artisan streams:compile"      # Compile streams entry models.
alias a:st:d="php artisan streams:destroy"       # Destroy a namespace.
alias a:st:p="php artisan streams:publish"       # Publish configuration and translations for streams.
alias a:st:r="php artisan streams:refresh"       # Refresh streams generated components.

# tntsearch
alias a:tn:im="php artisan tntsearch:import"     # Import the given model into the search index

# vendor
alias a:ve:p="php artisan vendor:publish"        # Publish any publishable assets from vendor packages

# shellcheck shell=bash
cite 'about-alias'
about-alias 'dnf aliases for fedora 22+ distros'

alias dnfl="dnf list"            # List packages
alias dnfli="dnf list installed" # List installed packages
alias dnfgl="dnf grouplist"      # List package groups
alias dnfmc="dnf makecache"      # Generate metadata cache
alias dnfp="dnf info"            # Show package information
alias dnfs="dnf search"          # Search package

alias dnfu="sudo dnf upgrade"       # Upgrade package
alias dnfi="sudo dnf install"       # Install package
alias dnfri='sudo dnf reinstall'    # Reinstall package
alias dnfgi="sudo dnf groupinstall" # Install package group
cite 'about-alias'
about-alias 'fuck/please to retry last command with sudo'

# Play nicely with 'thefuck' plugin
if ! _command_exists fuck ; then
cite 'about-alias'
about-alias 'puppet aliases'

# Aliases
alias pupval="puppet parser validate *.pp"
cite 'about-alias'
about-alias 'the silver searcher (ag) aliases'

## Summary for args to less:
# less(1)
#   -M (-M or --LONG-PROMPT) Prompt very verbosely
#   -I (-I or --IGNORE-CASE) Searches with '/' ignore case
#   -R (-R or --RAW-CONTROL-CHARS) For handling ANSI colors
#   -F (-F or --quit-if-one-screen) Auto exit if <1 screen
#   -X (-X or --no-init) Disable termcap init & deinit
cite 'about-alias'
about-alias 'common npm abbreviations'

# Aliases

# npm
alias ni='npm install'
alias nis='npm install --save'
alias nid='npm install --save-dev'
alias nit='npm install-test'
alias nits='npm install-test --save'
alias nitd='npm install-test --save-dev'
alias nu='npm uninstall'
alias nus='npm uninstall --save'
alias nusd='npm uninstall --save-dev'
alias np='npm publish'
alias nup='npm unpublish'
alias nlk='npm link'
alias nod='npm outdated'
alias nrb='npm rebuild'
alias nud='npm update'
alias nr='npm run'
alias nls='npm list --depth=0 2>/dev/null'
alias nlsg='npm list -g --depth=0 2>/dev/null'

# npx
alias nx='npx'
alias nxplease='npx $(fc -ln -1)'
alias nxn='npx --no-install '
alias nxp='npx -p '
alias nxnp='npx --no-install -p '
alias nxq='npx -q '
alias nxnq='npx --no-install -q '
alias nxqp='npx -q -p '
alias nxnqp='npx --no-install -q -p '
alias nxni='npx --no-install --ignore-existing '
alias nxip='npx --ignore-existing -p '
alias nxnip='npx --no-install --ignore-existing -p '
alias nxqi='npx -q --ignore-existing '
alias nxniq='npx --no-install --ignore-existing -q '
# Aliases for Terraform and Terragrunt

cite 'about-alias'
about-alias 'Terragrunt abbreviations'

alias tg='terragrunt'
alias tgv='terragrunt validate'
alias tgp='terragrunt plan'
alias tga='terragrunt apply'
alias tgd='terragrunt destroy'
cite 'about-alias'
about-alias 'common composer abbreviations'

# Aliases
alias coab='composer about'
alias coar='composer archive'
alias cob='composer browser'
alias cocpr='composer check-platform-reqs'
alias cocc='composer clear-cache'
alias cocfg='composer config'
alias cocp='composer create-project'
alias codp='composer depends'
alias codiag='composer diagnose'
alias codmp='composer dump-autoload'
alias coex='composer exec'
alias coglob='composer global'
alias coh='composer help'
alias cohome='composer home'
alias coi='composer install'
alias coinf='composer info'
alias coini='composer init'
alias coli='composer license'
alias colis='composer list'
alias coout='composer outdated'
alias cop='composer prohibits'
alias corem='composer remove'
alias coreq='composer require'
alias coreqd='composer require --dev'
alias cors='composer run-script'
alias cos='composer search'
alias cosu='composer self-update'
alias coshow='composer show'
alias costat='composer status'
alias cosugg='composer suggest'
alias coup='composer update'
cite about-alias
about-alias 'general aliases'

if ls --color -d . &> /dev/null
then
  alias ls="ls --color=auto"
elif ls -G -d . &> /dev/null
then
  alias ls='ls -G'        # Compact view, show colors
fi

# List directory contents
alias sl=ls
alias la='ls -AF'       # Compact view, show hidden
alias ll='ls -al'
alias l='ls -a'
alias l1='ls -1'

alias _="sudo"

# Shortcuts to edit startup files
alias vbrc="vim ~/.bashrc"
alias vbpf="vim ~/.bash_profile"

# colored grep
# Need to check an existing file for a pattern that will be found to ensure
# that the check works when on an OS that supports the color option
if grep --color=auto "a" "${BASH_IT}/"*.md &> /dev/null
then
  alias grep='grep --color=auto'
fi

if which gshuf &> /dev/null
then
  alias shuf=gshuf
fi

alias c='clear'
alias k='clear'
alias cls='clear'

alias edit="$EDITOR"
alias pager="$PAGER"

alias q='exit'

alias irc="${IRC_CLIENT:=irc}"

# Language aliases
alias rb='ruby'
alias py='python'
alias ipy='ipython'

# Pianobar can be found here: http://github.com/PromyLOPh/pianobar/

alias piano='pianobar'

alias ..='cd ..'         # Go up one directory
alias cd..='cd ..'       # Common misspelling for going up one directory
alias ...='cd ../..'     # Go up two directories
alias ....='cd ../../..' # Go up three directories
alias -- -='cd -'        # Go back

# Shell History
alias h='history'

# Tree
if [ ! -x "$(which tree 2>/dev/null)" ]
then
  alias tree="find . -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'"
fi

# Directory
alias md='mkdir -p'
alias rd='rmdir'

# Shorten extract
alias xt="extract"

# sudo editors
alias svim="sudo vim"
alias snano="sudo nano"

# Display whatever file is regular file or folder
catt() {
  for i in "$@"; do
    if [ -d "$i" ]; then
      ls "$i"
    else
      cat "$i"
    fi
  done
}

# The Bash-it aliases were moved to the `bash-it.aliases.bash` file. The intent of this
# is to keep the script readable and less bloated. If you don't need to use
# the `general` aliases, but you want the Bash-it aliases, you can disable the `general`
# aliases and enable just the ones for Bash-it explicitly:
# bash-it disable alias general
# bash-it enable alias bash-it
cite 'about-alias'
about-alias 'yarn package manager aliases'

# Aliases
alias ya='yarn'
alias yai='yarn init'
alias yaa='yarn add'
alias yaga='yarn global add'
alias yaad='yarn add --dev'
alias yau='yarn upgrade'
alias yarm='yarn remove'
alias yagrm='yarn global remove'
alias yaod='yarn outdated'
alias yapa='yarn pack'
alias yap='yarn publish'
alias yasu='yarn self-update'
alias yaru='yarn run'
alias yat='yarn test'
alias yas='yarn serve'
alias yacc='yarn cache clean'
alias yack='yarn check'
alias yals='yarn list'
alias yain='yarn info'
alias yali='yarn licenses ls'
alias yaloi='yarn login'
# Aliases for Terraform and Terragrunt

cite 'about-alias'
about-alias 'Terraform abbreviations'

cite 'about-alias'
about-alias 'the Node.js environment aliases'

# alias to setup nodejs development environment
alias node-dev='export NODE_ENV=development'
# Some aliases for Homebrew Cask

cite 'about-alias'
about-alias 'homebrew-cask abbreviations'

alias bcin='brew cask install'
alias bcrm='brew cask uninstall'
alias bczp='brew cask zap'
alias bccl='brew cask cleanup'
alias bcls='brew cask list'
cite 'about-alias'
about-alias 'puppet bolt aliases'

# Aliases
alias bolt='bolt command run --tty --no-host-key-check'
cite 'about-alias'
about-alias 'homesick aliases'

# Aliases
alias sikhm="homesick cd dotfiles"
alias sikclone="homesick clone"
alias sikcomt="homesick commit dotfiles"
alias sikdstry="homesick destroy"
alias sikdif="homesick diff dotfiles"
alias sikexec="homesick exec dotfiles"
alias sikexeca="homesick exec_all"
alias sikgen="homesick generate"
alias sikhlp="homesick help"
alias siklnk="homesick link dotfiles"
alias sikls="homesick list"
alias sikopn="homesick open dotfiles"
alias sikpll="homesick pull dotfiles"
alias sikpsh="homesick push dotfiles"
alias sikrc="homesick rc dotfiles"
alias sikpth="homesick show_path dotfiles"
#!/bin/bash
#
# -binaryanomaly

cite 'about-alias'
about-alias 'Apt and dpkg aliases for Ubuntu and Debian distros.'

# set apt aliases
function _set_pkg_aliases()
{
	if [ -x $(which apt) ]; then
		alias apts='apt-cache search'
		alias aptshow='apt-cache show'
		alias aptinst='sudo apt-get install -V'
		alias aptupd='sudo apt-get update'
		alias aptupg='sudo apt-get dist-upgrade -V && sudo apt-get autoremove'
		alias aptupgd='sudo apt-get update && sudo apt-get dist-upgrade -V && sudo apt-get autoremove'
		alias aptrm='sudo apt-get remove'
		alias aptpurge='sudo apt-get remove --purge'

		alias chkup='/usr/lib/update-notifier/apt-check -p --human-readable'
		alias chkboot='cat /var/run/reboot-required'

		alias pkgfiles='dpkg --listfiles'
	fi
cite 'about-alias'
about-alias 'ruby bundler'

# Bundler Commands
alias be='bundle exec'
#!/bin/bash

cite 'about-alias'
about-alias 'MSYS2 aliases'

LS_COMMON="-hG"
LS_COMMON="$LS_COMMON --color=auto"
LS_COMMON="$LS_COMMON -I NTUSER.DAT\* -I ntuser.dat\*"

# alias
cite 'about-alias'
about-alias 'jitsu task abbreviations'

# jitsu
alias j='jitsu'
alias jl='jitsu login'
alias jo='jitsu logout'

# deploy and update
alias jd='jitsu apps deploy'
alias ju='jitsu apps update'

# new and start, restart, stop
alias jn='jitsu apps create'
alias js='jitsu apps start'
alias jr='jitsu apps restart'
alias jx='jitsu apps stop'

# logs
alias jll='jitsu logs'
alias jlog='jitsu logs'
alias jlogs='jitsu logs'

# env
alias je='jitsu env'
alias jel='jitsu env list'
alias jes='jitsu env set'
alias jeg='jitsu env get'
alias jed='jitsu env delete'
alias jec='jitsu env clear'
alias jesv='jitsu env save'
alias jeld='jitsu env load'

# configuration
alias jc='jitsu conf'
alias jcl='jitsu config list'
alias jcs='jitsu config set'
alias jcg='jitsu config get'
alias jcd='jitsu config delete'

#  list and install, view
alias jls='jitsu list'
alias jin='jitsu install'
alias jv='jitsu apps view'

# shellcheck shell=bash
cite 'about-alias'
about-alias 'common git abbreviations'

alias g='git'
alias get='git'

# add
alias ga='git add'
alias gall='git add -A'
alias gap='git add -p'

# branch
alias gb='git branch'
alias gbD='git branch -D'
alias gba='git branch -a'
alias gbd='git branch -d'
alias gbm='git branch -m'
alias gbt='git branch --track'
alias gdel='git branch -D'

# for-each-ref
alias gbc='git for-each-ref --format="%(authorname) %09 %(if)%(HEAD)%(then)*%(else)%(refname:short)%(end) %09 %(creatordate)" refs/remotes/ --sort=authorname DESC' # FROM https://stackoverflow.com/a/58623139/10362396

# commit
alias gc='git commit -v'
alias gca='git commit -v -a'
alias gcaa='git commit -a --amend -C HEAD' # Add uncommitted and unstaged changes to the last commit
alias gcam='git commit -v -am'
alias gcamd='git commit --amend'
alias gcm='git commit -v -m'
alias gci='git commit --interactive'
alias gcsam='git commit -S -am'

# checkout
alias gcb='git checkout -b'
alias gco='git checkout'
alias gcob='git checkout -b'
alias gcobu='git checkout -b ${USER}/'
alias gcom='git checkout master'
alias gcpd='git checkout master; git pull; git branch -D'
alias gct='git checkout --track'

# clone
alias gcl='git clone'

# clean
alias gclean='git clean -fd'

# cherry-pick
alias gcp='git cherry-pick'
alias gcpx='git cherry-pick -x'

# diff
alias gd='git diff'
alias gds='git diff --staged'
alias gdt='git difftool'

# archive
alias gexport='git archive --format zip --output'

# fetch
alias gf='git fetch --all --prune'
alias gft='git fetch --all --prune --tags'
alias gftv='git fetch --all --prune --tags --verbose'
alias gfv='git fetch --all --prune --verbose'
alias gmu='git fetch origin -v; git fetch upstream -v; git merge upstream/master'
alias gup='git fetch && git rebase'

# log
alias gg='git log --graph --pretty=format:'\''%C(bold)%h%Creset%C(magenta)%d%Creset %s %C(yellow)<%an> %C(cyan)(%cr)%Creset'\'' --abbrev-commit --date=relative'
alias ggf='git log --graph --date=short --pretty=format:'\''%C(auto)%h %Cgreen%an%Creset %Cblue%cd%Creset %C(auto)%d %s'\'''
alias ggs='gg --stat'
alias gll='git log --graph --pretty=oneline --abbrev-commit'
alias gnew='git log HEAD@{1}..HEAD@{0}' # Show commits since last pull, see http://blogs.atlassian.com/2014/10/advanced-git-aliases/
alias gwc='git whatchanged'

# ls-files
alias gu='git ls-files . --exclude-standard --others' # Show untracked files
alias glsut='gu'
alias glsum='git diff --name-only --diff-filter=U' # Show unmerged (conflicted) files

# gui
alias ggui='git gui'

# home
alias ghm='cd '\''$(git rev-parse --show-toplevel)'\''' # Git home
# appendage to ghm
if ! _command_exists gh; then
	alias gh='ghm'
fi

# merge
alias gm='git merge'

# mv
alias gmv='git mv'

# patch
alias gpatch='git format-patch -1'

# push
alias gp='git push'
alias gpd='git push --delete'
alias gpf='git push --force'
alias gpo='git push origin HEAD'
alias gpom='git push origin master'
alias gpu='git push --set-upstream'
alias gpunch='git push --force-with-lease'
alias gpuo='git push --set-upstream origin'
alias gpuoc='git push --set-upstream origin $(git symbolic-ref --short HEAD)'

# pull
alias gl='git pull'
alias glum='git pull upstream master'
alias gpl='git pull'
alias gpp='git pull && git push'
alias gpr='git pull --rebase'

# remote
alias gr='git remote'
alias gra='git remote add'
alias grv='git remote -v'

# rm
alias grm='git rm'

# rebase
alias grb='git rebase'
alias grm='git rebase master'
alias grmi='git rebase master -i'
alias gprom='git fetch origin master && git rebase origin/master && git update-ref refs/heads/master origin/master' # Rebase with latest remote master

# reset
alias gus='git reset HEAD'
alias gpristine='git reset --hard && git clean -dfx'

# status
alias gs='git status'
alias gss='git status -s'

# shortlog
alias gcount='git shortlog -sn'
alias gsl='git shortlog -sn'

# show
alias gsh='git show'

# svn
alias gsd='git svn dcommit'
alias gsr='git svn rebase' # Git SVN

# stash
alias gst='git stash'
alias gstb='git stash branch'
alias gstd='git stash drop'
alias gstl='git stash list'
alias gstp='git stash pop'  # kept due to long-standing usage
alias gstpo='git stash pop' # recommended for it's symmetry with gstpu (push)

## 'stash push' introduced in git v2.13.2
alias gstpu='git stash push'
alias gstpum='git stash push -m'

## 'stash save' deprecated since git v2.16.0, alias is now push
alias gsts='git stash push'
alias gstsm='git stash push -m'

# submodules
alias gsu='git submodule update --init --recursive'

# switch
# these aliases requires git v2.23+
alias gsw='git switch'
alias gswc='git switch --create'
alias gswm='git switch master'
alias gswt='git switch --track'

# tag
alias gt='git tag'
alias gta='git tag -a'
alias gtd='git tag -d'
alias gtl='git tag -l'

case $OSTYPE in
	darwin*)
		alias gtls="git tag -l | gsort -V"
		;;
	*)
		alias gtls='git tag -l | sort -V'
		;;
esac

# functions
function gdv() {
# shellcheck shell=bash
cite 'about-alias'
about-alias 'vim abbreviations'

VIM=$(command -v vim)
GVIM=$(command -v gvim)
MVIM=$(command -v mvim)

if [[ -n $VIM ]]; then
	alias v='$VIM'
	# open the vim help in fullscreen incorporated from
	# https://stackoverflow.com/a/4687513
	alias vimh='${VIM} -c ":h | only"'
fi

# open vim in new tab is taken from
# http://stackoverflow.com/questions/936501/let-gvim-always-run-a-single-instancek
case $OSTYPE in
	darwin*)
		[[ -n $MVIM ]] && function mvimt { command mvim --remote-tab-silent "$@" || command mvim "$@"; }
#!/bin/bash

cite 'about-alias'
about-alias 'Curl aliases for convenience.'

# set apt aliases
function _set_pkg_aliases()
{
	if [ -x $(which curl) ]; then
		# follow redirects
                alias cl='curl -L'
                # follow redirects, download as original name
                alias clo='curl -L -O'
                # follow redirects, download as original name, continue
                alias cloc='curl -L -C - -O'
                # follow redirects, download as original name, continue, retry 5 times
                alias clocr='curl -L -C - -O --retry 5'
                # follow redirects, fetch banner
                alias clb='curl -L -I'
		# see only response headers from a get request
# Some aliases for Homebrew

cite 'about-alias'
about-alias 'homebrew abbreviations'

alias bup='brew update && brew upgrade'
alias bout='brew outdated'
alias bin='brew install'
alias brm='brew uninstall'
alias bcl='brew cleanup'
cite 'about-alias'
about-alias 'emacs editor'

case $OSTYPE in
  linux*)
    alias em='emacs'
    alias en='emacs -nw'
    alias e='emacsclient -n'
    alias et='emacsclient -t'
    alias ed='emacs --daemon'
    alias E='SUDO_EDITOR=emacsclient sudo -e'
    ;;
  darwin*)
    alias em='open -a emacs'
    ;;
cite 'about-alias'
about-alias 'mercurial abbreviations'

alias hs='hg status'
alias hsum='hg summary'
cite 'about-alias'
about-alias 'common svn abbreviations'

# Aliases
alias svs='svn status'
alias sa='svn add'
alias sci='svn ci -m'
alias sco='svn co'
alias sup='svn up'
alias scu='svn cleanup'
cite about-plugin
about-plugin 'Simplify `curl cht.sh/<query>` to `cht.sh <query>`'

# Play nicely if user already installed cht.sh cli tool
if ! _command_exists cht.sh ; then
	function cht.sh () {
		about 'Executes a cht.sh curl query using the provided arguments'
		param ' [ ( topic [sub-topic] ) | ~keyword ] [ :list | :help | :learn ]'
		example '$ cht.sh :help'
		example '$ cht.sh :list'
		example '$ cht.sh tar'
		example '$ cht.sh js "parse json"'
		example '$ cht.sh python :learn'
		example '$ cht.sh rust :list'
		group 'cht-sh'

		# Separate arguments with '/', preserving spaces within them
		local query=$(IFS=/ ; echo "$*")
		curl "cht.sh/${query}"
	}
# Load git-subrepo if you are using it, and initialize completions

cite about-plugin
about-plugin 'load git-subrepo if you are using it, and initialize completions'

# plugin for plenv

cite about-plugin
about-plugin 'plenv plugin for Perl'

if [[ -e "${HOME}/.plenv/bin" ]] ; then

  # load plenv bin dir into path if it exists
  pathmunge "${HOME}/.plenv/bin"

fi

if [[ `which plenv` ]] ; then

  # init plenv
# make sure that tmux is launched in 256 color mode

cite about-plugin
about-plugin 'make sure that tmux is launched in 256 color mode'

cite about-plugin
about-plugin 'display info about your battery charge level'

ac_adapter_connected(){
  if _command_exists upower;
  then
    upower -i $(upower -e | grep -i BAT) | grep 'state' | grep -q 'charging\|fully-charged'
    return $?
  elif _command_exists acpi;
  then
    acpi -a | grep -q "on-line"
    return $?
  elif _command_exists pmset;
  then
    pmset -g batt | grep -q 'AC Power'
    return $?
  elif _command_exists ioreg;
  then
    ioreg -n AppleSmartBattery -r | grep -q '"ExternalConnected" = Yes'
    return $?
  elif _command_exists WMIC;
  then
    WMIC Path Win32_Battery Get BatteryStatus /Format:List | grep -q 'BatteryStatus=2'
    return $?
  fi
}

ac_adapter_disconnected(){
  if _command_exists upower;
  then
    upower -i $(upower -e | grep -i BAT) | grep 'state' | grep -q 'discharging'
    return $?
  elif _command_exists acpi;
  then
    acpi -a | grep -q "off-line"
    return $?
  elif _command_exists pmset;
  then
    pmset -g batt | grep -q 'Battery Power'
    return $?
  elif _command_exists ioreg;
  then
    ioreg -n AppleSmartBattery -r | grep -q '"ExternalConnected" = No'
    return $?
  elif _command_exists WMIC;
  then
    WMIC Path Win32_Battery Get BatteryStatus /Format:List | grep -q 'BatteryStatus=1'
    return $?
  fi
}

battery_percentage(){
  about 'displays battery charge as a percentage of full (100%)'
  group 'battery'

  declare COMMAND_OUTPUT="no"

  if _command_exists upower;
  then
    COMMAND_OUTPUT=$(upower --show-info $(upower --enumerate | grep -i BAT) | grep percentage | grep -o "[0-9]\+" | head -1)
  elif _command_exists acpi;
  then
    COMMAND_OUTPUT=$(acpi -b | awk -F, '/,/{gsub(/ /, "", $0); gsub(/%/,"", $0); print $2}' )
  elif _command_exists pmset;
  then
    COMMAND_OUTPUT=$(pmset -g ps | sed -n 's/.*[[:blank:]]+*\(.*%\).*/\1/p' | grep -o "[0-9]\+" | head -1)
  elif _command_exists ioreg;
  then
    COMMAND_OUTPUT=$(ioreg -n AppleSmartBattery -r | awk '$1~/Capacity/{c[$1]=$3} END{OFMT="%05.2f"; max=c["\"MaxCapacity\""]; print (max>0? 100*c["\"CurrentCapacity\""]/max: "?")}' | grep -o "[0-9]\+" | head -1)
  elif _command_exists WMIC;
  then
    COMMAND_OUTPUT=$(WMIC PATH Win32_Battery Get EstimatedChargeRemaining /Format:List | grep -o '[0-9]\+' | head -1)
  else
    COMMAND_OUTPUT="no"
  fi

  if [ "${COMMAND_OUTPUT}" != "no" ]; then
    printf "%02d" "${COMMAND_OUTPUT:--1}"
  else
    echo "${COMMAND_OUTPUT}"
  fi
}

battery_charge(){
  about 'graphical display of your battery charge'
  group 'battery'

  # Full char
  local F_C='▸'
  # Depleted char
  local D_C='▹'
  local DEPLETED_COLOR="${normal}"
  local FULL_COLOR="${green}"
  local HALF_COLOR="${yellow}"
  local DANGER_COLOR="${red}"
  local BATTERY_OUTPUT="${DEPLETED_COLOR}${D_C}${D_C}${D_C}${D_C}${D_C}"
  local BATTERY_PERC=$(battery_percentage)

  case $BATTERY_PERC in
    no)
      echo ""
    ;;
    9*)
      echo "${FULL_COLOR}${F_C}${F_C}${F_C}${F_C}${F_C}${normal}"
    ;;
    8*)
      echo "${FULL_COLOR}${F_C}${F_C}${F_C}${F_C}${HALF_COLOR}${F_C}${normal}"
    ;;
    7*)
      echo "${FULL_COLOR}${F_C}${F_C}${F_C}${F_C}${DEPLETED_COLOR}${D_C}${normal}"
    ;;
    6*)
      echo "${FULL_COLOR}${F_C}${F_C}${F_C}${HALF_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${normal}"
    ;;
    5*)
      echo "${FULL_COLOR}${F_C}${F_C}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${normal}"
    ;;
    4*)
      echo "${FULL_COLOR}${F_C}${F_C}${HALF_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${normal}"
    ;;
    3*)
      echo "${FULL_COLOR}${F_C}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${normal}"
    ;;
    2*)
      echo "${FULL_COLOR}${F_C}${HALF_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${normal}"
    ;;
    1*)
      echo "${FULL_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${D_C}${normal}"
    ;;
    05)
      echo "${DANGER_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${D_C}${normal}"
    ;;
    04)
      echo "${DANGER_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${D_C}${normal}"
    ;;
    03)
      echo "${DANGER_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${D_C}${normal}"
    ;;
    02)
      echo "${DANGER_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${D_C}${normal}"
    ;;
    0*)
      echo "${HALF_COLOR}${F_C}${DEPLETED_COLOR}${D_C}${D_C}${D_C}${D_C}${normal}"
    ;;
    *)
cite about-plugin
about-plugin 'load pyenv, if you are using it'

export PYENV_ROOT="$HOME/.pyenv"
pathmunge "$PYENV_ROOT/bin"

[[ `which pyenv 2>/dev/null` ]] && eval "$(pyenv init - bash)"

#Load pyenv virtualenv if the virtualenv plugin is installed.
if pyenv virtualenv-init - &> /dev/null; then
# The install directory is hard-coded. TODO: allow the directory to be specified on the command line.

cite about-plugin
about-plugin 'download jquery files into current project'

[[ -z "$JQUERY_VERSION_NUMBER" ]] && JQUERY_VERSION_NUMBER="1.6.1"
[[ -z "$JQUERY_UI_VERSION_NUMBER" ]] && JQUERY_UI_VERSION_NUMBER="1.8.13"

function rails_jquery {
  about 'download rails.js into public/javascripts'
  group 'javascript'

  curl -o public/javascripts/rails.js http://github.com/rails/jquery-ujs/raw/master/src/rails.js
}

function jquery_install {
  about 'download jquery.js into public/javascripts'
  group 'javascript'

  if [ -z "$1" ]
  then
      version=$JQUERY_VERSION_NUMBER
  else
      version="$1"
  fi
  curl -o public/javascripts/jquery.js "http://ajax.googleapis.com/ajax/libs/jquery/$version/jquery.min.js"
}

function jquery_ui_install {
  about 'download jquery_us.js into public/javascripts'
  group 'javascript'

  if [ -z "$1" ]
  then
      version=$JQUERY_UI_VERSION_NUMBER
  else
      version="$1"
  fi

  curl -o public/javascripts/jquery_ui.js "http://ajax.googleapis.com/ajax/libs/jqueryui/$version/jquery-ui.min.js"
# shellcheck shell=bash
cite about-plugin
about-plugin 'Alert (BEL) when process ends after a threshold of seconds'

precmd_return_notification() {
	export LAST_COMMAND_DURATION=$(($(date +%s) - ${LAST_COMMAND_TIME:=$(date +%s)}))
	[[ ${LAST_COMMAND_DURATION} -gt ${NOTIFY_IF_COMMAND_RETURNS_AFTER:-5} ]] && echo -e "\a"
	export LAST_COMMAND_TIME=
}

preexec_return_notification() {
	[ -z "${LAST_COMMAND_TIME}" ] && export LAST_COMMAND_TIME=$(date +%s)
}

precmd_functions+=(precmd_return_notification)
#!/usr/bin/env bash

cite about-plugin
about-plugin 'enables powerline daemon'

command -v powerline-daemon &>/dev/null || return
powerline-daemon -q

#the following should not be executed if bashit powerline themes in use
case "$BASH_IT_THEME" in
	*powerline*)
		return
		;;
esac
POWERLINE_BASH_CONTINUATION=1
POWERLINE_BASH_SELECT=1
bashPowerlineInit=$(python -c \
	"import os; \
	import powerline;\
	print(os.path.join(os.path.dirname(\
	powerline.__file__),\
	'bindings', \
	'bash', \
	'powerline.sh'))")
[ -e $bashPowerlineInit ] || return
cite about-plugin
about-plugin 'mankier.com explain function to explain other commands'

explain () {
  about 'explain any bash command via mankier.com manpage API'
  param '1: Name of the command to explain'
  example '$ explain                # interactive mode. Type commands to explain in REPL'
  example '$ explain '"'"'cmd -o | ...'"'"' # one quoted command to explain it.'
  group 'explain'

  if [ "$#" -eq 0 ]; then
    while read  -p "Command: " cmd; do
      curl -Gs "https://www.mankier.com/api/explain/?cols="$(tput cols) --data-urlencode "q=$cmd"
    done
    echo "Bye!"
  elif [ "$#" -eq 1 ]; then
    curl -Gs "https://www.mankier.com/api/explain/?cols="$(tput cols) --data-urlencode "q=$1"
  else
    echo "Usage"
    echo "explain                  interactive mode."
cite about-plugin
about-plugin 'load rbenv, if you are using it'

export RBENV_ROOT="$HOME/.rbenv"
pathmunge "$RBENV_ROOT/bin"
# shellcheck shell=bash
cite about-plugin
about-plugin 'search history using the prefix already entered'

# enter a few characters and press UpArrow/DownArrow
# shellcheck shell=bash
cite about-plugin
about-plugin 'improve history handling with sane defaults'

# append to bash_history if Terminal.app quits
shopt -s histappend

# erase duplicates; alternative option: export HISTCONTROL=ignoredups
export HISTCONTROL=${HISTCONTROL:-ignorespace:erasedups}

# resize history to 100x the default (500)
export HISTSIZE=${HISTSIZE:-50000}

top-history() {
	about 'print the name and count of the most commonly run tools'

	if [[ -n $HISTTIMEFORMAT ]]; then
		# To parse history we need a predictable format, which HISTTIMEFORMAT
		# gets in the way of. So we unset it and set a trap to guarantee the
		# user's environment returns to normal even if the pipeline below fails.
		# shellcheck disable=SC2064
		trap "export HISTTIMEFORMAT='$HISTTIMEFORMAT'" RETURN
		unset HISTTIMEFORMAT
	fi

	history \
		| awk '{
				a[$2]++
			}END{
				for(i in a)
				printf("%s\t%s\n", a[i], i)
			}' \
		| sort --reverse --numeric-sort \
		| head \
		| column \
# bash completion for pack                                 -*- shell-script -*-

cite about-plugin
about-plugin 'CNB pack cli aliases'


__pack_debug()
{
    if [[ -n ${BASH_COMP_DEBUG_FILE} ]]; then
        echo "$*" >> "${BASH_COMP_DEBUG_FILE}"
    fi
}

# Homebrew on Macs have version 1.3 of bash-completion which doesn't include
# _init_completion. This is a very minimal version of that function.
__pack_init_completion()
{
    COMPREPLY=()
    _get_comp_words_by_ref "$@" cur prev words cword
}

__pack_index_of_word()
{
    local w word=$1
    shift
    index=0
    for w in "$@"; do
        [[ $w = "$word" ]] && return
        index=$((index+1))
    done
    index=-1
}

__pack_contains_word()
{
    local w word=$1; shift
    for w in "$@"; do
        [[ $w = "$word" ]] && return
    done
    return 1
}

__pack_handle_reply()
{
    __pack_debug "${FUNCNAME[0]}"
    case $cur in
        -*)
            if [[ $(type -t compopt) = "builtin" ]]; then
                compopt -o nospace
            fi
            local allflags
            if [ ${#must_have_one_flag[@]} -ne 0 ]; then
                allflags=("${must_have_one_flag[@]}")
            else
                allflags=("${flags[*]} ${two_word_flags[*]}")
            fi
            COMPREPLY=( $(compgen -W "${allflags[*]}" -- "$cur") )
            if [[ $(type -t compopt) = "builtin" ]]; then
                [[ "${COMPREPLY[0]}" == *= ]] || compopt +o nospace
            fi

            # complete after --flag=abc
            if [[ $cur == *=* ]]; then
                if [[ $(type -t compopt) = "builtin" ]]; then
                    compopt +o nospace
                fi

                local index flag
                flag="${cur%=*}"
                __pack_index_of_word "${flag}" "${flags_with_completion[@]}"
                COMPREPLY=()
                if [[ ${index} -ge 0 ]]; then
                    PREFIX=""
                    cur="${cur#*=}"
                    ${flags_completion[${index}]}
                    if [ -n "${ZSH_VERSION}" ]; then
                        # zsh completion needs --flag= prefix
                        eval "COMPREPLY=( \"\${COMPREPLY[@]/#/${flag}=}\" )"
                    fi
                fi
            fi
            return 0;
            ;;
    esac

    # check if we are handling a flag with special work handling
    local index
    __pack_index_of_word "${prev}" "${flags_with_completion[@]}"
    if [[ ${index} -ge 0 ]]; then
        ${flags_completion[${index}]}
        return
    fi

    # we are parsing a flag and don't have a special handler, no completion
    if [[ ${cur} != "${words[cword]}" ]]; then
        return
    fi

    local completions
    completions=("${commands[@]}")
    if [[ ${#must_have_one_noun[@]} -ne 0 ]]; then
        completions=("${must_have_one_noun[@]}")
    fi
    if [[ ${#must_have_one_flag[@]} -ne 0 ]]; then
        completions+=("${must_have_one_flag[@]}")
    fi
    COMPREPLY=( $(compgen -W "${completions[*]}" -- "$cur") )

    if [[ ${#COMPREPLY[@]} -eq 0 && ${#noun_aliases[@]} -gt 0 && ${#must_have_one_noun[@]} -ne 0 ]]; then
        COMPREPLY=( $(compgen -W "${noun_aliases[*]}" -- "$cur") )
    fi

    if [[ ${#COMPREPLY[@]} -eq 0 ]]; then
        declare -F __custom_func >/dev/null && __custom_func
    fi

    # available in bash-completion >= 2, not always present on macOS
    if declare -F __ltrim_colon_completions >/dev/null; then
        __ltrim_colon_completions "$cur"
    fi

    # If there is only 1 completion and it is a flag with an = it will be completed
    # but we don't want a space after the =
    if [[ "${#COMPREPLY[@]}" -eq "1" ]] && [[ $(type -t compopt) = "builtin" ]] && [[ "${COMPREPLY[0]}" == --*= ]]; then
       compopt -o nospace
    fi
}

# The arguments should be in the form "ext1|ext2|extn"
__pack_handle_filename_extension_flag()
{
    local ext="$1"
    _filedir "@(${ext})"
}

__pack_handle_subdirs_in_dir_flag()
{
    local dir="$1"
    pushd "${dir}" >/dev/null 2>&1 && _filedir -d && popd >/dev/null 2>&1
}

__pack_handle_flag()
{
    __pack_debug "${FUNCNAME[0]}: c is $c words[c] is ${words[c]}"

    # if a command required a flag, and we found it, unset must_have_one_flag()
    local flagname=${words[c]}
    local flagvalue
    # if the word contained an =
    if [[ ${words[c]} == *"="* ]]; then
        flagvalue=${flagname#*=} # take in as flagvalue after the =
        flagname=${flagname%=*} # strip everything after the =
        flagname="${flagname}=" # but put the = back
    fi
    __pack_debug "${FUNCNAME[0]}: looking for ${flagname}"
    if __pack_contains_word "${flagname}" "${must_have_one_flag[@]}"; then
        must_have_one_flag=()
    fi

    # if you set a flag which only applies to this command, don't show subcommands
    if __pack_contains_word "${flagname}" "${local_nonpersistent_flags[@]}"; then
      commands=()
    fi

    # keep flag value with flagname as flaghash
    # flaghash variable is an associative array which is only supported in bash > 3.
    if [[ -z "${BASH_VERSION}" || "${BASH_VERSINFO[0]}" -gt 3 ]]; then
        if [ -n "${flagvalue}" ] ; then
            flaghash[${flagname}]=${flagvalue}
        elif [ -n "${words[ $((c+1)) ]}" ] ; then
            flaghash[${flagname}]=${words[ $((c+1)) ]}
        else
            flaghash[${flagname}]="true" # pad "true" for bool flag
        fi
    fi

    # skip the argument to a two word flag
    if __pack_contains_word "${words[c]}" "${two_word_flags[@]}"; then
        c=$((c+1))
        # if we are looking for a flags value, don't show commands
        if [[ $c -eq $cword ]]; then
            commands=()
        fi
    fi

    c=$((c+1))

}

__pack_handle_noun()
{
    __pack_debug "${FUNCNAME[0]}: c is $c words[c] is ${words[c]}"

    if __pack_contains_word "${words[c]}" "${must_have_one_noun[@]}"; then
        must_have_one_noun=()
    elif __pack_contains_word "${words[c]}" "${noun_aliases[@]}"; then
        must_have_one_noun=()
    fi

    nouns+=("${words[c]}")
    c=$((c+1))
}

__pack_handle_command()
{
    __pack_debug "${FUNCNAME[0]}: c is $c words[c] is ${words[c]}"

    local next_command
    if [[ -n ${last_command} ]]; then
        next_command="_${last_command}_${words[c]//:/__}"
    else
        if [[ $c -eq 0 ]]; then
            next_command="_pack_root_command"
        else
            next_command="_${words[c]//:/__}"
        fi
    fi
    c=$((c+1))
    __pack_debug "${FUNCNAME[0]}: looking for ${next_command}"
    declare -F "$next_command" >/dev/null && $next_command
}

__pack_handle_word()
{
    if [[ $c -ge $cword ]]; then
        __pack_handle_reply
        return
    fi
    __pack_debug "${FUNCNAME[0]}: c is $c words[c] is ${words[c]}"
    if [[ "${words[c]}" == -* ]]; then
        __pack_handle_flag
    elif __pack_contains_word "${words[c]}" "${commands[@]}"; then
        __pack_handle_command
    elif [[ $c -eq 0 ]]; then
        __pack_handle_command
    elif __pack_contains_word "${words[c]}" "${command_aliases[@]}"; then
        # aliashash variable is an associative array which is only supported in bash > 3.
        if [[ -z "${BASH_VERSION}" || "${BASH_VERSINFO[0]}" -gt 3 ]]; then
            words[c]=${aliashash[${words[c]}]}
            __pack_handle_command
        else
            __pack_handle_noun
        fi
    else
        __pack_handle_noun
    fi
    __pack_handle_word
}

_pack_build()
{
    last_command="pack_build"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--builder=")
    local_nonpersistent_flags+=("--builder=")
    flags+=("--buildpack=")
    local_nonpersistent_flags+=("--buildpack=")
    flags+=("--clear-cache")
    local_nonpersistent_flags+=("--clear-cache")
    flags+=("--env=")
    two_word_flags+=("-e")
    local_nonpersistent_flags+=("--env=")
    flags+=("--env-file=")
    local_nonpersistent_flags+=("--env-file=")
    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-pull")
    local_nonpersistent_flags+=("--no-pull")
    flags+=("--path=")
    two_word_flags+=("-p")
    local_nonpersistent_flags+=("--path=")
    flags+=("--publish")
    local_nonpersistent_flags+=("--publish")
    flags+=("--run-image=")
    local_nonpersistent_flags+=("--run-image=")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

_pack_run()
{
    last_command="pack_run"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--builder=")
    local_nonpersistent_flags+=("--builder=")
    flags+=("--buildpack=")
    local_nonpersistent_flags+=("--buildpack=")
    flags+=("--clear-cache")
    local_nonpersistent_flags+=("--clear-cache")
    flags+=("--env=")
    two_word_flags+=("-e")
    local_nonpersistent_flags+=("--env=")
    flags+=("--env-file=")
    local_nonpersistent_flags+=("--env-file=")
    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-pull")
    local_nonpersistent_flags+=("--no-pull")
    flags+=("--path=")
    two_word_flags+=("-p")
    local_nonpersistent_flags+=("--path=")
    flags+=("--port=")
    local_nonpersistent_flags+=("--port=")
    flags+=("--run-image=")
    local_nonpersistent_flags+=("--run-image=")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

_pack_rebase()
{
    last_command="pack_rebase"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-pull")
    local_nonpersistent_flags+=("--no-pull")
    flags+=("--publish")
    local_nonpersistent_flags+=("--publish")
    flags+=("--run-image=")
    local_nonpersistent_flags+=("--run-image=")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

_pack_create-builder()
{
    last_command="pack_create-builder"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--builder-config=")
    two_word_flags+=("-b")
    local_nonpersistent_flags+=("--builder-config=")
    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-pull")
    local_nonpersistent_flags+=("--no-pull")
    flags+=("--publish")
    local_nonpersistent_flags+=("--publish")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_flag+=("--builder-config=")
    must_have_one_flag+=("-b")
    must_have_one_noun=()
    noun_aliases=()
}

_pack_set-run-image-mirrors()
{
    last_command="pack_set-run-image-mirrors"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--mirror=")
    two_word_flags+=("-m")
    local_nonpersistent_flags+=("--mirror=")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_flag+=("--mirror=")
    must_have_one_flag+=("-m")
    must_have_one_noun=()
    noun_aliases=()
}

_pack_inspect-builder()
{
    last_command="pack_inspect-builder"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

_pack_set-default-builder()
{
    last_command="pack_set-default-builder"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

_pack_version()
{
    last_command="pack_version"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

_pack_completion()
{
    last_command="pack_completion"

    command_aliases=()

    commands=()

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

_pack_root_command()
{
    last_command="pack"

    command_aliases=()

    commands=()
    commands+=("build")
    commands+=("run")
    commands+=("rebase")
    commands+=("create-builder")
    commands+=("set-run-image-mirrors")
    commands+=("inspect-builder")
    commands+=("set-default-builder")
    commands+=("version")
    commands+=("completion")

    flags=()
    two_word_flags=()
    local_nonpersistent_flags=()
    flags_with_completion=()
    flags_completion=()

    flags+=("--help")
    flags+=("-h")
    local_nonpersistent_flags+=("--help")
    flags+=("--no-color")
    flags+=("--quiet")
    flags+=("-q")
    flags+=("--timestamps")

    must_have_one_flag=()
    must_have_one_noun=()
    noun_aliases=()
}

__start_pack()
{
    local cur prev words cword
    declare -A flaghash 2>/dev/null || :
    declare -A aliashash 2>/dev/null || :
    if declare -F _init_completion >/dev/null 2>&1; then
        _init_completion -s || return
    else
        __pack_init_completion -n "=" || return
    fi

    local c=0
    local flags=()
    local two_word_flags=()
    local local_nonpersistent_flags=()
    local flags_with_completion=()
    local flags_completion=()
    local commands=("pack")
    local must_have_one_flag=()
    local must_have_one_noun=()
    local last_command
    local nouns=()

    __pack_handle_word
}

if [[ $(type -t compopt) = "builtin" ]]; then
    complete -o default -F __start_pack pack
else
    complete -o default -o nospace -F __start_pack pack
fi

#!/usr/bin/env bash
cite about-plugin
about-plugin 'sshagent helper functions'

function _get_sshagent_pid_from_env_file() {
  local env_file="${1}"
  [[ -r "${env_file}" ]] || {
    echo "";
    return
  }
  tail -1 "${env_file}" \
  | cut -d' ' -f4 \
  | cut -d';' -f1
}

function _get_process_status_field() {
  # uses /proc filesystem
  local \
    pid \
    status_file \
    field
  pid="${1}"
  field="${2}"
  status_file="/proc/${pid}/status"
  if ! ([[ -d "${status_file%/*}" ]] \
    && [[ -r "${status_file}" ]]); then
    echo ""; return;
  fi
  grep "${field}:" "${status_file}" \
  | cut -d':' -f2 \
  | sed -e 's/[[:space:]]\+//g' \
  | cut -d'(' -f1
}

function _is_item_in_list() {
  local item
  for item in "${@:1}"; do
    if [[ "${item}" == "${1}" ]]; then
      return 1
    fi
  done
  return 0
}


function _is_proc_alive_at_pid() {
  local \
    pid \
    expected_name \
    actual_name \
    actual_state
  pid="${1?}"
  expected_name="ssh-agent"
  # we want to exclude: X (killed), T (traced), Z (zombie)
  actual_name=$(_get_process_status_field "${pid}" "Name")
  [[ "${expected_name}" == "${actual_name}" ]] || return 1
  actual_state=$(_get_process_status_field "${pid}" "State")
  if _is_item_in_list "${actual_state}" "X" "T" "Z"; then
    return 1
  fi
  return 0
}


function _ensure_valid_sshagent_env() {
  local \
    agent_pid \
    tmp_res

  mkdir -p "${HOME}/.ssh"
  type restorecon &> /dev/null
  tmp_res="$?"

  if [[ "${tmp_res}" -eq 0 ]]; then
    restorecon -rv "${HOME}/.ssh"
  fi

  # no env file -> shoot a new agent
  if ! [[ -r "${SSH_AGENT_ENV}" ]]; then
    ssh-agent > "${SSH_AGENT_ENV}"
    return
  fi

  ## do not trust pre-existing SSH_AGENT_ENV
  agent_pid=$(_get_sshagent_pid_from_env_file "${SSH_AGENT_ENV}")
  if [[ -z "${agent_pid}" ]]; then
    # no pid detected -> shoot a new agent
    ssh-agent > "${SSH_AGENT_ENV}"
    return
  fi

  ## do not trust SSH_AGENT_PID
  if _is_proc_alive_at_pid "${agent_pid}"; then
    return
  fi

  ssh-agent > "${SSH_AGENT_ENV}"
  return
}


function _ensure_sshagent_dead() {
  [[ -r "${SSH_AGENT_ENV}" ]] \
  || return ## no agent file - no problems
  ## ensure the file indeed points to a really running agent:
  agent_pid=$(
    _get_sshagent_pid_from_env_file \
    "${SSH_AGENT_ENV}"
  )

  [[ -n "${agent_pid}" ]] \
  || return # no pid - no problem

  _is_proc_alive_at_pid "${agent_pid}" \
  || return # process is not alive - no problem

  echo -e -n "Killing ssh-agent (pid:${agent_pid}) ... "
  kill -9 "${agent_pid}" && echo "DONE" || echo "FAILED"
  rm -f "${SSH_AGENT_ENV}"
}


function sshagent() {
  about 'ensures ssh-agent is up and running'
  param '1: on|off '
  example '$ sshagent on'
  group 'ssh'
  [[ -z "${SSH_AGENT_ENV}" ]] \
  && export SSH_AGENT_ENV="${HOME}/.ssh/agent_env.${HOSTNAME}"

  case "${1}" in
    on) _ensure_valid_sshagent_env;
      # shellcheck disable=SC1090
      source "${SSH_AGENT_ENV}" > /dev/null;
      ;;
    off) _ensure_sshagent_dead
      ;;
    *)
      ;;
  esac
cite about-plugin
about-plugin 'Initialization for fuck'

# https://github.com/nvbn/thefuck

cite about-plugin
about-plugin 'Proxy Tools'

disable-proxy ()
{
	about 'Disables proxy settings for Bash, npm and SSH'
	group 'proxy'

	unset http_proxy
	unset https_proxy
	unset HTTP_PROXY
	unset HTTPS_PROXY
	unset ALL_PROXY
	unset no_proxy
	unset NO_PROXY
	echo "Disabled proxy environment variables"

	npm-disable-proxy
	ssh-disable-proxy
	svn-disable-proxy
}

enable-proxy ()
{
	about 'Enables proxy settings for Bash, npm and SSH'
	group 'proxy'

	export http_proxy=$BASH_IT_HTTP_PROXY
	export https_proxy=$BASH_IT_HTTPS_PROXY
	export HTTP_PROXY=$http_proxy
	export HTTPS_PROXY=$https_proxy
	export ALL_PROXY=$http_proxy
	export no_proxy=$BASH_IT_NO_PROXY
	export NO_PROXY=$no_proxy
	echo "Enabled proxy environment variables"

	npm-enable-proxy
	ssh-enable-proxy
	svn-enable-proxy
}

enable-proxy-alt ()
{
	about 'Enables alternate proxy settings for Bash, npm and SSH'
	group 'proxy'

	export http_proxy=$BASH_IT_HTTP_PROXY_ALT
	export https_proxy=$BASH_IT_HTTPS_PROXY_ALT
	export HTTP_PROXY=$http_proxy
	export HTTPS_PROXY=$https_proxy
	export ALL_PROXY=$http_proxy
	export no_proxy=$BASH_IT_NO_PROXY
	export NO_PROXY=$no_proxy
	echo "Enabled alternate proxy environment variables"

	npm-enable-proxy $http_proxy $https_proxy
	ssh-enable-proxy
	svn-enable-proxy $http_proxy
}

show-proxy ()
{
	about 'Shows the proxy settings for Bash, Git, npm and SSH'
	group 'proxy'

	echo ""
	echo "Environment Variables"
	echo "====================="
	env | grep -i "proxy" | grep -v "BASH_IT"

	bash-it-show-proxy
	npm-show-proxy
	git-global-show-proxy
	svn-show-proxy
	ssh-show-proxy
}

proxy-help ()
{
	about 'Provides an overview of the bash-it proxy configuration'
	group 'proxy'

	cat << EOF
Bash-it provides support for enabling/disabling proxy settings for various shell tools.

The following backends are currently supported (in addition to the shell's environment variables): Git, SVN, npm, ssh

Bash-it uses the following variables to set the shell's proxy settings when you call 'enable-proxy'.
These variables are best defined in a custom script in bash-it's custom script folder ('$BASH_IT/custom'),
e.g. '$BASH_IT/custom/proxy.env.bash'
* BASH_IT_HTTP_PROXY and BASH_IT_HTTPS_PROXY: Define the proxy URL to be used, e.g. 'http://localhost:1234'
* BASH_IT_NO_PROXY: A comma-separated list of proxy exclusions, e.g. '127.0.0.1,localhost'

Run 'glossary proxy' to show the available proxy functions with a short description.
EOF

	bash-it-show-proxy
}

bash-it-show-proxy ()
{
	about 'Shows the bash-it proxy settings'
	group 'proxy'

	echo ""
	echo "bash-it Environment Variables"
	echo "============================="
	echo "(These variables will be used to set the proxy when you call 'enable-proxy')"
	echo ""
	env | grep -e "BASH_IT.*PROXY"
}

npm-show-proxy ()
{
	about 'Shows the npm proxy settings'
	group 'proxy'

	if $(command -v npm &> /dev/null) ; then
		echo ""
		echo "npm"
		echo "==="
		echo "npm HTTP  proxy: " `npm config get proxy`
		echo "npm HTTPS proxy: " `npm config get https-proxy`
		echo "npm proxy exceptions: " `npm config get noproxy`
	fi
}

npm-disable-proxy ()
{
	about 'Disables npm proxy settings'
	group 'proxy'

	if $(command -v npm &> /dev/null) ; then
		npm config delete proxy
		npm config delete https-proxy
		npm config delete noproxy
		echo "Disabled npm proxy settings"
	fi
}

npm-enable-proxy ()
{
	about 'Enables npm proxy settings'
	group 'proxy'

	local my_http_proxy=${1:-$BASH_IT_HTTP_PROXY}
	local my_https_proxy=${2:-$BASH_IT_HTTPS_PROXY}
	local my_no_proxy=${3:-$BASH_IT_NO_PROXY}

	if $(command -v npm &> /dev/null) ; then
		npm config set proxy $my_http_proxy
		npm config set https-proxy $my_https_proxy
		npm config set noproxy $my_no_proxy
		echo "Enabled npm proxy settings"
	fi
}

git-global-show-proxy ()
{
	about 'Shows global Git proxy settings'
	group 'proxy'

	if $(command -v git &> /dev/null) ; then
		echo ""
		echo "Git (Global Settings)"
		echo "====================="
		echo "Git (Global) HTTP  proxy: " `git config --global --get http.proxy`
		echo "Git (Global) HTTPS proxy: " `git config --global --get https.proxy`
	fi
}

git-global-disable-proxy ()
{
	about 'Disables global Git proxy settings'
	group 'proxy'

	if $(command -v git &> /dev/null) ; then
		git config --global --unset-all http.proxy
		git config --global --unset-all https.proxy
		echo "Disabled global Git proxy settings"
	fi
}

git-global-enable-proxy ()
{
	about 'Enables global Git proxy settings'
	group 'proxy'

	if $(command -v git &> /dev/null) ; then
		git-global-disable-proxy

		git config --global --add http.proxy $BASH_IT_HTTP_PROXY
		git config --global --add https.proxy $BASH_IT_HTTPS_PROXY
		echo "Enabled global Git proxy settings"
	fi
}

git-show-proxy ()
{
	about 'Shows current Git project proxy settings'
	group 'proxy'

	if $(command -v git &> /dev/null) ; then
		echo "Git Project Proxy Settings"
		echo "====================="
		echo "Git HTTP  proxy: " `git config --get http.proxy`
		echo "Git HTTPS proxy: " `git config --get https.proxy`
	fi
}

git-disable-proxy ()
{
	about 'Disables current Git project proxy settings'
	group 'proxy'

	if $(command -v git &> /dev/null) ; then
		git config --unset-all http.proxy
		git config --unset-all https.proxy
		echo "Disabled Git project proxy settings"
	fi
}

git-enable-proxy ()
{
	about 'Enables current Git project proxy settings'
	group 'proxy'

	if $(command -v git &> /dev/null) ; then
		git-disable-proxy

		git config --add http.proxy $BASH_IT_HTTP_PROXY
		git config --add https.proxy $BASH_IT_HTTPS_PROXY
		echo "Enabled Git project proxy settings"
	fi
}


svn-show-proxy ()
{
	about 'Shows SVN proxy settings'
	group 'proxy'

	if $(command -v svn &> /dev/null) && $(command -v python2 &> /dev/null) ; then
		echo ""
		echo "SVN Proxy Settings"
		echo "=================="
		python2 - <<END
import ConfigParser, os
config = ConfigParser.ConfigParser()
config.read(os.path.expanduser('~/.subversion/servers'))
if (config.has_section('global')):
	proxy_host = ''
	proxy_port = ''
	proxy_exceptions = ''
	if (config.has_option('global', 'http-proxy-host')):
		proxy_host = config.get('global', 'http-proxy-host')
	if (config.has_option('global', 'http-proxy-port')):
		proxy_port = config.get('global', 'http-proxy-port')
	if (config.has_option('global', 'http-proxy-exceptions')):
		proxy_exceptions = config.get('global', 'http-proxy-exceptions')
	print 'http-proxy-host      : ' + proxy_host
	print 'http-proxy-port      : ' + proxy_port
	print 'http-proxy-exceptions: ' + proxy_exceptions
END
	fi
}

svn-disable-proxy ()
{
	about 'Disables SVN proxy settings'
	group 'proxy'

	if $(command -v svn &> /dev/null) && $(command -v python2 &> /dev/null) ; then
		python2 - <<END
import ConfigParser, os
config = ConfigParser.ConfigParser()
config.read(os.path.expanduser('~/.subversion/servers'))
if config.has_section('global'):
	changed = False
	if config.has_option('global', 'http-proxy-host'):
		config.remove_option('global', 'http-proxy-host')
		changed = True
	if config.has_option('global', 'http-proxy-port'):
		config.remove_option('global', 'http-proxy-port')
		changed = True
	if config.has_option('global', 'http-proxy-exceptions'):
		config.remove_option('global', 'http-proxy-exceptions')
		changed = True
	if changed:
		with open(os.path.expanduser('~/.subversion/servers'), 'wb') as configfile:
			config.write(configfile)
	print 'Disabled SVN proxy settings'
END
	fi
}

svn-enable-proxy ()
{
	about 'Enables SVN proxy settings'
	group 'proxy'

	if $(command -v svn &> /dev/null) && $(command -v python2 &> /dev/null) ; then
		local my_http_proxy=${1:-$BASH_IT_HTTP_PROXY}

		python2 - "$my_http_proxy" "$BASH_IT_NO_PROXY" <<END
import ConfigParser, os, sys, urlparse
pieces = urlparse.urlparse(sys.argv[1])
host = pieces.hostname
port = pieces.port
exceptions = sys.argv[2]
config = ConfigParser.ConfigParser()
config.read(os.path.expanduser('~/.subversion/servers'))
if not config.has_section('global'):
	config.add_section('global')
if host is not None:
	config.set('global', 'http-proxy-host', host)
else:
	config.remove_option('global', 'http-proxy-host')
if port is not None:
	config.set('global', 'http-proxy-port', port)
else:
	config.remove_option('global', 'http-proxy-port')
if exceptions is not None:
	config.set('global', 'http-proxy-exceptions', exceptions)
else:
	config.remove_option('global', 'http-proxy-exceptions')
with open(os.path.expanduser('~/.subversion/servers'), 'wb') as configfile:
	config.write(configfile)
print 'Enabled SVN proxy settings'
END
	fi
}

ssh-show-proxy ()
{
	about 'Shows SSH config proxy settings (from ~/.ssh/config)'
	group 'proxy'

	if [ -f ~/.ssh/config ] ; then
		echo ""
		echo "SSH Config Enabled in ~/.ssh/config"
		echo "==================================="
		awk '
		    $1 == "Host" {
		        host = $2;
		        next;
		    }
		    $1 == "ProxyCommand" {
		        $1 = "";
		        printf "%s\t%s\n", host, $0
		    }
		' ~/.ssh/config | column -t

		echo ""
		echo "SSH Config Disabled in ~/.ssh/config"
		echo "===================================="
		awk '
		    $1 == "Host" {
		        host = $2;
		        next;
		    }
		    $0 ~ "^#.*ProxyCommand.*" {
		        $1 = "";
		        $2 = "";
		        printf "%s\t%s\n", host, $0
		    }
		' ~/.ssh/config | column -t
	fi
}

ssh-disable-proxy ()
{
	about 'Disables SSH config proxy settings'
	group 'proxy'

	if [ -f ~/.ssh/config ] ; then
		sed -e's/^.*ProxyCommand/#	ProxyCommand/' "${BASH_IT_SED_I_PARAMETERS[@]}"  ~/.ssh/config
		echo "Disabled SSH config proxy settings"
	fi
}


ssh-enable-proxy ()
{
	about 'Enables SSH config proxy settings'
	group 'proxy'

	if [ -f ~/.ssh/config ] ; then
		sed -e's/#	ProxyCommand/	ProxyCommand/' "${BASH_IT_SED_I_PARAMETERS[@]}"  ~/.ssh/config
		echo "Enabled SSH config proxy settings"
# shellcheck shell=bash
cite about-plugin
about-plugin 'automatically set your xterm title with host and location info'

_short-dirname() {
	local dir_name=$(dirs +0)
	[ "$SHORT_TERM_LINE" = true ] && [ "${#dir_name}" -gt 8 ] && echo "${dir_name##*/}" || echo "${dir_name}"
}

_short-command() {
	local input_command="$*"
	[ "$SHORT_TERM_LINE" = true ] && [ "${#input_command}" -gt 8 ] && echo "${input_command%% *}" || echo "${input_command}"
}

set_xterm_title() {
	local title="$1"
	echo -ne "\033]0;$title\007"
}

precmd_xterm_title() {
	set_xterm_title "${SHORT_USER:-${USER}}@${SHORT_HOSTNAME:-${HOSTNAME}} $(_short-dirname) $PROMPT_CHAR"
}

preexec_xterm_title() {
	set_xterm_title "$(_short-command "${1}") {$(_short-dirname)} (${SHORT_USER:-${USER}}@${SHORT_HOSTNAME:-${HOSTNAME}})"
}

case "$TERM" in
	xterm* | rxvt*)
		precmd_functions+=(precmd_xterm_title)
cite about-plugin
about-plugin 'miscellaneous tools'

function ips ()
{
    about 'display all ip addresses for this host'
    group 'base'
    if command -v ifconfig &>/dev/null
    then
        ifconfig | awk '/inet /{ gsub(/addr:/, ""); print $2 }'
    elif command -v ip &>/dev/null
    then
        ip addr | grep -oP 'inet \K[\d.]+'
    else
        echo "You don't have ifconfig or ip command installed!"
    fi
}

function down4me ()
{
    about 'checks whether a website is down for you, or everybody'
    param '1: website url'
    example '$ down4me http://www.google.com'
    group 'base'
    curl -Ls "http://downforeveryoneorjustme.com/$1" | sed '/just you/!d;s/<[^>]*>//g'
}

function myip ()
{
    about 'displays your ip address, as seen by the Internet'
    group 'base'
    list=("http://myip.dnsomatic.com/" "http://checkip.dyndns.com/" "http://checkip.dyndns.org/")
    for url in ${list[*]}
    do
        res=$(curl -fs "${url}")
        if [ $? -eq 0 ];then
            break;
        fi
    done
    res=$(echo "$res" | grep -Eo '[0-9\.]+')
    echo -e "Your public IP is: ${echo_bold_green} $res ${echo_normal}"
}

function pickfrom ()
{
    about 'picks random line from file'
    param '1: filename'
    example '$ pickfrom /usr/share/dict/words'
    group 'base'
    local file=$1
    [ -z "$file" ] && reference $FUNCNAME && return
    length=$(cat $file | wc -l)
    n=$(expr $RANDOM \* $length \/ 32768 + 1)
    head -n $n $file | tail -1
}

function passgen ()
{
    about 'generates random password from dictionary words'
    param 'optional integer length'
    param 'if unset, defaults to 4'
    example '$ passgen'
    example '$ passgen 6'
    group 'base'
    local i pass length=${1:-4}
    pass=$(echo $(for i in $(eval echo "{1..$length}"); do pickfrom /usr/share/dict/words; done))
    echo "With spaces (easier to memorize): $pass"
    echo "Without (use this as the password): $(echo $pass | tr -d ' ')"
}

# Create alias pass to passgen when pass isn't installed or
# BASH_IT_LEGACY_PASS is true.
if ! command -v pass &>/dev/null || [ "$BASH_IT_LEGACY_PASS" = true ]
then
  alias pass=passgen
fi

function pmdown ()
{
    about 'preview markdown file in a browser'
    param '1: markdown file'
    example '$ pmdown README.md'
    group 'base'
    if command -v markdown &>/dev/null
    then
      markdown $1 | browser
    else
      echo "You don't have a markdown command installed!"
    fi
}

function mkcd ()
{
    about 'make one or more directories and cd into the last one'
    param 'one or more directories to create'
    example '$ mkcd foo'
    example '$ mkcd /tmp/img/photos/large'
    example '$ mkcd foo foo1 foo2 fooN'
    example '$ mkcd /tmp/img/photos/large /tmp/img/photos/self /tmp/img/photos/Beijing'
    group 'base'
    mkdir -p -- "$@" && eval cd -- "\"\$$#\""
}

function lsgrep ()
{
    about 'search through directory contents with grep'
    group 'base'
    ls | grep "$*"
}

function quiet ()
{
    about 'what *does* this do?'
    group 'base'
    $* &> /dev/null &
}

function banish-cookies ()
{
    about 'redirect .adobe and .macromedia files to /dev/null'
    group 'base'
    rm -r ~/.macromedia ~/.adobe
    ln -s /dev/null ~/.adobe
    ln -s /dev/null ~/.macromedia
}

function usage ()
{
    about 'disk usage per directory, in Mac OS X and Linux'
    param '1: directory name'
    group 'base'
    if [ $(uname) = "Darwin" ]; then
        if [ -n "$1" ]; then
            du -hd 1 "$1"
        else
            du -hd 1
        fi

    elif [ $(uname) = "Linux" ]; then
        if [ -n "$1" ]; then
            du -h --max-depth=1 "$1"
        else
            du -h --max-depth=1
        fi
    fi
}

if [ ! -e "${BASH_IT}/plugins/enabled/todo.plugin.bash" ] && [ ! -e "${BASH_IT}/plugins/enabled/*${BASH_IT_LOAD_PRIORITY_SEPARATOR}todo.plugin.bash" ]; then
# if user has installed todo plugin, skip this...
    function t ()
    {
        about 'one thing todo'
        param 'if not set, display todo item'
        param '1: todo text'
        if [[ "$*" == "" ]] ; then
            cat ~/.t
        else
            echo "$*" > ~/.t
        fi
    }
fi

function command_exists ()
{
    about 'checks for existence of a command'
    param '1: command to check'
    example '$ command_exists ls && echo exists'
    group 'base'
    type "$1" &> /dev/null ;
}

mkiso ()
{
    about 'creates iso from current dir in the parent dir (unless defined)'
    param '1: ISO name'
    param '2: dest/path'
    param '3: src/path'
    example 'mkiso'
    example 'mkiso ISO-Name dest/path src/path'
    group 'base'

    if type "mkisofs" > /dev/null; then
        [ -z ${1+x} ] && local isoname=${PWD##*/} || local isoname=$1
        [ -z ${2+x} ] && local destpath=../ || local destpath=$2
        [ -z ${3+x} ] && local srcpath=${PWD} || local srcpath=$3

        if [ ! -f "${destpath}${isoname}.iso" ]; then
            echo "writing ${isoname}.iso to ${destpath} from ${srcpath}"
            mkisofs -V ${isoname} -iso-level 3 -r -o "${destpath}${isoname}.iso" "${srcpath}"
        else
            echo "${destpath}${isoname}.iso already exists"
        fi
    else
        echo "mkisofs cmd does not exist, please install cdrtools"
    fi
}

# useful for administrators and configs
function buf ()
{
    about 'back up file with timestamp'
    param 'filename'
    group 'base'
    local filename=$1
    local filetime=$(date +%Y%m%d_%H%M%S)
    cp -a "${filename}" "${filename}_${filetime}"
}

function del() {
    about 'move files to hidden folder in tmp, that gets cleared on each reboot'
cite about-plugin
about-plugin 'load jenv, if you are using it'

# Don't modify the environment if we can't find the tool:
# - Check if in $PATH already
# - Check if installed manually to $JENV_ROOT
# - Check if installed manually to $HOME
_command_exists jenv ||
  [[ -n "$JENV_ROOT" && -x "$JENV_ROOT/bin/jenv" ]] ||
  [[ -x "$HOME/.jenv/bin/jenv" ]] ||
  return

# Set JENV_ROOT, if not already set
export JENV_ROOT="${JENV_ROOT:-$HOME/.jenv}"

# Add JENV_ROOT/bin to PATH, if that's where it's installed
! _command_exists jenv &&
  [[ -x "$JENV_ROOT/bin/jenv" ]] &&
  pathmunge "$JENV_ROOT/bin"

cite about-plugin
about-plugin 'source into environment when cding to directories'

if [[ -n "${ZSH_VERSION}" ]]
then __array_offset=0
else __array_offset=1
fi

autoenv_init()
{
  typeset target home _file
  typeset -a _files
  target=$1
  home="$(dirname "$HOME")"

  _files=( $(
    while [[ "$PWD" != "/" && "$PWD" != "$home" ]]
    do
      _file="$PWD/.env"
      if [[ -e "${_file}" ]]
      then echo "${_file}"
      fi
      builtin cd ..
    done
  ) )

  _file=${#_files[@]}
  while (( _file > 0 ))
  do
    source "${_files[_file-__array_offset]}"
    : $(( _file -= 1 ))
  done
}

cd()
{
  if builtin cd "$@"
  then
    autoenv_init
    return 0
cite about-plugin
about-plugin 'video to gif, gif to WebM helper functions'

# Based loosely on:
#  https://gist.github.com/SlexAxton/4989674#comment-1199058
#  https://linustechtips.com/main/topic/343253-tutorial-convert-videogifs-to-webm/
#  and other sources
# Renamed gifify to v2gif to go avoid clobbering https://github.com/jclem/gifify
# Requirements (Mac OS X using Homebrew): brew install ffmpeg giflossy imagemagick
# Requirements on Ubuntu: sudo apt install ffmpeg imagemagick ; plus install https://github.com/pornel/giflossy
# Optional: install mediainfo for autodetection of original video FPS.
# Optional: if lossy is not important, Ubuntu has gifsicle packaged for apt-get, instead of giflossy
# Optional: gifski (from `brew install gifski` or github.com/ImageOptim/gifski)
#           for high quality huge files.
function v2gif {
  about 'Converts a .mov/.avi/.mp4 file into an into an animated GIF.'
  group 'gif'
  param '1: MOV/AVI/MP4 file name(s)'
  param '2: -w <num> ; Optional: max width in pixels'
  param '3: -l <num> ; Optional: extra lossy level for smaller files (80-200 make sense, needs giflossy instead of gifsicle)'
  param '4: -h       ; Optional: high quality using gifski (installed seperately) - overrides "--lossy" above!'
  param '5: -d       ; Optional: delete the original video file if succeeded'
  param '6: -t       ; Optional: Tag the result with quality stamp for comparison use'
  param '7: -f <num> ; Optional: Change number of frames per second (default 10 or original FPS if mediainfo installed)'
  param '8: -a <num> ; Optional: Alert if resulting file is over <num> kilobytes (default is 5000, 0 turns off)'
  param '9: -m       ; Optional: Also create a WebM file (will one day replace GIF, Smaller and higher quality than mp4)'
  example '$ v2gif foo.mov'
  example '$ v2gif foo.mov -w 600'
  example '$ v2gif -l 100 -d *.mp4'
  example '$ v2gif -dh *.avi'
  example '$ v2gif -thw 600 *.avi *.mov'

  local convert=$(which convert)     ; [[ -x "$convert" ]]   || { echo "No convert found!" ; return 2 ;}
  local ffmpeg=$(which ffmpeg)       ; [[ -x "$ffmpeg" ]]    || { echo "No ffmpeg found!" ; return 2 ;}
  local mediainfo=$(which mediainfo) ; [[ -x "$mediainfo" ]] || { echo "No mediainfo found!" ; return 2 ;}
  local gifsicle=$(which gifsicle)   ; [[ -x "$gifsicle" ]]  || { echo "No gifsicle found!" ; return 2 ;}
  local getopt=$(which getopt)

  if [[ "$OSTYPE" == "darwin"* ]] ; then
  # Getopt on BSD is incompatible with GNU
    getopt=/usr/local/opt/gnu-getopt/bin/getopt
    [[ -x "$getopt" ]] || { echo "No GNU-getopt found!" ; return 2 ;}
  fi

  # Parse the options
  local args=$($getopt -l "alert:" -l "lossy:" -l "width:" -l del,delete -l high -l tag -l "fps:" -l webm -o "a:l:w:f:dhmt" -- "$@")

  if [ $? -ne 0 ]; then
    echo 'Terminating...' >&2
    return 2
  fi

  eval set -- "$args"
  local use_gifski=""
  local opt_del_after=""
  local maxsize=""
  local lossiness=""
  local maxwidthski=""
  local giftagopt=""
  local giftag=""
  local defaultfps=10
  local infps=""
  local fps=""
  local make_webm=""
  local alert=5000
  while [ $# -ge 1 ]; do
    case "$1" in
      --)
        # No more options left.
        shift
        break
        ;;
      -d|--del|--delete)
        # Delete after
        opt_del_after="true"
        shift
        ;;
      -h|--high)
        #High Quality, use gifski
        local gifski=$(which gifski) ; [[ -x "$gifski" ]] || { echo "No gifski found!" ; return 2 ; }
        use_gifski=true
        giftag="${giftag}-h"
        shift
        ;;
      -w|--width)
        maxsize="-vf scale=$2:-1"
        maxwidthski="-W $2"
        giftag="${giftag}-w$2"
        shift 2
        ;;
      -t|--tag)
        # mark with a quality tag
        giftagopt="true"
        shift
        ;;
      -l|--lossy)
        # Use giflossy parameter
        lossiness="--lossy=$2"
        giftag="${giftag}-l$2"
        shift 2
        ;;
      -f|--fps)
        # select fps
        infps="$2"
        giftag="${giftag}-f$2"
        shift 2
        ;;
      -a|--alert)
        # set size alert
        alert="$2"
        shift 2
        ;;
      -m|--webm)
        # set size alert
        make_webm="true"
        shift
        ;;
    esac
  done

  if [[ -z "$*" ]]; then
    echo "$(tput setaf 1)No input files given. Example: v2gif file [file...] [-w <max width (pixels)>] [-l <lossy level>] $(tput sgr 0)"
    echo "-d/--del/--delete Delete original vid if done suceessfully (and file not over the size limit)"
    echo "-h/--high         High Quality - use Gifski instead of gifsicle"
    echo "-w/--width N      Lock maximum gif width to N pixels, resize if necessary"
    echo "-t/--tag          Add a tag to the output gif describing the options used (useful for comparing several options)"
    echo "-l/--lossy N      Use the Giflossy parameter for gifsicle (If your version supports it)"
    echo "-f/--fps N        Override autodetection of incoming vid FPS (useful for downsampling)"
    echo "-a/--alert N      Alert if over N kilobytes (Defaults to 5000)"
    echo "-m/--webm         Also create a webm file"
    return 1
  fi

  # Prepare the quality tag if requested.
  [[ -z "$giftag" ]] && giftag="-default"
  [[ -z "$giftagopt" ]] && giftag=""

  for file ; do

    local output_file="${file%.*}${giftag}.gif"
    local del_after=$opt_del_after

    if [[ "$make_webm" ]] ; then
      $ffmpeg -loglevel panic -i "$file" \
        -c:v libvpx -crf 4 -threads 0 -an -b:v 2M -auto-alt-ref 0 \
        -quality best -loop 0 "${file%.*}.webm" || return 2
    fi

    # Set FPS to match the video if possible, otherwise fallback to default.
    if [[ "$infps" ]] ; then
      fps=$infps
    else
      fps=$defaultfps
      if [[ -x $mediainfo ]] ; then
        fps=$($mediainfo "$file" | grep "Frame rate   " |sed 's/.*: \([0-9.]\+\) .*/\1/' | head -1)
        [[ -z "$fps" ]] && fps=$($mediainfo "$file" | grep "Minimum frame rate" |sed 's/.*: \([0-9.]\+\) .*/\1/' | head -1)
      fi
    fi

    echo "$(tput setaf 2)Creating '$output_file' at $fps FPS ...$(tput sgr 0)"

    if [[ "$use_gifski" = "true" ]] ; then
      # I trust @pornel to do his own resizing optimization choices
      $ffmpeg -loglevel panic -i "$file" -r $fps -vcodec png v2gif-tmp-%05d.png && \
        $gifski v2gif-tmp-*.png $maxwidthski --fps $(printf "%.0f" $fps) -o "$output_file" || return 2
    else
      $ffmpeg -loglevel panic -i "$file" $maxsize -r $fps -vcodec png v2gif-tmp-%05d.png && \
        $convert +dither -layers Optimize v2gif-tmp-*.png GIF:- | \
        $gifsicle $lossiness --no-warnings --colors 256 --delay=$(echo "100/$fps"|bc) --loop --optimize=3 --multifile - > "$output_file" || return 2
    fi

    rm v2gif-tmp-*.png

    # Checking if the file is bigger than Twitter likes and warn
    if [[ $alert -gt 0 ]] ; then
      local out_size=$(wc --bytes < "$output_file")
      if [[ $out_size -gt $(( alert * 1000 )) ]] ; then
        echo "$(tput setaf 3)Warning: '$output_file' is $((out_size/1000))kb.$(tput sgr 0)"
        [[ "$del_after" == "true" ]] && echo "$(tput setaf 3)Warning: Keeping '$file' even though --del requested.$(tput sgr 0)"
        del_after=""
      fi
    fi

    [[ "$del_after" = "true" ]] && rm "$file"

  done

  echo "$(tput setaf 2)Done.$(tput sgr 0)"
}

function any2webm() {
  about 'Converts an movies and Animated GIF files into an into a modern quality WebM video.'
  group 'gif'
  param '1: GIF/video file name(s)'
  param '2: -s <WxH> ; Optional: set <W>idth and <H>eight in pixels'
  param '3: -d       ; Optional: delete the original file if succeeded'
  param '4: -t       ; Optional: Tag the result with quality stamp for comparison use'
  param '5: -f <num> ; Optional: Change number of frames per second'
  param '6: -b <num> ; Optional: Set Bandwidth (quality/size of resulting file), Defaults to 2M (bits/sec, accepts fractions)"'
  param '7: -a <num> ; Optional: Alert if resulting file is over <num> kilobytes (default is 5000, 0 turns off)'
  example '$ any2webm foo.gif'
  example '$ any2webm *.mov -b 1.5M -s 600x480'

  # Parse the options
  local args=$(getopt -l alert -l "bandwidth:" -l "width:" -l del,delete -l tag -l "fps:" -l webm -o "a:b:w:f:dt" -- "$@")

  if [ $? -ne 0 ]; then
    echo 'Terminating...' >&2
    return 2
  fi

  eval set -- "$args"
  local opt_del_after=""
  local size=""
  local webmtagopt=""
  local webmtag=""
  local defaultfps=10
  local fps=""
  local bandwidth="2M"
  local alert=5000
  while [ $# -ge 1 ]; do
    case "$1" in
      --)
        # No more options left.
        shift
        break
        ;;
      -d|--del|--delete)
        # Delete after
        opt_del_after="true"
        shift
        ;;
      -s|--size)
        size="-s $2"
        webmtag="${webmtag}-s$2"
        shift 2
        ;;
      -t|--tag)
        # mark with a quality tag
        webmtagopt="true"
        shift
        ;;
      -f|--fps)
        # select fps
        fps="-r $2"
        webmtag="${webmtag}-f$2"
        shift 2
        ;;
      -b|--bandwidth)
        # select bandwidth
        bandwidth="$2"
        webmtag="${webmtag}-b$2"
        shift 2
        ;;
      -a|--alert)
        # set size alert
        alert="$2"
        shift 2
        ;;
    esac
  done

  if [[ -z "$*" ]]; then
    echo "$(tput setaf 1)No input files given. Example: any2webm file [file...] [-w <max width (pixels)>] < $(tput sgr 0)"
    return 1
  fi

  # Prepare the quality tag if requested.
  [[ -z "$webmtag" ]] && webmtag="-default"
  [[ -z "$webmtagopt" ]] && webmtag=""

  for file ; do

    local output_file="${file%.*}${webmtag}.webm"
    local del_after=$opt_del_after

    echo "$(tput setaf 2)Creating '$output_file' ...$(tput sgr 0)"

    $ffmpeg -loglevel panic -i "$file" \
      -c:v libvpx -crf 4 -threads 0 -an -b:v $bandwidth -auto-alt-ref 0 \
      -quality best $fps $size -loop 0 -pix_fmt yuva420p "$output_file" || return 2

    # Checking if the file is bigger than Twitter likes and warn
    if [[ $alert -gt 0 ]] ; then
      local out_size=$(wc --bytes < "$output_file")
      if [[ $out_size -gt $(( alert * 1000 )) ]] ; then
        echo "$(tput setaf 3)Warning: '$output_file' is $((out_size/1000))kb.$(tput sgr 0)"
        [[ "$del_after" == "true" ]] && echo "$(tput setaf 3)Warning: Keeping '$file' even though --del requested.$(tput sgr 0)"
        del_after=""
      fi
    fi

    [[ "$del_after" = "true" ]] && rm "$file"

  done
cite about-plugin
about-plugin 'ssh helper functions'

function add_ssh() {
  about 'add entry to ssh config'
  param '1: host'
  param '2: hostname'
  param '3: user'
  group 'ssh'

  [[ $# -ne 3 ]] && echo "add_ssh host hostname user" && return 1
  [[ ! -d ~/.ssh ]] && mkdir -m 700 ~/.ssh
  [[ ! -e ~/.ssh/config ]] && touch ~/.ssh/config && chmod 600 ~/.ssh/config
  echo -en "\n\nHost $1\n  HostName $2\n  User $3\n  ServerAliveInterval 30\n  ServerAliveCountMax 120" >> ~/.ssh/config
}

function sshlist() {
  about 'list hosts defined in ssh config'
  group 'ssh'

  awk '$1 ~ /Host$/ {for (i=2; i<=NF; i++) print $i}' ~/.ssh/config
}

function ssh-add-all() {
  about 'add all ssh private keys to agent'
cite about-plugin
about-plugin 'Helper functions for Ruby on Rails'

# Quick function to kill a daemonized Rails server
function killrails() {
  about 'Searches for a daemonized Rails server in tmp/pids and attempts to kill it.'
  group 'rails'

  railsPid="$(cat tmp/pids/server.pid)"
  if [ ! -z "$railsPid" ]; then
    echo "[OK] Rails Server Process Id : ${railsPid}"
    kill -9 $railsPid
    echo "[OK] Process Killed"
  else
    echo "[FAIL] Error killing Rails server"
cite about-plugin
about-plugin 'manage your jekyll site'

editpost() {
  about 'edit a post'
  param '1: site directory'
  group 'jekyll'

  unset SITE
  if [ -z "$1" ]
  then
    echo "Error: no site specified."
    echo "The site is the name of the directory your project is in."
    return 1
  fi

  for site in ${SITES[@]}
  do
    if [ "$(basename $site)" = "$1" ]
    then
      SITE=$site
      break
    fi
  done

  if [ -z "$SITE" ]
  then
    echo "No such site."
    return 1
  fi

  builtin cd "$SITE/_posts"

  COUNTER=1
  NUMBER="$RANDOM"
  TMPFILE="/tmp/editpost-$NUMBER"

  for POST in *
  do
    DATE=`echo $POST | grep -oE "[0-9]{4}-[0-9]{1,2}-[0-9]{1,2}"`
    TITLE=`cat $POST | grep -oE "title: (.+)"`
    TITLE=`echo $TITLE | sed 's/title: //'`
    echo "$COUNTER) 	$DATE	$TITLE" >> "$TMPFILE"
    POSTS[$COUNTER]=$POST
    COUNTER=`expr $COUNTER + 1`
  done
  less $TMPFILE
  read -p "Number of post to edit: " POST_TO_EDIT
  if [ -z "$JEKYLL_EDITOR" ]
  then
    nano "${POSTS[$POST_TO_EDIT]}"
  else
    "$JEKYLL_EDITOR" "${POSTS[$POST_TO_EDIT]}"
  fi
}

newpost() {
  about 'create a new post'
  param '1: site directory'
  group 'jekyll'

  unset SITE
  if [ -z "$1" ]
  then
    echo "Error: no site specified."
    echo "The site is the name of the directory your project is in."
    return 1
  fi

  if [ -z "$SITE" ]
  then
    echo "No such site."
    return 1
  fi

  loc=0

  for site in ${SITES[@]}
  do
    if [ "$(basename $site)" = "$1" ]
    then
      SITE=$site
      JEKYLL_FORMATTING=${MARKUPS[$loc]}
      break
    fi
    loc=$(($loc+1))
  done

  # 'builtin cd' into the local jekyll root

  builtin cd "$SITE/_posts"

  # Get the date for the new post's filename

  FNAME_DATE=$(date "+%Y-%m-%d")

  # If the user is using markdown or textile formatting, let them choose what type of post they want. Sort of like Tumblr.

  OPTIONS="Text Quote Image Audio Video Link"

  if [ $JEKYLL_FORMATTING = "markdown" -o $JEKYLL_FORMATTING = "textile" ]
  then
    select OPTION in $OPTIONS
    do
      if [[ $OPTION = "Text" ]]
      then
        POST_TYPE="Text"
        break
      fi

      if [[ $OPTION = "Quote" ]]
      then
        POST_TYPE="Quote"
        break
      fi

      if [[ $OPTION = "Image" ]]
      then
        POST_TYPE="Image"
        break
      fi

      if [[ $OPTION = "Audio" ]]
      then
        POST_TYPE="Audio"
        break
      fi

      if [[ $OPTION = "Video" ]]
      then
        POST_TYPE="Video"
        break
      fi

      if [[ $OPTION = "Link" ]]
      then
        POST_TYPE="Link"
        break
      fi
    done
  fi

  # Get the title for the new post

  read -p "Enter title of the new post: " POST_TITLE

  # Convert the spaces in the title to hyphens for use in the filename

  FNAME_POST_TITLE=`echo $POST_TITLE | tr ' ' "-"`

  # Now, put it all together for the full filename

  FNAME="$FNAME_DATE-$FNAME_POST_TITLE.$JEKYLL_FORMATTING"

  # And, finally, create the actual post file. But we're not done yet...

  touch "$FNAME"

  # Write a little stuff to the file for the YAML Front Matter

  echo "---" >> $FNAME

  # Now we have to get the date, again. But this time for in the header (YAML Front Matter) of
  # the file

  YAML_DATE=$(date "+%B %d %Y %X")

  # Echo the YAML Formatted date to the post file

  echo "date: $YAML_DATE" >> $FNAME

  # Echo the original post title to the YAML Front Matter header

  echo "title: $POST_TITLE" >> $FNAME

  # And, now, echo the "post" layout to the YAML Front Matter header

  echo "layout: post" >> $FNAME

  # Close the YAML Front Matter Header

  echo "---" >> $FNAME
  echo >> $FNAME

  # Generate template text based on the post type

  if [[ $JEKYLL_FORMATTING = "markdown" ]]
  then
    if [[ $POST_TYPE = "Text" ]]
    then
      true
    fi

    if [[ $POST_TYPE = "Quote" ]]
    then
      echo "> Quote" >> $FNAME
      echo >> $FNAME
      echo "&mdash; Author" >> $FNAME
    fi

    if [[ $POST_TYPE = "Image" ]]
    then
      echo "![Alternate Text](/path/to/image/or/url)" >> $FNAME
    fi

    if [[ $POST_TYPE = "Audio" ]]
    then
      echo "<html><audio src=\"/path/to/audio/file\" controls=\"controls\"></audio></html>" >> $FNAME
    fi

    if [[ $POST_TYPE = "Video" ]]
    then
      echo "<html><video src=\"/path/to/video\" controls=\"controls\"></video></html>" >> $FNAME
    fi

    if [[ $POST_TYPE = "Link" ]]
    then
      echo "[link][1]" >> $FNAME
      echo >> $FNAME
      echo "> Quote" >> $FNAME
      echo >> $FNAME
      echo "[1]: url" >> $FNAME
    fi
  fi

  if [[ $JEKYLL_FORMATTING = "textile" ]]
  then
    if [[ $POST_TYPE = "Text" ]]
    then
      true
    fi

    if [[ $POST_TYPE = "Quote" ]]
    then
      echo "bq. Quote" >> $FNAME
      echo >> $FNAME
      echo "&mdash; Author" >> $FNAME
    fi

    if [[ $POST_TYPE = "Image" ]]
    then
      echo "!url(alt text)" >> $FNAME
    fi

    if [[ $POST_TYPE = "Audio" ]]
    then
      echo "<html><audio src=\"/path/to/audio/file\" controls=\"controls\"></audio></html>" >> $FNAME
    fi

    if [[ $POST_TYPE = "Video" ]]
    then
      echo "<html><video src=\"/path/to/video\" controls=\"controls\"></video></html>" >> $FNAME
    fi

    if [[ $POST_TYPE = "Link" ]]
    then
      echo "\"Site\":url" >> $FNAME
      echo >> $FNAME
      echo "bq. Quote" >> $FNAME
    fi
  fi

  # Open the file in your favorite editor

  "$JEKYLL_EDITOR" $FNAME
}

function testsite() {
  about 'launches local jekyll server'
  param '1: site directory'
  group 'jekyll'

  unset SITE
  if [ -z "$1" ]
  then
    echo "Error: no site specified."
    echo "The site is the name of the directory your project is in."
    return 1
  fi

  for site in ${SITES[@]}
  do
    if [ "$(basename $site)" = "$1" ]
    then
      SITE=$site
      break
    fi
  done

  if [ -z "$SITE" ]
  then
    echo "No such site."
    return 1
  fi

  builtin cd $SITE
  jekyll --server --auto
}

function buildsite() {
  about 'builds site'
  param '1: site directory'
  group 'jekyll'

  unset SITE
  if [ -z "$1" ]
  then
    echo "Error: no site specified."
    echo "The site is the name of the directory your project is in."
    return 1
  fi

  for site in ${SITES[@]}
  do
    if [ "$(basename $site)" = "$1" ]
    then
      SITE=$site
      break
    fi
  done

  if [ -z "$SITE" ]
  then
    echo "No such site."
    return 1
  fi

  builtin cd $SITE
  rm -rf _site
  jekyll --no-server
}

function deploysite() {
  about 'rsyncs site to remote host'
  param '1: site directory'
  group 'jekyll'

  unset SITE
  if [ -z "$1" ]
  then
    echo "Error: no site specified."
    echo "The site is the name of the directory your project is in."
    return 1
  fi

  loc=0

  for site in ${SITES[@]}
  do
    if [ "$(basename $site)" = "$1" ]
    then
      SITE=$site
      REMOTE=${REMOTES[$loc]}
      break
    fi
    loc=$(($loc+1))
  done

  if [ -z "$SITE" ]
  then
    echo "No such site."
    return 1
  fi

  builtin cd $SITE
cite about-plugin
about-plugin 'Search&Select history with percol'

# Notice
## You have to upgrade bash to bash 4.x on Mac OS X.
## http://stackoverflow.com/questions/16416195/how-do-i-upgrade-bash-in-mac-osx-mountain-lion-and-set-it-the-correct-path

# Install
## (sudo) pip install percol
## bash-it enable percol

# Usage
## C-r to search&select from history

_replace_by_history() {
    if command -v tac>/dev/null; then
        alias _tac=tac
    else
        alias _tac="tail -r"
    fi
    local l=$(HISTTIMEFORMAT= history | _tac | sed -e 's/^\ *[0-9]*\ *//' | percol --query "$READLINE_LINE")
    READLINE_LINE="$l"
    READLINE_POINT=${#l}
}


if command -v percol>/dev/null; then
    current_version=${BASH_VERSION%%[^0-9]*}
    if [ $current_version -lt 4 ]; then
       echo -e "\033[91mWarning: You have to upgrade Bash to Bash v4.x to use the 'percol' plugin.\033[m"
cite about-plugin
about-plugin 'Load Software Development Kit Manager'

# Use $SDKMAN_DIR if defined,
# otherwise default to ~/.sdkman
cite about-plugin
about-plugin 'speeds up your life by using gitstatus for git status calculations. install from https://github.com/romkatv/gitstatus'

function gitstatus_on_disable() {
  about 'Destructor of gitstatus plugin'
  group 'gitstatus'

  unset SCM_GIT_USE_GITSTATUS
  _command_exists gitstatus_stop && gitstatus_stop
}

# No scm-check
[[ $SCM_CHECK == "true" ]] || return

# non-interactive shell
[[ $- == *i* ]] || return

: "${SCM_GIT_GITSTATUS_DIR:="$HOME/gitstatus"}"
if [[ -d ${SCM_GIT_GITSTATUS_DIR} ]]; then
  source "${SCM_GIT_GITSTATUS_DIR}/gitstatus.plugin.sh"
  # Start the actual gitstatus binary
  gitstatus_stop && gitstatus_start -s -1 -u -1 -c -1 -d -1
  export SCM_GIT_USE_GITSTATUS=true
else
	_log_warning "Could not find gitstatus directory in ${SCM_GIT_GITSTATUS_DIR}. Please specify directory location using SCM_GIT_GITSTATUS_DIR."
cite about-plugin
about-plugin 'manage your nginx service'

export NGINX_PATH='/opt/nginx'
pathmunge $NGINX_PATH/sbin after

function nginx_reload() {
  about 'reload your nginx config'
  group 'nginx'

  FILE="${NGINX_PATH}/logs/nginx.pid"
  if [ -e $FILE ]; then
    echo "Reloading NGINX..."
    PID=`cat $NGINX_PATH/logs/nginx.pid`
    sudo kill -HUP $PID
  else
    echo "Nginx pid file not found"
    return 0
  fi
}

function nginx_stop() {
  about 'stop nginx'
  group 'nginx'

  FILE="${NGINX_PATH}/logs/nginx.pid"
  if [ -e $FILE ]; then
    echo "Stopping NGINX..."
    PID=`cat $NGINX_PATH/logs/nginx.pid`
    sudo kill -INT $PID
  else
    echo "Nginx pid file not found"
    return 0
  fi
}

function nginx_start() {
  about 'start nginx'
  group 'nginx'

  FILE="${NGINX_PATH}/sbin/nginx"
  if [ -e $FILE ]; then
    echo "Starting NGINX..."
    sudo $NGINX_PATH/sbin/nginx
  else
    echo "Couldn't start nginx"
  fi
}

function nginx_restart() {
  about 'restart nginx'
  group 'nginx'

  FILE="${NGINX_PATH}/logs/nginx.pid"
  if [ -e $FILE ]; then
    echo "Stopping NGINX..."
    PID=`cat $NGINX_PATH/logs/nginx.pid`
    sudo kill -INT $PID
    sleep 1
    echo "Starting NGINX..."
    sudo $NGINX_PATH/sbin/nginx
  else
    echo "Nginx pid file not found"
    return 0
  fi
cite about-plugin
about-plugin 'load pipsi, if you are using it'

if [[ -f "$HOME/.local/bin/pipsi" ]]
then
cite about-plugin
about-plugin 'set textmate as a default editor'

if $(command -v mate &> /dev/null) ; then
  export EDITOR="$(which mate) -w"
cite about-plugin
about-plugin 'osx-specific functions'

# OS X: Open new tabs in same directory
if [ $(uname) = "Darwin" ]; then
  if type update_terminal_cwd > /dev/null 2>&1 ; then
    if ! [[ $PROMPT_COMMAND =~ (^|;)update_terminal_cwd($|;) ]] ; then
      PROMPT_COMMAND="${PROMPT_COMMAND%;};update_terminal_cwd"
      declared="$(declare -p PROMPT_COMMAND)"
      [[ "$declared" =~ \ -[aAilrtu]*x[aAilrtu]*\  ]] 2>/dev/null
      [[ $? -eq 0 ]] && export PROMPT_COMMAND
    fi
  fi
fi

function tab() {
  about 'opens a new terminal tab'
  group 'osx'

  osascript 2>/dev/null <<EOF
    tell application "System Events"
      tell process "Terminal" to keystroke "t" using command down
    end
    tell application "Terminal"
      activate
      do script with command " cd \"$PWD\"; $*" in window 0
    end tell
EOF
}

# renames the current os x terminal tab title
function tabname {
  printf "\e]1;$1\a"
}

# renames the current os x terminal window title
function winname {
  printf "\e]2;$1\a"
}

# this one switches your os x dock between 2d and 3d
# thanks to savier.zwetschge.org
function dock-switch() {
    about 'switch dock between 2d and 3d'
    param '1: "2d" or "3d"'
    example '$ dock-switch 2d'
    group 'osx'

    if [ $(uname) = "Darwin" ]; then

        if [ $1 = 3d ] ; then
            defaults write com.apple.dock no-glass -boolean NO
            killall Dock

        elif [ $1 = 2d ] ; then
            defaults write com.apple.dock no-glass -boolean YES
            killall Dock

        else
            echo "usage:"
            echo "dock-switch 2d"
            echo "dock-switch 3d."
        fi
    else
        echo "Sorry, this only works on Mac OS X"
    fi
}

function pman ()
{
    about 'view man documentation in Preview'
    param '1: man page to view'
    example '$ pman bash'
    group 'osx'
    man -t "${1}" | open -fa $PREVIEW
}

function pri ()
{
    about 'display information about Ruby classes, modules, or methods, in Preview'
    param '1: Ruby method, module, or class'
    example '$ pri Array'
    group 'osx'
    ri -T "${1}" | open -fa $PREVIEW
}

# Download a file and open it in Preview
function prevcurl() {
  about 'download a file and open it in Preview'
  param '1: url'
  group 'osx'

  if [ ! $(uname) = "Darwin" ]
  then
    echo "This function only works with Mac OS X"
    return 1
  fi
  curl "$*" | open -fa $PREVIEW
}

function refresh-launchpad() {
  about 'Reset launchpad layout in macOS'
  example '$ refresh-launchpad'
  group 'osx'

  if [ $(uname) = "Darwin" ];then
    defaults write com.apple.dock ResetLaunchPad -bool TRUE
    killall Dock
  else
    echo "Sorry, this only works on Mac OS X"
  fi
}

function list-jvms(){
  about 'List java virtual machines and their states in macOS'
  example 'list-jvms'
  group 'osx'

  JVMS_DIR="/Library/Java/JavaVirtualMachines"
  JVMS=( $(ls ${JVMS_DIR}) )
  JVMS_STATES=()

  # Map state of JVM
  for (( i = 0; i < ${#JVMS[@]}; i++ )); do
    if [[ -f "${JVMS_DIR}/${JVMS[$i]}/Contents/Info.plist" ]]; then
      JVMS_STATES[${i}]=enabled
    else
      JVMS_STATES[${i}]=disabled
    fi
      echo "${i} ${JVMS[$i]} ${JVMS_STATES[$i]}"
  done
}

function pick-default-jvm(){
  about 'Pick the default Java Virtual Machines in system-wide scope in macOS'
  example 'pick-default-jvm'

  # Call function for listing
  list-jvms

  # Declare variables
  local DEFAULT_JVM_DIR=""
  local DEFAULT_JVM=""
  local OPTION=""

  # OPTION for default jdk and set variables
  while [[ ! "$OPTION" =~ ^[0-9]+$ || OPTION -ge "${#JVMS[@]}" ]]; do
    read -p "Enter Default JVM: "  OPTION
      if [[ ! "$OPTION" =~ ^[0-9]+$  ]]; then
        echo "Please enter a number"
      fi

      if [[ OPTION -ge "${#JVMS[@]}" ]]; then
        echo "Please select one of the displayed JVMs"
      fi
  done

  DEFAULT_JVM_DIR="${JVMS_DIR}/${JVMS[$OPTION]}"
  DEFAULT_JVM="${JVMS[$OPTION]}"

  # Disable all jdk
  for (( i = 0; i < ${#JVMS[@]}; i++ )); do
    if [[ -f "${JVMS_DIR}/${JVMS[$i]}/Contents/Info.plist" ]]; then
      sudo mv "${JVMS_DIR}/${JVMS[$i]}/Contents/Info.plist" "${JVMS_DIR}/${JVMS[$i]}/Contents/Info.plist.disable"
    fi
  done

  # Enable default jdk
  if [[ -f "${DEFAULT_JVM_DIR}/Contents/Info.plist.disable" ]]; then
    sudo mv "${DEFAULT_JVM_DIR}/Contents/Info.plist.disable" "${DEFAULT_JVM_DIR}/Contents/Info.plist"
    echo "Enabled ${DEFAULT_JVM} as default JVM"
  fi
}

# Make this backwards compatible
# Bash-it no longer bundles nvm, as this was quickly becoming outdated.
#
# BASH_IT_LOAD_PRIORITY: 225
#
# Please install nvm from https://github.com/creationix/nvm.git if you want to use it.

cite about-plugin
about-plugin 'node version manager configuration'

export NVM_DIR=${NVM_DIR:-$HOME/.nvm}
# This loads nvm
if command -v brew &>/dev/null && [ -s $(brew --prefix nvm)/nvm.sh ]
then
  . $(brew --prefix nvm)/nvm.sh
else
  [ -s "$NVM_DIR/nvm.sh" ] && . "$NVM_DIR/nvm.sh"
fi

if ! command -v nvm &>/dev/null
then
  function nvm() {
    echo "Bash-it no longer bundles the nvm script. Please install the latest version from"
    echo ""
    echo "https://github.com/creationix/nvm.git"
    echo ""
# Load after the other completions to understand what needs to be completed
# BASH_IT_LOAD_PRIORITY: 365

cite about-plugin
about-plugin 'Automatic completion of aliases'

# References:
# http://superuser.com/a/437508/119764
# http://stackoverflow.com/a/1793178/1228454

# This needs to be a plugin so it gets executed after the completions and the aliases have been defined.
# Bash-it loads its components in the order
# 1) Aliases
# 2) Completions
# 3) Plugins
# 4) Custom scripts

# Automatically add completion for all aliases to commands having completion functions
function alias_completion {
    local namespace="alias_completion"

    # parse function based completion definitions, where capture group 2 => function and 3 => trigger
    local compl_regex='complete( +[^ ]+)* -F ([^ ]+) ("[^"]+"|[^ ]+)'
    # parse alias definitions, where capture group 1 => trigger, 2 => command, 3 => command arguments
    local alias_regex="alias( -- | )([^=]+)='(\"[^\"]+\"|[^ ]+)(( +[^ ]+)*)'"

    # create array of function completion triggers, keeping multi-word triggers together
    eval "local completions=($(complete -p | sed -Ene "/$compl_regex/s//'\3'/p"))"
    (( ${#completions[@]} == 0 )) && return 0

    # create temporary file for wrapper functions and completions
    local tmp_file; tmp_file="$(mktemp -t "${namespace}-${RANDOM}XXXXXX")" || return 1

    local completion_loader; completion_loader="$(complete -p -D 2>/dev/null | sed -Ene 's/.* -F ([^ ]*).*/\1/p')"

    # read in "<alias> '<aliased command>' '<command args>'" lines from defined aliases
    local line; while read line; do
        eval "local alias_tokens; alias_tokens=($line)" 2>/dev/null || continue # some alias arg patterns cause an eval parse error
        local alias_name="${alias_tokens[0]}" alias_cmd="${alias_tokens[1]}" alias_args="${alias_tokens[2]# }"

        # skip aliases to pipes, boolean control structures and other command lists
        # (leveraging that eval errs out if $alias_args contains unquoted shell metacharacters)
        eval "local alias_arg_words; alias_arg_words=($alias_args)" 2>/dev/null || continue
        # avoid expanding wildcards
        read -a alias_arg_words <<< "$alias_args"

        # skip alias if there is no completion function triggered by the aliased command
        if [[ ! " ${completions[*]} " =~ " $alias_cmd " ]]; then
            if [[ -n "$completion_loader" ]]; then
                # force loading of completions for the aliased command
                eval "$completion_loader $alias_cmd"
                # 124 means completion loader was successful
                [[ $? -eq 124 ]] || continue
                completions+=($alias_cmd)
            else
                continue
            fi
        fi
        local new_completion="$(complete -p "$alias_cmd" 2>/dev/null)"

        # create a wrapper inserting the alias arguments if any
        if [[ -n $alias_args ]]; then
            local compl_func="${new_completion/#* -F /}"; compl_func="${compl_func%% *}"
            # avoid recursive call loops by ignoring our own functions
            if [[ "${compl_func#_$namespace::}" == $compl_func ]]; then
                local compl_wrapper="_${namespace}::${alias_name}"
                    echo "function $compl_wrapper {
                        local compl_word=\$2
                        local prec_word=\$3
                        # check if prec_word is the alias itself. if so, replace it
                        # with the last word in the unaliased form, i.e.,
                        # alias_cmd + ' ' + alias_args.
                        if [[ \$COMP_LINE == \"\$prec_word \$compl_word\" ]]; then
                            prec_word='$alias_cmd $alias_args'
                            prec_word=\${prec_word#* }
                        fi
                        (( COMP_CWORD += ${#alias_arg_words[@]} ))
                        COMP_WORDS=($alias_cmd $alias_args \${COMP_WORDS[@]:1})
                        (( COMP_POINT -= \${#COMP_LINE} ))
                        COMP_LINE=\${COMP_LINE/$alias_name/$alias_cmd $alias_args}
                        (( COMP_POINT += \${#COMP_LINE} ))
                        $compl_func \"$alias_cmd\" \"\$compl_word\" \"\$prec_word\"
                    }" >> "$tmp_file"
                    new_completion="${new_completion/ -F $compl_func / -F $compl_wrapper }"
            fi
        fi

        # replace completion trigger by alias
        if [[ -n $new_completion ]]; then
            new_completion="${new_completion% *} $alias_name"
# shellcheck shell=bash
cite about-plugin
about-plugin 'search history using the substring already entered'

# enter a few characters and press UpArrow/DownArrow
cite about-plugin
about-plugin 'Java and JAR helper functions'

function jar_manifest {
  about "extracts the specified JAR file's MANIFEST file and prints it to stdout"
  group 'java'
  param '1: JAR file to extract the MANIFEST from'
  example 'jar_manifest lib/foo.jar'

  unzip -c $1 META-INF/MANIFEST.MF
cite about-plugin
about-plugin 'ruby and rubygems specific functions and settings'

# Make commands installed with 'gem install --user-install' available
# ~/.gem/ruby/${RUBY_VERSION}/bin/
if which ruby >/dev/null && which gem >/dev/null; then
  pathmunge "$(ruby -e 'print Gem.user_dir')/bin" after
fi

function remove_gem {
  about 'removes installed gem'
  param '1: installed gem name'
  group 'ruby'

  gem list | grep $1 | awk '{ print $1; }' | xargs sudo gem uninstall
# shellcheck shell=bash
cite about-plugin
about-plugin 'git helper functions'

function git_remote {
	about "adds remote $GIT_HOSTING:$1 to current repo"
	group "git"

	echo "Running: git remote add origin ${GIT_HOSTING}:$1.git"
	git remote add origin "$GIT_HOSTING:$1".git
}

function git_first_push {
	about 'push into origin refs/heads/master'
	group 'git'

	echo "Running: git push origin master:refs/heads/master"
	git push origin master:refs/heads/master
}

function git_pub() {
	about 'publishes current branch to remote origin'
	group 'git'
	BRANCH=$(git rev-parse --abbrev-ref HEAD)

	echo "Publishing ${BRANCH} to remote origin"
	git push -u origin "$BRANCH"
}

function git_revert() {
	about 'applies changes to HEAD that revert all changes after this commit'
	group 'git'

	git reset "$1"
	git reset --soft "HEAD@{1}"
	git commit -m "Revert to ${1}"
	git reset --hard
}

function git_rollback() {
	about 'resets the current HEAD to this commit'
	group 'git'

	function is_clean() {
		if [[ $(git diff --shortstat 2> /dev/null | tail -n1) != "" ]]; then
			echo "Your branch is dirty, please commit your changes"
			kill -INT $$
		fi
	}

	function commit_exists() {
		git rev-list --quiet "$1"
		status=$?
		if [ $status -ne 0 ]; then
			echo "Commit ${1} does not exist"
			kill -INT $$
		fi
	}

	function keep_changes() {
		while true; do
			# shellcheck disable=SC2162
			read -p "Do you want to keep all changes from rolled back revisions in your working tree? [Y/N]" RESP
			case $RESP in

				[yY])
					echo "Rolling back to commit ${1} with unstaged changes"
					git reset "$1"
					break
					;;
				[nN])
					echo "Rolling back to commit ${1} with a clean working tree"
					git reset --hard "$1"
					break
					;;
				*)
					echo "Please enter Y or N"
					;;
			esac
		done
	}

	if [ -n "$(git symbolic-ref HEAD 2> /dev/null)" ]; then
		is_clean
		commit_exists "$1"

		while true; do
			# shellcheck disable=SC2162
			read -p "WARNING: This will change your history and move the current HEAD back to commit ${1}, continue? [Y/N]" RESP
			case $RESP in

				[yY])
					keep_changes "$1"
					break
					;;
				[nN])
					break
					;;
				*)
					echo "Please enter Y or N"
					;;
			esac
		done
	else
		echo "you're currently not in a git repository"
	fi
}

function git_remove_missing_files() {
	about "git rm's missing files"
	group 'git'

	git ls-files -d -z | xargs -0 git update-index --remove
}

# Adds files to git's exclude file (same as .gitignore)
function local-ignore() {
	about 'adds file or path to git exclude file'
	param '1: file or path fragment to ignore'
	group 'git'
	echo "$1" >> .git/info/exclude
}

# get a quick overview for your git repo
function git_info() {
	about 'overview for your git repo'
	group 'git'

	if [ -n "$(git symbolic-ref HEAD 2> /dev/null)" ]; then
		# print informations
		echo "git repo overview"
		echo "-----------------"
		echo

		# print all remotes and thier details
		for remote in $(git remote show); do
			echo "$remote":
			git remote show "$remote"
			echo
		done

		# print status of working repo
		echo "status:"
		if [ -n "$(git status -s 2> /dev/null)" ]; then
			git status -s
		else
			echo "working directory is clean"
		fi

		# print at least 5 last log entries
		echo
		echo "log:"
		git log -5 --oneline
		echo

	else
		echo "you're currently not in a git repository"

	fi
}

function git_stats {
	about 'display stats per author'
	group 'git'

	# awesome work from https://github.com/esc/git-stats
	# including some modifications

	if [ -n "$(git symbolic-ref HEAD 2> /dev/null)" ]; then
		echo "Number of commits per author:"
		git --no-pager shortlog -sn --all
		AUTHORS=$(git shortlog -sn --all | cut -f2 | cut -f1 -d' ')
		LOGOPTS=""
		if [ "$1" == '-w' ]; then
			LOGOPTS="$LOGOPTS -w"
			shift
		fi
		if [ "$1" == '-M' ]; then
			LOGOPTS="$LOGOPTS -M"
			shift
		fi
		if [ "$1" == '-C' ]; then
			LOGOPTS="$LOGOPTS -C --find-copies-harder"
			shift
		fi
		for a in $AUTHORS; do
			echo '-------------------'
			echo "Statistics for: $a"
			echo -n "Number of files changed: "
			# shellcheck disable=SC2086
			git log $LOGOPTS --all --numstat --format="%n" --author="$a" | cut -f3 | sort -iu | wc -l
			echo -n "Number of lines added: "
			# shellcheck disable=SC2086
			git log $LOGOPTS --all --numstat --format="%n" --author="$a" | cut -f1 | awk '{s+=$1} END {print s}'
			echo -n "Number of lines deleted: "
			# shellcheck disable=SC2086
			git log $LOGOPTS --all --numstat --format="%n" --author="$a" | cut -f2 | awk '{s+=$1} END {print s}'
			echo -n "Number of merges: "
			# shellcheck disable=SC2086
			git log $LOGOPTS --all --merges --author="$a" | grep -c '^commit'
		done
	else
		echo "you're currently not in a git repository"
	fi
}

function gittowork() {
	about 'Places the latest .gitignore file for a given project type in the current directory, or concatenates onto an existing .gitignore'
	group 'git'
	param '1: the language/type of the project, used for determining the contents of the .gitignore file'
	example '$ gittowork java'

	result=$(curl -L "https://www.gitignore.io/api/$1" 2> /dev/null)

	if [[ $result =~ ERROR ]]; then
		echo "Query '$1' has no match. See a list of possible queries with 'gittowork list'"
	elif [[ $1 = list ]]; then
		echo "$result"
	else
		if [[ -f .gitignore ]]; then
			result=$(echo "$result" | grep -v "# Created by http://www.gitignore.io")
			echo ".gitignore already exists, appending..."
			echo "$result" >> .gitignore
		else
			echo "$result" > .gitignore
		fi
	fi
}

function gitignore-reload() {
	about 'Empties the git cache, and readds all files not blacklisted by .gitignore'
	group 'git'
	example '$ gitignore-reload'

	# The .gitignore file should not be reloaded if there are uncommited changes.
	# Firstly, require a clean work tree. The function require_clean_work_tree()
	# was stolen with love from https://www.spinics.net/lists/git/msg142043.html

	# Begin require_clean_work_tree()

	# Update the index
	git update-index -q --ignore-submodules --refresh
	err=0

	# Disallow unstaged changes in the working tree
	if ! git diff-files --quiet --ignore-submodules --; then
		echo >&2 "ERROR: Cannot reload .gitignore: Your index contains unstaged changes."
		git diff-index --cached --name-status -r --ignore-submodules HEAD -- >&2
		err=1
	fi

	# Disallow uncommited changes in the index
	if ! git diff-index --cached --quiet HEAD --ignore-submodules; then
		echo >&2 "ERROR: Cannot reload .gitignore: Your index contains uncommited changes."
		git diff-index --cached --name-status -r --ignore-submodules HEAD -- >&2
		err=1
	fi

	# Prompt user to commit or stash changes and exit
	if [ $err = 1 ]; then
		echo >&2 "Please commit or stash them."
	fi

	# End require_clean_work_tree()

	# If we're here, then there are no uncommited or unstaged changes dangling around.
	# Proceed to reload .gitignore
	if [ $err = 0 ]; then
		# Remove all cached files
		git rm -r --cached .

		# Re-add everything. The changed .gitignore will be picked up here and will exclude the files
		# now blacklisted by .gitignore
		echo >&2 "Running git add ."
		git add .
		echo >&2 "Files readded. Commit your new changes now."
	fi
}

function git-changelog() {
	# ---------------------------------------------------------------
	#  ORIGINAL ANSWER: https://stackoverflow.com/a/2979587/10362396 |
	# ---------------------------------------------------------------
	about 'Creates the git changelog from one point to another by date'
	group 'git'
	example '$ git-changelog origin/master...origin/release [md|txt]'

	if [[ "$1" != *"..."* ]]; then
		echo "Please include the valid 'diff' to make changelog"
		return 1
	fi

	local NEXT=$(date +%F)

	if [[ "$2" == "md" ]]; then
		echo "# CHANGELOG $1"

		# shellcheck disable=SC2162
		git log "$1" --no-merges --format="%cd" --date=short | sort -u -r | while read DATE; do
			echo
			echo "### $DATE"
			git log --no-merges --format=" * (%h) %s by [%an](mailto:%ae)" --since="$DATE 00:00:00" --until="$DATE 24:00:00"
			NEXT=$DATE
		done
	else
		echo "CHANGELOG $1"
		echo ----------------------

		# shellcheck disable=SC2162
		git log "$1" --no-merges --format="%cd" --date=short | sort -u -r | while read DATE; do
			echo
			echo [$DATE]
			git log --no-merges --format=" * (%h) %s by %an <%ae>" --since="$DATE 00:00:00" --until="$DATE 24:00:00"
			NEXT=$DATE
		done
cite about-plugin
about-plugin 'Node.js helper functions'

# Ensure local modules are preferred in PATH
pathmunge "./node_modules/.bin" "after"

# Check that we have npm
out=$(command -v npm 2>&1) || return

# If not using nodenv, ensure global modules are in PATH
cite about-plugin
about-plugin 'pygmentize instead of cat to terminal if possible'

if $(command -v pygmentize &> /dev/null) ; then
  # get the full paths to binaries
  CAT_BIN=$(which cat)
  LESS_BIN=$(which less)
  BASH_IT_CCAT_STYLE="${BASH_IT_CCAT_STYLE:=default}"
  BASH_IT_CLESS_STYLE="${BASH_IT_CLESS_STYLE:=default}"

  # pigmentize cat and less outputs - call them ccat and cless to avoid that
  # especially cat'ed output in scripts gets mangled with pygemtized meta characters
  function ccat()
  {
      about 'runs either pygmentize or cat on each file passed in'
      param '*: files to concatenate (as normally passed to cat)'
      example 'cat mysite/manage.py dir/text-file.txt'
      for var;
      do
          pygmentize -f 256 -O style="$BASH_IT_CCAT_STYLE" -g "$var" 2>/dev/null || "$CAT_BIN" "$var";
      done
  }

  function cless()
  {
      about 'it pigments the file passed in and passes it to less for pagination'
      param '$1: the file to paginate with less'
      example 'less mysite/manage.py'
      pygmentize -f 256 -O style="$BASH_IT_CLESS_STYLE" -g $* | "$LESS_BIN" -R
  }
cite about-plugin
about-plugin 'Toggle sudo at the beginning of the current or the previous command by hitting the ESC key twice'

function sudo-command-line() {
  about "toggle sudo at the beginning of the current or the previous command by hitting the ESC key twice"
  group "sudo"

  [[ ${#READLINE_LINE} -eq 0 ]] && READLINE_LINE=$(fc -l -n -1 | xargs)
  if [[ $READLINE_LINE == sudo\ * ]]; then
    READLINE_LINE="${READLINE_LINE#sudo }"
  else
    READLINE_LINE="sudo $READLINE_LINE"
  fi
  READLINE_POINT=${#READLINE_LINE}
}

# Define shortcut keys: [Esc] [Esc]

# Readline library requires bash version 4 or later
if [ "${BASH_VERSINFO}" -ge 4 ]; then
cite about-plugin
about-plugin 'Maven jgitflow build helpers'

function hotfix-start {
  about 'helper function for starting a new hotfix'
  group 'jgitflow'

  mvn jgitflow:hotfix-start ${JGITFLOW_MVN_ARGUMENTS}
}

function hotfix-finish {
  about 'helper function for finishing a hotfix'
  group 'jgitflow'

  mvn jgitflow:hotfix-finish -Darguments="${JGITFLOW_MVN_ARGUMENTS}" && git push && git push origin master && git push --tags
}

function feature-start {
  about 'helper function for starting a new feature'
  group 'jgitflow'

  mvn jgitflow:feature-start ${JGITFLOW_MVN_ARGUMENTS}
}

function feature-finish {
  about 'helper function for finishing a feature'
  group 'jgitflow'

  mvn jgitflow:feature-finish ${JGITFLOW_MVN_ARGUMENTS}
  echo -e '\033[32m----------------------------------------------------------------\033[0m'
  echo -e '\033[32m===== REMEMBER TO CREATE A NEW RELEASE TO DEPLOY THIS FEATURE ====\033[0m'
  echo -e '\033[32m----------------------------------------------------------------\033[0m'
}

function release-start {
  about 'helper function for starting a new release'
  group 'jgitflow'

  mvn jgitflow:release-start ${JGITFLOW_MVN_ARGUMENTS}
}

function release-finish {
  about 'helper function for finishing a release'
  group 'jgitflow'

cite about-plugin
about-plugin 'svn helper functions'

rm_svn(){
  about 'remove ".svn" files from directory'
  param '1: directory to search for files'
  group 'svn'

  if [ -z "$1" ]; then
      reference rm_svn
      return
  fi
  find $1 -name .svn -print0 | xargs -0 rm -rf
}

svn_add(){
    about 'add to svn repo'
    group 'svn'

    svn status | grep '^\?' | sed -e 's/? *//' | sed -e 's/ /\ /g' | xargs svn add
# Directory stack navigation:
#
# Add to stack with: pu /path/to/directory
# Delete current dir from stack with: po
# Show stack with: d
# Jump to location by number.

cite about-plugin
about-plugin 'directory stack navigation'

# Show directory stack
alias d="dirs -v -l"

# Change to location in stack by number
alias 1="pushd"
alias 2="pushd +2"
alias 3="pushd +3"
alias 4="pushd +4"
alias 5="pushd +5"
alias 6="pushd +6"
alias 7="pushd +7"
alias 8="pushd +8"
alias 9="pushd +9"

# Clone this location
alias pc="pushd \$(pwd)"

# Push new location
alias pu="pushd"

# Pop current location
alias po="popd"

function dirs-help() {
  about 'directory navigation alias usage'
  group 'dirs'

  echo "Directory Navigation Alias Usage"
  echo
  echo "Use the power of directory stacking to move"
  echo "between several locations with ease."
  echo
  echo "d	: Show directory stack."
  echo "po	: Remove current location from stack."
  echo "pc	: Adds current location to stack."
  echo "pu <dir>: Adds given location to stack."
  echo "1	: Change to stack location 1."
  echo "2	: Change to stack location 2."
  echo "3	: Change to stack location 3."
  echo "4	: Change to stack location 4."
  echo "5	: Change to stack location 5."
  echo "6	: Change to stack location 6."
  echo "7	: Change to stack location 7."
  echo "8	: Change to stack location 8."
  echo "9	: Change to stack location 9."
}

# Add bookmarking functionality
# Usage:

if [ ! -f ~/.dirs ]; then  # if doesn't exist, create it
    touch ~/.dirs
else
    source ~/.dirs
fi

alias L='cat ~/.dirs'

# Goes to destination dir, otherwise stay in the dir
G () {
    about 'goes to destination dir'
    param '1: directory'
    example '$ G ..'
    group 'dirs'

    cd "${1:-$(pwd)}" ;
}

S () {
    about 'save a bookmark'
    param '1: bookmark name'
    example '$ S mybkmrk'
    group 'dirs'

    [[ $# -eq 1 ]] || { echo "${FUNCNAME[0]} function requires 1 argument"; return 1; }

    sed "/$@/d" ~/.dirs > ~/.dirs1;
    \mv ~/.dirs1 ~/.dirs;
    echo "$@"=\"`pwd`\" >> ~/.dirs;
    source ~/.dirs ;
}

R () {
    about 'remove a bookmark'
    param '1: bookmark name'
    example '$ R mybkmrk'
    group 'dirs'

    [[ $# -eq 1 ]] || { echo "${FUNCNAME[0]} function requires 1 argument"; return 1; }

    sed "/$@/d" ~/.dirs > ~/.dirs1;
    \mv ~/.dirs1 ~/.dirs;
}

alias U='source ~/.dirs' 	# Update bookmark stack
cite about-plugin
about-plugin 'hg helper functions'

hg_dirty() {
    about 'displays dirty status of hg repository'
    group 'hg'

    hg status --no-color 2> /dev/null \
    | awk '$1 == "?" { print "?" } $1 != "?" { print "!" }' \
    | sort | uniq | head -c1
}

hg_in_repo() {
    about 'determine if pwd is an hg repo'
    group 'hg'

    [[ `hg branch 2> /dev/null` ]] && echo 'on '
}

hg_branch() {
cite about-plugin
about-plugin 'Helper functions for using docker-compose'

function docker-compose-fresh() {
  about 'Shut down, remove and start again the docker-compose setup, then tail the logs'
  group 'docker-compose'
  param '1: name of the docker-compose.yaml file to use (optional). Default: docker-compose.yaml'
  example 'docker-compose-fresh docker-compose-foo.yaml'

  local DCO_FILE_PARAM=""
  if [ -n "$1" ]; then
    echo "Using docker-compose file: $1"
    DCO_FILE_PARAM="--file $1"
  fi

# Load RVM, if you are using it

cite about-plugin
about-plugin 'load rvm, if you are using it'

[[ -s "$HOME/.rvm/scripts/rvm" ]] && source "$HOME/.rvm/scripts/rvm"

# Check to make sure that RVM is actually loaded before adding
# the customizations to it.
if [ "$rvm_path" ]
then
    # Load the auto-completion script if RVM was loaded.
    [[ -r $rvm_path/scripts/completion ]] && . $rvm_path/scripts/completion

    switch () {
      rvm $1
      local v=$(rvm_version)
      rvm wrapper $1 textmate
      echo "Switch to Ruby version: "$v
    }

    rvm_default () {
      rvm --default $1
      rvm wrapper $1 textmate
    }

    function rvm_version () {
      ruby --version
    }

# make sure virtualenvwrapper is enabled if available

cite about-plugin
about-plugin 'virtualenvwrapper and pyenv-virtualenvwrapper helper functions'

if _command_exists pyenv; then
  pyenv virtualenvwrapper
else
  [[ `which virtualenvwrapper.sh` ]] && . virtualenvwrapper.sh
fi


function mkvenv {
  about 'create a new virtualenv for this directory'
  group 'virtualenv'

  cwd=`basename \`pwd\``
  mkvirtualenv --distribute $cwd
}


function mkvbranch {
  about 'create a new virtualenv for the current branch'
  group 'virtualenv'

  mkvirtualenv --distribute "$(basename `pwd`)@$SCM_BRANCH"
}

function wovbranch {
  about 'sets workon branch'
  group 'virtualenv'

  workon "$(basename `pwd`)@$SCM_BRANCH"
}

function wovenv {
  about 'works on the virtualenv for this directory'
  group 'virtualenv'

  workon "$(basename `pwd`)"
cite about-plugin
about-plugin 'load nodenv, if you are using it'

export NODENV_ROOT="$HOME/.nodenv"
pathmunge "$NODENV_ROOT/bin"
# based on https://gist.github.com/318247

cite about-plugin
about-plugin 'render commandline output in your browser'

function browser() {
    about 'pipe html to a browser'
    example '$ echo "<h1>hi mom!</h1>" | browser'
    example '$ ron -5 man/rip.5.ron | browser'
    group 'browser'

    if [ -t 0 ]; then
        if [ -n "$1" ]; then
            open $1
        else
            reference browser
        fi

    else
        f="/tmp/browser.$RANDOM.html"
        cat /dev/stdin > $f
        open $f
    fi
}


function wmate() {
    about 'pipe hot spicy interwebs into textmate and cleanup!'
    example '$ wmate google.com'
    group 'browser'

    if [ -t 0 ]; then
        if [ -n "$1" ]; then
            wget -qO- $1 | /usr/bin/mate

TIDY=`/usr/bin/osascript << EOT
tell application "TextMate"
	activate
end tell

tell application "System Events"
	tell process "TextMate"
		tell menu bar 1
			tell menu bar item "Bundles"
				tell menu "Bundles"
					tell menu item "HTML"
						tell menu "HTML"
							click menu item "Tidy"
						end tell
					end tell
				end tell
			end tell
		end tell
	end tell
end tell
EOT`

        else
            reference wmate
      fi
    fi
}

function raw() {
    about 'write wget into a temp file and pump it into your browser'
    example '$ raw google.com'
    group 'browser'

    if [ -t 0 ]; then
        if [ -n "$1" ]; then
            wget -qO- $1 | browser
        else
            reference raw
        fi
    fi
cite about-plugin
about-plugin 'use mactex'

# add mactex to the path if its present
MACTEX_PATH=/usr/local/texlive/2009/bin/universal-darwin
# Load after the system completion to make sure that the fzf completions are working
# BASH_IT_LOAD_PRIORITY: 375

cite about-plugin
about-plugin 'load fzf, if you are using it'

_command_exists fzf || return

if [ -r ~/.fzf.bash ] ; then
  source ~/.fzf.bash
elif [ -r "${XDG_CONFIG_HOME:-$HOME/.config}"/fzf/fzf.bash ] ; then
  source "${XDG_CONFIG_HOME:-$HOME/.config}"/fzf/fzf.bash
fi

if [ -z ${FZF_DEFAULT_COMMAND+x}  ] && _command_exists fd ; then
  export FZF_DEFAULT_COMMAND='fd --type f'
fi

fe() {
  about "Open the selected file in the default editor"
  group "fzf"
  param "1: Search term"
  example "fe foo"

  local IFS=$'\n'
  local files
  files=($(fzf-tmux --query="$1" --multi --select-1 --exit-0))
  [[ -n "$files" ]] && ${EDITOR:-vim} "${files[@]}"
}

fcd() {
  about "cd to the selected directory"
  group "fzf"
  param "1: Directory to browse, or . if omitted"
  example "fcd aliases"

  local dir
  dir=$(find ${1:-.} -path '*/\.*' -prune \
                  -o -type d -print 2> /dev/null | fzf +m) &&
  cd "$dir"
cite about-plugin
about-plugin 'initialize jump (see https://github.com/gsamokovarov/jump). Add `export JUMP_OPTS=("--bind=z")` to change keybinding'

__init_jump() {
  command -v jump &> /dev/null || return
cite about-plugin
about-plugin 'postgres helper functions'


export PGVERSION=`pg_config --version | awk '{print $2}'`
export POSTGRES_BIN=`pg_config --bindir`
COMMON_PGDATA_PATHS=("/usr/local/var/postgres" "/var/pgsql" "/Library/Server/PostgreSQL/Data")
for possible in "${COMMON_PGDATA_PATHS[@]}"
do
   :
   if [ -f "$possible/pg_hba.conf" ]
   then
       # echo "PGDATA: $possible"
       export PGDATA=$possible
   fi
done





function postgres_start {
  about 'Starts PostgreSQL server'
  group 'postgres'

  echo 'Starting Postgres....';
  $POSTGRES_BIN/pg_ctl -D $PGDATA -l $PGDATA/logfile  start
}

function postgres_stop {
  about 'Stops PostgreSQL server'
  group 'postgres'

  echo 'Stopping Postgres....';
  $POSTGRES_BIN/pg_ctl -D $PGDATA -l $PGDATA/logfile stop -s -m fast
}

function postgres_status {
  about 'Returns status of PostgreSQL server'
  group 'postgres'

  # $POSTGRES_BIN/pg_ctl -D $PGDATA status
  if [[ $(is_postgres_running) == "no server running" ]]
  then
    echo "Postgres service [STOPPED]"
  else
    echo "Postgres service [RUNNING]"
  fi
}


function is_postgres_running {
  $POSTGRES_BIN/pg_ctl -D $PGDATA status | egrep -o "no server running"
}


function postgres_restart {
  about 'Restarts status of PostgreSQL server'
  group 'postgres'

  echo 'Restarting Postgres....';
  $POSTGRES_BIN/pg_ctl -D $PGDATA restart
}

function postgres_logfile {
  about 'View the last 500 lines from logfile'
  group 'postgres'

  tail -500 $PGDATA/logfile | less
}

function postgres_serverlog {
  about 'View the last 500 lines from server.log'
  group 'postgres'

  tail -500 $PGDATA/server.log | less
}


# function postgres_syslog {
#   about 'View the last 500 lines from syslog'
#   group 'postgres'
#
#   tail -500 $PGDATA/pg_log/`ls -Art $PGDATA/pg_log | tail -n 1` | less
# }
cite about-plugin
about-plugin 'Helpers to more easily work with Docker'

function docker-remove-most-recent-container() {
  about 'attempt to remove the most recent container from docker ps -a'
  group 'docker'
  docker ps -ql | xargs docker rm
}

function docker-remove-most-recent-image() {
  about 'attempt to remove the most recent image from docker images'
  group 'docker'
  docker images -q | head -1 | xargs docker rmi
}

function docker-remove-stale-assets() {
  about 'attempt to remove exited containers and dangling images'
  group 'docker'
  docker ps --filter status=exited -q | xargs docker rm --volumes
  docker images --filter dangling=true -q | xargs docker rmi
}

function docker-enter() {
  about 'enter the specified docker container using bash'
  group 'docker'
  param '1: Name of the container to enter'
  example 'docker-enter oracle-xe'

  docker exec -it "$@" /bin/bash;
}

function docker-remove-images() {
  about 'attempt to remove images with supplied tags or all if no tags are supplied'
  group 'docker'
  if [ -z "$1" ]; then
    docker rmi $(docker images -q)
  else
    DOCKER_IMAGES=""
    for IMAGE_ID in $@; do DOCKER_IMAGES="$DOCKER_IMAGES\|$IMAGE_ID"; done
    # Find the image IDs for the supplied tags
    ID_ARRAY=($(docker images | grep "${DOCKER_IMAGES:2}" | awk {'print $3'}))
    # Strip out duplicate IDs before attempting to remove the image(s)
    docker rmi $(echo ${ID_ARRAY[@]} | tr ' ' '\n' | sort -u | tr '\n' ' ')
 fi
}

function docker-image-dependencies() {
  about 'attempt to create a Graphiz image of the supplied image ID dependencies'
  group 'docker'
  if hash dot 2>/dev/null; then
    OUT=$(mktemp -t docker-viz-XXXX.png)
    docker images -viz | dot -Tpng > $OUT
    case $OSTYPE in
      linux*)
        xdg-open $OUT
        ;;
      darwin*)
        open $OUT
        ;;
    esac
  else
    >&2 echo "Can't show dependencies; Graphiz is not installed"
  fi
}

function docker-runtime-environment() {
  about 'attempt to list the environmental variables of the supplied image ID'
  group 'docker'
  docker run "$@" env
}

function docker-archive-content() {
  about 'show the content of the provided Docker image archive'
  group 'docker'
  param '1: image archive name'
  example 'docker-archive-content images.tar.gz'

  if [ -n "$1" ]; then
    tar -xzOf $1 manifest.json | jq '[.[] | .RepoTags] | add'
  fi
#!/bin/bash
cite about-plugin
about-plugin 'Todo.txt integration'

# you may override any of the exported variables below in your .bash_profile

if [ -z "$TODOTXT_DEFAULT_ACTION" ]; then
  # typing 't' by itself will list current todos
  export TODOTXT_DEFAULT_ACTION=ls
fi
cite about-plugin
about-plugin 'Add a gw command to use gradle wrapper if present, else use system gradle'

function gw() {
  local file="gradlew"
  local curr_path="${PWD}"
  local result="gradle"

  # Search recursively upwards for file.
  until [[ "${curr_path}" == "/" ]]; do
    if [[ -e "${curr_path}/${file}" ]]; then
      result="${curr_path}/${file}"
      break
    else
      curr_path=$(dirname "${curr_path}")
    fi
  done

  # Call gradle
  "${result}" $*
# shellcheck shell=bash
cite about-plugin
about-plugin 'go environment variables & path configuration'

# Load after basher and goenv
# BASH_IT_LOAD_PRIORITY: 270

# Test `go version` because goenv creates shim scripts that will be found in PATH
# but do not always resolve to a working install.
{ _command_exists go && go version &> /dev/null; } || return 0

export GOROOT="${GOROOT:-$(go env GOROOT)}"
export GOPATH="${GOPATH:-$(go env GOPATH)}"

# $GOPATH/bin is the default location for binaries. Because GOPATH accepts a list of paths and each
# might be managed differently, we add each path's /bin folder to PATH using pathmunge,
# while preserving ordering.
# e.g. GOPATH=foo:bar  ->  PATH=foo/bin:bar/bin
_bash-it-gopath-pathmunge() {
	_about 'Ensures paths in GOPATH are added to PATH using pathmunge, with /bin appended'
	_group 'go'
	if [[ -z $GOPATH ]]; then
		echo 'GOPATH empty' >&2
		return 1
	fi
	local paths i
	IFS=: read -r -a paths <<< "$GOPATH"
	i=${#paths[@]}
	while [[ $i -gt 0 ]]; do
		i=$((i - 1))
		if [[ -n "${paths[i]}" ]]; then
			pathmunge "${paths[i]}/bin"
		fi
	done
}
cite about-plugin
about-plugin 'AWS helper functions'

AWS_CONFIG_FILE="${AWS_CONFIG_FILE:-$HOME/.aws/config}"
AWS_SHARED_CREDENTIALS_FILE="${AWS_SHARED_CREDENTIALS_FILE:-$HOME/.aws/credentials}"

function awskeys {
    about 'helper function for AWS credentials file'
    group 'aws'

    if [[ ! -f "${AWS_SHARED_CREDENTIALS_FILE}" ]]; then
        echo "AWS credentials file not found"
        return 1
    fi

    if [[ $# -eq 1 ]] && [[ "$1" = "list" ]]; then
        __awskeys_list "$2"
    elif [[ $# -eq 1 ]] && [[ "$1" = "unset" ]]; then
        __awskeys_unset "$2"
    elif [[ $# -eq 2 ]] && [[ "$1" = "show" ]]; then
        __awskeys_show "$2"
    elif [[ $# -eq 2 ]] && [[ "$1" = "export" ]]; then
        __awskeys_export "$2"
    else
        __awskeys_help
    fi
}

function __awskeys_help {
    echo -e "Usage: awskeys [COMMAND] [profile]\n"
    echo -e "Helper to AWS credentials file.\n"
    echo -e "Commands:\n"
    echo "   help    Show this help message"
    echo "   list    List available AWS credentials profiles"
    echo "   show    Show the AWS keys associated to a credentials profile"
    echo "   export  Export an AWS credentials profile keys as environment variables"
    echo "   unset   Unset the AWS keys variables from the environment"
}

function __awskeys_get {
    local ln=$(grep -n "\[ *$1 *\]" "${AWS_SHARED_CREDENTIALS_FILE}" | cut -d ":" -f 1)
    if [[ -n "${ln}" ]]; then
        tail -n +${ln} "${AWS_SHARED_CREDENTIALS_FILE}" | egrep -m 2 "aws_access_key_id|aws_secret_access_key"
        tail -n +${ln} "${AWS_SHARED_CREDENTIALS_FILE}" | egrep -m 1 "aws_session_token"
    fi
}

function __awskeys_list {
    local credentials_list="$((egrep '^\[ *[a-zA-Z0-9_-]+ *\]$' "${AWS_SHARED_CREDENTIALS_FILE}"; grep "\[profile" "${AWS_CONFIG_FILE}" | sed "s|\[profile |\[|g") | sort | uniq)"
    if [[ -n $"{credentials_list}" ]]; then
        echo -e "Available credentials profiles:\n"
        for profile in ${credentials_list}; do
            echo "    $(echo ${profile} | tr -d "[]")"
        done
        echo
    else
        echo "No profiles found in credentials file"
    fi
}

function __awskeys_show {
    local p_keys="$(__awskeys_get $1)"
    if [[ -n "${p_keys}" ]]; then
        echo "${p_keys}"
    else
        echo "Profile $1 not found in credentials file"
    fi
}

function __awskeys_export {
    if [[ $(__awskeys_list) == *"$1"* ]]; then
        local p_keys=( $(__awskeys_get $1 | tr -d " ") )
        if [[ -n "${p_keys}" ]]; then
            for p_key in ${p_keys[@]}; do
                local key="${p_key%=*}"
                export "$(echo ${key} | tr [:lower:] [:upper:])=${p_key#*=}"
            done
        fi
        export AWS_PROFILE="$1"
    else
        echo "Profile $1 not found in credentials file"
    fi
}

function __awskeys_unset {
    unset AWS_PROFILE AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN
}

function __awskeys_comp {
    local cur prev opts prevprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"

    opts="help list show export unset"

    case "${prev}" in
        help|list|unset)
            return 0
            ;;
        show|export)
            local profile_list="$(__awskeys_list | grep "    ")"
            COMPREPLY=( $(compgen -W "${profile_list}" -- ${cur}) )
            return 0
            ;;
    esac

    COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )

    return 0
cite about-plugin
about-plugin 'Helpers to get Docker setup correctly for boot2docker'

# Note, this might need to be different if you have an older version
# of boot2docker, or its configured for a different IP
cite about-plugin
about-plugin 'quickly navigate configured paths with `pj` and `pjo`. example: "export PROJECT_PATHS=~/projects:~/work/projects"'

function pj {
about 'navigate quickly to your various project directories'
group 'projects'


if [ -z "$PROJECT_PATHS" ]; then
  echo "error: PROJECT_PATHS not set"
  return 1
fi


local cmd
local dest
local -a dests


if [ "$1" == "open" ]; then
  shift
  cmd="$EDITOR"
fi
cmd="${cmd:-cd}"


if [ -z "$1" ]; then
  echo "error: no project provided"
  return 1
fi


# collect possible destinations to account for directories
# with the same name in project directories
for i in ${PROJECT_PATHS//:/$'\n'}; do
  if [ -d "$i"/"$1" ]; then
    dests+=("$i/$1")
  fi
done


# when multiple destinations are found, present a menu
if [ ${#dests[@]} -eq 0 ]; then
  echo "error: no such project '$1'"
  return 1

elif [ ${#dests[@]} -eq 1 ]; then
  dest="${dests[0]}"

elif [ ${#dests[@]} -gt 1 ]; then
  PS3="Multiple project directories found. Please select one: "
  dests+=("cancel")
  select d in "${dests[@]}"; do
    case $d in
      "cancel")
        return
        ;;
      *)
        dest=$d
        break
        ;;
    esac
  done

else
  echo "error: please report this error"
  return 1 # should never reach this

fi

# shellcheck shell=bash
cite about-plugin
about-plugin 'load goenv, if you are using it'

# https://github.com/syndbg/goenv

# Load after basher
# BASH_IT_LOAD_PRIORITY: 260

# Don't modify the environment if we can't find the tool:
# - Check if in $PATH already
# - Check if installed manually to $GOENV_ROOT
# - Check if installed manually to $HOME
_command_exists goenv \
	|| [[ -n "$GOENV_ROOT" && -x "$GOENV_ROOT/bin/goenv" ]] \
	|| [[ -x "$HOME/.goenv/bin/goenv" ]] \
	|| return 0

# Set GOENV_ROOT, if not already set
export GOENV_ROOT="${GOENV_ROOT:-$HOME/.goenv}"

# Add GOENV_ROOT/bin to PATH, if that's where it's installed
if ! _command_exists goenv && [[ -x "$GOENV_ROOT/bin/goenv" ]]; then
	pathmunge "$GOENV_ROOT/bin"
fi

# Initialize goenv
eval "$(goenv init - bash)"

# If moving to a directory with a goenv version set, reload the shell
# to ensure the shell environment matches expectations.
_bash-it-goenv-preexec() {
	export GOENV_OLD_VERSION="$(goenv version-name)"
}
_bash-it-goenv-precmd() {
	if [[ -n $GOENV_OLD_VERSION ]] && [[ "$GOENV_OLD_VERSION" != "$(goenv version-name)" ]]; then
		exec env -u PATH -u GOROOT -u GOPATH -u GOENV_OLD_VERSION "${0/-/}" --login
	fi
	unset GOENV_OLD_VERSION
}
cite about-plugin
about-plugin 'alias "shttp" to SimpleHTTPServer'

if [ $(uname) = "Linux" ]
then
  alias shttp='python2 -m SimpleHTTPServer'
else
  alias shttp='python -m SimpleHTTPServer'
fi

function pyedit() {
    about 'opens python module in your EDITOR'
    param '1: python module to open'
    example '$ pyedit requests'
    group 'python'

    xpyc=`python -c "import os, sys; f = open(os.devnull, 'w'); sys.stderr = f; module = __import__('$1'); sys.stdout.write(module.__file__)"`

    if [ "$xpyc" == "" ]; then
        echo "Python module $1 not found"
        return -1

    elif [[ $xpyc == *__init__.py* ]]; then
        xpydir=`dirname $xpyc`;
        echo "$EDITOR $xpydir";
        $EDITOR "$xpydir";
    else
        echo "$EDITOR ${xpyc%.*}.py";
        $EDITOR "${xpyc%.*}.py";
    fi
cite about-plugin
about-plugin 'load fasd, if you are using it'

_command_exists fasd || return

# shellcheck shell=bash
cite about-plugin
about-plugin 'initializes basher, the shell package manager'

# https://github.com/basherpm/basher

if ! _command_exists basher; then
	if [[ -x "$HOME/.basher/bin/basher" ]]; then
		pathmunge "$HOME/.basher/bin"
	else
		_log_warning 'basher not found'
		return 0
	fi
fi

cite about-plugin
about-plugin 'Autojump configuration, see https://github.com/wting/autojump for more details'

# Only supports the Homebrew variant, Debian and Arch at the moment.
# Feel free to provide a PR to support other install locations
if command -v brew &>/dev/null && [[ -s $(brew --prefix)/etc/profile.d/autojump.sh ]]; then
  . $(brew --prefix)/etc/profile.d/autojump.sh
elif command -v dpkg &>/dev/null && dpkg -s autojump &>/dev/null ; then
  . "$(dpkg-query -S autojump.sh | cut -d' ' -f2)"
elif command -v pacman &>/dev/null && pacman -Q autojump &>/dev/null ; then
cite about-plugin
about-plugin 'OS X Time Machine functions'

function time-machine-destination() {
  group "osx-timemachine"
  about "Shows the OS X Time Machine destination/mount point"

  echo $(tmutil destinationinfo | grep "Mount Point" | sed -e 's/Mount Point   : \(.*\)/\1/g')
}

function time-machine-list-machines() {
  group "osx-timemachine"
  about "Lists the OS X Time Machine machines on the backup volume"

  local tmdest="$(time-machine-destination)/Backups.backupdb"

  find "$tmdest" -maxdepth 1 -mindepth 1 -type d | grep -v "/\." | while read line ; do
    echo "$(basename "$line")"
  done
}

function time-machine-list-all-backups() {
  group "osx-timemachine"
  about "Shows all of the backups for the specified machine"
  param "1: Machine name (optional)"
  example "time-machine-list-all-backups my-laptop"

  # Use the local hostname if none provided
  local COMPUTERNAME=${1:-$(scutil --get ComputerName)}
  local BACKUP_LOCATION="$(time-machine-destination)/Backups.backupdb/$COMPUTERNAME"

  find "$BACKUP_LOCATION" -maxdepth 1 -mindepth 1 -type d | while read line ; do
    echo "$line"
  done
}

function time-machine-list-old-backups() {
  group "osx-timemachine"
  about "Shows all of the backups for the specified machine, except for the most recent backup"
  param "1: Machine name (optional)"
  example "time-machine-list-old-backups my-laptop"

  # Use the local hostname if none provided
  local COMPUTERNAME=${1:-$(scutil --get ComputerName)}
  local BACKUP_LOCATION="$(time-machine-destination)/Backups.backupdb/$COMPUTERNAME"

  # List all but the most recent one
  find "$BACKUP_LOCATION" -maxdepth 1 -mindepth 1 -type d -name 2\* | sed \$d | while read line ; do
    echo "$line"
  done
}

# Taken from here: http://stackoverflow.com/a/30547074/1228454
function _tm_startsudo() {
    sudo -v
    ( while true; do sudo -v; sleep 50; done; ) &
    SUDO_PID="$!"
    trap _tm_stopsudo SIGINT SIGTERM
}
function _tm_stopsudo() {
    kill "$SUDO_PID"
    trap - SIGINT SIGTERM
    sudo -k
}

function time-machine-delete-old-backups() {
  group "osx-timemachine"
  about "Deletes all of the backups for the specified machine, with the exception of the most recent one"
  param "1: Machine name (optional)"
  example "time-machine-delete-old-backups my-laptop"

  # Use the local hostname if none provided
  local COMPUTERNAME=${1:-$(scutil --get ComputerName)}

  # Ask for sudo credentials only once
  _tm_startsudo

  echo "$(time-machine-list-old-backups "$COMPUTERNAME")" | while read i ; do
    # Delete the backup
    sudo tmutil delete "$i"
cite about-plugin
about-plugin 'one command to extract them all...'

# extract file(s) from compressed status
extract() {
    local opt
    local OPTIND=1
    while getopts "hv" opt; do
        case "$opt" in
            h)
                cat <<End-Of-Usage
Usage: ${FUNCNAME[0]} [option] <archives>
    options:
        -h  show this message and exit
        -v  verbosely list files processed
End-Of-Usage
                return
                ;;
            v)
                local -r verbose='v'
                ;;
            ?)
                extract -h >&2
                return 1
                ;;
        esac
    done
    shift $((OPTIND-1))

    [ $# -eq 0 ] && extract -h && return 1
    while [ $# -gt 0 ]; do
        if [[ ! -f "$1" ]]; then
            echo "extract: '$1' is not a valid file" >&2
            shift
            continue
        fi

        local -r filename=$(basename -- $1)
        local -r filedirname=$(dirname -- $1)
        local targetdirname=$(sed 's/\(\.tar\.bz2$\|\.tbz$\|\.tbz2$\|\.tar\.gz$\|\.tgz$\|\.tar$\|\.tar\.xz$\|\.txz$\|\.tar\.Z$\|\.7z$\)//g' <<< $filename)
        if [ "$filename" = "$targetdirname" ]; then
            # archive type either not supported or it doesn't need dir creation
            targetdirname=""
        else
            mkdir -v "$filedirname/$targetdirname"
        fi

        if [ -f "$1" ]; then
            case "$1" in
                *.tar.bz2|*.tbz|*.tbz2) tar "x${verbose}jf" "$1" -C "$filedirname/$targetdirname" ;;
                *.tar.gz|*.tgz) tar "x${verbose}zf" "$1" -C "$filedirname/$targetdirname" ;;
                *.tar.xz|*.txz) tar "x${verbose}Jf" "$1" -C "$filedirname/$targetdirname" ;;
                *.tar.Z) tar "x${verbose}Zf" "$1" -C "$filedirname/$targetdirname" ;;
                *.bz2) bunzip2 "$1" ;;
                *.deb) dpkg-deb -x${verbose} "$1" "${1:0:-4}" ;;
                *.pax.gz) gunzip "$1"; set -- "$@" "${1:0:-3}" ;;
                *.gz) gunzip "$1" ;;
                *.pax) pax -r -f "$1" ;;
                *.pkg) pkgutil --expand "$1" "${1:0:-4}" ;;
                *.rar) unrar x "$1" ;;
                *.rpm) rpm2cpio "$1" | cpio -idm${verbose} ;;
                *.tar) tar "x${verbose}f" "$1" -C "$filedirname/$targetdirname" ;;
                *.xz) xz --decompress "$1" ;;
                *.zip|*.war|*.jar) unzip "$1" ;;
                *.Z) uncompress "$1" ;;
                *.7z) 7za x "$1" ;;
                *) echo "'$1' cannot be extracted via extract" >&2;;
            esac
        fi

cite about-plugin
about-plugin 'colorize man pages for better readability'

export LESS_TERMCAP_mb=$'\e[1;32m'
export LESS_TERMCAP_md=$'\e[1;32m'
#!/bin/bash
#

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Copyright (c) 2014 Docker, Inc

# bash completion for docker-compose
#
# This work is based on the completion for the docker command.
#
# This script provides completion of:
#  - commands and their options
#  - service names
#  - filepaths
#
# To enable the completions either:
#  - place this file in /etc/bash_completion.d
#  or
#  - copy this file to e.g. ~/.docker-compose-completion.sh and add the line
#    below to your .bashrc after bash completion features are loaded
#    . ~/.docker-compose-completion.sh

__docker_compose_previous_extglob_setting=$(shopt -p extglob)
shopt -s extglob

__docker_compose_q() {
	docker-compose 2>/dev/null "${top_level_options[@]}" "$@"
}

# Transforms a multiline list of strings into a single line string
# with the words separated by "|".
__docker_compose_to_alternatives() {
	local parts=( $1 )
	local IFS='|'
	echo "${parts[*]}"
}

# Transforms a multiline list of options into an extglob pattern
# suitable for use in case statements.
__docker_compose_to_extglob() {
	local extglob=$( __docker_compose_to_alternatives "$1" )
	echo "@($extglob)"
}

# Determines whether the option passed as the first argument exist on
# the commandline. The option may be a pattern, e.g. `--force|-f`.
__docker_compose_has_option() {
	local pattern="$1"
	for (( i=2; i < $cword; ++i)); do
		if [[ ${words[$i]} =~ ^($pattern)$ ]] ; then
			return 0
		fi
	done
	return 1
}

# Returns `key` if we are currently completing the value of a map option (`key=value`)
# which matches the extglob passed in as an argument.
# This function is needed for key-specific completions.
__docker_compose_map_key_of_current_option() {
        local glob="$1"

        local key glob_pos
        if [ "$cur" = "=" ] ; then        # key= case
                key="$prev"
                glob_pos=$((cword - 2))
        elif [[ $cur == *=* ]] ; then     # key=value case (OSX)
                key=${cur%=*}
                glob_pos=$((cword - 1))
        elif [ "$prev" = "=" ] ; then
                key=${words[$cword - 2]}  # key=value case
                glob_pos=$((cword - 3))
        else
                return
        fi

        [ "${words[$glob_pos]}" = "=" ] && ((glob_pos--))  # --option=key=value syntax

        [[ ${words[$glob_pos]} == @($glob) ]] && echo "$key"
}

# suppress trailing whitespace
__docker_compose_nospace() {
	# compopt is not available in ancient bash versions
	type compopt &>/dev/null && compopt -o nospace
}


# Outputs a list of all defined services, regardless of their running state.
# Arguments for `docker-compose ps` may be passed in order to filter the service list,
# e.g. `status=running`.
__docker_compose_services() {
	__docker_compose_q ps --services "$@"
}

# Applies completion of services based on the current value of `$cur`.
# Arguments for `docker-compose ps` may be passed in order to filter the service list,
# see `__docker_compose_services`.
__docker_compose_complete_services() {
	COMPREPLY=( $(compgen -W "$(__docker_compose_services "$@")" -- "$cur") )
}

# The services for which at least one running container exists
__docker_compose_complete_running_services() {
	local names=$(__docker_compose_services --filter status=running)
	COMPREPLY=( $(compgen -W "$names" -- "$cur") )
}


_docker_compose_build() {
	case "$prev" in
		--build-arg)
			COMPREPLY=( $( compgen -e -- "$cur" ) )
			__docker_compose_nospace
			return
			;;
		--memory|-m)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--build-arg --compress --force-rm --help --memory -m --no-cache --no-rm --pull --parallel -q --quiet" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services --filter source=build
			;;
	esac
}


_docker_compose_bundle() {
	case "$prev" in
		--output|-o)
			_filedir
			return
			;;
	esac

	COMPREPLY=( $( compgen -W "--push-images --help --output -o" -- "$cur" ) )
}


_docker_compose_config() {
	case "$prev" in
		--hash)
			if [[ $cur == \\* ]] ; then
				COMPREPLY=( '\*' )
			else
				COMPREPLY=( $(compgen -W "$(__docker_compose_services) \\\* " -- "$cur") )
			fi
			return
			;;
	esac

	COMPREPLY=( $( compgen -W "--hash --help --quiet -q --resolve-image-digests --services --volumes" -- "$cur" ) )
}


_docker_compose_create() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--build --force-recreate --help --no-build --no-recreate" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_docker_compose() {
	case "$prev" in
		--tlscacert|--tlscert|--tlskey)
			_filedir
			return
			;;
		--file|-f)
			_filedir "y?(a)ml"
			return
			;;
		--log-level)
			COMPREPLY=( $( compgen -W "debug info warning error critical" -- "$cur" ) )
			return
			;;
		--project-directory)
			_filedir -d
			return
			;;
		$(__docker_compose_to_extglob "$daemon_options_with_args") )
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "$daemon_boolean_options $daemon_options_with_args $top_level_options_with_args --help -h --no-ansi --verbose --version -v" -- "$cur" ) )
			;;
		*)
			COMPREPLY=( $( compgen -W "${commands[*]}" -- "$cur" ) )
			;;
	esac
}


_docker_compose_down() {
	case "$prev" in
		--rmi)
			COMPREPLY=( $( compgen -W "all local" -- "$cur" ) )
			return
			;;
		--timeout|-t)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --rmi --timeout -t --volumes -v --remove-orphans" -- "$cur" ) )
			;;
	esac
}


_docker_compose_events() {
	case "$prev" in
		--json)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --json" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_exec() {
	case "$prev" in
		--index|--user|-u|--workdir|-w)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "-d --detach --help --index --privileged -T --user -u --workdir -w" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_running_services
			;;
	esac
}


_docker_compose_help() {
	COMPREPLY=( $( compgen -W "${commands[*]}" -- "$cur" ) )
}

_docker_compose_images() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --quiet -q" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}

_docker_compose_kill() {
	case "$prev" in
		-s)
			COMPREPLY=( $( compgen -W "SIGHUP SIGINT SIGKILL SIGUSR1 SIGUSR2" -- "$(echo $cur | tr '[:lower:]' '[:upper:]')" ) )
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help -s" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_running_services
			;;
	esac
}


_docker_compose_logs() {
	case "$prev" in
		--tail)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--follow -f --help --no-color --tail --timestamps -t" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_pause() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_running_services
			;;
	esac
}


_docker_compose_port() {
	case "$prev" in
		--protocol)
			COMPREPLY=( $( compgen -W "tcp udp" -- "$cur" ) )
			return;
			;;
		--index)
			return;
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --index --protocol" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_ps() {
	local key=$(__docker_compose_map_key_of_current_option '--filter')
	case "$key" in
		source)
			COMPREPLY=( $( compgen -W "build image" -- "${cur##*=}" ) )
			return
			;;
		status)
			COMPREPLY=( $( compgen -W "paused restarting running stopped" -- "${cur##*=}" ) )
			return
			;;
	esac

	case "$prev" in
		--filter)
			COMPREPLY=( $( compgen -W "source status" -S "=" -- "$cur" ) )
			__docker_compose_nospace
			return;
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--all -a --filter --help --quiet -q --services" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_pull() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --ignore-pull-failures --include-deps --no-parallel --quiet -q" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services --filter source=image
			;;
	esac
}


_docker_compose_push() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --ignore-push-failures" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_restart() {
	case "$prev" in
		--timeout|-t)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --timeout -t" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_running_services
			;;
	esac
}


_docker_compose_rm() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--force -f --help --stop -s -v" -- "$cur" ) )
			;;
		*)
			if __docker_compose_has_option "--stop|-s" ; then
				__docker_compose_complete_services
			else
				__docker_compose_complete_services --filter status=stopped
			fi
			;;
	esac
}


_docker_compose_run() {
	case "$prev" in
		-e)
			COMPREPLY=( $( compgen -e -- "$cur" ) )
			__docker_compose_nospace
			return
			;;
		--entrypoint|--label|-l|--name|--user|-u|--volume|-v|--workdir|-w)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--detach -d --entrypoint -e --help --label -l --name --no-deps --publish -p --rm --service-ports -T --use-aliases --user -u --volume -v --workdir -w" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_scale() {
	case "$prev" in
		=)
			COMPREPLY=("$cur")
			return
			;;
		--timeout|-t)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --timeout -t" -- "$cur" ) )
			;;
		*)
			COMPREPLY=( $(compgen -S "=" -W "$(__docker_compose_services)" -- "$cur") )
			__docker_compose_nospace
			;;
	esac
}


_docker_compose_start() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services --filter status=stopped
			;;
	esac
}


_docker_compose_stop() {
	case "$prev" in
		--timeout|-t)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help --timeout -t" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_running_services
			;;
	esac
}


_docker_compose_top() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_running_services
			;;
	esac
}


_docker_compose_unpause() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--help" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services --filter status=paused
			;;
	esac
}


_docker_compose_up() {
	case "$prev" in
		=)
			COMPREPLY=("$cur")
			return
			;;
		--exit-code-from)
			__docker_compose_complete_services
			return
			;;
		--scale)
			COMPREPLY=( $(compgen -S "=" -W "$(__docker_compose_services)" -- "$cur") )
			__docker_compose_nospace
			return
			;;
		--timeout|-t)
			return
			;;
	esac

	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--abort-on-container-exit --always-recreate-deps --build -d --detach --exit-code-from --force-recreate --help --no-build --no-color --no-deps --no-recreate --no-start --renew-anon-volumes -V --remove-orphans --scale --timeout -t" -- "$cur" ) )
			;;
		*)
			__docker_compose_complete_services
			;;
	esac
}


_docker_compose_version() {
	case "$cur" in
		-*)
			COMPREPLY=( $( compgen -W "--short" -- "$cur" ) )
			;;
	esac
}


_docker_compose() {
	local previous_extglob_setting=$(shopt -p extglob)
	shopt -s extglob

	local commands=(
		build
		bundle
		config
		create
		down
		events
		exec
		help
		images
		kill
		logs
		pause
		port
		ps
		pull
		push
		restart
		rm
		run
		scale
		start
		stop
		top
		unpause
		up
		version
	)

	# Options for the docker daemon that have to be passed to secondary calls to
	# docker-compose executed by this script.
	local daemon_boolean_options="
		--skip-hostname-check
		--tls
		--tlsverify
	"
	local daemon_options_with_args="
		--file -f
		--host -H
		--project-directory
		--project-name -p
		--tlscacert
		--tlscert
		--tlskey
	"

	# These options are require special treatment when searching the command.
	local top_level_options_with_args="
		--log-level
	"

	COMPREPLY=()
	local cur prev words cword
	_get_comp_words_by_ref -n : cur prev words cword

	# search subcommand and invoke its handler.
	# special treatment of some top-level options
	local command='docker_compose'
	local top_level_options=()
	local counter=1

	while [ $counter -lt $cword ]; do
		case "${words[$counter]}" in
			$(__docker_compose_to_extglob "$daemon_boolean_options") )
				local opt=${words[counter]}
				top_level_options+=($opt)
				;;
			$(__docker_compose_to_extglob "$daemon_options_with_args") )
				local opt=${words[counter]}
				local arg=${words[++counter]}
				top_level_options+=($opt $arg)
				;;
			$(__docker_compose_to_extglob "$top_level_options_with_args") )
				(( counter++ ))
				;;
			-*)
				;;
			*)
				command="${words[$counter]}"
				break
				;;
		esac
		(( counter++ ))
	done

	local completions_func=_docker_compose_${command//-/_}
	declare -F $completions_func >/dev/null && $completions_func

	eval "$previous_extglob_setting"
	return 0
}

eval "$__docker_compose_previous_extglob_setting"
# shellcheck shell=bash
cite "about-completion"
about-completion "lerna(javascript project manager tool) completion"

function __lerna_completion() {
	local cur compls

	# The currently-being-completed word.
	cur="${COMP_WORDS[COMP_CWORD]}"

	# Options
	compls="add bootstrap changed clean create diff exec \
	import init link list publish run version    \
	--loglevel --concurrency --reject-cycles    \
	--progress --sort --no-sort --help          \
	--version"

	# Tell complete what stuff to show.
	# shellcheck disable=2207
	COMPREPLY=($(compgen -W "$compls" -- "$cur"))
# shellcheck shell=bash
# cargo (Rust package manager) completion

if _binary_exists rustup && _binary_exists cargo; then
	eval "$(rustup completions bash cargo)"
# shellcheck shell=bash
cite "about-completion"
about-completion "npm (Node Package Manager) completion"

if _command_exists npm; then
# shellcheck shell=bash
cite "about-completion"
about-completion "composer completion"

function __composer_completion() {
	local cur coms opts com
	COMPREPLY=()
	_get_comp_words_by_ref -n : cur words

	# lookup for command
	for word in "${words[@]:1}"; do
		if [[ $word != -* ]]; then
			com=$word
			break
		fi
	done

	# completing for an option
	if [[ ${cur} == --* ]]; then
		opts="--help --quiet --verbose --version --ansi --no-ansi --no-interaction --profile --no-plugins --working-dir"

		case "$com" in
			about)
				opts="${opts} "
				;;
			archive)
				opts="${opts} --format --dir --file"
				;;
			browse)
				opts="${opts} --homepage --show"
				;;
			clear-cache)
				opts="${opts} "
				;;
			config)
				opts="${opts} --global --editor --auth --unset --list --file --absolute"
				;;
			create-project)
				opts="${opts} --stability --prefer-source --prefer-dist --repository --repository-url --dev --no-dev --no-custom-installers --no-scripts --no-progress --no-secure-http --keep-vcs --no-install --ignore-platform-reqs"
				;;
			depends)
				opts="${opts} --recursive --tree"
				;;
			diagnose)
				opts="${opts} "
				;;
			dump-autoload)
				opts="${opts} --no-scripts --optimize --classmap-authoritative --apcu --no-dev"
				;;
			exec)
				opts="${opts} --list"
				;;
			global)
				opts="${opts} "
				;;
			help)
				opts="${opts} --xml --format --raw"
				;;
			init)
				opts="${opts} --name --description --author --type --homepage --require --require-dev --stability --license --repository"
				;;
			install)
				opts="${opts} --prefer-source --prefer-dist --dry-run --dev --no-dev --no-custom-installers --no-autoloader --no-scripts --no-progress --no-suggest --optimize-autoloader --classmap-authoritative --apcu-autoloader --ignore-platform-reqs"
				;;
			licenses)
				opts="${opts} --format --no-dev"
				;;
			list)
				opts="${opts} --xml --raw --format"
				;;
			outdated)
				opts="${opts} --outdated --all --direct --strict"
				;;
			prohibits)
				opts="${opts} --recursive --tree"
				;;
			remove)
				opts="${opts} --dev --no-progress --no-update --no-scripts --update-no-dev --update-with-dependencies --no-update-with-dependencies --ignore-platform-reqs --optimize-autoloader --classmap-authoritative --apcu-autoloader"
				;;
			require)
				opts="${opts} --dev --prefer-source --prefer-dist --no-progress --no-suggest --no-update --no-scripts --update-no-dev --update-with-dependencies --ignore-platform-reqs --prefer-stable --prefer-lowest --sort-packages --optimize-autoloader --classmap-authoritative --apcu-autoloader"
				;;
			run-script)
				opts="${opts} --timeout --dev --no-dev --list"
				;;
			search)
				opts="${opts} --only-name --type"
				;;
			self-update)
				opts="${opts} --rollback --clean-backups --no-progress --update-keys --stable --preview --snapshot"
				;;
			show)
				opts="${opts} --all --installed --platform --available --self --name-only --path --tree --latest --outdated --minor-only --direct --strict"
				;;
			status)
				opts="${opts} "
				;;
			suggests)
				opts="${opts} --by-package --by-suggestion --no-dev"
				;;
			update)
				opts="${opts} --prefer-source --prefer-dist --dry-run --dev --no-dev --lock --no-custom-installers --no-autoloader --no-scripts --no-progress --no-suggest --with-dependencies --optimize-autoloader --classmap-authoritative --apcu-autoloader --ignore-platform-reqs --prefer-stable --prefer-lowest --interactive --root-reqs"
				;;
			validate)
				opts="${opts} --no-check-all --no-check-lock --no-check-publish --with-dependencies --strict"
				;;

		esac

		# shellcheck disable=SC2207
		COMPREPLY=($(compgen -W "${opts}" -- "${cur}"))
		__ltrim_colon_completions "$cur"

		return 0
	fi

	# completing for a command
	if [[ "$cur" == "$com" ]]; then
		coms="about archive browse clear-cache config create-project depends diagnose dump-autoload exec global help init install licenses list outdated prohibits remove require run-script search self-update show status suggests update validate"

		# shellcheck disable=SC2207
		COMPREPLY=($(compgen -W "${coms}" -- "${cur}"))
		__ltrim_colon_completions "$cur"

		return 0
# Copyright (c) 2017 Eric Wendelin

# Permission is hereby granted, free of charge, to any person obtaining a copy of
# this software and associated documentation files (the "Software"), to deal in
# the Software without restriction, including without limitation the rights to
# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
# of the Software, and to permit persons to whom the Software is furnished to do
# so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Bash breaks words on : by default. Subproject tasks have ':'
# Avoid inaccurate completions for subproject tasks
COMP_WORDBREAKS=$(echo "$COMP_WORDBREAKS" | sed -e 's/://g')

__gradle-set-project-root-dir() {
    local dir=`pwd`
    project_root_dir=`pwd`
    while [[ $dir != '/' ]]; do
        if [[ -f "$dir/settings.gradle" || -f "$dir/gradlew" ]]; then
            project_root_dir=$dir
            return 0
        fi
        dir="$(dirname "$dir")"
    done
    return 1
}

__gradle-init-cache-dir() {
    cache_dir="$HOME/.gradle/completion"
    mkdir -p $cache_dir
}

__gradle-set-build-file() {
    # Look for default build script in the settings file (settings.gradle by default)
    # Otherwise, default is the file 'build.gradle' in the current directory.
    gradle_build_file="$project_root_dir/build.gradle"
    if [[ -f "$project_root_dir/settings.gradle" ]]; then
        local build_file_name=$(grep "^rootProject\.buildFileName" "$project_root_dir/settings.gradle" | \
            sed -n -e "s/rootProject\.buildFileName = [\'\"]\(.*\)[\'\"]/\1/p")
        gradle_build_file="$project_root_dir/${build_file_name:-build.gradle}"
    fi
}

__gradle-set-cache-name() {
    # Cache name is constructed from the absolute path of the build file.
    cache_name=$(echo $gradle_build_file | sed -e 's/\//_/g')
}

__gradle-set-files-checksum() {
    # Cache MD5 sum of all Gradle scripts and modified timestamps
    if builtin command -v md5 > /dev/null; then
        gradle_files_checksum=$(md5 -q -s "$(cat "$cache_dir/$cache_name" | xargs ls -o 2>/dev/null)")
    elif builtin command -v md5sum > /dev/null; then
        gradle_files_checksum=$(cat "$cache_dir/$cache_name" | xargs ls -o 2>/dev/null | md5sum | awk '{print $1}')
    else
        echo "Cannot generate completions as neither md5 nor md5sum exist on \$PATH"
    fi
}

__gradle-generate-script-cache() {
    # Invalidate cache after 3 weeks by default
    local cache_ttl_mins=${GRADLE_CACHE_TTL_MINUTES:-30240}
    local script_exclude_pattern=${GRADLE_COMPLETION_EXCLUDE_PATTERN:-"/(build|integTest|out)/"}

    if [[ ! $(find $cache_dir/$cache_name -mmin -$cache_ttl_mins 2>/dev/null) ]]; then
        # Cache all Gradle scripts
        local gradle_build_scripts=$(find $project_root_dir -type f -name "*.gradle" -o -name "*.gradle.kts" 2>/dev/null | egrep -v "$script_exclude_pattern")
        printf "%s\n" "${gradle_build_scripts[@]}" > $cache_dir/$cache_name
    fi
}

__gradle-long-options() {
    local args="--build-cache           - Enables the Gradle build cache
--build-file            - Specifies the build file
--configure-on-demand   - Only relevant projects are configured
--console               - Type of console output to generate (plain auto rich)
--continue              - Continues task execution after a task failure
--continuous            - Continuous mode. Automatically re-run build after changes
--daemon                - Use the Gradle Daemon
--debug                 - Log at the debug level
--dry-run               - Runs the build with all task actions disabled
--exclude-task          - Specify a task to be excluded
--full-stacktrace       - Print out the full (very verbose) stacktrace
--gradle-user-home      - Specifies the Gradle user home directory
--gui                   - Launches the Gradle GUI app (Deprecated)
--help                  - Shows a help message
--include-build         - Run the build as a composite, including the specified build
--info                  - Set log level to INFO
--init-script           - Specifies an initialization script
--max-workers           - Set the maximum number of workers that Gradle may use
--no-build-cache        - Do not use the Gradle build cache
--no-daemon             - Do not use the Gradle Daemon
--no-rebuild            - Do not rebuild project dependencies
--no-scan               - Do not create a build scan
--no-search-upwards     - Do not search in parent directories for a settings.gradle
--offline               - Build without accessing network resources
--parallel              - Build projects in parallel
--profile               - Profile build time and create report
--project-cache-dir     - Specifies the project-specific cache directory
--project-dir           - Specifies the start directory for Gradle
--project-prop          - Sets a project property of the root project
--quiet                 - Log errors only
--recompile-scripts     - Forces scripts to be recompiled, bypassing caching
--refresh-dependencies  - Refresh the state of dependencies
--rerun-tasks           - Specifies that any task optimization is ignored
--scan                  - Create a build scan
--settings-file         - Specifies the settings file
--stacktrace            - Print out the stacktrace also for user exceptions
--status                - Print Gradle Daemon status
--stop                  - Stop all Gradle Daemons
--system-prop           - Set a system property
--version               - Prints Gradle version info
--warn                  - Log warnings and errors only"
    COMPREPLY=( $(compgen -W "$args" -- "${COMP_WORDS[COMP_CWORD]}") )
}

__gradle-properties() {
    local args="-Dorg.gradle.cache.reserved.mb=   - Reserve Gradle Daemon memory for operations
-Dorg.gradle.caching=             - Set true to enable Gradle build cache
-Dorg.gradle.daemon.debug=        - Set true to debug Gradle Daemon
-Dorg.gradle.daemon.idletimeout=  - Kill Gradle Daemon after # idle millis
-Dorg.gradle.debug=               - Set true to debug Gradle Client
-Dorg.gradle.jvmargs=             - Set JVM arguments
-Dorg.gradle.java.home=           - Set JDK home dir
-Dorg.gradle.logging.level=       - Set default Gradle log level (quiet warn lifecycle info debug)
-Dorg.gradle.parallel=            - Set true to enable parallel project builds (incubating)
-Dorg.gradle.parallel.intra=      - Set true to enable intra-project parallel builds (incubating)
-Dorg.gradle.workers.max=         - Set the number of workers Gradle is allowed to use"
    COMPREPLY=( $(compgen -W "$args" -- "${COMP_WORDS[COMP_CWORD]}") )
    return 0
}

__gradle-short-options() {
    local args="-?                      - Shows a help message
-a                      - Do not rebuild project dependencies
-b                      - Specifies the build file
-c                      - Specifies the settings file
-d                      - Log at the debug level
-g                      - Specifies the Gradle user home directory
-h                      - Shows a help message
-i                      - Set log level to INFO
-m                      - Runs the build with all task actions disabled
-p                      - Specifies the start directory for Gradle
-q                      - Log errors only
-s                      - Print out the stacktrace also for user exceptions
-t                      - Continuous mode. Automatically re-run build after changes
-u                      - Do not search in parent directories for a settings.gradle
-v                      - Prints Gradle version info
-w                      - Log warnings and errors only
-x                      - Specify a task to be excluded
-D                      - Set a system property
-I                      - Specifies an initialization script
-P                      - Sets a project property of the root project
-S                      - Print out the full (very verbose) stacktrace"
    COMPREPLY=( $(compgen -W "$args" -- "${COMP_WORDS[COMP_CWORD]}") )
}

__gradle-notify-tasks-cache-build() {
    # Notify user of cache rebuild
    echo -e " (Building completion cache. Please wait)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\c"
    __gradle-generate-tasks-cache
    # Remove "please wait" message by writing a bunch of spaces then moving back to the left
    echo -e "                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\c"
}

__gradle-generate-tasks-cache() {
    __gradle-set-files-checksum

    # Use Gradle wrapper when it exists.
    local gradle_cmd="gradle"
    if [[ -x "$project_root_dir/gradlew" ]]; then
        gradle_cmd="$project_root_dir/gradlew"
    fi

    # Run gradle to retrieve possible tasks and cache.
    # Reuse Gradle Daemon if IDLE but don't start a new one.
    local gradle_tasks_output
    if [[ ! -z "$($gradle_cmd --status 2>/dev/null | grep IDLE)" ]]; then
        gradle_tasks_output="$($gradle_cmd -b $gradle_build_file --daemon -q tasks --all)"
    else
        gradle_tasks_output="$($gradle_cmd -b $gradle_build_file --no-daemon -q tasks --all)"
    fi
    local output_line
    local task_description
    local -a gradle_all_tasks=()
    local -a root_tasks=()
    local -a subproject_tasks=()
    for output_line in $gradle_tasks_output; do
        if [[ $output_line =~ ^([[:lower:]][[:alnum:][:punct:]]*)([[:space:]]-[[:space:]]([[:print:]]*))? ]]; then
            task_name="${BASH_REMATCH[1]}"
            task_description="${BASH_REMATCH[3]}"
            gradle_all_tasks+=( "$task_name  - $task_description" )
            # Completion for subproject tasks with ':' prefix
            if [[ $task_name =~ ^([[:alnum:][:punct:]]+):([[:alnum:]]+) ]]; then
                gradle_all_tasks+=( ":$task_name  - $task_description" )
                subproject_tasks+=( "${BASH_REMATCH[2]}" )
            else
                root_tasks+=( "$task_name" )
            fi
        fi
    done

    # subproject tasks can be referenced implicitly from root project
    if [[ $GRADLE_COMPLETION_UNQUALIFIED_TASKS == "true" ]]; then
        local -a implicit_tasks=()
        implicit_tasks=( $(comm -23 <(printf "%s\n" "${subproject_tasks[@]}" | sort) <(printf "%s\n" "${root_tasks[@]}" | sort)) )
        for task in $(printf "%s\n" "${implicit_tasks[@]}"); do
            gradle_all_tasks+=( $task )
        done
    fi

    printf "%s\n" "${gradle_all_tasks[@]}" > $cache_dir/$gradle_files_checksum
    echo $gradle_files_checksum > $cache_dir/$cache_name.md5
}

__gradle-completion-init() {
    local cache_dir cache_name gradle_build_file gradle_files_checksum project_root_dir

    local OLDIFS="$IFS"
    local IFS=$'\n'

    __gradle-init-cache-dir
    __gradle-set-project-root-dir
    __gradle-set-build-file
    if [[ -f $gradle_build_file ]]; then
        __gradle-set-cache-name
        __gradle-generate-script-cache
        __gradle-set-files-checksum
        __gradle-notify-tasks-cache-build
    fi

    IFS="$OLDIFS"

    return 0
}

_gradle() {
    local cache_dir cache_name gradle_build_file gradle_files_checksum project_root_dir
    local cur=${COMP_WORDS[COMP_CWORD]}
    # Set bash internal field separator to '\n'
    # This allows us to provide descriptions for options and tasks
    local OLDIFS="$IFS"
    local IFS=$'\n'

    if [[ ${cur} == --* ]]; then
        __gradle-long-options
    elif [[ ${cur} == -D* ]]; then
        __gradle-properties
    elif [[ ${cur} == -* ]]; then
        __gradle-short-options
    else
        __gradle-init-cache-dir
        __gradle-set-project-root-dir
        __gradle-set-build-file
        if [[ -f $gradle_build_file ]]; then
            __gradle-set-cache-name
            __gradle-generate-script-cache
            __gradle-set-files-checksum

            # The cache key is md5 sum of all gradle scripts, so it's valid if it exists.
            if [[ -f $cache_dir/$cache_name.md5 ]]; then
                local cached_checksum="$(cat $cache_dir/$cache_name.md5)"
                local -a cached_tasks
                if [[ -z $cur ]]; then
                    cached_tasks=( $(cat $cache_dir/$cached_checksum) )
                else
                    cached_tasks=( $(grep "^$cur" $cache_dir/$cached_checksum) )
                fi
                COMPREPLY=( $(compgen -W "${cached_tasks[*]}" -- "$cur") )
            else
                __gradle-notify-tasks-cache-build
            fi

            # Regenerate tasks cache in the background
            if [[ $gradle_files_checksum != "$(cat $cache_dir/$cache_name.md5)" || ! -f $cache_dir/$gradle_files_checksum ]]; then
                $(__gradle-generate-tasks-cache 1>&2 2>/dev/null &)
            fi
        else
            # Default tasks available outside Gradle projects
            local args="buildEnvironment     - Displays all buildscript dependencies declared in root project.
components           - Displays the components produced by root project.
dependencies         - Displays all dependencies declared in root project.
dependencyInsight    - Displays the insight into a specific dependency in root project.
dependentComponents  - Displays the dependent components of components in root project.
help                 - Displays a help message.
init                 - Initializes a new Gradle build.
model                - Displays the configuration model of root project.
projects             - Displays the sub-projects of root project.
properties           - Displays the properties of root project.
tasks                - Displays the tasks runnable from root project.
wrapper              - Generates Gradle wrapper files."
            COMPREPLY=( $(compgen -W "$args" -- "${COMP_WORDS[COMP_CWORD]}") )
        fi
    fi

    IFS="$OLDIFS"

    # Remove description ("[:space:]" and after) if only one possibility
    if [[ ${#COMPREPLY[*]} -eq 1 ]]; then
        COMPREPLY=( ${COMPREPLY[0]%%  *} )
    fi

    return 0
}
complete -F _gradle gradle
complete -F _gradle gradle.bat
complete -F _gradle gradlew
complete -F _gradle gradlew.bat
complete -F _gradle ./gradlew
complete -F _gradle ./gradlew.bat
# shellcheck shell=bash
# pipx completion

if _command_exists register-python-argcomplete && _command_exists pipx; then
	eval "$(register-python-argcomplete pipx)"
#! bash
# bash completion for the `bundle` command.
#
# Copyright (c) 2008 Daniel Luz

# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without
# restriction, including without limitation the rights to use,
# copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following
# conditions:

# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
# OTHER DEALINGS IN THE SOFTWARE.
#
# To use, source this file on bash:
#   . completion-bundle

__bundle() {
    local bundle_bin=("${_RUBY_COMMAND_PREFIX[@]}" "$1")
    local cur prev
    _get_comp_words_by_ref -n : cur prev
    local bundle_command
    local bundle_command_index
    __bundle_get_command
    COMPREPLY=()

    local options
    if [[ $cur = -* && $bundle_command != exec ]]; then
        options="-V --help --no-color --no-no-color --verbose --no-verbose"
        case $bundle_command in
        "")
            options="$options --version";;
        check)
            options="$options --dry-run --gemfile --path -r --retry";;
        clean)
            options="$options --dry-run --force";;
        config)
            options="$options --local --global --delete";;
        doctor)
            options="$options --gemfile --quiet --no-quiet";;
        gem)
            options="$options -b -e -t --bin --coc --no-coc --edit --exe
                     --no-exe --ext --no-ext --mit --no-mit --test";;
        init)
            options="$options --gemspec";;
        install)
            options="$options --binstubs --clean --deployment --force --frozen
                     --full-index --gemfile --jobs --local --no-cache
                     --no-prune --path --quiet --retry --shebang --standalone
                     --system --trust-policy --with --without";;
        lock)
            options="$options --add-platform --conservative --full-index
                     --local --lockfile --major --minor --patch --print
                     --remove-platform --strict --update";;
        package)
            options="$options --all --all-platforms";;
        platform)
            options="$options --ruby";;
        show)
            options="$options --outdated --paths --no-paths";;
        update)
            options="$options --bundler --conservative --force --full-index
                     --group --jobs --local --major --minor --patch --quiet
                     --ruby --source --strict";;
        viz)
            options="$options -f -F -R -v -W --file --format --requirements
                     --no-requirements --version --no-version --without";;
        esac
    else
        case $bundle_command in
        "" | help)
            options="help install update package exec config
                     check show outdated console open lock viz init gem
                     platform clean doctor"
            ;;
        check | install)
            case $prev in
            --binstubs | --path)
                _filedir -d
                return;;
            --standalone | --with | --without)
                __bundle_complete_groups
                return;;
            --trust-policy)
                options="HighSecurity MediumSecurity LowSecurity
                         AlmostNoSecurity NoSecurity";;
            esac
            ;;
        config)
            case $prev in
            config | --*)
                case $cur in
                local.*)
                    options=($(__bundle_exec_ruby 'puts Bundler.definition.specs.to_hash.keys'))
                    options=("${options[*]/#/local.}")
                    ;;
                *)
                    options=(path frozen without bin gemfile ssl_ca_cert
                             ssl_client_cert cache_path disable_multisource
                             ignore_messages retry redirect timeout
                             force_ruby_platform specific_platform
                             disable_checksum_validation disable_version_check
                             allow_offline_install auto_install
                             cache_all_platforms cache_all clean console
                             disable_exec_load disable_local_branch_check
                             disable_shared_gems jobs major_deprecations
                             no_install no_prune only_update_to_newer_versions
                             plugins shebang silence_root_warning
                             ssl_verify_mode system_bindir user_agent)
                    # We want to suggest the options above as complete words,
                    # and also "local." and "mirror." as prefixes
                    # To achieve that, disable automatic space insertion,
                    # insert it manually, then add the non-spaced prefixes
                    compopt -o nospace
                    options=("${options[@]/%/ }")
                    # And add prefix suggestions
                    options+=(local. mirror.)
                    # Override $IFS for completion to work
                    local IFS=$'\n'
                    COMPREPLY=($(compgen -W '${options[@]}' -- "$cur"))
                    return
                    ;;
                esac
                ;;
            path | local.*)
                _filedir -d
                return;;
            esac
            ;;
        exec)
            if [[ $COMP_CWORD -eq $bundle_command_index ]]; then
                # Figure out Bundler's binaries dir
                local bundler_bin=$(__bundle_exec_ruby 'puts Bundler.bundle_path + "bin"')
                if [[ -d $bundler_bin ]]; then
                    local binaries=("$bundler_bin"/*)
                    # If there are binaries, strip directory name and use them
                    [[ -f "$binaries" ]] && options="${binaries[@]##*/}"
                else
                    # No binaries found; use full command completion
                    COMPREPLY=($(compgen -c -- "$cur"))
                    return
                fi
            else
                local _RUBY_COMMAND_PREFIX=("${bundle_bin[@]}" exec)
                _command_offset $bundle_command_index
                return
            fi
            ;;
        gem)
            case $prev in
            -e | --edit)
                COMPREPLY=($(compgen -c -- "$cur"))
                return;;
            -t | --test)
                options="minitest rspec";;
            esac
            ;;
        update)
            case $prev in
            --group)
                __bundle_complete_groups
                return;;
            *)
                options=($(__bundle_exec_ruby 'puts Bundler.definition.specs.to_hash.keys'))
            esac
            ;;
        viz)
            case $prev in
            -F | --format)
                options="dot jpg png svg";;
            -W | --without)
                __bundle_complete_groups
                return;;
            esac
            ;;
        esac
    fi
    COMPREPLY=($(compgen -W "${options[*]}" -- "$cur"))
}

__bundle_get_command() {
    local i
    for ((i=1; i < $COMP_CWORD; ++i)); do
        local arg=${COMP_WORDS[$i]}

        case $arg in
        [^-]*)
            bundle_command=$arg
            bundle_command_index=$((i + 1))
            return;;
        --version)
            # Command-killer
            bundle_command=-
            return;;
        --help)
            bundle_command=help
            bundle_command_index=$((i + 1))
            return;;
        esac
    done
}

# Provides completion for Bundler group names.
#
# Multiple groups can be entered, separated either by spaces or by colons.
# Input is read from $cur, and the result is directly written to $COMPREPLY.
__bundle_complete_groups() {
    # Group being currently written
    local cur_group=${cur##*[ :]}
    # All groups written before
    local prefix=${cur%"$cur_group"}
    local groups=$(__bundle_exec_ruby 'puts Bundler.definition.dependencies.map(&:groups).reduce(:|).map(&:to_s)')
    if [[ ! $groups ]]; then
        COMPREPLY=()
        return
    fi
    # Duplicate "default" and anything already in $prefix, so that `uniq`
    # strips it; groups may be separated by ':', ' ', or '\ '
    local excluded=$'\ndefault\n'${prefix//[: \'\"\\]/$'\n'}
    # Include them twice to ensure they are duplicates
    groups=$groups$excluded$excluded
    COMPREPLY=($(compgen -W "$(sort <<<"$groups" | uniq -u)" -- "$cur_group"))
    # Prepend prefix to all entries
    COMPREPLY=("${COMPREPLY[@]/#/$prefix}")
    __ltrim_colon_completions "$cur"
}

# __bundle_exec_ruby <script> [args...]
#
# Runs a Ruby script with Bundler loaded.
# Results may be cached.
__bundle_exec_ruby() {
    local bundle_bin=(${bundle_bin[@]:-bundle})
    # Lockfile is inferred here, and might not be correct (for example, when
    # running on a subdirectory). However, a wrong file path won't be a
    # cadastrophic mistake; it just means the cache won't be invalidated when
    # the local gem list changes (but will still invalidate if the command is
    # run on another directory)
    local lockfile=$PWD/Gemfile.lock
    local cachedir=${XDG_CACHE_HOME:-~/.cache}/completion-ruby
    local cachefile=$cachedir/bundle--exec-ruby
    # A representation of all arguments with newlines replaced by spaces,
    # to fit in a single line as a cache identifier
    local cache_id_line="${bundle_bin[*]} @ $lockfile: ${*//$'\n'/ }"

    if [[ (! -f $lockfile || $cachefile -nt $lockfile) &&
          $(head -n 1 -- "$cachefile" 2>/dev/null) = "$cache_id_line" ]]; then
        tail -n +2 -- "$cachefile"
    else
        local output=$("${bundle_bin[@]}" exec ruby -e "$@" 2>/dev/null)
        if [[ $? -eq 0 ]]; then
            (mkdir -p -- "$cachedir" &&
             echo "$cache_id_line"$'\n'"$output" >$cachefile) 2>/dev/null
            echo "$output"
        fi
    fi
}

if _command_exists ng; then
  # No longer supported, please see https://github.com/angular/angular-cli/issues/11043
  # Fix courtesy of https://stackoverflow.com/questions/50194674/ng-completion-no-longer-exists
  # . <(ng completion --bash)

# Invoke (pyinvoke.org) tab-completion script to be sourced with Bash shell.

# Copyright (c) 2020 Jeff Forcier.
# All rights reserved.

# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:

#     * Redistributions of source code must retain the above copyright notice,
#       this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above copyright notice,
#       this list of conditions and the following disclaimer in the documentation
#       and/or other materials provided with the distribution.

# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# https://github.com/pyinvoke/invoke/blob/master/completion/bash

_complete_invoke() {
    local candidates

    # COMP_WORDS contains the entire command string up til now (including
    # program name).
    # We hand it to Invoke so it can figure out the current context: spit back
    # core options, task names, the current task's options, or some combo.
    candidates=`invoke --complete -- ${COMP_WORDS[*]}`

    # `compgen -W` takes list of valid options & a partial word & spits back
    # possible matches. Necessary for any partial word completions (vs
    # completions performed when no partial words are present).
    #
    # $2 is the current word or token being tabbed on, either empty string or a
    # partial word, and thus wants to be compgen'd to arrive at some subset of
    # our candidate list which actually matches.
    #
    # COMPREPLY is the list of valid completions handed back to `complete`.
    COMPREPLY=( $(compgen -W "${candidates}" -- $2) )
}


# Tell shell builtin to use the above for completing 'inv'/'invoke':
#!bash
#
# git-flow-completion
# ===================
#
# Bash completion support for [git-flow (AVH Edition)](http://github.com/petervanderdoes/gitflow)
#
# The contained completion routines provide support for completing:
#
#  * git-flow init and version
#  * feature, hotfix and release branches
#  * remote feature, hotfix and release branch names
#
#
# Installation
# ------------
#
# To achieve git-flow completion nirvana:
#
#  0. Install git-completion.
#
#  1. Install this file. Either:
#
#     a. Place it in a `bash-completion.d` folder:
#
#        * /etc/bash-completion.d
#        * /usr/local/etc/bash-completion.d
#        * ~/bash-completion.d
#
#     b. Or, copy it somewhere (e.g. ~/.git-flow-completion.sh) and put the following line in
#        your .bashrc:
#
#            source ~/.git-flow-completion.sh
#
#  2. If you are using Git < 1.7.1: Edit git-completion.sh and add the following line to the giant
#     $command case in _git:
#
#         flow)        _git_flow ;;
#
#
# The Fine Print
# --------------
#
# Author:
# Copyright 2012-2013 Peter van der Does.
#
# Original Author:
# Copyright (c) 2011 [Justin Hileman](http://justinhileman.com)
#
# Distributed under the [MIT License](http://creativecommons.org/licenses/MIT/)

__git_flow_config_file_options="
	--local --global --system --file=
	"

_git_flow ()
{
	local subcommands="init feature release hotfix support help version config finish delete publish rebase"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	init)
		__git_flow_init
		return
		;;
	feature)
		__git_flow_feature
		return
		;;
	release)
		__git_flow_release
		return
		;;
	hotfix)
		__git_flow_hotfix
		return
		;;
	support)
		__git_flow_support
		return
		;;
	config)
		__git_flow_config
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_init ()
{
	local subcommands="help"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
	fi

	case "$cur" in
	--*)
		__gitcomp "
				--nodefaults --defaults
				--noforce --force
				$__git_flow_config_file_options
				"
		return
		;;
	esac
}

__git_flow_feature ()
{
	local subcommands="list start finish publish track diff rebase checkout pull help delete"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"

	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	pull)
		__gitcomp_nl "$(__git_remotes)"
		return
		;;
	checkout)
		__gitcomp_nl "$(__git_flow_list_local_branches 'feature')"
		return
		;;
	delete)
		case "$cur" in
		--*)
			__gitcomp "
					--noforce --force
					--noremote --remote
					"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'feature')"
		return
		;;
	finish)
		case "$cur" in
		--*)
			__gitcomp "
					--nofetch --fetch
					--norebase --rebase
					--nopreserve-merges --preserve-merges
					--nokeep --keep
					--keepremote
					--keeplocal
					--noforce_delete --force_delete
					--nosquash --squash
					--no-ff
				"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'feature')"
		return
		;;
	diff)
		__gitcomp_nl "$(__git_flow_list_local_branches 'feature')"
		return
		;;
	rebase)
		case "$cur" in
		--*)
			__gitcomp "
					--nointeractive --interactive
					--nopreserve-merges --preserve-merges
				"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'feature')"
		return
		;;
	publish)
		__gitcomp_nl "$(__git_flow_list_branches 'feature')"
		return
		;;
	track)
		__gitcomp_nl "$(__git_flow_list_branches 'feature')"
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_release ()
{
	local subcommands="list start finish track publish help delete"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	finish)
		case "$cur" in
		--*)
			__gitcomp "
					--nofetch --fetch
					--sign
					--signingkey
					--message
					--nomessagefile --messagefile=
					--nopush --push
					--nokeep --keep
					--keepremote
					--keeplocal
					--noforce_delete --force_delete
					--notag --tag
					--nonobackmerge --nobackmerge
					--nosquash --squash
				"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'release')"
		return
		;;
	rebase)
		case "$cur" in
		--*)
			__gitcomp "
					--nointeractive --interactive
					--nopreserve-merges --preserve-merges
				"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'release')"
		return
		;;
	delete)
		case "$cur" in
		--*)
			__gitcomp "
					--noforce --force
					--noremote --remote
					"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'release')"
		return
		;;
	publish)
		__gitcomp_nl "$(__git_flow_list_branches 'release')"
		return
		;;
	track)
		__gitcomp_nl "$(__git_flow_list_branches 'release')"
		return
		;;
	start)
	case "$cur" in
		--*)
			__gitcomp "
					--nofetch --fetch
				"
			return
			;;
		esac
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac

}

__git_flow_hotfix ()
{
	local subcommands="list start finish track publish help delete"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	finish)
		case "$cur" in
		--*)
			__gitcomp "
					--nofetch --fetch
					--sign
					--signingkey
					--message
					--nomessagefile --messagefile=
					--nopush --push
					--nokeep --keep
					--keepremote
					--keeplocal
					--noforce_delete --force_delete
					--notag --tag
					--nonobackmerge --nobackmerge
				"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'hotfix')"
		return
		;;
	rebase)
		case "$cur" in
		--*)
			__gitcomp "
					--nointeractive --interactive
					--nopreserve-merges --preserve-merges
				"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'hotfix')"
		return
		;;
	delete)
		case "$cur" in
		--*)
			__gitcomp "
					--noforce --force
					--noremote --remote
					"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'hotfix')"
		return
		;;
	publish)
		__gitcomp_nl "$(__git_flow_list_branches 'hotfix')"
		return
		;;
	track)
		__gitcomp_nl "$(__git_flow_list_branches 'hotfix')"
		return
		;;
	start)
		case "$cur" in
		--*)
			__gitcomp "
					--nofetch --fetch
				"
			return
			;;
		esac
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_support ()
{
	local subcommands="list start help"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	start)
		case "$cur" in
		--*)
			__gitcomp "
					--nofetch --fetch
				"
			return
			;;
		esac
		return
		;;
	rebase)
		case "$cur" in
		--*)
			__gitcomp "
					--nointeractive --interactive
					--nopreserve-merges --preserve-merges
				"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches 'support')"
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_config ()
{
	local subcommands="list set base"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	set)
		case "$cur" in
		--*)
			__gitcomp "
						$__git_flow_config_file_options
					"
			return
			;;
		esac
		__gitcomp "
			master develop
			feature hotfix release support
			versiontagprefix
			"
		return
		;;
	base)
		case "$cur" in
		--*)
			__gitcomp "
						set get
					"
			return
			;;
		esac
		__gitcomp_nl "$(__git_flow_list_local_branches)"
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_prefix ()
{
	case "$1" in
	feature|release|hotfix|support)
		git config "gitflow.prefix.$1" 2> /dev/null || echo "$1/"
		return
		;;
	esac
}

__git_flow_list_local_branches ()
{
	if [ -n "$1" ]; then
		local prefix="$(__git_flow_prefix $1)"
		git for-each-ref --shell --format="ref=%(refname:short)" refs/heads/$prefix | \
			while read -r entry; do
				eval "$entry"
				ref="${ref#$prefix}"
				echo "$ref"
			done | sort
	else
		git for-each-ref --format="ref=%(refname:short)" refs/heads/ | sort

	fi
}

__git_flow_list_remote_branches ()
{
	local prefix="$(__git_flow_prefix $1)"
	local origin="$(git config gitflow.origin 2> /dev/null || echo "origin")"
	git for-each-ref --shell --format='%(refname:short)' refs/remotes/$origin/$prefix | \
			while read -r entry; do
				eval "$entry"
				ref="${ref##$prefix}"
				echo "$ref"
			done | sort
}

__git_flow_list_branches ()
{
	local origin="$(git config gitflow.origin 2> /dev/null || echo "origin")"
	if [ -n "$1" ]; then
		local prefix="$(__git_flow_prefix $1)"
		git for-each-ref --shell --format="ref=%(refname:short)" refs/heads/$prefix refs/remotes/$origin/$prefix | \
			while read -r entry; do
				eval "$entry"
				ref="${ref##$prefix}"
				echo "$ref"
			done | sort
	else
		git for-each-ref --format="%(refname:short)" refs/heads/ refs/remotes/$origin | sort
	fi
}
# Bash completion for Makefile
# Loosely adapted from http://stackoverflow.com/a/38415982/1472048

_makecomplete() {
  COMPREPLY=()

  # https://www.gnu.org/software/make/manual/html_node/Makefile-Names.html
  local files=()
  for f in 'GNUmakefile' 'makefile' 'Makefile' ; do
    [ -f "$f" ] && files+=("$f")
  done

  [ "${#files[@]}" -eq 0 ] && return 0

  # collect all targets
  local targets=()
  for f in "${files[@]}" ; do
    while IFS='' read -r line ; do
      targets+=("$line")
    done < <(grep -oE '^[a-zA-Z0-9_-]+:([^=]|$)' "$f" | cut -d':' -f1)
  done

  [ "${#targets[@]}" -eq 0 ] && return 0

  # use the targets for completion
  while IFS='' read -r line ; do
    COMPREPLY+=("$line")
  done < <(compgen -W "$(tr ' ' '\n' <<<"${targets[@]}" | sort -u)" -- "${COMP_WORDS[COMP_CWORD]}")

  return 0
# Completions for JBoss Application Server 7 (EAP 6)
# VERSION: 0.6
# DATE: 2012-10-30
# rparree-at-edc4it-dot-com

# MIT License

# Copyright (c) 2020 Raphael Parree

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

_serverProfiles(){
    if [[ $COMP_WORDS == *standalone.sh* ]]
    then
      serverdir="../standalone/configuration/"
    else
       # assume is domain.sh
      serverdir="../domain/configuration/"
    fi

    for i in  ${!COMP_WORDS[*]}
    do
      if [[ "${COMP_WORDS[i]}" == "-Djboss.server.base.dir" || "${COMP_WORDS[i]}" == "-Djboss.domain.base.dir" ]]; then
        serverdir="${COMP_WORDS[i+2]}/configuration"
      fi

    done
    if [ -d "${serverdir}" ]
    then

      IFS=$'\n' tmp="$(ls "${serverdir}" | grep xml)"
        local fls="${tmp[@]// /\ }"
      unset IFS
      COMPREPLY=( $(compgen -W "${fls} initial boot last v" -- "$cur" ))
    fi
}

_bindingAddress(){
  # from /etc/bash_completion.d/ssh
    COMPREPLY=( "${COMPREPLY[@]}" $( compgen -W \
    "0.0.0.0 $( PATH="$PATH:/sbin" ifconfig -a | \
    sed -ne 's/.*addr:\([^[:space:]]*\).*/\1/p' \
        -ne 's/.*inet[[:space:]]\{1,\}\([^[:space:]]*\).*/\1/p' )" \
    -- "$cur" ) )
}

_jboss(){

    local cur prev words cword
    COMPREPLY=()
    _get_comp_words_by_ref -n = cur prev words cword

    case $cur in

        -Djboss.socket.binding.port-offset=*)
            cur=${cur#*=}
            #static list of common bindings sets
            local bindings="100 200 300 400 10000 20000 30000 40000"
            COMPREPLY=( $(compgen -W "${bindings}" -- ${cur}) )
            return 0
            ;;
        -Djboss.default.jgroups.stack=*)
            cur=${cur#*=}
            #static list of standard JGroups stacks
            local stacks="udp udp-async udp-sync tcp tcp-sync"
            COMPREPLY=( $(compgen -W "${stacks}" -- ${cur}) )
            return 0
            ;;

        -Dorg.jboss.ejb3.remoting.IsLocalInterceptor.passByRef=*|-Dcom.sun.management.jmxremote.authenticate=*|-Dcom.sun.management.jmxremote.ssl=*)
            cur=${cur#*=}
            local booleans="true false"
            COMPREPLY=( $(compgen -W "${booleans}" -- ${cur}) )
            return 0
            ;;

        -Djboss.server.base.dir=*|-Djboss.home.dir=*|-Djboss.domain.base.dir=*)
           cur=${cur#*=}
           _filedir -d
           return 0
           ;;

        -Djboss.domain.master.address=*|-Djboss.bind.address*=*)
           cur=${cur#*=}
           _bindingAddress
           return 0
           ;;
        --server-config=*|-c=|--host-config=*)
	   cur=${cur#*=}
           _serverProfiles
           return 0


    esac


    case $prev in
        -u)
            # a few from RFC 2365 IPv4 Local Scope ()
           local addresses="239.255.0.1 239.255.0.2 239.255.0.3"
            COMPREPLY=( $(compgen -W "${addresses}" -- ${cur}) )
            return 0
            ;;
        -b*)
            _bindingAddress
            return 0
            ;;
        -c)
            _serverProfiles
            return 0
            ;;
        *)
            ;;
    esac
    # *** from jboss5  ********************
    # *** -modulepath  -c -m  -g -l -d -p -n -B -L -C  -Djboss.platform.mbeanserver -Djboss.server.base.directory
    # ***  -Djboss.Domain -Djboss.modcluster.proxyList  -Djboss.jvmRoute -Djboss.default.jgroups.stack -Dorg.jboss.ejb3.remoting.IsLocalInterceptor.passByRef -Djboss.platform.mbeanserver -Dcom.sun.management.jmxremote.port -Dcom.sun.management.jmxremote.ssl
    # *************************************

    # standard commands for standalone and domain mode
    local commandsWithoutEqualSign='-b -bmanagement -bunsecure -bpublic --admin-only -h -help -u -version -V -v'
    local commandsWithEqualSign='-P -Djboss.node.name -Djboss.home.dir -Djboss.socket.binding.port-offset -Djboss.bind.address.management -Djboss.bind.address -Djboss.bind.address.unsecure'

    if [[ $COMP_WORDS == *standalone.sh* ]]
    then
       commandsWithoutEqualSign="${commandsWithoutEqualSign} -c"
       commandsWithEqualSign="${commandsWithEqualSign} --server-config -Djboss.server.base.dir -c"
    else
       # assume is domain.sh
       commandsWithoutEqualSign="${commandsWithoutEqualSign} --backup  --cached-dc"
       commandsWithEqualSign="${commandsWithEqualSign} -Djboss.domain.master.address --host-config -Djboss.domain.master.port -Djboss.domain.base.dir "
    fi




    COMPREPLY=( $( compgen -W "$commandsWithoutEqualSign" -- "$cur" )
                $( compgen -W "$commandsWithEqualSign"  -S '=' -- "$cur" ) )
    return 0
#!/usr/bin/env bash

# Loads the system's Bash completion modules.
# If Homebrew is installed (OS X), it's Bash completion modules are loaded.

if [[ -r /etc/bash_completion ]] ; then
  # shellcheck disable=SC1091
  source /etc/bash_completion

# Some distribution makes use of a profile.d script to import completion.
elif [[ -r /etc/profile.d/bash_completion.sh ]] ; then
  # shellcheck disable=SC1091
  source /etc/profile.d/bash_completion.sh

fi

if [[ "$(uname -s)" == 'Darwin' ]] && _command_exists brew ; then
  BREW_PREFIX=${BREW_PREFIX:-$(brew --prefix)}

  # homebrew/versions/bash-completion2 (required for projects.completion.bash) is installed to this path
# defaults
# Bash command line completion for defaults
#
# Created by Jonathon Mah on 2006-11-08.
# Copyright 2006 Playhaus. All rights reserved.
#
# Version 1.0 (2006-11-08)


_defaults_domains()
{
    local cur
    COMPREPLY=()
    cur=${COMP_WORDS[COMP_CWORD]}

	local domains=$( defaults domains | sed -e 's/, /:/g' | tr : '\n' | sed -e 's/ /\\ /g' | grep -i "^$cur" )
	local IFS=$'\n'
	COMPREPLY=( $domains )
	if [[ $( echo '-app' | grep "^$cur" ) ]]; then
		COMPREPLY[${#COMPREPLY[@]}]="-app"
	fi

    return 0
}


_defaults()
{
	local cur prev host_opts cmds cmd domain keys key_index
    cur=${COMP_WORDS[COMP_CWORD]}
    prev=${COMP_WORDS[COMP_CWORD-1]}

	host_opts='-currentHost -host'
	cmds='read read-type write rename delete domains find help'

	if [[ $COMP_CWORD -eq 1 ]]; then
		COMPREPLY=( $( compgen -W "$host_opts $cmds" -- $cur ) )
		return 0
	elif [[ $COMP_CWORD -eq 2 ]]; then
		if [[ "$prev" == "-currentHost" ]]; then
			COMPREPLY=( $( compgen -W "$cmds" -- $cur ) )
			return 0
		elif [[ "$prev" == "-host" ]]; then
			return 0
			_known_hosts -a
		else
			_defaults_domains
			return 0
		fi
	elif [[ $COMP_CWORD -eq 3 ]]; then
		if [[ ${COMP_WORDS[1]} == "-host" ]]; then
			_defaults_domains
			return 0
		fi
    fi

	# Both a domain and command have been specified

	if [[ ${COMP_WORDS[1]} == [${cmds// /|}] ]]; then
		cmd=${COMP_WORDS[1]}
		domain=${COMP_WORDS[2]}
		key_index=3
		if [[ "$domain" == "-app" ]]; then
			if [[ $COMP_CWORD -eq 3 ]]; then
				# Completing application name. Can't help here, sorry
				return 0
			fi
			domain="-app ${COMP_WORDS[3]}"
			key_index=4
		fi
	elif [[ ${COMP_WORDS[2]} == "-currentHost" ]] && [[ ${COMP_WORDS[2]} == [${cmds// /|}] ]]; then
		cmd=${COMP_WORDS[2]}
		domain=${COMP_WORDS[3]}
		key_index=4
		if [[ "$domain" == "-app" ]]; then
			if [[ $COMP_CWORD -eq 4 ]]; then
				# Completing application name. Can't help here, sorry
				return 0
			fi
			domain="-app ${COMP_WORDS[4]}"
			key_index=5
		fi
	elif [[ ${COMP_WORDS[3]} == "-host" ]] && [[ ${COMP_WORDS[3]} == [${cmds// /|}] ]]; then
		cmd=${COMP_WORDS[3]}
		domain=${COMP_WORDS[4]}
		key_index=5
		if [[ "$domain" == "-app" ]]; then
			if [[ $COMP_CWORD -eq 5 ]]; then
				# Completing application name. Can't help here, sorry
				return 0
			fi
			domain="-app ${COMP_WORDS[5]}"
			key_index=6
		fi
	fi

	keys=$( defaults read $domain 2>/dev/null | sed -n -e '/^    [^}) ]/p' | sed -e 's/^    \([^" ]\{1,\}\) = .*$/\1/g' -e 's/^    "\([^"]\{1,\}\)" = .*$/\1/g' | sed -e 's/ /\\ /g' )

	case $cmd in
	read|read-type)
		# Complete key
		local IFS=$'\n'
		COMPREPLY=( $( echo "$keys" | grep -i "^${cur//\\/\\\\}" ) )
		;;
	write)
		if [[ $key_index -eq $COMP_CWORD ]]; then
			# Complete key
			local IFS=$'\n'
			COMPREPLY=( $( echo "$keys" | grep -i "^${cur//\\/\\\\}" ) )
		elif [[ $((key_index+1)) -eq $COMP_CWORD ]]; then
			# Complete value type
			# Unfortunately ${COMP_WORDS[key_index]} fails on keys with spaces
			local value_types='-string -data -integer -float -boolean -date -array -array-add -dict -dict-add'
			local cur_type=$( defaults read-type $domain ${COMP_WORDS[key_index]} 2>/dev/null | sed -e 's/^Type is \(.*\)/-\1/' -e's/dictionary/dict/' | grep "^$cur" )
			if [[ $cur_type ]]; then
				COMPREPLY=( $cur_type )
			else
				COMPREPLY=( $( compgen -W "$value_types" -- $cur ) )
			fi
		elif [[ $((key_index+2)) -eq $COMP_CWORD ]]; then
			# Complete value
			# Unfortunately ${COMP_WORDS[key_index]} fails on keys with spaces
			COMPREPLY=( $( defaults read $domain ${COMP_WORDS[key_index]} 2>/dev/null | grep -i "^${cur//\\/\\\\}" ) )
		fi
		;;
	rename)
		if [[ $key_index -eq $COMP_CWORD ]] ||
		   [[ $((key_index+1)) -eq $COMP_CWORD ]]; then
			# Complete source and destination keys
			local IFS=$'\n'
			COMPREPLY=( $( echo "$keys" | grep -i "^${cur//\\/\\\\}" ) )
		fi
		;;
	delete)
		if [[ $key_index -eq $COMP_CWORD ]]; then
			# Complete key
			local IFS=$'\n'
			COMPREPLY=( $( echo "$keys" | grep -i "^${cur//\\/\\\\}" ) )
		fi
		;;
	esac

    return 0
}

complete -F _defaults -o default defaults


# This file is licensed under the BSD license, as follows:
#
# Copyright (c) 2006, Playhaus
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
# * Neither the name of the Playhaus nor the names of its contributors may be
#   used to endorse or promote products derived from this software without
#   specific prior written permission.
#
# This software is provided by the copyright holders and contributors "as is"
# and any express or implied warranties, including, but not limited to, the
# implied warranties of merchantability and fitness for a particular purpose are
# disclaimed. In no event shall the copyright owner or contributors be liable
# for any direct, indirect, incidental, special, exemplary, or consequential
# shellcheck shell=bash

# rustup (Rust toolchain installer) completion

if _binary_exists rustup; then
# shellcheck shell=bash

function __notify-send_completions() {
	local curr=$(_get_cword)
	local prev=$(_get_pword)

	case $prev in
		-u | --urgency)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "low normal critical" -- "$curr"))
			;;
		*)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-? --help -u --urgency -t --expire-time -a --app-name -i --icon -c --category -h --hint -v --version" -- "$curr"))
			;;
#!/usr/bin/bash

if command -v laravel > /dev/null; then
    __laravel_completion()  {
        local OPTS=("-h --help -q --quiet --ansi --no-ansi -n --no-interaction -v -vv -vvv --verbose help list new")
        COMPREPLY=()
        for _opt_ in ${OPTS[@]}; do
            if [[ "$_opt_" == "$2"* ]]; then
                COMPREPLY+=("$_opt_")
            fi
#!/usr/bin/env bash

# tmux completion
# See: http://www.debian-administration.org/articles/317 for how to write more.
# Usage: Put "source bash_completion_tmux.sh" into your .bashrc

_tmux_expand ()
{
    [ "$cur" != "${cur%\\}" ] && cur="$cur"'\';
    if [[ "$cur" == \~*/* ]]; then
        eval cur=$cur;
    else
        if [[ "$cur" == \~* ]]; then
            cur=${cur#\~};
            COMPREPLY=($( compgen -P '~' -u $cur ));
            return ${#COMPREPLY[@]};
        fi;
    fi
}

_tmux_filedir ()
{
    local IFS='
';
    _tmux_expand || return 0;
    if [ "$1" = -d ]; then
        COMPREPLY=(${COMPREPLY[@]} $( compgen -d -- $cur ));
        return 0;
    fi;
    COMPREPLY=(${COMPREPLY[@]} $( eval compgen -f -- \"$cur\" ))
}

function _tmux_complete_client() {
    local IFS=$'\n'
    local cur="${1}"
    COMPREPLY=( ${COMPREPLY[@]:-} $(compgen -W "$(tmux -q list-clients 2>/dev/null | cut -f 1 -d ':')" -- "${cur}") )
}
function _tmux_complete_session() {
    local IFS=$'\n'
    local cur="${1}"
    COMPREPLY=( ${COMPREPLY[@]:-} $(compgen -W "$(tmux -q list-sessions 2>/dev/null | cut -f 1 -d ':')" -- "${cur}") )
}
function _tmux_complete_window() {
    local IFS=$'\n'
    local cur="${1}"
    local session_name="$(echo "${cur}" | sed 's/\\//g' | cut -d ':' -f 1)"
    local sessions

    sessions="$(tmux -q list-sessions 2>/dev/null | sed -re 's/([^:]+:).*$/\1/')"
    if [[ -n "${session_name}" ]]; then
        sessions="${sessions}
        $(tmux -q list-windows -t "${session_name}" 2>/dev/null | sed -re 's/^([^:]+):.*$/'"${session_name}"':\1/')"
    fi
    cur="$(echo "${cur}" | sed -e 's/:/\\\\:/')"
    sessions="$(echo "${sessions}" | sed -e 's/:/\\\\:/')"
    COMPREPLY=( ${COMPREPLY[@]:-} $(compgen -W "${sessions}" -- "${cur}") )
}

_tmux() {
    local cur prev
    local i cmd cmd_index option option_index
    local opts=""
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"

    if [ ${prev} == -f ]; then
        _tmux_filedir
    else
    # Search for the command
    local skip_next=0
    for ((i=1; $i<=$COMP_CWORD; i++)); do
        if [[ ${skip_next} -eq 1 ]]; then
            #echo "Skipping"
            skip_next=0;
        elif [[ ${COMP_WORDS[i]} != -* ]]; then
            cmd="${COMP_WORDS[i]}"
            cmd_index=${i}
            break
        elif [[ ${COMP_WORDS[i]} == -f ]]; then
            skip_next=1
        fi
    done

    # Search for the last option command
    skip_next=0
    for ((i=1; $i<=$COMP_CWORD; i++)); do
        if [[ ${skip_next} -eq 1 ]]; then
            #echo "Skipping"
            skip_next=0;
        elif [[ ${COMP_WORDS[i]} == -* ]]; then
            option="${COMP_WORDS[i]}"
            option_index=${i}
            if [[ ${COMP_WORDS[i]} == -- ]]; then
                break;
            fi
        elif [[ ${COMP_WORDS[i]} == -f ]]; then
            skip_next=1
        fi
    done

    if [[ $COMP_CWORD -le $cmd_index ]]; then
        # The user has not specified a command yet
        COMPREPLY=( ${COMPREPLY[@]:-} $(compgen -W "$(tmux start-server \; list-commands | cut -d' ' -f1)" -- "${cur}") )
    else
        case ${cmd} in
            attach-session|attach)
            case "$prev" in
                -t) _tmux_complete_session "${cur}" ;;
                *) options="-t -d" ;;
            esac ;;
            detach-client|detach)
            case "$prev" in
                -t) _tmux_complete_client "${cur}" ;;
                *) options="-t" ;;
            esac ;;
            lock-client|lockc)
            case "$prev" in
                -t) _tmux_complete_client "${cur}" ;;
                *) options="-t" ;;
            esac ;;
            lock-session|locks)
            case "$prev" in
                -t) _tmux_complete_session "${cur}" ;;
                *) options="-t -d" ;;
            esac ;;
            new-session|new)
            case "$prev" in
                -t) _tmux_complete_session "${cur}" ;;
                -[n|d|s]) options="-d -n -s -t --" ;;
                *)
                if [[ ${COMP_WORDS[option_index]} == -- ]]; then
                    _command_offset ${option_index}
                else
                    options="-d -n -s -t --"
                fi
                ;;
            esac
            ;;
            refresh-client|refresh)
            case "$prev" in
                -t) _tmux_complete_client "${cur}" ;;
                *) options="-t" ;;
            esac ;;
            rename-session|rename)
            case "$prev" in
                -t) _tmux_complete_session "${cur}" ;;
                *) options="-t" ;;
            esac ;;
            source-file|source) _tmux_filedir ;;
            has-session|has|kill-session)
            case "$prev" in
                -t) _tmux_complete_session "${cur}" ;;
                *) options="-t" ;;
            esac ;;
            suspend-client|suspendc)
            case "$prev" in
                -t) _tmux_complete_client "${cur}" ;;
                *) options="-t" ;;
            esac ;;
            switch-client|switchc)
            case "$prev" in
                -c) _tmux_complete_client "${cur}" ;;
                -t) _tmux_complete_session "${cur}" ;;
                *) options="-l -n -p -c -t" ;;
            esac ;;

            send-keys|send)
            case "$option" in
                -t) _tmux_complete_window "${cur}" ;;
                *) options="-t" ;;
            esac ;;
          esac # case ${cmd}
        fi # command specified
      fi # not -f

      if [[ -n "${options}" ]]; then
          COMPREPLY=( ${COMPREPLY[@]:-} $(compgen -W "${options}" -- "${cur}") )
      fi

      return 0

}
complete -F _tmux tmux

# shellcheck shell=bash
cite "about-completion"
about-completion "conda completion"

if _command_exists conda; then
	if _command_exists register-python-argcomplete; then
		eval "$(register-python-argcomplete conda)"
	else
		_log_warning "Argcomplete not found. Please run 'conda install argcomplete'"
	fi
#!/usr/bin/bash

if command -v wpscan > /dev/null; then
    __wpscan_completion()  {
        local OPTS=("--help --hh --version --url --ignore-main-redirect --verbose --output --format --detection-mode --scope --headers --user-agent --vhost --random-user-agent --user-agents-list --http-auth --max-threads --throttle --request-timeout --connect-timeout --disable-tlc-checks --proxy --proxy-auth --cookie-string --cookie-jar --cache-ttl --clear-cache --server --cache-dir --update --no-update --wp-content-dir --wp-plugins-dir --wp-version-detection --main-theme-detection --enumerate --exclude-content-based --plugins-list --plugins-detection --plugins-version-all --plugins-version-detection --themes-list --themes-detection --themes-version-all --themes-version-detection --timthumbs-list --timthumbs-detection --config-backups-list --config-backups-detection --db-exports-list --db-exports-detection --medias-detection --users-list --users-detection --passwords --usernames --multicall-max-passwords --password-attack --stealthy")
        COMPREPLY=()
        for _opt_ in ${OPTS[@]}; do
            if [[ "$_opt_" == "$2"* ]]; then
                COMPREPLY+=("$_opt_")
            fi
#!/usr/bin/env bash

_bash-it-comp-enable-disable()
{
  local enable_disable_args="alias completion plugin"
  COMPREPLY=( $(compgen -W "${enable_disable_args}" -- ${cur}) )
}

_bash-it-comp-list-available-not-enabled()
{
  subdirectory="$1"

  local available_things

  available_things=$(for f in `compgen -G "${BASH_IT}/$subdirectory/available/*.bash" | sort -d`;
    do
      file_entity=$(basename $f)

      typeset enabled_component=$(command ls "${BASH_IT}/$subdirectory/enabled/"{[0-9]*$BASH_IT_LOAD_PRIORITY_SEPARATOR$file_entity,$file_entity} 2>/dev/null | head -1)
      typeset enabled_component_global=$(command ls "${BASH_IT}/enabled/"[0-9]*$BASH_IT_LOAD_PRIORITY_SEPARATOR$file_entity 2>/dev/null | head -1)

      if [ -z "$enabled_component" ] && [ -z "$enabled_component_global" ]
      then
        basename $f | sed -e 's/\(.*\)\..*\.bash/\1/g'
      fi
    done)

  COMPREPLY=( $(compgen -W "all ${available_things}" -- ${cur}) )
}

_bash-it-comp-list-enabled()
{
  local subdirectory="$1"
  local suffix enabled_things

  suffix=$(echo "$subdirectory" | sed -e 's/plugins/plugin/g')

  enabled_things=$(for f in `sort -d <(compgen -G "${BASH_IT}/$subdirectory/enabled/*.${suffix}.bash") <(compgen -G "${BASH_IT}/enabled/*.${suffix}.bash")`;
    do
      basename $f | sed -e 's/\(.*\)\..*\.bash/\1/g' | sed -e "s/^[0-9]*---//g"
    done)

  COMPREPLY=( $(compgen -W "all ${enabled_things}" -- ${cur}) )
}

_bash-it-comp-list-available()
{
  subdirectory="$1"

  local enabled_things

  enabled_things=$(for f in `compgen -G "${BASH_IT}/$subdirectory/available/*.bash" | sort -d`;
    do
      basename $f | sed -e 's/\(.*\)\..*\.bash/\1/g'
    done)

  COMPREPLY=( $(compgen -W "${enabled_things}" -- ${cur}) )
}

_bash-it-comp()
{
  local cur prev opts
  COMPREPLY=()
  cur="${COMP_WORDS[COMP_CWORD]}"
  prev="${COMP_WORDS[COMP_CWORD-1]}"
  chose_opt="${COMP_WORDS[1]}"
  file_type="${COMP_WORDS[2]}"
  opts="disable enable help migrate reload restart doctor search show update version"
  case "${chose_opt}" in
    show)
      local show_args="aliases completions plugins"
      COMPREPLY=( $(compgen -W "${show_args}" -- ${cur}) )
      return 0
      ;;
    help)
      if [ x"${prev}" == x"aliases" ]; then
        _bash-it-comp-list-available aliases
        return 0
      else
        local help_args="aliases completions migrate plugins update"
        COMPREPLY=( $(compgen -W "${help_args}" -- ${cur}) )
        return 0
      fi
      ;;
    doctor)
      local doctor_args="errors warnings all"
      COMPREPLY=( $(compgen -W "${doctor_args}" -- ${cur}) )
      return 0
      ;;
    update)
      if [[ ${cur} == -* ]];then
        local update_args="-s --silent"
      else
        local update_args="stable dev"
      fi
      COMPREPLY=( $(compgen -W "${update_args}" -- ${cur}) )
      return 0
      ;;
    migrate | reload | search | version)
      return 0
      ;;
    enable | disable)
      if [ x"${chose_opt}" == x"enable" ];then
        suffix="available-not-enabled"
      else
        suffix="enabled"
      fi
      case "${file_type}" in
        alias)
            _bash-it-comp-list-${suffix} aliases
            return 0
            ;;
        plugin)
            _bash-it-comp-list-${suffix} plugins
            return 0
            ;;
        completion)
            _bash-it-comp-list-${suffix} completion
            return 0
            ;;
        *)
            _bash-it-comp-enable-disable
            return 0
            ;;
      esac
      ;;
  esac

  COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )

  return 0
}

# Activate completion for bash-it and its common misspellings
complete -F _bash-it-comp bash-it
# shellcheck shell=bash
cite "about-completion"
about-completion "docker completion"

# Make sure docker is installed
_command_exists docker || return

# Don't handle completion if it's already managed
_completion_exists docker && return

_docker_bash_completion_paths=(
	# MacOS
	'/Applications/Docker.app/Contents/Resources/etc/docker.bash-completion'
	# Linux
	'/usr/share/bash-completion/completions/docker'
)

for fn in "${_docker_bash_completion_paths[@]}"; do
	if [ -r "$fn" ]; then
		# shellcheck disable=SC1090
#!/usr/bin/env bash
# Bash Maven completion

_mvn()
{
   local cmds cur colonprefixes
   cmds="clean validate compile test package integration-test   \
      verify install deploy test-compile site generate-sources  \
      process-sources generate-resources process-resources      \
      eclipse:eclipse eclipse:add-maven-repo eclipse:clean      \
      idea:idea -DartifactId= -DgroupId= -Dmaven.test.skip=true \
      -Declipse.workspace= -DarchetypeArtifactId=               \
      netbeans-freeform:generate-netbeans-project               \
      tomcat:run tomcat:run-war tomcat:deploy jboss-as:deploy   \
      versions:display-dependency-updates                       \
      versions:display-plugin-updates dependency:analyze        \
      dependency:analyze-dep-mgt dependency:resolve             \
      dependency:sources dependency:tree release:prepare        \
      release:rollback release:perform --batch-mode"

   COMPREPLY=()
   cur=${COMP_WORDS[COMP_CWORD]}
   # Work-around bash_completion issue where bash interprets a colon
   # as a separator.
   # Work-around borrowed from the darcs work-around for the same
   # issue.
   colonprefixes=${cur%"${cur##*:}"}
   COMPREPLY=( $(compgen -W '$cmds'  -- $cur))
   local i=${#COMPREPLY[*]}
   while [ $((--i)) -ge 0 ]; do
      COMPREPLY[$i]=${COMPREPLY[$i]#"$colonprefixes"}
   done

        return 0
} &&
#!/bin/bash

# ---------------------------------------------------------------------------+
#                                                                            |
# Thanks to Alexander Korznikov                                                                 |
# http://www.korznikov.com/2014/12/bash-tab-completion-for-awesome-tool.html |
#                                                                            |
# ---------------------------------------------------------------------------+

if command -v sqlmap > /dev/null; then

    _sqlmap()
    {
        local cur prev

        COMPREPLY=()
        cur=$(_get_cword)
        prev=$(_get_pword)

        case $prev in

    # List directory content
    --tamper)
        COMPREPLY=( $( compgen -W "$tamper" -- "$cur" ) )
        return 0
        ;;
    --output-dir|-t|-l|-m|-r|--load-cookies|--proxy-file|--sql-file|--shared-lib|--file-write)
        _filedir
        return 0
        ;;
    -c)
        _filedir ini
        return 0
        ;;
    --method)
        COMPREPLY=( $( compgen -W 'GET POST PUT' -- "$cur" ) )
        return 0
        ;;
    --auth-type)
        COMPREPLY=( $( compgen -W 'Basic Digest NTLM PKI' -- "$cur" ) )
        return 0
        ;;
    --tor-type)
        COMPREPLY=( $( compgen -W 'HTTP SOCKS4 SOCKS5' -- "$cur" ) )
        return 0
        ;;
    -v)
        COMPREPLY=( $( compgen -W '1 2 3 4 5 6' -- "$cur" ) )
        return 0
        ;;
    --dbms)
        COMPREPLY=( $( compgen -W 'mysql mssql access postgres' -- "$cur" ) )
        return 0
        ;;
    --level|--crawl)
        COMPREPLY=( $( compgen -W '1 2 3 4 5' -- "$cur" ) )
        return 0
        ;;
    --risk)
        COMPREPLY=( $( compgen -W '0 1 2 3' -- "$cur" ) )
        return 0
        ;;
    --technique)
        COMPREPLY=( $( compgen -W 'B E U S T Q' -- "$cur" ) )
        return 0
        ;;
    -s)
        _filedir sqlite
        return 0
        ;;
    --dump-format)
        COMPREPLY=( $( compgen -W 'CSV HTML SQLITE' -- "$cur" ) )
        return 0
        ;;
    -x)
        _filedir xml
        return 0
        ;;
        esac

        if [[ "$cur" == * ]]; then
        COMPREPLY=( $( compgen -W '-h --help -hh --version -v -d -u --url -l -x -m -r -g -c --method \
        --data --param-del --cookie --cookie-del --load-cookies \
        --drop-set-cookie --user-agent --random-agent --host --referer \
        --headers --auth-type --auth-cred --auth-private --ignore-401 \
        --proxy --proxy-cred --proxy-file --ignore-proxy --tor --tor-port \
        --tor-type --check-tor --delay --timeout --retries --randomize \
        --safe-url --safe-freq --skip-urlencode --csrf-token --csrf-url \
        --force-ssl --hpp --eval -o --predict-output --keep-alive \
        --null-connection --threads -p  --skip --dbms --dbms-cred \
        --os --invalid-bignum --invalid-logical --invalid-string \
        --no-cast --no-escape --prefix --suffix --tamper --level \
        --risk --string --not-string --regexp --code --text-only \
        --titles --technique --time-sec --union-cols --union-char \
        --union-from --dns-domain --second-order -f --fingerprint \
        -a --all -b --banner --current-user --current-db --hostname \
        --is-dba --users --passwords --privileges --roles --dbs --tables \
        --columns --schema --count --dump --dump-all --search --comments \
        -D -T -C -X -U --exclude-sysdbs --where --start --stop \
        --first --last --sql-query --sql-shell --sql-file --common-tables \
        --common-columns --udf-inject --shared-lib --file-read --file-write \
        --file-dest --os-cmd --os-shell --os-pwn --os-smbrelay --os-bof \
        --priv-esc --msf-path --tmp-path --reg-read --reg-add --reg-del \
        --reg-key --reg-value --reg-data --reg-type -s -t --batch \
        --charset --crawl --csv-del --dump-format --eta --flush-session \
        --forms --fresh-queries --hex --output-dir --parse-errors \
        --pivot-column --save --scope --test-filter --update \
        -z --alert --answers --beep --check-waf --cleanup \
        --dependencies --disable-coloring --gpage --identify-waf \
        --mobile --page-rank --purge-output --smart \
        --sqlmap-shell --wizard' -- "$cur" ) )
        # this removes any options from the list of completions that have
        # already been specified somewhere on the command line, as long as
        # these options can only be used once (in a word, "options", in
        # opposition to "tests" and "actions", as in the find(1) manpage).
        onlyonce=' -h --help -hh --version -v -d -u --url -l -x -m -r -g -c \
        --drop-set-cookie --random-agent \
        --ignore-401 \
        --ignore-proxy --tor \
        --check-tor \
        --skip-urlencode \
        --force-ssl --hpp -o --predict-output --keep-alive \
        --null-connection -p \
        --invalid-bignum --invalid-logical --invalid-string \
        --no-cast --no-escape \
        --text-only \
        --titles \
        -f --fingerprint \
        -a --all -b --banner --current-user --current-db --hostname \
        --is-dba --users --passwords --privileges --roles --dbs --tables \
        --columns --schema --count --dump --dump-all --search --comments \
        -D -T -C -X -U --exclude-sysdbs \
        --sql-shell --common-tables \
        --common-columns --udf-inject \
        --os-shell --os-pwn --os-smbrelay --os-bof \
        --priv-esc --reg-read --reg-add --reg-del \
        -s -t --batch \
        --eta --flush-session \
        --forms --fresh-queries --hex --parse-errors \
        --save --update \
        -z --beep --check-waf --cleanup \
        --dependencies --disable-coloring --identify-waf \
        --mobile --page-rank --purge-output --smart \
        --sqlmap-shell --wizard '
        COMPREPLY=( $( \
            (while read -d ' ' i; do
                [[ -z "$i" || "${onlyonce/ ${i%% *} / }" == "$onlyonce" ]] &&
                continue
                # flatten array with spaces on either side,
                # otherwise we cannot grep on word boundaries of
                # first and last word
                COMPREPLY=" ${COMPREPLY[@]} "
                # remove word from list of completions
                COMPREPLY=( ${COMPREPLY/ ${i%% *} / } )
                done
                printf '%s ' "${COMPREPLY[@]}") <<<"${COMP_WORDS[@]}"
            ) )

    #    else
    #        _filedir bat
        fi
    }


    complete -F _sqlmap sqlmap
# shellcheck shell=bash

__vuejs_completion() {
	local prev=$(_get_pword)
	local curr=$(_get_cword)

	case $prev in
		create)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-p -d -i -m -r -g -n -f -c -x -b -h --help --preset --default --inilinePreset --packageManager --registry --git --no-git --force --merge --clone --proxy --bare  --skipGetStarted" -- "$curr"))
			;;
		add | invoke)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "--registry -h --help" -- "$curr"))
			;;
		inspect)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-v --help --verbose --mode --rule --plugin --plugins --rules" -- "$curr"))
			;;
		serve)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-o -h --help --open -c --copy -p --port" -- "$curr"))
			;;
		build)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-t --target -n --name -d --dest -h --help" -- "$curr"))
			;;
		ui)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-H --host -p --port -D --dev --quiet --headless -h --help" -- "$curr"))
			;;
		init)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-c --clone --offline -h --help" -- "$curr"))
			;;
		config)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-g --get -s --set -d --delete -e --edit --json -h --help" -- "$curr"))
			;;
		outdated)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "--next -h --help" -- "$curr"))
			;;
		upgrade)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-t --to -f --from -r --registry --all --next -h --help" -- "$curr"))
			;;
		migrate)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-f --from -h --help" -- "$curr"))
			;;
		*)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "-h --help -v --version create add invoke inspect serve build ui init config outdated upgrade migrate info" -- "$curr"))
			;;
# shellcheck shell=bash
# minikube (Local Kubernetes) completion

if _command_exists minikube; then
	eval "$(minikube completion bash)"
#!bash
#
# git-flow-completion
# ===================
#
# Bash completion support for [git-flow](http://github.com/nvie/gitflow)
#
# The contained completion routines provide support for completing:
#
#  * git-flow init and version
#  * feature, hotfix and release branches
#  * remote feature branch names (for `git-flow feature track`)
#
#
# Installation
# ------------
#
# To achieve git-flow completion nirvana:
#
#  0. Install git-completion.
#
#  1. Install this file. Either:
#
#     a. Place it in a `bash-completion.d` folder:
#
#        * /etc/bash-completion.d
#        * /usr/local/etc/bash-completion.d
#        * ~/bash-completion.d
#
#     b. Or, copy it somewhere (e.g. ~/.git-flow-completion.sh) and put the following line in
#        your .bashrc:
#
#            source ~/.git-flow-completion.sh
#
#  2. If you are using Git < 1.7.1: Edit git-completion.sh and add the following line to the giant
#     $command case in _git:
#
#         flow)        _git_flow ;;
#
#
# The Fine Print
# --------------
#
# Copyright (c) 2010 [Justin Hileman](http://justinhileman.com)
#
# Distributed under the [MIT License](http://creativecommons.org/licenses/MIT/)

_git_flow ()
{
	local subcommands="init feature release hotfix"
	local subcommand="$(__git_find_subcommand "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	feature)
		__git_flow_feature
		return
		;;
	release)
		__git_flow_release
		return
		;;
	hotfix)
		__git_flow_hotfix
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_feature ()
{
	local subcommands="list start finish publish track diff rebase checkout pull"
	local subcommand="$(__git_find_subcommand "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	pull)
		__gitcomp "$(__git_remotes)"
		return
		;;
	checkout|finish|diff|rebase)
		__gitcomp "$(__git_flow_list_features)"
		return
		;;
	publish)
		__gitcomp "$(comm -23 <(__git_flow_list_features) <(__git_flow_list_remote_features))"
		return
		;;
	track)
		__gitcomp "$(__git_flow_list_remote_features)"
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_list_features ()
{
	git flow feature list 2> /dev/null | tr -d ' |*'
}

__git_flow_list_remote_features ()
{
	git branch -r 2> /dev/null | grep "origin/$(__git_flow_feature_prefix)" | awk '{ sub(/^origin\/$(__git_flow_feature_prefix)/, "", $1); print }'
}

__git_flow_feature_prefix ()
{
	git config gitflow.prefix.feature 2> /dev/null || echo "feature/"
}

__git_flow_release ()
{
	local subcommands="list start finish"
	local subcommand="$(__git_find_subcommand "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	finish)
		__gitcomp "$(__git_flow_list_releases)"
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac

}

__git_flow_list_releases ()
{
	git flow release list 2> /dev/null
}

__git_flow_hotfix ()
{
	local subcommands="list start finish"
	local subcommand="$(__git_find_subcommand "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand" in
	finish)
		__gitcomp "$(__git_flow_list_hotfixes)"
		return
		;;
	*)
		COMPREPLY=()
		;;
	esac
}

__git_flow_list_hotfixes ()
{
	git flow hotfix list 2> /dev/null
}

# temporarily wrap __git_find_on_cmdline() for backwards compatibility
if [ -z "`type -t __git_find_subcommand`" ]; then
#!/usr/bin/env bash
# Bash completion support for Capistrano.

export COMP_WORDBREAKS=${COMP_WORDBREAKS/\:/}

_capcomplete() {
    if [ -f Capfile ]; then
        recent=`ls -t .cap_tasks~ Capfile **/*.cap 2> /dev/null | head -n 1`
        if [[ $recent != '.cap_tasks~' ]]; then
            cap --version | grep 'Capistrano v2.' > /dev/null
            if [ $? -eq 0 ]; then
              # Capistrano 2.x
              cap --tool --verbose --tasks | cut -d " " -f 2 > .cap_tasks~
            else
              # Capistrano 3.x
              cap --all --tasks | cut -d " " -f 2 > .cap_tasks~
            fi
        fi
        COMPREPLY=($(compgen -W "`cat .cap_tasks~`" -- ${COMP_WORDS[COMP_CWORD]}))
        return 0
#!/usr/bin/env bash

# Only operate on MacOS since there are no linux paths
if [[ "$(uname -s)" != 'Darwin' ]] ; then
  _log_warning "unsupported operating system - only 'Darwin' is supported"
  return 0
fi

# Make sure git is installed
_command_exists git || return 0

# Don't handle completion if it's already managed
if complete -p git &>/dev/null ; then
  _log_warning "completion already loaded - this usually means it is safe to stop using this completion"
  return 0
fi

_git_bash_completion_found=false
_git_bash_completion_paths=(
  # MacOS non-system locations
  '/Library/Developer/CommandLineTools/usr/share/git-core/git-completion.bash'
  '/Applications/Xcode.app/Contents/Developer/usr/share/git-core/git-completion.bash'
)

# Load the first completion file found
for _comp_path in "${_git_bash_completion_paths[@]}" ; do
  if [ -r "$_comp_path" ] ; then
    _git_bash_completion_found=true
    source "$_comp_path"
    break
  fi
done

# Cleanup
if [[ "${_git_bash_completion_found}" == false ]]; then
# shellcheck shell=bash
cite "about-completion"
about-completion "Hashicorp consul completion"

if _command_exists consul; then
#!/usr/bin/env bash
# Bash completion support for ssh.

export COMP_WORDBREAKS=${COMP_WORDBREAKS/\:/}

_sshcomplete() {
    local CURRENT_PROMPT="${COMP_WORDS[COMP_CWORD]}"
    if [[ ${CURRENT_PROMPT} == *@*  ]] ; then
      local OPTIONS="-P ${CURRENT_PROMPT/@*/}@ -- ${CURRENT_PROMPT/*@/}"
    else
      local OPTIONS=" -- ${CURRENT_PROMPT}"
    fi

    # parse all defined hosts from .ssh/config and files included there
    for fl in "$HOME/.ssh/config" \
        $(grep "^\s*Include" "$HOME/.ssh/config" |
            awk '{for (i=2; i<=NF; i++) print $i}' |
            sed -Ee "s|^([^/~])|$HOME/.ssh/\1|" -e "s|^~/|$HOME/|")
    do
        if [ -r "$fl" ]; then
            COMPREPLY=( ${COMPREPLY[@]} $(compgen -W "$(grep -i ^Host "$fl" |grep -v '[*!]' | awk '{for (i=2; i<=NF; i++) print $i}' )" ${OPTIONS}) )
        fi
    done

    # parse all hosts found in .ssh/known_hosts
    if [ -r "$HOME/.ssh/known_hosts" ]; then
        if grep -v -q -e '^ ssh-rsa' "$HOME/.ssh/known_hosts" ; then
            COMPREPLY=( ${COMPREPLY[@]} $(compgen -W "$( awk '{print $1}' "$HOME/.ssh/known_hosts" | grep -v ^\| | cut -d, -f 1 | sed -e 's/\[//g' | sed -e 's/\]//g' | cut -d: -f1 | grep -v ssh-rsa)" ${OPTIONS}) )
        fi
    fi

    # parse hosts defined in /etc/hosts
    if [ -r /etc/hosts ]; then
        COMPREPLY=( ${COMPREPLY[@]} $(compgen -W "$( grep -v '^[[:space:]]*$' /etc/hosts | grep -v '^#' | awk '{for (i=2; i<=NF; i++) print $i}' )" ${OPTIONS}) )
    fi
#!/usr/bin/env bash

# nvm (Node Version Manager) completion

if [ "$NVM_DIR" ] && [ -r "$NVM_DIR"/bash_completion ];
#!/bin/bash
# Borrowed from grunt-cli
# http://gruntjs.com/
#
# Copyright jQuery Foundation and other contributors, https://jquery.org/

# This software consists of voluntary contributions made by many
# individuals. For exact contribution history, see the revision history
# available at https://github.com/gruntjs/grunt .

# The following license applies to all parts of this software except as
# documented below:

# ====

# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:

# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

# Usage:
#
# To enable bash <tab> completion for gulp, add the following line (minus the
# leading #, which is the bash comment character) to your ~/.bashrc file:
#
# eval "$(gulp --completion=bash)"
# Enable bash autocompletion.
function _gulp_completions() {
# The currently-being-completed word.
local cur="${COMP_WORDS[COMP_CWORD]}"
#Grab tasks
# shellcheck shell=bash
cite "about-completion"
about-completion "jungle(AWS cli tool) completion"

if _command_exists jungle; then
# shellcheck shell=bash

# https://pip.pypa.io/en/stable/user_guide/#command-completion
# Of course, you should first install pip, say on Debian:
# sudo apt-get install python-pip
# If the pip package is installed within virtual environments, say, python managed by pyenv,
# you should first initialize the corresponding environment.
# So that pip is in the system's path.
if _command_exists pip; then
	eval "$(pip completion --bash)"
# shellcheck shell=bash
cite "about-completion"
about-completion "GitHub CLI completion"

if _binary_exists gh; then
# shellcheck shell=bash
_sdkman_complete() {
	local CANDIDATES
	local CANDIDATE_VERSIONS

	COMPREPLY=()

	if [ "$COMP_CWORD" -eq 1 ]; then
		mapfile -t COMPREPLY < <(compgen -W "install uninstall rm list ls use default home env current upgrade ug version broadcast help offline selfupdate update flush" -- "${COMP_WORDS[COMP_CWORD]}")
	elif [ "$COMP_CWORD" -eq 2 ]; then
		case "${COMP_WORDS[COMP_CWORD - 1]}" in
			"install" | "i" | "uninstall" | "rm" | "list" | "ls" | "use" | "u" | "default" | "d" | "home" | "h" | "current" | "c" | "upgrade" | "ug")
				CANDIDATES=$(echo "${SDKMAN_CANDIDATES_CSV}" | tr ',' ' ')
				mapfile -t COMPREPLY < <(compgen -W "$CANDIDATES" -- "${COMP_WORDS[COMP_CWORD]}")
				;;
			"env")
				mapfile -t COMPREPLY < <(compgen -W "init" -- "${COMP_WORDS[COMP_CWORD]}")
				;;
			"offline")
				mapfile -t COMPREPLY < <(compgen -W "enable disable" -- "${COMP_WORDS[COMP_CWORD]}")
				;;
			"selfupdate")
				mapfile -t COMPREPLY < <(compgen -W "force" -- "${COMP_WORDS[COMP_CWORD]}")
				;;
			"flush")
				mapfile -t COMPREPLY < <(compgen -W "archives tmp broadcast version" -- "${COMP_WORDS[COMP_CWORD]}")
				;;
			*) ;;

		esac
	elif [ "$COMP_CWORD" -eq 3 ]; then
		case "${COMP_WORDS[COMP_CWORD - 2]}" in
			"uninstall" | "rm" | "use" | "u" | "default" | "d" | "home" | "h")
				_sdkman_candidate_local_versions "${COMP_WORDS[COMP_CWORD - 1]}"
				mapfile -t COMPREPLY < <(compgen -W "$CANDIDATE_VERSIONS" -- "${COMP_WORDS[COMP_CWORD]}")
				;;
			"install" | "i")
				_sdkman_candidate_all_versions "${COMP_WORDS[COMP_CWORD - 1]}"
				mapfile -t COMPREPLY < <(compgen -W "$CANDIDATE_VERSIONS" -- "${COMP_WORDS[COMP_CWORD]}")
				;;
			*) ;;

		esac
	fi

	return 0
}

_sdkman_candidate_local_versions() {

	CANDIDATE_VERSIONS=$(__sdkman_cleanup_local_versions "$1")

}

_sdkman_candidate_all_versions() {

	candidate="$1"
	CANDIDATE_LOCAL_VERSIONS=$(__sdkman_cleanup_local_versions "$candidate")
	if [ "$SDKMAN_OFFLINE_MODE" = "true" ]; then
		CANDIDATE_VERSIONS=$CANDIDATE_LOCAL_VERSIONS
	else
		# sdkman has a specific output format for Java candidate since
		# there are multiple vendors and builds.
		if [ "$candidate" = "java" ]; then
			CANDIDATE_ONLINE_VERSIONS="$(__sdkman_list_versions "$candidate" | grep " " | grep "\." | cut -c 62-)"
		else
			CANDIDATE_ONLINE_VERSIONS="$(__sdkman_list_versions "$candidate" | grep " " | grep "\." | cut -c 6-)"
		fi
		# the last grep is used to filter out sdkman flags, such as:
		# "+" - local version
		# "*" - installed
		# ">" - currently in use
		CANDIDATE_VERSIONS="$(echo "$CANDIDATE_ONLINE_VERSIONS $CANDIDATE_LOCAL_VERSIONS" | tr ' ' '\n' | grep -v -e '^[[:space:]|\*|\>|\+]*$' | sort | uniq -u) "
	fi

}

__sdkman_cleanup_local_versions() {

	__sdkman_build_version_csv "$1" | tr ',' ' '
# shellcheck shell=bash
about-completion "completion for go command using gocomplete"

# bash completion for go tool
# https://github.com/posener/complete

# Test `go version` because goenv creates shim scripts that will be found in PATH
# but do not always resolve to a working install.
if _command_exists go && go version &> /dev/null; then
	# Same idea here, but no need to test a subcommand
#!/usr/bin/bash
_vboxmanage_realopts() {
    echo $(vboxmanage|grep -i vboxmanage|cut -d' ' -f2|grep '\['|tr -s '[\[\|\]\n' ' ')
    echo " "
}

__vboxmanage_startvm() {
    RUNNING=$(vboxmanage list runningvms | cut -d' ' -f1 | tr -d '"')
    TOTAL=$(vboxmanage list vms | cut -d' ' -f1 | tr -d '"')

    AVAILABLE=""
    for VM in $TOTAL; do
    MATCH=0;
    for RUN in $RUNNING "x"; do
        if [ "$VM" == "$RUN" ]; then
        MATCH=1
        fi
    done
    (( $MATCH == 0 )) && AVAILABLE="$AVAILABLE $VM "
    done
    echo $AVAILABLE
}

__vboxmanage_list() {
    INPUT=$(vboxmanage list | tr -s '[\[\]\|\n]' ' ' | cut -d' ' -f4-)

    PRUNED=""
    if [ "$1" == "long" ]; then
    for WORD in $INPUT; do
        [ "$WORD" == "-l" ] && continue;
        [ "$WORD" == "--long" ] && continue;

        PRUNED="$PRUNED $WORD"
    done
    else
    PRUNED=$INPUT
    fi

    echo $PRUNED
}


__vboxmanage_list_vms() {
    VMS=""
    if [ "x$1" == "x" ]; then
    SEPARATOR=" "
    else
    SEPARATOR=$1
    fi

    for VM in $(vboxmanage list vms | cut -d' ' -f1 | tr -d '"'); do
    [ "$VMS" != "" ] && VMS="${VMS}${SEPARATOR}"
    VMS="${VMS}${VM}"
    done

    echo $VMS
}

__vboxmanage_list_runningvms() {
    VMS=""
    if [ "$1" == "" ]; then
    SEPARATOR=" "
    else
    SEPARATOR=$1
    fi

    for VM in $(vboxmanage list runningvms | cut -d' ' -f1 | tr -d '"'); do
    [ "$VMS" != "" ] && VMS="${VMS}${SEPARATOR}"
    VMS="${VMS}${VM}"
    done

    echo $VMS

}

__vboxmanage_controlvm() {
    echo "pause resume reset poweroff savestate acpipowerbutton"
    echo "acpisleepbutton keyboardputscancode guestmemoryballoon"
    echo "gueststatisticsinterval usbattach usbdetach vrde vrdeport"
    echo "vrdeproperty vrdevideochannelquality setvideomodehint"
    echo "screenshotpng setcredentials teleport plugcpu unplugcpu"
    echo "cpuexecutioncap"

# setlinkstate<1-N>
# nic<1-N> null|nat|bridged|intnet|hostonly|generic
#                                      [<devicename>] |
                          # nictrace<1-N> on|off
                          #   nictracefile<1-N> <filename>
                          #   nicproperty<1-N> name=[value]
                          #   natpf<1-N> [<rulename>],tcp|udp,[<hostip>],
                          #                 <hostport>,[<guestip>],<guestport>
                          #   natpf<1-N> delete <rulename>

}

__vboxmanage_default() {
    realopts=$(_vboxmanage_realopts)
    opts=$realopts$(vboxmanage | grep -i vboxmanage | cut -d' ' -f2 | grep -v '\[' | sort | uniq)
    pruned=""

    # echo ""
    # echo "DEBUG: cur: $cur, prev: $prev"
    # echo "DEBUG: default: |$p1|$p2|$p3|$p4|"
    case ${cur} in
    -*)
        echo $opts
        # COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
        ;;
    esac;

    for WORD in $opts; do
    MATCH=0
    for OPT in "${COMP_WORDS[@]}"; do
            # opts=$(echo ${opts} | grep -v $OPT);
        if [ "$OPT" == "$WORD" ]; then
        MATCH=1
        break;
        fi
        if [ "$OPT" == "-v" ] && [ "$WORD" == "--version" ]; then
        MATCH=1
        break;
        fi
        if [ "$OPT" == "--version" ] && [ "$WORD" == "-v" ]; then
        MATCH=1
        break;
        fi
        if [ "$OPT" == "-q" ] && [ "$WORD" == "--nologo" ]; then
        MATCH=1
        break;
        fi
        if [ "$OPT" == "--nologo" ] && [ "$WORD" == "-q" ]; then
        MATCH=1
        break;
        fi
    done
    (( $MATCH == 1 )) && continue;
    pruned="$pruned $WORD"

    done

    # COMPREPLY=($(compgen -W "${pruned}" -- ${cur}))
    echo $pruned
    return 0
}

_vboxmanage() {
    # vboxmanage | grep -i vboxmanage | cut -d' ' -f2 | sort | uniq
    local cur p1 p2 p3 p4 opts
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"

    # echo "cur: |$cur|"
    # echo "prev: |$prev|"

    # In case current is complete command
    case $cur in
    startvm|list|controlvm)
        COMPREPLY=($(compgen -W "$cur "))
        return 0
        ;;
    esac

    case $prev in
    -v|--version)
        return 0
        ;;

    -l|--long)
        opts=$(__vboxmanage_list "long")
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
        ;;
    startvm|list)
        opts=$(__vboxmanage_$prev)
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
        ;;
    --type)
        COMPREPLY=($(compgen -W "gui headless" -- ${cur}))
        return 0
        ;;
    gui|headless)
        # Done. no more completion possible
        return 0
        ;;
    vboxmanage|-q|--nologo)
        # echo "Got vboxmanage"
        opts=$(__vboxmanage_default)
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
        ;;
    controlvm)
        opts=$(__vboxmanage_list_vms)
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
        ;;
    esac

    for VM in $(__vboxmanage_list_vms); do
    if [ "$VM" == "$prev" ]; then
        pprev=${COMP_WORDS[COMP_CWORD-2]}
        # echo "previous: $pprev"
        case $pprev in
        startvm)
            opts="--type"
            COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
            return 0
            ;;
        controlvm)
            opts=$(__vboxmanage_controlvm)
            COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
            return 0;
            ;;
        esac
    fi
    done

    # echo "Got to end withoug completion"
#!/usr/bin/env bash
# Bash completion support for the 'dirs' plugin (commands G, R).

_dirs-complete() {
    local CURRENT_PROMPT="${COMP_WORDS[COMP_CWORD]}"

    # parse all defined shortcuts from ~/.dirs
    if [ -r "$HOME/.dirs" ]; then
        COMPREPLY=($(compgen -W "$(grep -v '^#' ~/.dirs | sed -e 's/\(.*\)=.*/\1/')" -- ${CURRENT_PROMPT}) )
    fi
#!/bin/bash

# grunt-cli
# http://gruntjs.com/
#
# Copyright jQuery Foundation and other contributors, https://jquery.org/

# This software consists of voluntary contributions made by many
# individuals. For exact contribution history, see the revision history
# available at https://github.com/gruntjs/grunt .

# The following license applies to all parts of this software except as
# documented below:

# ====

# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:

# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

# Usage:
#
# To enable bash <tab> completion for grunt, add the following line (minus the
# leading #, which is the bash comment character) to your ~/.bashrc file:
#
# eval "$(grunt --completion=bash)"

# Search the current directory and all parent directories for a gruntfile.
function _grunt_gruntfile() {
  local curpath="$PWD"
  while [[ "$curpath" ]]; do
    for gruntfile in "$curpath/"{G,g}runtfile.{js,coffee}; do
      if [[ -e "$gruntfile" ]]; then
        echo "$gruntfile"
        return
      fi
    done
    curpath="${curpath%/*}"
  done
  return 1
}

# Enable bash autocompletion.
function _grunt_completions() {
  # The currently-being-completed word.
  local cur="${COMP_WORDS[COMP_CWORD]}"
  # The current gruntfile, if it exists.
  local gruntfile="$(_grunt_gruntfile)"
  # The current grunt version, available tasks, options, etc.
  local gruntinfo="$(grunt --version --verbose 2>/dev/null)"
  # Options and tasks.
  local opts="$(echo "$gruntinfo" | awk '/Available options: / {$1=$2=""; print $0}')"
  local compls="$(echo "$gruntinfo" | awk '/Available tasks: / {$1=$2=""; print $0}')"
  # Only add -- or - options if the user has started typing -
  [[ "$cur" == -* ]] && compls="$compls $opts"
__kitchen_instance_list () {
  # cache to .kitchen.list.yml
  if [[ .kitchen.yml -nt .kitchen.list.yml || .kitchen.local.yml -nt .kitchen.list.yml ]]; then
    # update list if config has updated
    kitchen list --bare > .kitchen.list.yml
  fi
  cat .kitchen.list.yml
}

__kitchen_options () {
  cur="${COMP_WORDS[COMP_CWORD]}"
  prev="${COMP_WORDS[COMP_CWORD-1]}"
  COMPREPLY=()

  case $prev in
    converge|create|destroy|diagnose|list|login|setup|test|verify)
      COMPREPLY=( $(compgen -W "$(__kitchen_instance_list)" -- ${cur} ))
      return 0
      ;;
    driver)
      COMPREPLY=( $(compgen -W "create discover help"  -- ${cur} ))
      return 0
      ;;
    *)
      COMPREPLY=( $(compgen -W "console converge create destroy driver help init list login setup test verify version"  -- ${cur} ))
#!/usr/bin/env bash

# Make sure terraform is installed
_command_exists terraform || return

# shellcheck shell=bash
cite "about-completion"
about-completion "gem completion"

__gem_completion() {
	local cur=${COMP_WORDS[COMP_CWORD]}
	local prev=${COMP_WORDS[COMP_CWORD - 1]}
	case $prev in
		install)
			# list the remote gems and add to completion
			if [ -z "$REMOTE_GEMS" ]; then
				read -r -a REMOTE_GEMS <<< "$(gem list --remote --no-versions | sed 's/\*\*\* REMOTE GEMS \*\*\*//' | tr '\n' ' ')"
			fi

			local cur=${COMP_WORDS[COMP_CWORD]}
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "${REMOTE_GEMS[*]}" -- "$cur"))
			return 0
			;;
		uninstall)
			# list all local installed gems and add to completion
			read -r -a LOCAL_GEMS <<< "$(gem list --no-versions | sed 's/\*\*\* LOCAL GEMS \*\*\*//' | tr '\n' ' ')"

			local cur=${COMP_WORDS[COMP_CWORD]}
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "${LOCAL_GEMS[*]}" -- "$cur"))
			return 0
			;;
	esac
	local commands=(build cert check cleanup contents dependency environment fetch generate_index help install list lock outdated owner pristine push query rdoc search server sources specification stale uninstall unpack update which)
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Copyright (c) 2020 SaltStack Team

# Original Author:
# written by David Pravec
#   - feel free to /msg alekibango on IRC if you want to talk about this file

# TODO: check if --config|-c was used and use configured config file for queries
# TODO: solve somehow completion for  salt -G pythonversion:[tab]
#       (not sure what to do with lists)
# TODO: --range[tab] --   how?
# TODO: --compound[tab] -- how?
# TODO: use history to extract some words, esp. if ${cur} is empty
# TODO: TEST EVERYTHING a lot
# TODO: cache results of some functions?  where? how long?
# TODO: is it ok to use '--timeout 2' ?


_salt_get_grains(){
    if [ "$1" = 'local' ] ; then
        salt-call --out=txt -- grains.ls | sed  's/^.*\[//' | tr -d ",']" |sed 's:\([a-z0-9]\) :\1\: :g'
    else
      salt '*' --timeout 2 --out=txt -- grains.ls | sed  's/^.*\[//' | tr -d ",']" |sed 's:\([a-z0-9]\) :\1\: :g'
    fi
}

_salt_get_grain_values(){
    if [ "$1" = 'local' ] ; then
        salt-call --out=txt -- grains.item $1 |sed 's/^\S*:\s//' |grep -v '^\s*$'
    else
        salt '*' --timeout 2 --out=txt -- grains.item $1 |sed 's/^\S*:\s//' |grep -v '^\s*$'
    fi
}


_salt(){
    local cur prev opts _salt_grains _salt_coms pprev ppprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    if [ ${COMP_CWORD} -gt 2 ]; then
    pprev="${COMP_WORDS[COMP_CWORD-2]}"
    fi
    if [ ${COMP_CWORD} -gt 3 ]; then
    ppprev="${COMP_WORDS[COMP_CWORD-3]}"
    fi

    opts="-h --help -d --doc --documentation --version --versions-report -c \
          --config-dir= -v --verbose -t --timeout= -s --static -b --batch= \
          --batch-size= -E --pcre -L --list -G --grain --grain-pcre -N \
          --nodegroup -R --range -C --compound -I --pillar \
          --return= -a --auth= --eauth= --extended-auth= -T --make-token -S \
          --ipcidr --out=pprint --out=yaml --out=overstatestage --out=json \
          --out=raw --out=highstate --out=key --out=txt --no-color --out-indent= "

    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    # 2 special cases for filling up grain values
    case "${pprev}" in
    -G|--grain|--grain-pcre)
    if [ "${cur}" = ":" ]; then
        COMPREPLY=($(compgen -W "`_salt_get_grain_values ${prev}`"  ))
        return 0
    fi
    ;;
    esac
    case "${ppprev}" in
    -G|--grain|--grain-pcre)
        if [ "${prev}" = ":" ]; then
        COMPREPLY=( $(compgen -W "`_salt_get_grain_values ${pprev}`" -- ${cur}) )
        return 0
        fi
    ;;
    esac

    if [ "${cur}" = "=" ] && [[ "${prev}" == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ "${pprev}" == --* ]]; then
       prev="${pprev}"
    fi

   case "${prev}" in

     -c|--config)
        COMPREPLY=($(compgen -f -- ${cur}))
        return 0
        ;;
     salt)
        COMPREPLY=($(compgen -W "\'*\' ${opts} `salt-key --no-color -l acc`" -- ${cur}))
        return 0
        ;;
     -E|--pcre)
        COMPREPLY=($(compgen -W "`salt-key --no-color -l acc`" -- ${cur}))
        return 0
        ;;
     -G|--grain|--grain-pcre)
        COMPREPLY=($(compgen -W "$(_salt_get_grains)" -- ${cur}))
        return 0
        ;;
     -C|--compound)
        COMPREPLY=() # TODO: finish this one? how?
        return 0
        ;;
     -t|--timeout)
        COMPREPLY=($( compgen -W "1 2 3 4 5 6 7 8 9 10 15 20 30 40 60 90 120 180" -- ${cur}))
        return 0
        ;;
     -b|--batch|--batch-size)
        COMPREPLY=($(compgen -W "1 2 3 4 5 6 7 8 9 10 15 20 30 40 50 60 70 80 90 100 120 150 200"))
        return 0
        ;;
     -N|--nodegroup)
        MASTER_CONFIG='/etc/salt/master'
        COMPREPLY=($(compgen -W "`awk -F ':'  'BEGIN {print_line = 0};  /^nodegroups/ {print_line = 1;getline } print_line && /^  */ {print $1} /^[^ ]/ {print_line = 0}' <${MASTER_CONFIG}`" -- ${cur}))
        return 0
     ;;
    esac

    _salt_coms="$(salt '*' --timeout 2 --out=txt -- sys.list_functions | sed 's/^.*\[//' | tr -d ",']" )"
    all="${opts} ${_salt_coms}"
    COMPREPLY=( $(compgen -W "${all}" -- ${cur}) )

  return 0
}

complete -F _salt salt


_saltkey(){
    local cur prev opts prev pprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    opts="-c --config-dir= -h --help --version --versions-report -q --quiet \
          -y --yes --gen-keys= --gen-keys-dir= --keysize= --key-logfile= \
          -l --list= -L --list-all -a --accept= -A --accept-all \
          -r --reject= -R --reject-all -p --print= -P --print-all \
          -d --delete= -D --delete-all -f --finger= -F --finger-all \
          --out=pprint --out=yaml --out=overstatestage --out=json --out=raw \
          --out=highstate --out=key --out=txt --no-color --out-indent= "
    if [ ${COMP_CWORD} -gt 2 ]; then
        pprev="${COMP_WORDS[COMP_CWORD-2]}"
    fi
    if [ ${COMP_CWORD} -gt 3 ]; then
        ppprev="${COMP_WORDS[COMP_CWORD-3]}"
    fi
    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    if [ "${cur}" = "=" ] && [[ "${prev}" == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ "${pprev}" == --* ]]; then
       prev="${pprev}"
    fi

    case "${prev}" in
     -a|--accept)
        COMPREPLY=($(compgen -W "$(salt-key -l un --no-color; salt-key -l rej --no-color)" -- ${cur}))
        return 0
      ;;
     -r|--reject)
        COMPREPLY=($(compgen -W "$(salt-key -l acc --no-color)" -- ${cur}))
        return 0
        ;;
     -d|--delete)
        COMPREPLY=($(compgen -W "$(salt-key -l acc --no-color; salt-key -l un --no-color; salt-key -l rej --no-color)" -- ${cur}))
        return 0
        ;;
     -c|--config)
        COMPREPLY=($(compgen -f -- ${cur}))
        return 0
        ;;
     --keysize)
        COMPREPLY=($(compgen -W "2048 3072 4096 5120 6144" -- ${cur}))
        return 0
        ;;
     --gen-keys)
        return 0
        ;;
     --gen-keys-dir)
        COMPREPLY=($(compgen -d -- ${cur}))
        return 0
        ;;
     -p|--print)
        COMPREPLY=($(compgen -W "$(salt-key -l acc --no-color; salt-key -l un --no-color; salt-key -l rej --no-color)" -- ${cur}))
        return 0
     ;;
     -l|--list)
        COMPREPLY=($(compgen -W "pre un acc accepted unaccepted rej rejected all" -- ${cur}))
        return 0
     ;;
     --accept-all)
        return 0
     ;;
    esac
    COMPREPLY=($(compgen -W "${opts} " -- ${cur}))
    return 0
}

complete -F _saltkey salt-key

_saltcall(){
    local cur prev opts _salt_coms pprev ppprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    opts="-h --help -d --doc --documentation --version --versions-report \
          -m --module-dirs= -g --grains --return= --local -c --config-dir= -l --log-level= \
          --out=pprint --out=yaml --out=overstatestage --out=json --out=raw \
          --out=highstate --out=key --out=txt --no-color --out-indent= "
    if [ ${COMP_CWORD} -gt 2 ]; then
        pprev="${COMP_WORDS[COMP_CWORD-2]}"
    fi
    if [ ${COMP_CWORD} -gt 3 ]; then
        ppprev="${COMP_WORDS[COMP_CWORD-3]}"
    fi
    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    if [ "${cur}" = "=" ] && [[ ${prev} == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ ${pprev} == --* ]]; then
       prev="${pprev}"
    fi

    case ${prev} in
    -m|--module-dirs)
        COMPREPLY=( $(compgen -d ${cur} ))
        return 0
        ;;
    -l|--log-level)
        COMPREPLY=( $(compgen -W "info none garbage trace warning error debug" -- ${cur}))
        return 0
        ;;
    -g|grains)
        return 0
        ;;
    salt-call)
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
        ;;
    esac

    _salt_coms="$(salt-call --out=txt -- sys.list_functions|sed 's/^.*\[//' | tr -d ",']"  )"
    COMPREPLY=( $(compgen -W "${opts} ${_salt_coms}" -- ${cur} ))
    return 0
}

complete -F _saltcall salt-call


_saltcp(){
    local cur prev opts target prefpart postpart helper filt pprev ppprev
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    opts="-t --timeout= -s --static -b --batch= --batch-size= \
          -h --help --version --versions-report -c --config-dir= \
          -E --pcre -L --list -G --grain --grain-pcre -N --nodegroup \
          -R --range -C --compound -I --pillar \
          --out=pprint --out=yaml --out=overstatestage --out=json --out=raw \
          --out=highstate --out=key --out=txt --no-color --out-indent= "
    if [[ "${cur}" == -* ]] ; then
        COMPREPLY=($(compgen -W "${opts}" -- ${cur}))
        return 0
    fi

    if [ "${cur}" = "=" ] && [[ "${prev}" == --* ]]; then
       cur=""
    fi
    if [ "${prev}" = "=" ] && [[ "${pprev}" == --* ]]; then
       prev=${pprev}
    fi

    case ${prev} in
    salt-cp)
        COMPREPLY=($(compgen -W "${opts} `salt-key -l acc --no-color`" -- ${cur}))
        return 0
    ;;
    -t|--timeout)
        # those numbers are just a hint
        COMPREPLY=($(compgen -W "2 3 4 8 10 15 20 25 30 40 60 90 120 180 240 300" -- ${cur} ))
        return 0
    ;;
    -E|--pcre)
        COMPREPLY=($(compgen -W "`salt-key -l acc --no-color`" -- ${cur}))
        return 0
    ;;
    -L|--list)
        # IMPROVEMENTS ARE WELCOME
        prefpart="${cur%,*},"
        postpart=${cur##*,}
        filt="^\($(echo ${cur}| sed 's:,:\\|:g')\)$"
            helper=($(salt-key -l acc --no-color | grep -v "${filt}" | sed "s/^/${prefpart}/"))
        COMPREPLY=($(compgen -W "${helper[*]}" -- ${cur}))

        return 0
    ;;
    -G|--grain|--grain-pcre)
        COMPREPLY=($(compgen -W "$(_salt_get_grains)" -- ${cur}))
        return 0
        ;;
        # FIXME
    -R|--range)
        # FIXME ??
        return 0
    ;;
    -C|--compound)
        # FIXME ??
        return 0
    ;;
    -c|--config)
        COMPREPLY=($(compgen -f -- ${cur}))
        return 0
    ;;
    esac

   # default is using opts:
   COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
# ------------------------------------------------------------
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
# ------------------------------------------------------------

# Programmable completion for the Subversion svn command under bash. Source
# this file (or on some systems add it to ~/.bash_completion and start a new
# shell) and bash's completion mechanism will know all about svn's options!
# Provides completion for the svnadmin, svndumpfilter, svnlook and svnsync
# commands as well.  Who wants to read man pages/help text...

# Known to work with bash 3.* with programmable completion and extended
# pattern matching enabled (use 'shopt -s extglob progcomp' to enable
# these if they are not already enabled).

shopt -s extglob

# Tree helper functions which only use bash, to ease readability.

# look for value associated to key from stdin in K/V hash file format
# val=$(_svn_read_hashfile svn:realmstring < some/file)
function _svn_read_hashfile()
{
  local tkey=$1 key= val=
  while true; do
    read tag len
    [ $tag = 'END' ] && break
    [ $tag != 'K' ] && {
      #echo "unexpected tag '$tag' instead of 'K'" >&2
      return
    }
    read -r -n $len key ; read
    read tag len
    [ $tag != 'V' ] && {
      #echo "unexpected tag '$tag' instead of 'V'" >&2
      return
    }
    read -r -n $len val ; read
    if [[ $key = $tkey ]] ; then
      echo "$val"
      return
    fi
  done
  #echo "target key '$tkey' not found" >&2
}

# _svn_grcut shell-regular-expression
# extract filenames from 'svn status' output
function _svn_grcut()
{
    local re=$1 line= old_IFS
    # fix IFS, so that leading spaces are not ignored by next read.
    # (there is a leading space in svn status output if only a prop is changed)
    old_IFS="$IFS"
    IFS=$'\n'
    while read -r line ; do
	[[ ! $re || $line == $re ]] && echo "${line/????????/}"
    done
    IFS="$old_IFS"
}

# extract stuff from svn info output
# _svn_info (URL|Repository Root)
function _svn_info()
{
  local what=$1 line=
  LANG=C LC_MESSAGES=C svn info --non-interactive 2> /dev/null | \
  while read line ; do
    [[ $line == *"$what: "* ]] && echo ${line#*: }
  done
}

# _svn_lls (dir|file|all) files...
# list svn-managed files from list
# some 'svn status --all-files' would be welcome here?
function _svn_lls()
{
    local opt=$1 f=
    shift
    for f in "$@" ; do
	# could try to check in .svn/entries? hmmm...
	if [[ $opt == @(dir|all) && -d "$f" ]] ; then
	    echo "$f/"
	elif [[ $opt == @(file|all) ]] ; then
	    # split f in directory/file names
	    local dn= fn="$f"
	    [[ "$f" == */* ]] && dn=${f%\/*}/ fn=${f##*\/}
	    # ??? this does not work for just added files, because they
	    # do not have a content reference yet...
	    [ -f "${dn}.svn/text-base/${fn}.svn-base" ] && echo "$f"
	fi
    done
}

# This completion guides the command/option order along the one suggested
# by "svn help", although other syntaxes are allowed.
#
# - there is a "real" parser to check for what is available and deduce what
#   can be suggested further.
# - the syntax should be coherent with subversion/svn/{cl.h,main.c}
# - although it is not a good practice, mixed options and arguments
#   is supported by the completion as it is by the svn command.
# - the completion works in the middle of a line,
#   but not really in the middle of an argument or option.
# - property names are completed: see comments about issues related to handling
#   ":" within property names although it is a word completion separator.
# - unknown properties are assumed to be simple file properties.
# - --revprop and --revision options are forced to revision properties
#   as they are mandatory in this case.
# - argument values are suggested to some other options, eg directory names
#   for --config-dir.
# - values for some options can be extended with environment variables:
#   SVN_BASH_FILE_PROPS: other properties on files/directories
#   SVN_BASH_REV_PROPS: other properties on revisions
#   SVN_BASH_ENCODINGS: encodings to be suggested
#   SVN_BASH_MIME_TYPE: mime types to be suggested
#   SVN_BASH_KEYWORDS: "svn:keywords" substitutions to be suggested
#   SVN_BASH_USERNAME: usernames suggested for --username
#   SVN_BASH_COMPL_EXT: completion extensions for file arguments, based on the
#      current subcommand, so that for instance only modified files are
#      suggested for 'revert', only not svn-managed files for 'add', and so on.
#      Possible values are:
#      - username: guess usernames from ~/.subversion/auth/...
#      - urls: guess urls from ~/.subversion/auth/... or others
#      - svnstatus: use 'svn status' for completion
#      - recurse: allow recursion (expensive)
#      - externals: recurse into externals (very expensive)
#     Former options are reasonable, but beware that both later options
#     may be unadvisable if used on large working copies.
#     None of these costly completions are activated by default.
#     Argument completion outside a working copy results in an error message.
#     Filenames with spaces are not completed properly.
#
# TODO
# - other options?
# - obsolete options could be removed from auto-comp? (e.g. -N)
# - obsolete commands could be removed? (e.g. resolved)
# - completion does not work properly when editing in the middle of the line
#   status/previous are those at the end of the line, not at the entry position
# - url completion should select more cases where it is relevant
# - url completion of http:// schemas could suggest sub directories?
# - add completion for experimental 'obliterate' feature?
_svn()
{
	local cur cmds cmdOpts pOpts mOpts rOpts qOpts nOpts optsParam opt

	COMPREPLY=()
	cur=${COMP_WORDS[COMP_CWORD]}

	# Possible expansions, without pure-prefix abbreviations such as "up".
	cmds='add blame annotate praise cat changelist cl checkout co cleanup'
	cmds="$cmds commit ci copy cp delete remove rm diff export help import"
	cmds="$cmds info list ls lock log merge mergeinfo mkdir move mv rename"
	cmds="$cmds patch propdel pdel propedit pedit propget pget proplist"
	cmds="$cmds plist propset pset relocate resolve resolved revert status"
	cmds="$cmds  switch unlock update upgrade"

	# help options have a strange command status...
	local helpOpts='--help -h'
	# all special options that have a command status
	local specOpts="--version $helpOpts"

	# options that require a parameter
	# note: continued lines must end '|' continuing lines must start '|'
	optsParam="-r|--revision|--username|--password|--targets"
	optsParam="$optsParam|-x|--extensions|-m|--message|-F|--file"
	optsParam="$optsParam|--encoding|--diff-cmd|--diff3-cmd|--editor-cmd"
	optsParam="$optsParam|--old|--new|--config-dir|--config-option"
	optsParam="$optsParam|--native-eol|-l|--limit|-c|--change"
	optsParam="$optsParam|--depth|--set-depth|--with-revprop"
	optsParam="$optsParam|--cl|--changelist|--accept|--show-revs"

	# svn:* and other (env SVN_BASH_*_PROPS) properties
	local svnProps revProps allProps psCmds propCmds

	# svn and user configured "file" (or directory) properties
	# the "svn:mergeinfo" prop is not included by default because it is
	# managed automatically, so there should be no need to edit it by hand.
	svnProps="svn:keywords svn:executable svn:needs-lock svn:externals
	          svn:ignore svn:eol-style svn:mime-type $SVN_BASH_FILE_PROPS"

	# svn and user configured revision properties
	revProps="svn:author svn:log svn:date $SVN_BASH_REV_PROPS"

	# all properties as an array variable
	allProps=( $svnProps $revProps )

	# subcommands that expect property names
	psCmds='propset|pset|ps'
	propCmds="$psCmds|propget|pget|pg|propedit|pedit|pe|propdel|pdel|pd"

	# possible URL schemas to access a subversion server
	local urlSchemas='file:/// http:// https:// svn:// svn+ssh://'

	# Parse arguments and set various variables about what was found.
	#
	# cmd: the current command if available
	#    isPropCmd: whether it expects a property name argument
	#    isPsCmd: whether it also expects a property value argument
	#    isHelpCmd: whether it is about help
	#    nExpectArgs: how many arguments are expected by the command
	# help: help requested about this command (if cmd=='help')
	# prop: property name (if appropriate)
	#    isRevProp: is it a special revision property
	# val: property value (if appropriate, under pset)
	# options: all options encountered
	#    hasRevPropOpt: is --revprop set
	#    hasRevisionOpt: is --revision set
	#    hasRelocateOpt: is --relocate set
	#    hasReintegrateOpt: is --reintegrate set
	#    acceptOpt: the value of --accept
	# nargs: how many arguments were found
	# stat: status of parsing at the 'current' word
	#
	# prev: previous command in the loop
	# last: status of last parameter analyzed
	# i: index
	local cmd= isPropCmd= isPsCmd= isHelpCmd= nExpectArgs= isCur= i=0
	local prev= help= prop= val= isRevProp= last='none' nargs=0 stat=
	local options= hasRevPropOpt= hasRevisionOpt= hasRelocateOpt=
	local acceptOpt= URL= hasReintegrateOpt=

	for opt in "${COMP_WORDS[@]}"
	do
	    # get status of current word (from previous iteration)
	    [[ $isCur ]] && stat=$last

	    # are we processing the current word
	    isCur=
	    [[ $i -eq $COMP_CWORD ]] && isCur=1
	    let i++

	    # FIRST must be the "svn" command
	    [ $last = 'none' ] && { last='first'; continue ; }

	    # SKIP option arguments
	    if [[ $prev == @($optsParam) ]] ; then

		# record accept value
		[[ $prev = '--accept' ]] && acceptOpt=$opt

		prev=''
		last='skip'
		continue ;
	    fi

	    # Argh...  This looks like a bash bug...
	    # Redirections are passed to the completion function
	    # although it is managed by the shell directly...
	    # It matters because we want to tell the user when no more
	    # completion is available, so it does not necessary
	    # fallback to the default case.
	    if [[ $prev == @(<|>|>>|[12]>|[12]>>) ]] ; then
		prev=''
		last='skip'
		continue ;
	    fi
	    prev=$opt

	    # get the subCoMmanD
	    if [[ ! $cmd && $opt \
               && ( $opt != -* || $opt == @(${specOpts// /|}) ) ]]
            then
		cmd=$opt
		[[ $cmd == @($propCmds) ]] && isPropCmd=1
		[[ $cmd == @($psCmds) ]] && isPsCmd=1
		[[ $cmd == @(${helpOpts// /|}) ]] && cmd='help'
		[[ $cmd = 'help' ]] && isHelpCmd=1
	        # HELP about a command asked with an option
		if [[ $isHelpCmd && $cmd && $cmd != 'help' && ! $help ]]
		then
		    help=$cmd
		    cmd='help'
		fi
		last='cmd'
		continue
	    fi

	    # HELP about a command
	    if [[ $isHelpCmd && ! $help && $opt && $opt != -* ]]
	    then
		help=$opt
		last='help'
		continue
	    fi

	    # PROPerty name
	    if [[ $isPropCmd && ! $prop && $opt && $opt != -* ]]
	    then
		prop=$opt
		[[ $prop == @(${revProps// /|}) ]] && isRevProp=1
		last='prop'
		continue
	    fi

	    # property VALue
	    if [[ $isPsCmd && $prop && ! $val && $opt != -* ]] ;
	    then
		val=$opt
		last='val'
		continue
	    fi

	    if [[ $last != 'onlyarg' ]]
	    then
	      # more OPTions
	      case $opt in
		  -r|--revision|--revision=*)
		      hasRevisionOpt=1
		      ;;
		  --revprop)
		      hasRevPropOpt=1
		      # restrict to revision properties!
		      allProps=( $revProps )
		      # on revprops, only one URL is expected
		      nExpectArgs=1
		      ;;
		  -h|--help)
		      isHelpCmd=1
		      ;;
		  -F|--file)
		      val='-F'
		      ;;
		  --relocate)
		      hasRelocateOpt=1
		      ;;
		  --reintegrate)
		      hasReintegrateOpt=1
		      ;;
	      esac

	      # no more options, only arguments, whatever they look like.
	      if [[ $opt = '--' && ! $isCur ]] ; then
		  last='onlyarg'
		  continue
	      fi

	      # options are recorded...
	      if [[ $opt == -* ]] ; then
		  # but not the current one!
		  [[ ! $isCur ]] && options="$options $opt "
		  last='opt'
		  continue
	      fi
	    else
		# onlyarg
		let nargs++
		continue
	    fi

	    # then we have an argument
	    if [[ $cmd = 'merge' && ! $URL ]] ; then
              # fist argument is the source URL for the merge
	      URL=$opt
	    fi

	    last='arg'
	    let nargs++
	done
	# end opt option processing...
	[[ $stat ]] || stat=$last

	# suggest all subcommands, including special help
	if [[ ! $cmd || $stat = 'cmd' ]]
	then
	    COMPREPLY=( $( compgen -W "$cmds $specOpts" -- $cur ) )
	    return 0
	fi

	# suggest all subcommands
	if [[ $stat = 'help' || ( $isHelpCmd && ! $help ) ]]
	then
	    COMPREPLY=( $( compgen -W "$cmds" -- $cur ) )
	    return 0
	fi

	# URL completion
	if [[ $cmd == @(co|checkout|ls|list) && $stat = 'arg' && \
			$SVN_BASH_COMPL_EXT == *urls* ]]
	then
		# see about COMP_WORDBREAKS workaround in prop completion
		if [[ $cur == file:* ]]
		then
			# file completion for file:// urls
			local where=${cur/file:/}
			COMPREPLY=( $(compgen -d -S '/' -X '*/.*' -- $where ) )
			return
		elif [[ $cur == *:* ]]
		then
			# get known urls
			local urls= file=
			for file in ~/.subversion/auth/svn.simple/* ; do
				if [ -r $file ] ; then
					local url=$(_svn_read_hashfile svn:realmstring < $file)
					url=${url/*</}
					url=${url/>*/}
					urls="$urls $url"
				fi
			done

			# only suggest/show possible suffixes
			local prefix=${cur%:*} suffix=${cur#*:} c= choices=
			for c in $urls ; do
				[[ $c == $prefix:* ]] && choices="$choices ${c#*:}"
			done

			COMPREPLY=( $(compgen -W "$choices" -- $suffix ) )
			return
		else
			# show schemas
			COMPREPLY=( $(compgen -W "$urlSchemas" -- $cur) )
			return
		fi
	fi

	if [[ $cmd = 'merge' || $cmd = 'mergeinfo' ]]
	then
	  local here=$(_svn_info URL)
	  # suggest a possible URL for merging
	  if [[ ! $URL && $stat = 'arg' ]] ; then
	    # we assume a 'standard' repos with branches and trunk
	    if [[ "$here" == */branches/* ]] ; then
	      # we guess that it is a merge from the trunk
	      COMPREPLY=( $(compgen -W ${here/\/branches\/*/\/trunk} -- $cur ) )
	      return 0
	    elif [[ "$here" == */trunk* ]] ; then
	      # we guess that it is a merge from a branch
	      COMPREPLY=( $(compgen -W ${here/\/trunk*/\/branches\/} -- $cur ) )
	      return 0
	    else
	      # no se, let us suggest the repository root...
	      COMPREPLY=( $(compgen -W $(_svn_info Root) -- $cur ) )
	      return 0
	    fi
	  elif [[ $URL == */branches/* && $here == */trunk* && \
	        ! $hasReintegrateOpt && $cur = '' && $stat = 'arg' ]] ; then
	    # force --reintegrate only if the current word is empty
	    COMPREPLY=( $(compgen -W '--reintegrate' -- $cur ) )
	    return 0
	  fi
	fi

	# help about option arguments
	if [[ $stat = 'skip' ]]
	then
	    local previous=${COMP_WORDS[COMP_CWORD-1]}
	    local values= dirs= beep= exes=

	    [[ $previous = '--config-dir' ]] && dirs=1

	    # external editor, diff, diff3...
	    [[ $previous = --*-cmd ]] && exes=1

	    [[ $previous = '--native-eol' ]] && values='LF CR CRLF'

	    # just to suggest that a number is expected. hummm.
	    [[ $previous = '--limit' ]] && values='0 1 2 3 4 5 6 7 8 9'

            # some special partial help about --revision option.
	    [[ $previous = '--revision' || $previous = '-r' ]] && \
		values='HEAD BASE PREV COMMITTED 0 {'

	    [[ $previous = '--encoding' ]] && \
		values="latin1 utf8 $SVN_BASH_ENCODINGS"

	    [[ $previous = '--extensions' || $previous = '-x' ]] && \
		values="--unified --ignore-space-change \
		   --ignore-all-space --ignore-eol-style --show-c-functions"

	    [[ $previous = '--depth' ]] && \
		values='empty files immediates infinity'

	    [[ $previous = '--set-depth' ]] && \
		values='empty exclude files immediates infinity'

	    [[ $previous = '--accept' ]] && \
	    {
	        # the list is different for 'resolve'
                if [[ $cmd = 'resolve' ]] ; then
		    # from svn help resolve
		    values='base working mine-full theirs-full'
		else # checkout merge switch update
		    values="postpone base mine-full theirs-full edit launch \
			mine-conflict theirs-conflict"
		fi
	    }

	    [[ $previous = '--show-revs' ]] && values='merged eligible'

	    if [[ $previous = '--username' ]] ; then
	      values="$SVN_BASH_USERNAME"
	      if [[ $SVN_BASH_COMPL_EXT == *username* ]] ; then
		local file=
		# digest? others?
		for file in ~/.subversion/auth/svn.simple/* ; do
		  if [ -r $file ] ; then
		    values="$values $(_svn_read_hashfile username < $file)"
		  fi
		done
	      fi
	      [[ ! "$values" ]] && beep=1
	    fi

	    # could look at ~/.subversion/ ?
	    # hmmm... this option should not exist
	    [[ $previous = '--password' ]] && beep=1

	    # TODO: provide help about other options such as:
	    # --old --new --with-revprop

	    # if the previous option required a parameter, do something
	    # or fallback on ordinary filename expansion
	    [[ $values ]] && COMPREPLY=( $( compgen -W "$values" -- $cur ) )
	    [[ $dirs ]] && COMPREPLY=( $( compgen -o dirnames -- $cur ) )
	    [[ $exes ]] && COMPREPLY=( $( compgen -c -- $cur ) )
	    [[ $beep ]] &&
	    {
		# 'no known completion'. hummm.
		echo -en "\a"
		COMPREPLY=( '' )
	    }
	    return 0
	fi

	# provide allowed property names after property commands
	if [[ $isPropCmd && ( ! $prop || $stat = 'prop' ) && $cur != -* ]]
	then
	    #
	    # Ok, this part is pretty ugly.
	    #
	    # The issue is that ":" is a completion word separator,
	    # which is a good idea for file:// urls but not within
	    # property names...
	    #
	    # The first idea was to remove locally ":" from COMP_WORDBREAKS
	    # and then put it back in all cases but in property name
	    # completion.  It does not always work.  There is a strange bug
	    # where one may get "svn:svn:xxx" in some unclear cases.
	    #
	    # Thus the handling is reprogrammed here...
	    # The code assumes that property names look like *:*,
	    # but it also works reasonably well with simple names.
	    #
	    # This hack is broken in bash4... not sure what to do about it,
            # especially while keeping the bash3 compatibility:-(
	    local choices=

	    if [[ $cur == *:* ]]
	    then
		# only suggest/show possible suffixes
		local prefix=${cur%:*} suffix=${cur#*:} c=
		for c in ${allProps[@]} ; do
		    [[ $c == $prefix:* ]] && choices="$choices ${c#*:}"
		done
		# everything will be appended to the prefix because ':' is
		# a separator, so cur is restricted to the suffix part.
		cur=$suffix
	    else
		# only one choice is fine
		COMPREPLY=( $( compgen -W "${allProps[*]}" -- $cur ) )
		[ ${#COMPREPLY[@]} -eq 1 ] && return 0

		# no ':' so only suggest prefixes?
		local seen= n=0 last= c=
		for c in ${allProps[@]%:*} ; do
		    # do not put the same prefix twice...
		    if [[ $c == $cur* && ( ! $seen || $c != @($seen) ) ]]
		    then
			let n++
			last=$c
			choices="$choices $c:"
			if [[ $seen ]]
			then
			    seen="$seen|$c*"
			else
			    seen="$c*"
			fi
		    fi
		done

		# supply two choices to force a partial completion and a beep
		[[ $n -eq 1 ]] && choices="$last:1 $last:2"
	    fi

	    COMPREPLY=( $( compgen -W "$choices" -- $cur ) )
	    return 0
	fi

	# force mandatory --revprop option on revision properties
	if [[ $isRevProp && ! $hasRevPropOpt ]]
	then
	    COMPREPLY=( $( compgen -W '--revprop' -- $cur ) )
	    return 0
	fi

	# force mandatory --revision option on revision properties
	if [[ $isRevProp && $hasRevPropOpt && ! $hasRevisionOpt ]]
	then
	    COMPREPLY=( $( compgen -W '--revision' -- $cur ) )
	    return 0
	fi

	# possible completion when setting property values
	if [[ $isPsCmd && $prop && ( ! $val || $stat = 'val' ) ]]
	then
	    # ' is a reminder for an arbitrary value
	    local values="\' --file"
	    case $prop in
		svn:keywords)
		    # just a subset?
		    values="Id Rev URL Date Author Header \' $SVN_BASH_KEYWORDS"
		    ;;
		svn:executable|svn:needs-lock)
		    # hmmm... canonical value * is special to the shell.
		    values='\\*'
		    ;;
		svn:eol-style)
		    values='native LF CR CRLF'
		    ;;
		svn:mime-type)
		    # could read /etc/mime.types if available. overkill.
		    values="text/ text/plain text/html text/xml text/rtf
                       image/ image/png image/gif image/jpeg image/tiff
                       audio/ audio/midi audio/mpeg
                       video/ video/mpeg video/mp4
                       application/ application/octet-stream
                       $SVN_BASH_MIME_TYPE"
		    ;;
	    esac

	    COMPREPLY=( $( compgen -W "$values" -- $cur ) )
	    # special case for --file... return even if within an option
	    [[ ${COMPREPLY} ]] && return 0
	fi

	# maximum number of additional arguments expected in various forms
	case $cmd in
	    merge)
		nExpectArgs=3
		;;
	    mergeinfo)
		nExpectArgs=1
		;;
	    copy|cp|move|mv|rename|ren|export|import)
		nExpectArgs=2
		;;
	    switch|sw)
		[[ ! $hasRelocateOpt ]] && nExpectArgs=2
		;;
	    help|h)
		nExpectArgs=0
		;;
	    --version)
		nExpectArgs=0
		;;
	esac

	# the maximum number of arguments is reached for a command
	if [[ $nExpectArgs && $nargs -gt $nExpectArgs ]]
	then
	    # some way to tell 'no completion at all'... is there a better one?
	    # Do not say 'file completion' here.
	    echo -en "\a"
	    COMPREPLY=( '' )
	    return 0
	fi

	# if not typing an option,
	# then fallback on filename expansion...
	if [[ $cur != -* || $stat = 'onlyarg' ]]  ; then

	    # do we allow possible expensive completion here?
	    if [[ $SVN_BASH_COMPL_EXT == *svnstatus* ]] ; then

		# build status command and options
		# "--quiet" removes 'unknown' files
		local status='svn status --non-interactive'

		[[ $SVN_BASH_COMPL_EXT == *recurse* ]] || \
		    status="$status --non-recursive"

		# I'm not sure that it can work with externals in call cases
		# the output contains translatable sentences (even with quiet)
		[[ $SVN_BASH_COMPL_EXT == *externals* ]] || \
		    status="$status --ignore-externals"

		local cs= files=
		# subtlety: must not set $cur* if $cur is empty in some cases
		[[ $cur ]] && cs=$cur*

		# 'files' is set according to the current subcommand
		case $cmd in
		    st*) # status completion must include all files
			files=$cur*
			;;
		    ci|commit|revert|di*) # anything edited
			files=$($status $cs| _svn_grcut '@([MADR!]*| M*|_M*)')
			;;
		    add) # unknown files
			files=$($status $cs| _svn_grcut '\?*')
			;;
		    unlock) # unlock locked files
			files=$($status $cs| _svn_grcut '@(??L*|?????[KOTB]*)')
			;;
		    resolve*) # files in conflict
			files=$($status $cs| _svn_grcut '@(?C*|C*)')
			;;
		    praise|blame|ann*) # any svn file but added
			files=$( _svn_lls all $cur* )
			;;
		    p*) # prop commands
			if [[ $cmd == @($propCmds) && \
			      $prop == @(svn:ignore|svn:externals) ]] ; then
			    # directory specific props
			    files=$( _svn_lls dir . $cur* )
			else
			    # ??? added directories appear twice: foo foo/
			    files="$( _svn_lls all $cur* )
                                   $($status $cs | _svn_grcut 'A*' )"
			fi
			;;
		    info) # information on any file
			files="$( _svn_lls all $cur* )
                               $($status $cs | _svn_grcut 'A*' )"
			;;
		    remove|rm|del*|move|mv|rename) # changing existing files
			files=$( _svn_lls all $cur* )
			;;
		    mkdir) # completion in mkdir can only be for subdirs?
			files=$( _svn_lls dir $cur* )
			;;
		    log|lock|up*|cl*|switch) # misc, all but added files
			files=$( _svn_lls all $cur* )
			;;
		    merge) # may do a better job? URL/WCPATH
			files=$( _svn_lls all $cur* )
			;;
		    ls|list) # better job? what about URLs?
			files=$( _svn_lls all $cur* )
			;;
		    *) # other commands: changelist export import cat mergeinfo
			local fallback=1
			;;
		esac

		# when not recursive, some relevant files may exist
		# within subdirectories, so they are added here.
		# should it be restricted to svn-managed subdirs? no??
		if [[ $SVN_BASH_COMPL_EXT != *recurse* ]] ; then
		    files="$files $( _svn_lls dir $cur* )"
		fi

		# set completion depending on computed 'files'
		if [[ $files ]] ; then
		    COMPREPLY=( $( compgen -W "$files" -- $cur ) )
		    # if empty, set to nope?
		    [[ "${COMPREPLY[*]}" ]] || COMPREPLY=( '' )
		elif [[ ! $fallback ]] ; then
		    # this suggests no completion...
		    echo -en "\a"
		    COMPREPLY=( '' )
		fi
	    fi
	    # else fallback to ordinary filename completion...
	    return 0
	fi

	# otherwise build possible options for the command
	pOpts="--username --password --no-auth-cache --non-interactive \
	       --trust-server-cert --force-interactive"
	mOpts="-m --message -F --file --encoding --force-log --with-revprop"
	rOpts="-r --revision"
	qOpts="-q --quiet"
	nOpts="-N --non-recursive --depth"
	gOpts="-g --use-merge-history"
	cOpts="--cl --changelist"

	cmdOpts=
	case $cmd in
	--version)
		cmdOpts="$qOpts"
		;;
	add)
		cmdOpts="--auto-props --no-auto-props --force --targets \
		         --no-ignore --parents $nOpts $qOpts $pOpts"
		;;
	blame|annotate|ann|praise)
		cmdOpts="$rOpts $pOpts -v --verbose --incremental --xml \
		         -x --extensions --force $gOpts"
		;;
	cat)
		cmdOpts="$rOpts $pOpts"
		;;
	changelist|cl)
		cmdOpts="--targets $pOpts $qOpts $cOpts \
                         -R --recursive --depth --remove"
		;;
	checkout|co)
		cmdOpts="$rOpts $qOpts $nOpts $pOpts --ignore-externals \
                         --force"
		;;
	cleanup)
		cmdOpts="--diff3-cmd $pOpts"
		;;
	commit|ci)
		cmdOpts="$mOpts $qOpts $nOpts --targets --editor-cmd $pOpts \
		         --no-unlock $cOpts --keep-changelists \
		         --include-externals"
		;;
	copy|cp)
		cmdOpts="$mOpts $rOpts $qOpts --editor-cmd $pOpts --parents \
		         --ignore-externals"
		;;
	delete|del|remove|rm)
		cmdOpts="--force $mOpts $qOpts --targets --editor-cmd $pOpts \
                         --keep-local"
		;;
	diff|di)
		cmdOpts="$rOpts -x --extensions --diff-cmd --no-diff-deleted \
		         $nOpts $pOpts --force --old --new --notice-ancestry \
		         -c --change --summarize $cOpts --xml --git \
		         --internal-diff --show-copies-as-adds \
		         --ignore-properties --properties-only --no-diff-added \
		         --patch-compatible"
		;;
	export)
		cmdOpts="$rOpts $qOpts $pOpts $nOpts --force --native-eol \
                         --ignore-externals --ignore-keywords"
		;;
	help|h|\?)
		cmdOpts=
		;;
	import)
		cmdOpts="--auto-props --no-auto-props $mOpts $qOpts $nOpts \
		         --no-ignore --editor-cmd $pOpts --force"
		;;
	info)
		cmdOpts="$pOpts $rOpts --targets -R --recursive --depth \
                         --incremental --xml $cOpts"
		;;
	list|ls)
		cmdOpts="$rOpts -v --verbose -R --recursive $pOpts \
                         --incremental --xml --depth --include-externals"
		;;
	lock)
		cmdOpts="-m --message -F --file --encoding --force-log \
                         --targets --force $pOpts"
		;;
	log)
		cmdOpts="$rOpts -v --verbose --targets $pOpts --stop-on-copy \
		         --incremental --xml $qOpts -l --limit -c --change \
                         $gOpts --with-all-revprops --with-revprop --depth \
		         --diff --diff-cmd -x --extensions --internal-diff \
		         --with-no-revprops --search --search-and"
		;;
	merge)
		cmdOpts="$rOpts $nOpts $qOpts --force --dry-run --diff3-cmd \
		         $pOpts --ignore-ancestry -c --change -x --extensions \
                         --record-only --accept --reintegrate \
		         --allow-mixed-revisions -v --verbose"
		;;
	mergeinfo)
	        cmdOpts="$rOpts $pOpts --depth --show-revs -R --recursive"
		;;
	mkdir)
		cmdOpts="$mOpts $qOpts --editor-cmd $pOpts --parents"
		;;
	move|mv|rename|ren)
		cmdOpts="$mOpts $rOpts $qOpts --force --editor-cmd $pOpts \
                         --parents --allow-mixed-revisions"
		;;
	patch)
		cmdOpts="$qOpts $pOpts --dry-run --ignore-whitespace \
			--reverse-diff --strip"
		;;
	propdel|pdel|pd)
		cmdOpts="$qOpts -R --recursive $rOpts $pOpts $cOpts \
                         --depth"
		[[ $isRevProp || ! $prop ]] && cmdOpts="$cmdOpts --revprop"
		;;
	propedit|pedit|pe)
		cmdOpts="--editor-cmd $pOpts $mOpts --force"
		[[ $isRevProp || ! $prop ]] && \
		    cmdOpts="$cmdOpts --revprop $rOpts"
		;;
	propget|pget|pg)
	        cmdOpts="-v --verbose -R --recursive $rOpts --strict \
		         $pOpts $cOpts --depth --xml --show-inherited-props"
		[[ $isRevProp || ! $prop ]] && cmdOpts="$cmdOpts --revprop"
		;;
	proplist|plist|pl)
		cmdOpts="-v --verbose -R --recursive $rOpts --revprop $qOpts \
		         $pOpts $cOpts --depth --xml --show-inherited-props"
		;;
	propset|pset|ps)
		cmdOpts="$qOpts --targets -R --recursive \
		         --encoding $pOpts --force $cOpts --depth"
		[[ $isRevProp || ! $prop ]] && \
		    cmdOpts="$cmdOpts --revprop $rOpts"
		[[ $val ]] || cmdOpts="$cmdOpts -F --file"
		;;
        relocate)
		cmdOpts="--ignore-externals $pOpts"
		;;
        resolve)
                cmdOpts="--targets -R --recursive $qOpts $pOpts --accept \
                         --depth"
                ;;
	resolved)
		cmdOpts="--targets -R --recursive $qOpts $pOpts --depth"
		;;
	revert)
		cmdOpts="--targets -R --recursive $qOpts $cOpts \
                         --depth $pOpts"
		;;
	status|stat|st)
		cmdOpts="-u --show-updates -v --verbose $nOpts $qOpts $pOpts \
		         --no-ignore --ignore-externals --incremental --xml \
                         $cOpts"
		;;
	switch|sw)
		cmdOpts="--relocate $rOpts $nOpts $qOpts $pOpts --diff3-cmd \
                         --force --accept --ignore-externals --set-depth \
		         --ignore-ancestry"
		;;
	unlock)
		cmdOpts="--targets --force $pOpts"
		;;
	update|up)
		cmdOpts="$rOpts $nOpts $qOpts $pOpts --diff3-cmd \
                         --ignore-externals --force --accept $cOpts \
                         --parents --editor-cmd --set-depth"
		;;
	upgrade)
		cmdOpts="$qOpts $pOpts"
		;;
	*)
		;;
	esac

	# add options that are nearly always available
	[[ "$cmd" != "--version" ]] && cmdOpts="$cmdOpts $helpOpts"
	cmdOpts="$cmdOpts --config-dir --config-option"

        # --accept (edit|launch) incompatible with --non-interactive
	if [[ $acceptOpt == @(edit|launch) ]] ;
	then
	    cmdOpts=${cmdOpts/ --non-interactive / }
	fi

	# take out options already given
	for opt in $options
	do
		local optBase

		# remove leading dashes and arguments
		case $opt in
		--*)    optBase=${opt/=*/} ;;
		-*)     optBase=${opt:0:2} ;;
		esac

		cmdOpts=" $cmdOpts "
		cmdOpts=${cmdOpts/ ${optBase} / }

		# take out alternatives and mutually exclusives
		case $optBase in
		-v)              cmdOpts=${cmdOpts/ --verbose / } ;;
		--verbose)       cmdOpts=${cmdOpts/ -v / } ;;
		-N)              cmdOpts=${cmdOpts/ --non-recursive / } ;;
		--non-recursive) cmdOpts=${cmdOpts/ -N / } ;;
		-R)              cmdOpts=${cmdOpts/ --recursive / } ;;
		--recursive)     cmdOpts=${cmdOpts/ -R / } ;;
		-x)              cmdOpts=${cmdOpts/ --extensions / } ;;
		--extensions)    cmdOpts=${cmdOpts/ -x / } ;;
		-q)              cmdOpts=${cmdOpts/ --quiet / } ;;
		--quiet)         cmdOpts=${cmdOpts/ -q / } ;;
		-h)              cmdOpts=${cmdOpts/ --help / } ;;
		--help)          cmdOpts=${cmdOpts/ -h / } ;;
		-l)              cmdOpts=${cmdOpts/ --limit / } ;;
		--limit)         cmdOpts=${cmdOpts/ -l / } ;;
		-r)              cmdOpts=${cmdOpts/ --revision / } ;;
		--revision)      cmdOpts=${cmdOpts/ -r / } ;;
		-c)              cmdOpts=${cmdOpts/ --change / } ;;
		--change)        cmdOpts=${cmdOpts/ -c / } ;;
		--auto-props)    cmdOpts=${cmdOpts/ --no-auto-props / } ;;
		--no-auto-props) cmdOpts=${cmdOpts/ --auto-props / } ;;
		-g)              cmdOpts=${cmdOpts/ --use-merge-history / } ;;
		--use-merge-history)
                                 cmdOpts=${cmdOpts/ -g / } ;;
		-m|--message|-F|--file)
			cmdOpts=${cmdOpts/ --message / }
			cmdOpts=${cmdOpts/ -m / }
			cmdOpts=${cmdOpts/ --file / }
			cmdOpts=${cmdOpts/ -F / }
			;;
		esac

		# remove help options within help subcommand
		if [ $isHelpCmd ] ; then
		    cmdOpts=${cmdOpts/ -h / }
		    cmdOpts=${cmdOpts/ --help / }
		fi
	done

	# provide help about available options
	COMPREPLY=( $( compgen -W "$cmdOpts" -- $cur ) )
	return 0
}
complete -F _svn -o default -X '@(*/.svn|*/.svn/|.svn|.svn/)' svn

_svnadmin ()
{
	local cur cmds cmdOpts optsParam opt helpCmds optBase i

	COMPREPLY=()
	cur=${COMP_WORDS[COMP_CWORD]}

	# Possible expansions, without pure-prefix abbreviations such as "h".
	cmds='crashtest create deltify dump freeze help hotcopy list-dblogs \
	      list-unused-dblogs load lock lslocks lstxns pack recover rmlocks \
	      rmtxns setlog setrevprop setuuid unlock upgrade verify --version'

	if [[ $COMP_CWORD -eq 1 ]] ; then
		COMPREPLY=( $( compgen -W "$cmds" -- $cur ) )
		return 0
	fi

	# options that require a parameter
	# note: continued lines must end '|' continuing lines must start '|'
	optsParam="-r|--revision|--parent-dir|--fs-type|-M|--memory-cache-size"
	optsParam="$optsParam|-F|--file"

	# if not typing an option, or if the previous option required a
	# parameter, then fallback on ordinary filename expansion
	helpCmds='help|--help|h|\?'
	if [[ ${COMP_WORDS[1]} != @($helpCmds) ]] && \
	   [[ "$cur" != -* ]] || \
	   [[ ${COMP_WORDS[COMP_CWORD-1]} == @($optsParam) ]] ; then
		return 0
	fi

	cmdOpts=
	case ${COMP_WORDS[1]} in
	create)
		cmdOpts="--bdb-txn-nosync --bdb-log-keep --config-dir \
		         --fs-type --pre-1.4-compatible --pre-1.5-compatible \
		         --pre-1.6-compatible --compatible-version"
		;;
	deltify)
		cmdOpts="-r --revision -q --quiet"
		;;
	dump)
		cmdOpts="-r --revision --incremental -q --quiet --deltas \
		         -M --memory-cache-size"
		;;
	freeze)
		cmdOpts="-F --file"
		;;
	help|h|\?)
		cmdOpts="$cmds"
		;;
	hotcopy)
		cmdOpts="--clean-logs"
		;;
	load)
		cmdOpts="--ignore-uuid --force-uuid --parent-dir -q --quiet \
		         --use-pre-commit-hook --use-post-commit-hook \
		         --bypass-prop-validation -M --memory-cache-size"
		;;
	lock|unlock)
		cmdOpts="--bypass-hooks"
		;;
	recover)
		cmdOpts="--wait"
		;;
	rmtxns)
		cmdOpts="-q --quiet"
		;;
	setlog)
		cmdOpts="-r --revision --bypass-hooks"
		;;
	setrevprop)
		cmdOpts="-r --revision --use-pre-revprop-change-hook \
		         --use-post-revprop-change-hook"
		;;
	verify)
		cmdOpts="-r --revision -q --quiet"
		;;
	*)
		;;
	esac

	cmdOpts="$cmdOpts --help -h"

	# take out options already given
	for (( i=2; i<=$COMP_CWORD-1; ++i )) ; do
		opt=${COMP_WORDS[$i]}

		case $opt in
		--*)    optBase=${opt/=*/} ;;
		-*)     optBase=${opt:0:2} ;;
		esac

		cmdOpts=" $cmdOpts "
		cmdOpts=${cmdOpts/ ${optBase} / }

		# take out alternatives
		case $optBase in
		-q)              cmdOpts=${cmdOpts/ --quiet / } ;;
		--quiet)         cmdOpts=${cmdOpts/ -q / } ;;
		-h)              cmdOpts=${cmdOpts/ --help / } ;;
		--help)          cmdOpts=${cmdOpts/ -h / } ;;
		-r)              cmdOpts=${cmdOpts/ --revision / } ;;
		--revision)      cmdOpts=${cmdOpts/ -r / } ;;
		-F)              cmdOpts=${cmdOpts/ --file / } ;;
		--file)          cmdOpts=${cmdOpts/ -F / } ;;
		-M)              cmdOpts=${cmdOpts/ --memory-cache-size / } ;;
		--memory-cache-size) cmdOpts=${cmdOpts/ --M / } ;;
		esac

		# skip next option if this one requires a parameter
		if [[ $opt == @($optsParam) ]] ; then
			((++i))
		fi
	done

	COMPREPLY=( $( compgen -W "$cmdOpts" -- $cur ) )

	return 0
}
complete -F _svnadmin -o default svnadmin

_svndumpfilter ()
{
	local cur cmds cmdOpts optsParam opt helpCmds optBase i

	COMPREPLY=()
	cur=${COMP_WORDS[COMP_CWORD]}

	# Possible expansions, without pure-prefix abbreviations such as "h".
	cmds='exclude help include --version'

	if [[ $COMP_CWORD -eq 1 ]] ; then
		COMPREPLY=( $( compgen -W "$cmds" -- $cur ) )
		return 0
	fi

	# options that require a parameter
	# note: continued lines must end '|' continuing lines must start '|'
	optsParam="--targets"

	# if not typing an option, or if the previous option required a
	# parameter, then fallback on ordinary filename expansion
	helpCmds='help|--help|h|\?'
	if [[ ${COMP_WORDS[1]} != @($helpCmds) ]] && \
	   [[ "$cur" != -* ]] || \
	   [[ ${COMP_WORDS[COMP_CWORD-1]} == @($optsParam) ]] ; then
		return 0
	fi

	cmdOpts=
	case ${COMP_WORDS[1]} in
	exclude|include)
		cmdOpts="--drop-empty-revs --renumber-revs
		         --skip-missing-merge-sources --targets
		         --preserve-revprops --quiet"
		;;
	help|h|\?)
		cmdOpts="$cmds"
		;;
	*)
		;;
	esac

	cmdOpts="$cmdOpts --help -h"

	# take out options already given
	for (( i=2; i<=$COMP_CWORD-1; ++i )) ; do
		opt=${COMP_WORDS[$i]}

		case $opt in
		--*)    optBase=${opt/=*/} ;;
		-*)     optBase=${opt:0:2} ;;
		esac

		cmdOpts=" $cmdOpts "
		cmdOpts=${cmdOpts/ ${optBase} / }

		# take out alternatives
		case $optBase in
		-h)              cmdOpts=${cmdOpts/ --help / } ;;
		--help)          cmdOpts=${cmdOpts/ -h / } ;;
		esac

		# skip next option if this one requires a parameter
		if [[ $opt == @($optsParam) ]] ; then
			((++i))
		fi
	done

	COMPREPLY=( $( compgen -W "$cmdOpts" -- $cur ) )

	return 0
}
complete -F _svndumpfilter -o default svndumpfilter

_svnlook ()
{
	local cur cmds cmdOpts optsParam opt helpCmds optBase i

	COMPREPLY=()
	cur=${COMP_WORDS[COMP_CWORD]}

	# Possible expansions, without pure-prefix abbreviations such as "h".
	cmds='author cat changed date diff dirs-changed help history info \
	      lock log propget proplist tree uuid youngest --version'

	if [[ $COMP_CWORD -eq 1 ]] ; then
		COMPREPLY=( $( compgen -W "$cmds" -- $cur ) )
		return 0
	fi

	# options that require a parameter
	# note: continued lines must end '|' continuing lines must start '|'
	optsParam="-r|--revision|-t|--transaction|-l|--limit|-x|--extensions"

	# if not typing an option, or if the previous option required a
	# parameter, then fallback on ordinary filename expansion
	helpCmds='help|--help|h|\?'
	if [[ ${COMP_WORDS[1]} != @($helpCmds) ]] && \
	   [[ "$cur" != -* ]] || \
	   [[ ${COMP_WORDS[COMP_CWORD-1]} == @($optsParam) ]] ; then
		return 0
	fi

	cmdOpts=
	case ${COMP_WORDS[1]} in
	author)
		cmdOpts="-r --revision -t --transaction"
		;;
	cat)
		cmdOpts="-r --revision -t --transaction"
		;;
	changed)
		cmdOpts="-r --revision -t --transaction --copy-info"
		;;
	date)
		cmdOpts="-r --revision -t --transaction"
		;;
	diff)
		cmdOpts="-r --revision -t --transaction --diff-copy-from \
		         --no-diff-added --no-diff-deleted -x --extensions"
		;;
	dirs-changed)
		cmdOpts="-r --revision -t --transaction"
		;;
	help|h|\?)
		cmdOpts="$cmds"
		;;
	history)
		cmdOpts="-r --revision -l --limit --show-ids"
		;;
	info)
		cmdOpts="-r --revision -t --transaction"
		;;
	lock)
		cmdOpts=
		;;
	log)
		cmdOpts="-r --revision -t --transaction"
		;;
	propget|pget|pg)
		cmdOpts="-r --revision -t --transaction --revprop"
		;;
	proplist|plist|pl)
		cmdOpts="-r --revision -t --transaction --revprop -v --verbose --xml"
		;;
	tree)
		cmdOpts="-r --revision -t --transaction --full-paths -N --non-recursive --show-ids"
		;;
	uuid)
		cmdOpts=
		;;
	youngest)
		cmdOpts=
		;;
	*)
		;;
	esac

	cmdOpts="$cmdOpts --help -h"

	# take out options already given
	for (( i=2; i<=$COMP_CWORD-1; ++i )) ; do
		opt=${COMP_WORDS[$i]}

		case $opt in
		--*)    optBase=${opt/=*/} ;;
		-*)     optBase=${opt:0:2} ;;
		esac

		cmdOpts=" $cmdOpts "
		cmdOpts=${cmdOpts/ ${optBase} / }

		# take out alternatives
		case $optBase in
		-N)              cmdOpts=${cmdOpts/ --non-recursive / } ;;
		--non-recursive) cmdOpts=${cmdOpts/ -N / } ;;
		-h)              cmdOpts=${cmdOpts/ --help / } ;;
		--help)          cmdOpts=${cmdOpts/ -h / } ;;
		-l)              cmdOpts=${cmdOpts/ --limit / } ;;
		--limit)         cmdOpts=${cmdOpts/ -l / } ;;
		-r)              cmdOpts=${cmdOpts/ --revision / } ;;
		--revision)      cmdOpts=${cmdOpts/ -r / } ;;
		-t)              cmdOpts=${cmdOpts/ --transaction / } ;;
		--transaction)   cmdOpts=${cmdOpts/ -t / } ;;
		-v)              cmdOpts=${cmdOpts/ --verbose / } ;;
		--verbose)       cmdOpts=${cmdOpts/ -v / } ;;
		-x)              cmdOpts=${cmdOpts/ --extensions / } ;;
		--extensions)    cmdOpts=${cmdOpts/ -x / } ;;
		esac

		# skip next option if this one requires a parameter
		if [[ $opt == @($optsParam) ]] ; then
			((++i))
		fi
	done

	COMPREPLY=( $( compgen -W "$cmdOpts" -- $cur ) )

	return 0
}
complete -F _svnlook -o default svnlook

_svnsync ()
{
	local cur cmds cmdOpts optsParam opt helpCmds optBase i

	COMPREPLY=()
	cur=${COMP_WORDS[COMP_CWORD]}

	# Possible expansions, without pure-prefix abbreviations such as "h".
	cmds='copy-revprops help info initialize synchronize --version'

	if [[ $COMP_CWORD -eq 1 ]] ; then
		COMPREPLY=( $( compgen -W "$cmds" -- $cur ) )
		return 0
	fi

	# options that require a parameter
	# note: continued lines must end '|' continuing lines must start '|'
	optsParam="--config-dir|--config-option|--source-username|--source-password"
	optsParam="$optsParam|--sync-username|--sync-password"

	# if not typing an option, or if the previous option required a
	# parameter, then fallback on ordinary filename expansion
	helpCmds='help|--help|h|\?'
	if [[ ${COMP_WORDS[1]} != @($helpCmds) ]] && \
	   [[ "$cur" != -* ]] || \
	   [[ ${COMP_WORDS[COMP_CWORD-1]} == @($optsParam) ]] ; then
		return 0
	fi

	cmdOpts=
	case ${COMP_WORDS[1]} in
	copy-revprops|initialize|init|synchronize|sync)
		cmdOpts="--non-interactive --no-auth-cache --trust-server-cert \
		         --source-username --source-password --sync-username \
		         --sync-password --config-dir --config-option -q --quiet"
		;;
	help|h|\?)
		cmdOpts="$cmds"
		;;
	info)
		cmdOpts="--non-interactive --no-auth-cache --trust-server-cert \
		         --source-username --source-password --sync-username \
		         --sync-password --config-dir --config-option"
		;;
	*)
		;;
	esac

	cmdOpts="$cmdOpts --help -h"

	# take out options already given
	for (( i=2; i<=$COMP_CWORD-1; ++i )) ; do
		opt=${COMP_WORDS[$i]}

		case $opt in
		--*)    optBase=${opt/=*/} ;;
		-*)     optBase=${opt:0:2} ;;
		esac

		cmdOpts=" $cmdOpts "
		cmdOpts=${cmdOpts/ ${optBase} / }

		# take out alternatives
		case $optBase in
		-h)              cmdOpts=${cmdOpts/ --help / } ;;
		--help)          cmdOpts=${cmdOpts/ -h / } ;;
		-q)              cmdOpts=${cmdOpts/ --quiet / } ;;
		--quiet)         cmdOpts=${cmdOpts/ -q / } ;;
		esac

		# skip next option if this one requires a parameter
		if [[ $opt == @($optsParam) ]] ; then
			((++i))
		fi
	done

	COMPREPLY=( $( compgen -W "$cmdOpts" -- $cur ) )

	return 0
}
complete -F _svnsync -o default svnsync

# reasonable completion for 'svnversion'
_svnversion ()
{
	local cmdOpts=" -n --no-newline -c --committed -h --help --version "
	local cur=${COMP_WORDS[COMP_CWORD]}

	COMPREPLY=()

	# parse current options
	local options= wcpath= trailurl= last='none' stat= opt= i=-1 isCur=
	for opt in ${COMP_WORDS[@]}
	do
		[[ $i -eq $COMP_CWORD ]] && stat=$last
		let i++

		# are we processing the current word?
		isCur=
		[[ $i -eq $COMP_CWORD ]] && isCur=1

		# skip first command, should be 'svnversion'
		if [ $last = 'none' ] ; then
			last='first'
			continue
		fi

		# get options
		if [[ $last != 'arg' && $opt == -* ]]
		then
			# if '--' is at the current position, it means that we are looking
			# for '--*' options, and not the end of option processing.
			if [[ $opt = '--' && ! $isCur ]]
			then
				last='arg'
			else
				options="$options $opt "
				last='opt'
			fi
			continue
		fi
		# get arguments
		if [[ $opt != -* ]]
		then
			last='arg'
			if [[ ! $wcpath ]]
			then
				wcpath=$opt
			elif [[ ! $trailurl ]]
			then
				trailurl=$opt
			fi
		fi
	done
	[[ $stat ]] || stat=$last

	# argument part
	if [[ $cur != -* || $stat = 'arg' ]]
	then
		[[ $wcpath && $trailurl ]] && COMPREPLY=( '' )
		return 0
	fi

	# suggest options, and  take out already given options
	for opt in $options
	do
		# take out options
		cmdOpts=${cmdOpts/ $opt / }

		# take out alternatives
		case $opt in
			-n)              cmdOpts=${cmdOpts/ --no-newline / } ;;
			--no-newline)    cmdOpts=${cmdOpts/ -n / } ;;
			-h)              cmdOpts=${cmdOpts/ --help / } ;;
			--help)          cmdOpts=${cmdOpts/ -h / } ;;
			-c)              cmdOpts=${cmdOpts/ --committed / } ;;
			--committed)     cmdOpts=${cmdOpts/ -c / } ;;
		esac
	done

	COMPREPLY=( $( compgen -W "$cmdOpts" -- $cur ) )

# shellcheck shell=bash
cite "about-completion"
about-completion "packer completion"

if _binary_exists packer; then
# shellcheck shell=bash
cite "about-completion"
about-completion "brew completion"

# Load late to make sure `system` completion loads first
# BASH_IT_LOAD_PRIORITY: 375

if [[ "$(uname -s)" != 'Darwin' ]]; then
	_log_warning "unsupported operating system - only 'Darwin' is supported"
	return 0
fi

# Make sure brew is installed
_command_exists brew || return 0

BREW_PREFIX=${BREW_PREFIX:-$(brew --prefix)}

if [[ -r "$BREW_PREFIX"/etc/bash_completion.d/brew ]]; then
	# shellcheck disable=1090
	source "$BREW_PREFIX"/etc/bash_completion.d/brew

elif [[ -r "$BREW_PREFIX"/Library/Contributions/brew_bash_completion.sh ]]; then
	# shellcheck disable=1090
	source "$BREW_PREFIX"/Library/Contributions/brew_bash_completion.sh

elif [[ -f "$BREW_PREFIX"/completions/bash/brew ]]; then
	# For the git-clone based installation, see here for more info:
	# https://github.com/Bash-it/bash-it/issues/1458
	# https://docs.brew.sh/Shell-Completion
	# shellcheck disable=1090
#!/usr/bin/env bash
#
# Bash completion support for Fabric (http://fabfile.org/)
#
#
# Copyright (C) 2011 by Konstantin Bakulin
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.
#
# Thanks to:
# - Adam Vandenberg,
#   https://github.com/adamv/dotfiles/blob/master/completion_scripts/fab_completion.bash
#
# - Enrico Batista da Luz,
#   https://github.com/ricobl/dotfiles/blob/master/bin/fab_bash_completion
#


# Use cache files for fab tasks or not.
# If set to "false" command "fab --shortlist" will be executed every time.
export FAB_COMPLETION_CACHE_TASKS=true

# File name where tasks cache will be stored (in current dir).
export FAB_COMPLETION_CACHED_TASKS_FILENAME=".fab_tasks~"


# Set command to get time of last file modification as seconds since Epoch
case `uname` in
    Darwin|FreeBSD)
        __FAB_COMPLETION_MTIME_COMMAND="stat -f '%m'"
        ;;
    *)
        __FAB_COMPLETION_MTIME_COMMAND="stat -c '%Y'"
        ;;
esac


#
# Get time of last fab cache file modification as seconds since Epoch
#
function __fab_chache_mtime() {
    ${__FAB_COMPLETION_MTIME_COMMAND} \
        $FAB_COMPLETION_CACHED_TASKS_FILENAME | xargs -n 1 expr
}


#
# Get time of last fabfile file/module modification as seconds since Epoch
#
function __fab_fabfile_mtime() {
    local f="fabfile"
    if [[ -e "$f.py" ]]; then
        ${__FAB_COMPLETION_MTIME_COMMAND} "$f.py" | xargs -n 1 expr
    else
        # Suppose that it's a fabfile dir
        find $f/*.py -exec ${__FAB_COMPLETION_MTIME_COMMAND} {} + \
            | xargs -n 1 expr | sort -n -r | head -1
    fi
}


#
# Completion for "fab" command
#
function __fab_completion() {
    # Return if "fab" command doesn't exists
    [[ -e `which fab 2> /dev/null` ]] || return 0

    # Variables to hold the current word and possible matches
    local cur="${COMP_WORDS[COMP_CWORD]}"
    local opts=()

    # Generate possible matches and store them in variable "opts"
    case "${cur}" in
        -*)
            if [[ -z "${__FAB_COMPLETION_LONG_OPT}" ]]; then
                export __FAB_COMPLETION_LONG_OPT=$(
                    fab --help | egrep -o "\-\-[A-Za-z_\-]+\=?" | sort -u)
            fi
            opts="${__FAB_COMPLETION_LONG_OPT}"
            ;;

        # Completion for short options is not nessary.
        # It's left here just for history.
        # -*)
        #     if [[ -z "${__FAB_COMPLETION_SHORT_OPT}" ]]; then
        #         export __FAB_COMPLETION_SHORT_OPT=$(
        #             fab --help | egrep -o "^ +\-[A-Za-z_\]" | sort -u)
        #     fi
        #     opts="${__FAB_COMPLETION_SHORT_OPT}"
        #     ;;

        *)
            # If "fabfile.py" or "fabfile" dir with "__init__.py" file exists
            local f="fabfile"
            if [[ -e "$f.py" || (-d "$f" && -e "$f/__init__.py") ]]; then
                # Build a list of the available tasks
                if $FAB_COMPLETION_CACHE_TASKS; then
                    # If use cache
                    if [[ ! -s ${FAB_COMPLETION_CACHED_TASKS_FILENAME} ||
                          $(__fab_fabfile_mtime) -gt $(__fab_chache_mtime) ]]; then
                        fab --shortlist > ${FAB_COMPLETION_CACHED_TASKS_FILENAME} \
                            2> /dev/null
                    fi
                    opts=$(cat ${FAB_COMPLETION_CACHED_TASKS_FILENAME})
                else
                    # Without cache
                    opts=$(fab --shortlist 2> /dev/null)
                fi
            fi
            ;;
    esac

    # Set possible completions
# shellcheck shell=bash

# Published originally as public domain code at https://github.com/wk8/knife-bash-autocomplete

##############
### CONFIG ###
##############
### feel free to change those constants
# the dir where to store the cache (must be writable and readable by the current user)
# must be an absolute path
_KNIFE_AUTOCOMPLETE_CACHE_DIR="$HOME/.knife_autocomplete_cache"
# the maximum # of _seconds_ after which a cache will be considered stale
# (a cache is refreshed whenever it is used! this is only for caches that might not have been used for a long time)
# WARNING: keep that value > 100
_KNIFE_AUTOCOMPLETE_MAX_CACHE_AGE=86400

###############################################
### END OF CONFIG - DON'T CHANGE CODE BELOW ###
###############################################

### init
_KAC_CACHE_TMP_DIR="$_KNIFE_AUTOCOMPLETE_CACHE_DIR/tmp"
# make sure the cache dir exists
mkdir -p "$_KAC_CACHE_TMP_DIR"

##############################
### Cache helper functions ###
##############################

# GNU or BSD stat?
stat -c %Y /dev/null > /dev/null 2>&1 && _KAC_STAT_COMMAND="stat -c %Y" || _KAC_STAT_COMMAND="stat -f %m"

# returns 0 iff the file whose path is given as 1st argument
# exists and has last been modified in the last $2 seconds
# returns 1 otherwise
_KAC_is_file_newer_than() {
	[ -f "$1" ] || return 1
	[ $(($(date +%s) - $($_KAC_STAT_COMMAND "$1"))) -gt "$2" ] && return 1 || return 0
}

# helper function for _KAC_get_and_regen_cache, see doc below
_KAC_regen_cache() {
	local CACHE_NAME=$1
	local CACHE_PATH="$_KNIFE_AUTOCOMPLETE_CACHE_DIR/$CACHE_NAME"
	local TMP_FILE=$(mktemp "$_KAC_CACHE_TMP_DIR/$CACHE_NAME.XXXX")
	shift 1
	# discard the temp file if it's empty AND the previous command didn't exit successfully, but still mark the cache as updated
	if ! "$@" > "$TMP_FILE" 2> /dev/null; then
		[[ $(wc -l "$TMP_FILE") == 0 ]] && rm -f "$TMP_FILE" && touch "$CACHE_PATH" && return 1
	else
		mv -f "$TMP_FILE" "$CACHE_PATH"
	fi
}

# cached files can't have spaces in their names
_KAC_get_cache_name_from_command() {
	echo "${@/ /_SPACE_}"
}

# the reverse operation from the function above
_KAC_get_command_from_cache_name() {
	echo "${@/_SPACE_/ }"
}

# given a command as argument, it fetches the cache for that command if it can find it
# otherwise it waits for the cache to be generated
# in either case, it regenerates the cache, and sets the _KAC_CACHE_PATH env variable
# for obvious reason, do NOT call that in a sub-shell (in particular, no piping)
_KAC_get_and_regen_cache() {
	# the cache name can't have space in it
	local CACHE_NAME=$(_KAC_get_cache_name_from_command "$@")
	local REGEN_CMD="_KAC_regen_cache $CACHE_NAME $*"
	_KAC_CACHE_PATH="$_KNIFE_AUTOCOMPLETE_CACHE_DIR/$CACHE_NAME"
	# no need to wait for the regen if the file already exists
	if [[ -f "$_KAC_CACHE_PATH" ]]; then
		($REGEN_CMD &)
	else
		$REGEN_CMD
	fi
}

# performs two things: first, deletes all obsolete temp files
# then refreshes stale caches that haven't been called in a long time
_KAC_clean_cache() {
	local FILE CMD
	# delete all obsolete temp files, could be lingering there for any kind of crash in the caching process
	for FILE in "$_KAC_CACHE_TMP_DIR"/*; do
		_KAC_is_file_newer_than "$FILE" "$_KNIFE_AUTOCOMPLETE_MAX_CACHE_AGE" || rm -f "$FILE"
	done
	# refresh really stale caches
	find "$_KNIFE_AUTOCOMPLETE_CACHE_DIR" -maxdepth 1 -type f -not -name '.*' \
		| while read -r FILE; do
			_KAC_is_file_newer_than "$FILE" "$_KNIFE_AUTOCOMPLETE_MAX_CACHE_AGE" && continue
			# first let's get the original command
			CMD=$(_KAC_get_command_from_cache_name "$(basename "$FILE")")
			# then regen the cache
			_KAC_get_and_regen_cache "$CMD" > /dev/null
		done
}

# perform a cache cleaning when loading this file
# On big systems this could baloon up to a 30 second run or more, so not enabling by default.
[[ "${KNIFE_CACHE_CLEAN}" ]] && _KAC_clean_cache

#####################################
### End of cache helper functions ###
#####################################

# returns all the possible knife sub-commands
_KAC_knife_commands() {
	knife --help | grep -E "^knife" | sed -E 's/ \(options\)//g'
}

# rebuilds the knife base command currently being completed, and assigns it to $_KAC_CURRENT_COMMAND
# additionnally, returns 1 iff the current base command is not complete, 0 otherwise
# also sets $_KAC_CURRENT_COMMAND_NB_WORDS if the base command is complete
_KAC_get_current_base_command() {
	local PREVIOUS="knife"
	local I=1
	local CURRENT
	while [ $I -le "$COMP_CWORD" ]; do
		# command words are all lower-case
		echo "${COMP_WORDS[$I]}" | grep -E "^[a-z]+$" > /dev/null || break
		CURRENT="$PREVIOUS ${COMP_WORDS[$I]}"
		grep -E "^$CURRENT" "$_KAC_CACHE_PATH" > /dev/null || break
		PREVIOUS=$CURRENT
		I=$((I + 1))
	done
	_KAC_CURRENT_COMMAND=$PREVIOUS
	[ $I -le "$COMP_CWORD" ] && _KAC_CURRENT_COMMAND_NB_WORDS=$I
}

# searches the position of the currently completed argument in the current base command
# (i.e. handles "plural" arguments such as knife cookbook upload cookbook1 cookbook2 and so on...)
# assumes the current base command is complete
_KAC_get_current_arg_position() {
	local CURRENT_ARG_POS=$((_KAC_CURRENT_COMMAND_NB_WORDS + 1))
	local COMPLETE_COMMAND=$(grep -E "^$_KAC_CURRENT_COMMAND" "$_KAC_CACHE_PATH")
	local CURRENT_ARG
	while [ "$CURRENT_ARG_POS" -le "$COMP_CWORD" ]; do
		CURRENT_ARG=$(echo "$COMPLETE_COMMAND" | cut -d ' ' -f "$CURRENT_ARG_POS")
		# we break if the current arg is a "plural" arg
		echo "$CURRENT_ARG" | grep -E "^\\[[^]]+(\\.\\.\\.\\]|$)" > /dev/null && break
		CURRENT_ARG_POS=$((CURRENT_ARG_POS + 1))
	done
	echo "$CURRENT_ARG_POS"
}

# the actual auto-complete function
_knife() {
	_KAC_get_and_regen_cache _KAC_knife_commands
	local RAW_LIST ITEM REGEN_CMD ARG_POSITION
	COMREPLY=()
	# get correct command & arg pos
	_KAC_get_current_base_command && ARG_POSITION=$(_KAC_get_current_arg_position) || ARG_POSITION=$((COMP_CWORD + 1))
	RAW_LIST=$(grep -E "^$_KAC_CURRENT_COMMAND" "$_KAC_CACHE_PATH" | cut -d ' ' -f $ARG_POSITION | uniq)

	# we need to process that raw list a bit, most notably for placeholders
	# NOTE: I chose to explicitely fetch & cache _certain_ informations for the server (cookbooks & node names, etc)
	# as opposed to a generic approach by trying to find a 'list' knife command corresponding to the
	# current base command - that might limit my script in some situation, but that way I'm sure it caches only
	# not-sensitive stuff (a generic approach could be pretty bad e.g. with the knife-rackspace plugin)
	LIST=""
	for ITEM in $RAW_LIST; do
		# always relevant if only lower-case chars : continuation of the base command
		echo "$ITEM" | grep -E "^[a-z]+$" > /dev/null && LIST="$LIST $ITEM" && continue
		case "$ITEM" in
			*COOKBOOK*)
				# special case for cookbooks : from site or local
				[[ ${COMP_WORDS[2]} == 'site' ]] && REGEN_CMD="knife cookbook site list" || REGEN_CMD="knife cookbook list"
				_KAC_get_and_regen_cache "$REGEN_CMD"
				LIST="$LIST $(cut -d ' ' -f 1 < "$_KAC_CACHE_PATH")"
				continue
				;;
			*ITEM*)
				# data bag item : another special case
				local DATA_BAG_NAME=${COMP_WORDS[$((COMP_CWORD - 1))]}
				REGEN_CMD="knife data bag show $DATA_BAG_NAME"
				;;
			*INDEX*)
				# see doc @ http://docs.opscode.com/knife_search.html
				LIST="$LIST client environment node role"
				REGEN_CMD="knife data bag list"
				;;
			*BAG*) REGEN_CMD="knife data bag list" ;;
			*CLIENT*) REGEN_CMD="knife client list" ;;
			*NODE*) REGEN_CMD="knife node list" ;;
			*ENVIRONMENT*) REGEN_CMD="knife environment list" ;;
			*ROLE*) REGEN_CMD="knife role list" ;;
			*USER*) REGEN_CMD="knife user list" ;;
			# not a generic argument we support...
			*) continue ;;
		esac
		_KAC_get_and_regen_cache "$REGEN_CMD"
		LIST="$LIST $(cat "$_KAC_CACHE_PATH")"
	done
	# shellcheck disable=SC2207,SC2086
	COMPREPLY=($(compgen -W "${LIST}" -- ${COMP_WORDS[COMP_CWORD]}))
}

#!/bin/bash

# (The MIT License)
#
# Copyright (c) 2014 Kura
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the 'Software'), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.


__pwdln() {
   pwdmod="${PWD}/"
   itr=0
   until [[ -z "$pwdmod" ]];do
      itr=$(($itr+1))
      pwdmod="${pwdmod#*/}"
   done
   echo -n $(($itr-1))
}

__vagrantinvestigate() {
    if [ -f "${PWD}/.vagrant" -o -d "${PWD}/.vagrant" ];then
      echo "${PWD}/.vagrant"
      return 0
   else
      pwdmod2="${PWD}"
      for (( i=2; i<=$(__pwdln); i++ ));do
         pwdmod2="${pwdmod2%/*}"
         if [ -f "${pwdmod2}/.vagrant" -o -d "${pwdmod2}/.vagrant" ];then
            echo "${pwdmod2}/.vagrant"
            return 0
         fi
      done
   fi
   return 1
}

_vagrant() {
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    commands="box cloud destroy global-status halt help hostmanager init login package plugin port powershell provision push rdp reload resume scp snapshot ssh ssh-config status suspend up upload validate vbguest version winrm winrm-config"

    if [ $COMP_CWORD == 1 ]
    then
      COMPREPLY=($(compgen -W "${commands}" -- ${cur}))
      return 0
    fi

    if [ $COMP_CWORD == 2 ]
    then
        case "$prev" in
            "init")
                local box_list=$(find "$HOME/.vagrant.d/boxes" -mindepth 1 -maxdepth 1 -type d -exec basename {} \;|sed -e 's/-VAGRANTSLASH-/\//')
                COMPREPLY=($(compgen -W "${box_list}" -- ${cur}))
                return 0
                ;;
            "up")
                vagrant_state_file=$(__vagrantinvestigate) || return 1
                if [[ -d $vagrant_state_file ]]
                then
                    vm_list=$(find $vagrant_state_file/machines -mindepth 1 -maxdepth 1 -type d -exec basename {} \;)
                fi
                local up_commands="--no-provision"
                COMPREPLY=($(compgen -W "${up_commands} ${vm_list}" -- ${cur}))
                return 0
                ;;
            "ssh"|"provision"|"reload"|"halt"|"suspend"|"resume"|"ssh-config")
                vagrant_state_file=$(__vagrantinvestigate) || return 1
                if [[ -f $vagrant_state_file ]]
                then
                      running_vm_list=$(grep 'active' $vagrant_state_file | sed -e 's/"active"://' | tr ',' '\n' | cut -d '"' -f 2 | tr '\n' ' ')
                else
                      running_vm_list=$(find $vagrant_state_file -type f -name "id" | awk -F"/" '{print $(NF-2)}')
                fi
                COMPREPLY=($(compgen -W "${running_vm_list}" -- ${cur}))
                return 0
                ;;
            "box")
                box_commands="add list outdated prune remove repackage update"
                COMPREPLY=($(compgen -W "${box_commands}" -- ${cur}))
                return 0
                ;;
            "plugin")
                plugin_commands="expunge install license list repair uninstall update"
                COMPREPLY=($(compgen -W "${plugin_commands}" -- ${cur}))
                return 0
                ;;
            "help")
                COMPREPLY=($(compgen -W "${commands}" -- ${cur}))
                return 0
                ;;
            "snapshot")
                snapshot_commands="delete list pop push restore save"
                COMPREPLY=($(compgen -W "${snapshot_commands}" -- ${cur}))
                return 0
                ;;
            *)
            ;;
        esac
    fi

    if [ $COMP_CWORD == 3 ]
    then
      action="${COMP_WORDS[COMP_CWORD-2]}"
      case "$action" in
          "up")
              if [ "$prev" == "--no-provision" ]; then
                  COMPREPLY=($(compgen -W "${vm_list}" -- ${cur}))
                  return 0
              fi
              ;;
          "box")
              case "$prev" in
                  "remove"|"repackage")
                      local box_list=$(find "$HOME/.vagrant.d/boxes" -mindepth 1 -maxdepth 1 -type d -exec basename {} \;|sed -e 's/-VAGRANTSLASH-/\//')
                      COMPREPLY=($(compgen -W "${box_list}" -- ${cur}))
                      return 0
                      ;;
                  *)
              esac
              ;;
          "snapshot")
              if [ "$prev" == "restore" ]; then
                  COMPREPLY=($(compgen -W "${vm_list}" -- ${cur}))
                  return 0
              fi
              ;;
      esac
    fi

    if [ $COMP_CWORD == 4 ]
    then
      action="${COMP_WORDS[COMP_CWORD-3]}"
      prev="${COMP_WORDS[COMP_CWORD-2]}"
      case "$action" in
          "snapshot")
              if [ "$prev" == "restore" ]; then
                  local snapshot_list="$(vagrant snapshot list ${cur} 2>/dev/null | awk '{ORS=" "} /==>/ {next} {print}')"
                  COMPREPLY=($(compgen -W "${snapshot_list}" -- ${cur}))
                  return 0
              fi
              ;;
          *)
          ;;
      esac
# Ensure that we log to doctor so the user can address these issues
_is_function _init_completion ||
  _log_error '_init_completion not found. Ensure bash-completion 2.0 or newer is installed and configured properly.'
_is_function _rl_enabled ||
  _log_error '_rl_enabled not found. Ensure bash-completion 2.0 or newer is installed and configured properly.'

_pj() {
  _is_function _init_completion || return
  _is_function _rl_enabled || return
  [ -n "$PROJECT_PATHS" ] || return
  shift
  [ "$1" == "open" ] && shift

  local cur prev words cword
  _init_completion || return

  local IFS=$'\n' i j k

  compopt -o filenames

  local -r mark_dirs=$(_rl_enabled mark-directories && echo y)
  local -r mark_symdirs=$(_rl_enabled mark-symlinked-directories && echo y)

  for i in ${PROJECT_PATHS//:/$'\n'}; do
    # create an array of matched subdirs
    k="${#COMPREPLY[@]}"
    for j in $( compgen -d $i/$cur ); do
      if [[ ( $mark_symdirs && -h $j || $mark_dirs && ! -h $j ) && ! -d ${j#$i/} ]]; then
        j+="/"
      fi
      COMPREPLY[k++]=${j#$i/}
    done
  done

  if [[ ${#COMPREPLY[@]} -eq 1 ]]; then
    i=${COMPREPLY[0]}
    if [[ "$i" == "$cur" && $i != "*/" ]]; then
      COMPREPLY[0]="${i}/"
    fi
  fi

  return 0
}

complete -F _pj -o nospace pj
# shellcheck shell=bash
cite "about-completion"
about-completion "Google Cloud SDK completion"

if _command_exists gcloud; then
	# get install path
	GOOGLE_SDK_ROOT=${GOOGLE_SDK_ROOT:-$(gcloud info --format="value(installation.sdk_root)")}

	# source all the bash completion file that are available
	for i in "${GOOGLE_SDK_ROOT}"/*.bash.inc; do
# shellcheck shell=bash
cite "about-completion"
about-completion "helm (Kubernetes Package Manager) completion"

if _command_exists helm; then
#!/usr/bin/env bash
# Bash completion support for Rake, Ruby Make.

export COMP_WORDBREAKS=${COMP_WORDBREAKS/\:/}

_rakecomplete() {
    if [ -f Rakefile ]; then
        recent=`ls -t .rake_tasks~ Rakefile **/*.rake 2> /dev/null | head -n 1`
        if [[ $recent != '.rake_tasks~' ]]; then
            rake --silent --tasks | cut -d " " -f 2 > .rake_tasks~
        fi
        COMPREPLY=($(compgen -W "`cat .rake_tasks~`" -- ${COMP_WORDS[COMP_CWORD]}))
        return 0
    fi
}
# shellcheck shell=bash

# https://pip.pypa.io/en/stable/user_guide/#command-completion
# Of course, you should first install pip, say on Debian:
# sudo apt-get install python3-pip
# If the pip package is installed within virtual environments, say, python managed by pyenv,
# you should first initialize the corresponding environment.
# So that pip3 is in the system's path.
if _command_exists pip3; then
	eval "$(pip3 completion --bash)"
# hub tab-completion script for bash.
# This script complements the completion script that ships with git.

# Copyright (c) 2009 Chris Wanstrath

# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:

# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

# If there is no git tab completion, but we have the _completion loader try to load it
if ! declare -F _git > /dev/null && declare -F _completion_loader > /dev/null; then
  _completion_loader git
fi

# Check that git tab completion is available and we haven't already set up completion
if declare -F _git > /dev/null && ! declare -F __git_list_all_commands_without_hub > /dev/null; then
  # Duplicate and rename the 'list_all_commands' function
  eval "$(declare -f __git_list_all_commands | \
        sed 's/__git_list_all_commands/__git_list_all_commands_without_hub/')"

  # Wrap the 'list_all_commands' function with extra hub commands
  __git_list_all_commands() {
    cat <<-EOF
alias
pull-request
pr
issue
release
fork
create
delete
browse
compare
ci-status
sync
EOF
    __git_list_all_commands_without_hub
  }

  # Ensure cached commands are cleared
  __git_all_commands=""

  ##########################
  # hub command completions
  ##########################

  # hub alias [-s] [SHELL]
  _git_alias() {
    local i c=2 s=-s sh shells="bash zsh sh ksh csh fish"
    while [ $c -lt $cword ]; do
      i="${words[c]}"
      case "$i" in
        -s)
          unset s
          ;;
        *)
          for sh in $shells; do
            if [ "$sh" = "$i" ]; then
              unset shells
              break
            fi
          done
          ;;
      esac
      ((c++))
    done
    __gitcomp "$s $shells"
  }

  # hub browse [-u] [--|[USER/]REPOSITORY] [SUBPAGE]
  _git_browse() {
    local i c=2 u=-u repo subpage
    local subpages_="commits issues tree wiki pulls branches stargazers
      contributors network network/ graphs graphs/"
    local subpages_network="members"
    local subpages_graphs="commit-activity code-frequency punch-card"
    while [ $c -lt $cword ]; do
      i="${words[c]}"
      case "$i" in
        -u)
          unset u
          ;;
        *)
          if [ -z "$repo" ]; then
            repo=$i
          else
            subpage=$i
          fi
          ;;
      esac
      ((c++))
    done
    if [ -z "$repo" ]; then
      __gitcomp "$u -- $(__hub_github_repos '\p')"
    elif [ -z "$subpage" ]; then
      case "$cur" in
        */*)
          local pfx="${cur%/*}" cur_="${cur#*/}"
          local subpages_var="subpages_$pfx"
          __gitcomp "${!subpages_var}" "$pfx/" "$cur_"
          ;;
        *)
          __gitcomp "$u ${subpages_}"
          ;;
      esac
    else
      __gitcomp "$u"
    fi
  }

  # hub compare [-u] [USER[/REPOSITORY]] [[START...]END]
  _git_compare() {
    local i c=$((cword - 1)) u=-u user remote owner repo arg_repo rev
    while [ $c -gt 1 ]; do
      i="${words[c]}"
      case "$i" in
        -u)
          unset u
          ;;
        *)
          if [ -z "$rev" ]; then
            # Even though the logic below is able to complete both user/repo
            # and revision in the right place, when there is only one argument
            # (other than -u) in the command, that argument will be taken as
            # revision. For example:
            # $ hub compare -u upstream
            # > https://github.com/USER/REPO/compare/upstream
            if __hub_github_repos '\p' | grep -Eqx "^$i(/[^/]+)?"; then
              arg_repo=$i
            else
              rev=$i
            fi
          elif [ -z "$arg_repo" ]; then
            arg_repo=$i
          fi
          ;;
      esac
      ((c--))
    done

    # Here we want to find out the git remote name of user/repo, in order to
    # generate an appropriate revision list
    if [ -z "$arg_repo" ]; then
      user=$(__hub_github_user)
      if [ -z "$user" ]; then
        for i in $(__hub_github_repos); do
          remote=${i%%:*}
          repo=${i#*:}
          if [ "$remote" = origin ]; then
            break
          fi
        done
      else
        for i in $(__hub_github_repos); do
          remote=${i%%:*}
          repo=${i#*:}
          owner=${repo%%/*}
          if [ "$user" = "$owner" ]; then
            break
          fi
        done
      fi
    else
      for i in $(__hub_github_repos); do
        remote=${i%%:*}
        repo=${i#*:}
        owner=${repo%%/*}
        case "$arg_repo" in
          "$repo"|"$owner")
            break
            ;;
        esac
      done
    fi

    local pfx cur_="$cur"
    case "$cur_" in
      *..*)
        pfx="${cur_%%..*}..."
        cur_="${cur_##*..}"
        __gitcomp_nl "$(__hub_revlist $remote)" "$pfx" "$cur_"
        ;;
      *)
        if [ -z "${arg_repo}${rev}" ]; then
          __gitcomp "$u $(__hub_github_repos '\o\n\p') $(__hub_revlist $remote)"
        elif [ -z "$rev" ]; then
          __gitcomp "$u $(__hub_revlist $remote)"
        else
          __gitcomp "$u"
        fi
        ;;
    esac
  }

  # hub create [NAME] [-p] [-d DESCRIPTION] [-h HOMEPAGE]
  _git_create() {
    local i c=2 name repo flags="-p -d -h"
    while [ $c -lt $cword ]; do
      i="${words[c]}"
      case "$i" in
        -d|-h)
          ((c++))
          flags=${flags/$i/}
          ;;
        -p)
          flags=${flags/$i/}
          ;;
        *)
          name=$i
          ;;
      esac
      ((c++))
    done
    if [ -z "$name" ]; then
      repo=$(basename "$(pwd)")
    fi
    case "$prev" in
      -d|-h)
        COMPREPLY=()
        ;;
      -p|*)
        __gitcomp "$repo $flags"
        ;;
    esac
  }

  # hub fork [--no-remote] [--remote-name REMOTE] [--org ORGANIZATION]
  _git_fork() {
    local i c=2 flags="--no-remote --remote-name --org"
    while [ $c -lt $cword ]; do
      i="${words[c]}"
      case "$i" in
        --org)
          ((c++))
          flags=${flags/$i/}
          ;;
        --remote-name)
          ((c++))
          flags=${flags/$i/}
          flags=${flags/--no-remote/}
          ;;
        --no-remote)
          flags=${flags/$i/}
          flags=${flags/--remote-name/}
          ;;
      esac
      ((c++))
    done
    case "$prev" in
      --remote-name|--org)
        COMPREPLY=()
        ;;
      *)
        __gitcomp "$flags"
        ;;
    esac
  }

  # hub pull-request [-f] [-m <MESSAGE>|-F <FILE>|-i <ISSUE>|<ISSUE-URL>] [-b <BASE>] [-h <HEAD>] [-a <USER>] [-M <MILESTONE>] [-l <LABELS>]
  _git_pull_request() {
    local i c=2 flags="-f -m -F -i -b -h -a -M -l"
    while [ $c -lt $cword ]; do
      i="${words[c]}"
      case "$i" in
        -m|-F|-i|-b|-h|-a|-M|-l)
          ((c++))
          flags=${flags/$i/}
          ;;
        -f)
          flags=${flags/$i/}
          ;;
      esac
      ((c++))
    done
    case "$prev" in
      -i)
        COMPREPLY=()
        ;;
      -b|-h|-a|-M|-l)
        # (Doesn't seem to need this...)
        # Uncomment the following line when 'owner/repo:[TAB]' misbehaved
        #_get_comp_words_by_ref -n : cur
        __gitcomp_nl "$(__hub_heads)"
        # __ltrim_colon_completions "$cur"
        ;;
      -F)
        COMPREPLY=( "$cur"* )
        ;;
      -f|*)
        __gitcomp "$flags"
        ;;
    esac
  }

  ###################
  # Helper functions
  ###################

  # __hub_github_user [HOST]
  # Return $GITHUB_USER or the default github user defined in hub config
  # HOST - Host to be looked-up in hub config. Default is "github.com"
  __hub_github_user() {
    if [ -n "$GITHUB_USER" ]; then
      echo $GITHUB_USER
      return
    fi
    local line h k v host=${1:-github.com} config=${HUB_CONFIG:-~/.config/hub}
    if [ -f "$config" ]; then
      while read line; do
        if [ "$line" = "---" ]; then
          continue
        fi
        k=${line%%:*}
        v=${line#*:}
        if [ -z "$v" ]; then
          if [ "$h" = "$host" ]; then
            break
          fi
          h=$k
          continue
        fi
        k=${k#* }
        v=${v#* }
        if [ "$h" = "$host" ] && [ "$k" = "user" ]; then
          echo "$v"
          break
        fi
      done < "$config"
    fi
  }

  # __hub_github_repos [FORMAT]
  # List all github hosted repository
  # FORMAT - Format string contains multiple of these:
  #   \m  remote
  #   \p  owner/repo
  #   \o  owner
  #   escaped characters (\n, \t ...etc) work
  # If omitted, prints all github repos in the format of "remote:owner/repo"
  __hub_github_repos() {
    local f format=$1
    if [ -z "$(__gitdir)" ]; then
      return
    fi
    if [ -z "$format" ]; then
      format='\1:\2'
    else
      format=${format//\m/\1}
      format=${format//\p/\2}
      format=${format//\o/\3}
    fi
    command git config --get-regexp 'remote\.[^.]*\.url' |
    grep -E ' ((https?|git)://|git@)github\.com[:/][^:/]+/[^/]+$' |
    sed -E 's#^remote\.([^.]+)\.url +.+[:/](([^/]+)/[^.]+)(\.git)?$#'"$format"'#'
  }

  # __hub_heads
  # List all local "branch", and remote "owner/repo:branch"
  __hub_heads() {
    local i remote repo branch dir=$(__gitdir)
    if [ -d "$dir" ]; then
      command git --git-dir="$dir" for-each-ref --format='%(refname:short)' \
        "refs/heads/"
      for i in $(__hub_github_repos); do
        remote=${i%%:*}
        repo=${i#*:}
        command git --git-dir="$dir" for-each-ref --format='%(refname:short)' \
          "refs/remotes/${remote}/" | while read branch; do
          echo "${repo}:${branch#${remote}/}"
        done
      done
    fi
  }

  # __hub_revlist [REMOTE]
  # List all tags, and branches under REMOTE, without the "remote/" prefix
  # REMOTE - Remote name to search branches from. Default is "origin"
  __hub_revlist() {
    local i remote=${1:-origin} dir=$(__gitdir)
    if [ -d "$dir" ]; then
      command git --git-dir="$dir" for-each-ref --format='%(refname:short)' \
        "refs/remotes/${remote}/" | while read i; do
        echo "${i#${remote}/}"
      done
      command git --git-dir="$dir" for-each-ref --format='%(refname:short)' \
        "refs/tags/"
    fi
  }

  # Enable completion for hub even when not using the alias
# shellcheck shell=bash
cite "about-completion"
about-completion "kubectl (Kubernetes CLI) completion"

if _binary_exists kubectl; then
# shellcheck shell=bash
cite "about-completion"
about-completion "vault completion"

if _binary_exists vault; then
#!/usr/bin/env bash
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" |"
SCM_THEME_PROMPT_SUFFIX="${green}|"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

VIRTUALENV_THEME_PROMPT_PREFIX="${green}ⓔ  "
VIRTUALENV_THEME_PROMPT_SUFFIX=""

function prompt_command() {
SCM_THEME_PROMPT_PREFIX=${SCM_THEME_PROMPT_SUFFIX}
SCM_THEME_PROMPT_DIRTY="${bold_red} ✗${normal}"
SCM_THEME_PROMPT_CLEAN="${bold_green} ✓${normal}"
SCM_GIT_CHAR="${green}±${normal}"

scm_prompt() {
    CHAR=$(scm_char)
    if [ $CHAR = $SCM_NONE_CHAR ]
        then
            return
        else
            echo " [$(scm_char)$(scm_prompt_info)]"
    fi
}

mark_prompt() {
    echo "${green}\$${normal}"
}

user_host_path_prompt() {
    ps_user="${green}\u${normal}";
    ps_host="${blue}\H${normal}";
    ps_path="${yellow}\w${normal}";
    echo "$ps_user@$ps_host:$ps_path"
}

prompt() {
  PS1="$(user_host_path_prompt)$(virtualenv_prompt)$(scm_prompt) $(mark_prompt) "
}

share_history() {
  history -a
  history -c
  history -r
}


# git branch parser
function parse_git_branch() {
    echo -e "\033[1;34m$(git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \(.*\)/(\1)/')\033[0m"
}

function parse_git_branch_no_color() {
    echo -e "$(git branch 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \(.*\)/(\1)/')"
}

function prompt() {
    # If not running interactively, don't do anything
    [[ $- != *i* ]] && return

    local force_color_prompt=yes

    if [ -n "$force_color_prompt" ]; then
        if [ -x /usr/bin/tput ] && tput setaf 1 >&/dev/null; then
        # We have color support; assume it's compliant with Ecma-48
        # (ISO/IEC-6429). (Lack of such support is extremely rare, and such
        # a case would tend to support setf rather than setaf.)
            local color_prompt=yes
        else
            local color_prompt=
        fi
    fi

    if [ "$color_prompt" = yes ]; then
        PS1="\[\033[0;31m\]\342\224\214\342\224\200\$([[ \$? != 0 ]] && echo \"[\[\033[0;31m\]\342\234\227\[\033[0;37m\]]\342\224\200\")[$(if [[ ${EUID} == 0 ]]; then echo '\[\033[01;31m\]root\[\033[01;33m\]@\[\033[01;96m\]\h'; else echo '\[\033[0;39m\]\u\[\033[01;33m\]@\[\033[01;96m\]\h'; fi)\[\033[0;31m\]]\342\224\200[\[\033[0;32m\]\w\[\033[0;31m\]]\n\[\033[0;31m\]\342\224\224\342\224\200\342\224\200\342\225\274 \[\033[0m\]\[\e[01;33m\]$(parse_git_branch) $\[\e[0m\] "

    else
        PS1='┌──[\u@\h]─[\w]\n└──╼ $(parse_git_branch_no_color) $ '
    fi
}
#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=" ${bold_red}⊘${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_THEME_PROMPT_PREFIX="${reset_color}( "
SCM_THEME_PROMPT_SUFFIX=" ${reset_color})"

GIT_THEME_PROMPT_DIRTY=" ${bold_red}⊘${normal}"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
GIT_THEME_PROMPT_PREFIX="${reset_color}( "
GIT_THEME_PROMPT_SUFFIX=" ${reset_color})"

STATUS_THEME_PROMPT_BAD="${bold_red}❯${reset_color}${normal} "
STATUS_THEME_PROMPT_OK="${bold_green}❯${reset_color}${normal} "
PURITY_THEME_PROMPT_COLOR="${PURITY_THEME_PROMPT_COLOR:=$blue}"

function prompt_command() {
    local ret_status="$( [ $? -eq 0 ] && echo -e "$STATUS_THEME_PROMPT_OK" || echo -e "$STATUS_THEME_PROMPT_BAD")"
    PS1="\n${PURITY_THEME_PROMPT_COLOR}\w $(scm_prompt_info)\n${ret_status} "
}
# shellcheck shell=bash

SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

is_vim_shell() {
	if [ -n "$VIMRUNTIME" ]; then
		echo "[${cyan}vim shell${normal}]"
	fi
}

scm_prompt() {
	CHAR=$(scm_char)
	if [ "$CHAR" = "$SCM_NONE_CHAR" ]; then
		return
	else
		echo " $(scm_char) (${white}$(scm_prompt_info)${normal})"
	fi
}

prompt() {
	PS1="${white}${background_blue} \u${normal}${background_blue}@${red}${background_blue}\h $(clock_prompt) ${reset_color}${normal} $(battery_charge)\n${bold_black}${background_white} \w ${normal}$(scm_prompt)$(is_vim_shell)\n${white}>${normal} "
}

#!/usr/bin/env bash

function _git-symbolic-ref {
 git symbolic-ref -q HEAD 2> /dev/null
}

# When on a branch, this is often the same as _git-commit-description,
# but this can be different when two branches are pointing to the
# same commit. _git-branch is used to explicitly choose the checked-out
# branch.
function _git-branch {
  if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
    test -n "${VCS_STATUS_LOCAL_BRANCH}" && echo "${VCS_STATUS_LOCAL_BRANCH}" || return 1
  else
    git symbolic-ref -q --short HEAD 2> /dev/null || return 1
  fi
}

function _git-tag {
  if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
    test -n "${VCS_STATUS_TAG}" && echo "${VCS_STATUS_TAG}"
  else
    git describe --tags --exact-match 2> /dev/null
  fi
}

function _git-commit-description {
  git describe --contains --all 2> /dev/null
}

function _git-short-sha {
  if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
    echo ${VCS_STATUS_COMMIT:0:7}
  else
    git rev-parse --short HEAD
  fi
}

# Try the checked-out branch first to avoid collision with branches pointing to the same ref.
function _git-friendly-ref {
  if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
    _git-branch || _git-tag || _git-short-sha # there is no tag based describe output in gitstatus
  else
    _git-branch || _git-tag || _git-commit-description || _git-short-sha
  fi
}

function _git-num-remotes {
  git remote | wc -l
}

function _git-upstream {
  local ref
  ref="$(_git-symbolic-ref)" || return 1
  git for-each-ref --format="%(upstream:short)" "${ref}"
}

function _git-upstream-remote {
  local upstream
  upstream="$(_git-upstream)" || return 1

  local branch
  branch="$(_git-upstream-branch)" || return 1
  echo "${upstream%"/${branch}"}"
}

function _git-upstream-branch {
  local ref
  ref="$(_git-symbolic-ref)" || return 1

  # git versions < 2.13.0 do not support "strip" for upstream format
  # regex replacement gives the wrong result for any remotes with slashes in the name,
  # so only use when the strip format fails.
  git for-each-ref --format="%(upstream:strip=3)" "${ref}" 2> /dev/null || git for-each-ref --format="%(upstream)" "${ref}" | sed -e "s/.*\/.*\/.*\///"
}

function _git-upstream-behind-ahead {
  git rev-list --left-right --count "$(_git-upstream)...HEAD" 2> /dev/null
}

function _git-upstream-branch-gone {
  [[ "$(git status -s -b | sed -e 's/.* //')" == "[gone]" ]]
}

function _git-hide-status {
  [[ "$(git config --get bash-it.hide-status)" == "1" ]]
}

function _git-status {
  local git_status_flags=
  [[ "${SCM_GIT_IGNORE_UNTRACKED}" = "true" ]] && git_status_flags='-uno' || true
  git status --porcelain ${git_status_flags} 2> /dev/null
}

function _git-status-counts {
  _git-status | awk '
  BEGIN {
    untracked=0;
    unstaged=0;
    staged=0;
  }
  {
    if ($0 ~ /^\?\? .+/) {
      untracked += 1
    } else {
      if ($0 ~ /^.[^ ] .+/) {
        unstaged += 1
      }
      if ($0 ~ /^[^ ]. .+/) {
        staged += 1
      }
    }
  }
  END {
    print untracked "\t" unstaged "\t" staged
  }'
}

function _git-remote-info {

  # prompt handling only, reimplement because patching the routine below gets ugly
  if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
    [[ "${VCS_STATUS_REMOTE_NAME}" == "" ]] && return
    [[ "${VCS_STATUS_LOCAL_BRANCH}" == "${VCS_STATUS_REMOTE_BRANCH}" ]] && local same_branch_name=true
    local same_branch_name=
    [[ "${VCS_STATUS_LOCAL_BRANCH}" == "${VCS_STATUS_REMOTE_BRANCH}" ]] && same_branch_name=true
    # no multiple remote support in gitstatusd
    if [[ "${SCM_GIT_SHOW_REMOTE_INFO}" = "true" || "${SCM_GIT_SHOW_REMOTE_INFO}" = "auto" ]]; then
      if [[ "${same_branch_name}" != "true" ]]; then
        remote_info="${VCS_STATUS_REMOTE_NAME}/${VCS_STATUS_REMOTE_BRANCH}"
      else
        remote_info="${VCS_STATUS_REMOTE_NAME}"
      fi
    elif [[ ${same_branch_name} != "true" ]]; then
      remote_info="${VCS_STATUS_REMOTE_BRANCH}"
    fi
    if [[ -n "${remote_info}" ]];then
      # no support for gone remote branches in gitstatusd
      local branch_prefix="${SCM_THEME_BRANCH_TRACK_PREFIX}"
      echo "${branch_prefix}${remote_info}"
    fi
  else
    [[ "$(_git-upstream)" == "" ]] && return

    [[ "$(_git-branch)" == "$(_git-upstream-branch)" ]] && local same_branch_name=true
    local same_branch_name=
    [[ "$(_git-branch)" == "$(_git-upstream-branch)" ]] && same_branch_name=true
    if [[ ("${SCM_GIT_SHOW_REMOTE_INFO}" = "auto" && "$(_git-num-remotes)" -ge 2) ||
           "${SCM_GIT_SHOW_REMOTE_INFO}" = "true" ]]; then
      if [[ "${same_branch_name}" != "true" ]]; then
        remote_info="\$(_git-upstream)"
      else
        remote_info="$(_git-upstream-remote)"
      fi
    elif [[ ${same_branch_name} != "true" ]]; then
      remote_info="\$(_git-upstream-branch)"
    fi
    if [[ -n "${remote_info}" ]];then
      local branch_prefix
      if _git-upstream-branch-gone; then
        branch_prefix="${SCM_THEME_BRANCH_GONE_PREFIX}"
      else
        branch_prefix="${SCM_THEME_BRANCH_TRACK_PREFIX}"
      fi
      echo "${branch_prefix}${remote_info}"
    fi
  fi
}

# Unused by bash-it, present for API compatibility
function git_status_summary {
  awk '
  BEGIN {
    untracked=0;
    unstaged=0;
    staged=0;
  }
  {
    if (!after_first && $0 ~ /^##.+/) {
      print $0
      seen_header = 1
    } else if ($0 ~ /^\?\? .+/) {
      untracked += 1
    } else {
      if ($0 ~ /^.[^ ] .+/) {
        unstaged += 1
      }
      if ($0 ~ /^[^ ]. .+/) {
        staged += 1
      }
    }
    after_first = 1
  }
  END {
    if (!seen_header) {
# Sexy Bash Prompt, inspired by "Extravagant Zsh Prompt"
# Screenshot: http://cloud.gf3.ca/M5rG
# A big thanks to \amethyst on Freenode
#
# Configuration:
#   * To visualize python environment (virtualenv and conda) add in your .bash_profile the following line:
#       export SEXY_THEME_SHOW_PYTHON=true

# Default setting
SEXY_THEME_SHOW_PYTHON="${SEXY_THEME_SHOW_PYTHON:=false}"

if tput setaf 1 &> /dev/null; then
    if [[ $(tput colors) -ge 256 ]] 2>/dev/null; then
      MAGENTA=$(tput setaf 9)
      ORANGE=$(tput setaf 172)
      GREEN=$(tput setaf 190)
      PURPLE=$(tput setaf 141)
      WHITE=$(tput setaf 0)
    else
      MAGENTA=$(tput setaf 5)
      ORANGE=$(tput setaf 4)
      GREEN=$(tput setaf 2)
      PURPLE=$(tput setaf 1)
      WHITE=$(tput setaf 7)
    fi
    BOLD=$(tput bold)
    RESET=$(tput sgr0)
else
    MAGENTA="\033[1;31m"
    ORANGE="\033[1;33m"
    GREEN="\033[1;32m"
    PURPLE="\033[1;35m"
    WHITE="\033[1;37m"
    BOLD=""
    RESET="\033[m"
fi

parse_git_dirty () {
  [[ $(git status 2> /dev/null | tail -n1 | cut -c 1-17) != "nothing to commit" ]] && echo "*"
}
parse_git_branch () {
  git branch --no-color 2> /dev/null | sed -e '/^[^*]/d' -e "s/* \(.*\)/\1$(parse_git_dirty)/"
}
env_prompt () {
  echo -e "($(virtualenv_prompt)$(condaenv_prompt))"
}

function prompt_command() {
  PS1="\[${BOLD}${MAGENTA}\]\u \[$WHITE\]at \[$ORANGE\]\h \[$WHITE\]in \[$GREEN\]\w\[$WHITE\]\$([[ -n \$(git branch 2> /dev/null) ]] && echo \" on \")\[$PURPLE\]\$(parse_git_branch)\[$WHITE\]\n\$ \[$RESET\]"

  if [ "$SEXY_THEME_SHOW_PYTHON" = true ] ; then
    PS1="\[${BOLD}${WHITE}\]$(env_prompt) "$PS1
  fi
}

#!/usr/bin/env bash

# Theme inspired on:
#  - Ronacher's dotfiles (mitsuhikos) - http://github.com/mitsuhiko/dotfiles/tree/master/bash/
#  - Glenbot - http://theglenbot.com/custom-bash-shell-for-development/
#  - My extravagant zsh - http://stevelosh.com/blog/2010/02/my-extravagant-zsh-prompt/
#  - Monokai colors - http://monokai.nl/blog/2006/07/15/textmate-color-theme/
#  - Bash_it modern theme
#
# Screenshot: http://goo.gl/VCmX5
# by Jesus de Mula <jesus@demula.name>

# For the real Monokai colors you should add these to your .XDefaults or
# terminal configuration:
#! ----------------------------------------------------------- TERMINAL COLORS
#! monokai - http://www.monokai.nl/blog/2006/07/15/textmate-color-theme/
#*background: #272822
#*foreground: #E2DA6E
#*color0: black
#! mild red
#*color1: #CD0000
#! light green
#*color2: #A5E02D
#! orange (yellow)
#*color3: #FB951F
#! "dark" blue
#*color4: #076BCC
#! hot pink
#*color5: #F6266C
#! cyan
#*color6: #64D9ED
#! gray
#*color7: #E5E5E5

# ----------------------------------------------------------------- COLOR CONF
D_DEFAULT_COLOR="${normal}"
D_INTERMEDIATE_COLOR="${white}"
D_USER_COLOR="${purple}"
D_SUPERUSER_COLOR="${red}"
D_MACHINE_COLOR="${cyan}"
D_DIR_COLOR="${green}"
D_SCM_COLOR="${yellow}"
D_BRANCH_COLOR="${yellow}"
D_CHANGES_COLOR="${white}"
D_CMDFAIL_COLOR="${red}"
D_VIMSHELL_COLOR="${cyan}"

# ------------------------------------------------------------------ FUNCTIONS
case $TERM in
  xterm*)
      TITLEBAR="\033]0;\w\007"
      ;;
  *)
      TITLEBAR=""
      ;;
esac

is_vim_shell() {
  if [ ! -z "$VIMRUNTIME" ];
  then
    echo "${D_INTERMEDIATE_COLOR}on ${D_VIMSHELL_COLOR}\
vim shell${D_DEFAULT_COLOR} "
  fi
}

mitsuhikos_lastcommandfailed() {
  code=$?
  if [ $code != 0 ];
  then
    echo "${D_INTERMEDIATE_COLOR}exited ${D_CMDFAIL_COLOR}\
$code ${D_DEFAULT_COLOR}"
  fi
}

# vcprompt for scm instead of bash_it default
demula_vcprompt() {
  if [ ! -z "$VCPROMPT_EXECUTABLE" ];
  then
    local D_VCPROMPT_FORMAT="on ${D_SCM_COLOR}%s${D_INTERMEDIATE_COLOR}:\
${D_BRANCH_COLOR}%b %r ${D_CHANGES_COLOR}%m%u ${D_DEFAULT_COLOR}"
    $VCPROMPT_EXECUTABLE -f "$D_VCPROMPT_FORMAT"
  fi
}

# checks if the plugin is installed before calling battery_charge
safe_battery_charge() {
  if _command_exists battery_charge ;
  then
    battery_charge
  fi
}

# -------------------------------------------------------------- PROMPT OUTPUT
prompt() {
  local LAST_COMMAND_FAILED=$(mitsuhikos_lastcommandfailed)
  local SAVE_CURSOR='\033[s'
  local RESTORE_CURSOR='\033[u'
  local MOVE_CURSOR_RIGHTMOST='\033[500C'
  local MOVE_CURSOR_5_LEFT='\033[5D'

  if [ $(uname) = "Linux" ];
  then
    PS1="${TITLEBAR}${SAVE_CURSOR}${MOVE_CURSOR_RIGHTMOST}${MOVE_CURSOR_5_LEFT}
$(safe_battery_charge)${RESTORE_CURSOR}\
${D_USER_COLOR}\u ${D_INTERMEDIATE_COLOR}\
at ${D_MACHINE_COLOR}\h ${D_INTERMEDIATE_COLOR}\
in ${D_DIR_COLOR}\w ${D_INTERMEDIATE_COLOR}\
${LAST_COMMAND_FAILED}\
$(demula_vcprompt)\
$(is_vim_shell)
${D_INTERMEDIATE_COLOR}$ ${D_DEFAULT_COLOR}"
  else
    PS1="${TITLEBAR}
${D_USER_COLOR}\u ${D_INTERMEDIATE_COLOR}\
at ${D_MACHINE_COLOR}\h  ${D_INTERMEDIATE_COLOR}\
in ${D_DIR_COLOR}\w ${D_INTERMEDIATE_COLOR}\
${LAST_COMMAND_FAILED}\
$(demula_vcprompt)\
$(is_vim_shell)\
$(safe_battery_charge)
${D_INTERMEDIATE_COLOR}$ ${D_DEFAULT_COLOR}"
  fi

  PS2="${D_INTERMEDIATE_COLOR}$ ${D_DEFAULT_COLOR}"
}
#!/usr/bin/env bash

SCM_THEME_PROMPT_PREFIX=" ${purple}"
SCM_THEME_PROMPT_SUFFIX=" ${normal}"
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${green}✓"
SCM_GIT_SHOW_DETAILS="false"

function prompt_command() {
  PS1="${yellow}\u${normal}${cyan}@\h${normal}${purple} ${normal}${green}\w${normal}$(scm_prompt_info)> "
# scm theming
SCM_THEME_PROMPT_PREFIX="|"
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${green}✓${normal}"
SCM_GIT_CHAR="${green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

VIRTUALENV_THEME_PROMPT_PREFIX="("
VIRTUALENV_THEME_PROMPT_SUFFIX=")"

### TODO: openSUSE has already colors enabled, check if those differs from stock
# LS colors, made with http://geoff.greer.fm/lscolors/
# export LSCOLORS="Gxfxcxdxbxegedabagacad"
# export LS_COLORS='no=00:fi=00:di=01;34:ln=00;36:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=41;33;01:ex=00;32:*.cmd=00;32:*.exe=01;32:*.com=01;32:*.bat=01;32:*.btm=01;32:*.dll=01;32:*.tar=00;31:*.tbz=00;31:*.tgz=00;31:*.rpm=00;31:*.deb=00;31:*.arj=00;31:*.taz=00;31:*.lzh=00;31:*.lzma=00;31:*.zip=00;31:*.zoo=00;31:*.z=00;31:*.Z=00;31:*.gz=00;31:*.bz2=00;31:*.tb2=00;31:*.tz2=00;31:*.tbz2=00;31:*.avi=01;35:*.bmp=01;35:*.fli=01;35:*.gif=01;35:*.jpg=01;35:*.jpeg=01;35:*.mng=01;35:*.mov=01;35:*.mpg=01;35:*.pcx=01;35:*.pbm=01;35:*.pgm=01;35:*.png=01;35:*.ppm=01;35:*.tga=01;35:*.tif=01;35:*.xbm=01;35:*.xpm=01;35:*.dl=01;35:*.gl=01;35:*.wmv=01;35:*.aiff=00;32:*.au=00;32:*.mid=00;32:*.mp3=00;32:*.ogg=00;32:*.voc=00;32:*.wav=00;32:'

scm_prompt() {
    CHAR=$(scm_char)
    if [ $CHAR = $SCM_NONE_CHAR ]
        then
            return
        else
            echo "[$(scm_char)$(scm_prompt_info)]"
    fi
}

pure_prompt() {
    ps_host="${bold_blue}\h${normal}";
    ps_user="${green}\u${normal}";
    ps_user_mark="${green} $ ${normal}";
    ps_root="${red}\u${red}";
    ps_root_mark="${red} # ${normal}"
    ps_path="${yellow}\w${normal}";

    # make it work
    case $(id -u) in
        0) PS1="$(virtualenv_prompt)$ps_root@$ps_host$(scm_prompt):$ps_path$ps_root_mark"
            ;;
        *) PS1="$(virtualenv_prompt)$ps_user@$ps_host$(scm_prompt):$ps_path$ps_user_mark"
            ;;
    esac
}

#!/usr/bin/env bash

function prompt_command() {
    PS1="${green}\u@\h $(clock_prompt) ${reset_color}${white}\w${reset_color}$(scm_prompt_info)${blue} →${bold_blue} ${reset_color} ${normal}";
}
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_cyan}±${normal}"
SCM_SVN_CHAR="${bold_green}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

#Mysql Prompt
export MYSQL_PS1="(\u@\h) [\d]> "

case $TERM in
        xterm*)
        TITLEBAR="\[\033]0;\w\007\]"
        ;;
        *)
        TITLEBAR=""
        ;;
esac

PS3=">> "

__my_rvm_ruby_version() {
    local gemset=$(echo $GEM_HOME | awk -F'@' '{print $2}')
  [ "$gemset" != "" ] && gemset="@$gemset"
    local version=$(echo $MY_RUBY_HOME | awk -F'-' '{print $2}')
    local full="$version$gemset"
  [ "$full" != "" ] && echo "[$full]"
}

__my_venv_prompt() {
  if [ ! -z "$VIRTUAL_ENV" ]
  then
    echo "[${blue}@${normal}${VIRTUAL_ENV##*/}]"
  fi
}

is_vim_shell() {
        if [ ! -z "$VIMRUNTIME" ]
        then
                echo "[${cyan}vim shell${normal}]"
        fi
}

modern_scm_prompt() {
        CHAR=$(scm_char)
        if [ $CHAR = $SCM_NONE_CHAR ]
        then
                return
        else
                echo "[$(scm_char)][$(scm_prompt_info)]"
        fi
}

prompt() {

   case $HOSTNAME in
    "clappy"* ) my_ps_host="${green}\h${normal}";
            ;;
    "icekernel") my_ps_host="${red}\h${normal}";
            ;;
    * ) my_ps_host="${green}\h${normal}";
            ;;
    esac

    my_ps_user="\[\033[01;32m\]\u\[\033[00m\]";
    my_ps_root="\[\033[01;31m\]\u\[\033[00m\]";
    my_ps_path="\[\033[01;36m\]\w\[\033[00m\]";

    # nice prompt
    case "`id -u`" in
        0) PS1="${TITLEBAR}[$my_ps_root][$my_ps_host]$(modern_scm_prompt)$(__my_rvm_ruby_version)[${cyan}\w${normal}]$(is_vim_shell)
$ "
        ;;
      *) PS1="${TITLEBAR}[$my_ps_user][$my_ps_host]$(modern_scm_prompt)$(__my_rvm_ruby_version)$(__my_venv_prompt)[${cyan}\w${normal}]$(is_vim_shell)
$ "
        ;;
    esac
}

PS2="> "



#!/usr/bin/env bash

# Theme inspired on:
#  - Ronacher's dotfiles (mitsuhikos) - http://github.com/mitsuhiko/dotfiles/tree/master/bash/
#  - Glenbot - http://theglenbot.com/custom-bash-shell-for-development/
#  - My extravagant zsh - http://stevelosh.com/blog/2010/02/my-extravagant-zsh-prompt/
#  - Monokai colors - http://monokai.nl/blog/2006/07/15/textmate-color-theme/
#  - Bash_it modern theme
#
# by Rana Amrit Parth<ramrit9@gmaiil.com>

# For the real Monokai colors you should add these to your .XDefaults or
# terminal configuration:
#! ----------------------------------------------------------- TERMINAL COLORS
#! monokai - http://www.monokai.nl/blog/2006/07/15/textmate-color-theme/
#*background: #272822
#*foreground: #E2DA6E
#*color0: black
#! mild red
#*color1: #CD0000
#! light green
#*color2: #A5E02D
#! orange (yellow)
#*color3: #FB951F
#! "dark" blue
#*color4: #076BCC
#! hot pink
#*color5: #F6266C
#! cyan
#*color6: #64D9ED
#! gray
#*color7: #E5E5E5

# ----------------------------------------------------------------- DEF COLOR
RCol='\e[0m'    # Text Reset

# Regular
Bla='\e[0;30m';
Red='\e[0;31m';
Gre='\e[0;32m';
Yel='\e[0;33m';
Blu='\e[0;34m';
Pur='\e[0;35m';
Cya='\e[0;36m';
Whi='\e[0;37m';

# Bold
BBla='\e[1;30m';
BRed='\e[1;31m';
BYel='\e[1;33m';
BGre='\e[1;32m';
BBlu='\e[1;34m';
BPur='\e[1;35m';
BCya='\e[1;36m';
BWhi='\e[1;37m';

# High Intensity
IBla='\e[0;90m';
IRed='\e[0;91m';
IGre='\e[0;92m';
IYel='\e[0;93m';
IBlu='\e[0;94m';
IPur='\e[0;95m';
ICya='\e[0;96m';
IWhi='\e[0;97m';

# ----------------------------------------------------------------- COLOR CONF
D_DEFAULT_COLOR="${Whi}"
D_INTERMEDIATE_COLOR="${BWhi}"
D_USER_COLOR="${Yel}"
D_SUPERUSER_COLOR="${Red}"
D_MACHINE_COLOR="${IYel}"
D_DIR_COLOR="${Gre}"
D_GIT_COLOR="${BBlu}"
D_SCM_COLOR="${BYel}"
D_BRANCH_COLOR="${BYel}"
D_CHANGES_COLOR="${Whi}"
D_CMDFAIL_COLOR="${Red}"
D_VIMSHELL_COLOR="${Cya}"

# ------------------------------------------------------------------ FUNCTIONS
case $TERM in
  xterm*)
      TITLEBAR="\033]0;\w\007"
      ;;
  *)
      TITLEBAR=""
      ;;
esac

is_vim_shell() {
  if [ ! -z "$VIMRUNTIME" ];
  then
    echo "${D_INTERMEDIATE_COLOR}on ${D_VIMSHELL_COLOR}\
vim shell${D_DEFAULT_COLOR} "
  fi
}

mitsuhikos_lastcommandfailed() {
  code=$?
  if [ $code != 0 ];
  then
    echo "${D_INTERMEDIATE_COLOR}exited ${D_CMDFAIL_COLOR}\
$code ${D_DEFAULT_COLOR}"
  fi
}

# vcprompt for scm instead of bash_it default
demula_vcprompt() {
  if [ ! -z "$VCPROMPT_EXECUTABLE" ];
  then
    local D_VCPROMPT_FORMAT="on ${D_SCM_COLOR}%s${D_INTERMEDIATE_COLOR}:\
${D_BRANCH_COLOR}%b %r ${D_CHANGES_COLOR}%m%u ${D_DEFAULT_COLOR}"
    $VCPROMPT_EXECUTABLE -f "$D_VCPROMPT_FORMAT"
  fi
}

# checks if the plugin is installed before calling battery_charge
safe_battery_charge() {
  if _command_exists battery_charge ;
  then
    battery_charge
  fi
}

prompt_git() {
	local s='';
	local branchName='';

	# Check if the current directory is in a Git repository.
	if [ $(git rev-parse --is-inside-work-tree &>/dev/null; echo "${?}") == '0' ]; then

		# check if the current directory is in .git before running git checks
		if [ "$(git rev-parse --is-inside-git-dir 2> /dev/null)" == 'false' ]; then

			# Ensure the index is up to date.
			git update-index --really-refresh -q &>/dev/null;

			# Check for uncommitted changes in the index.
			if ! $(git diff --quiet --ignore-submodules --cached); then
				s+='+';
			fi;

			# Check for unstaged changes.
			if ! $(git diff-files --quiet --ignore-submodules --); then
				s+='!';
			fi;

			# Check for untracked files.
			if [ -n "$(git ls-files --others --exclude-standard)" ]; then
				s+='?';
			fi;

			# Check for stashed files.
			if $(git rev-parse --verify refs/stash &>/dev/null); then
				s+='$';
			fi;

		fi;

		# Get the short symbolic ref.
		# If HEAD isn’t a symbolic ref, get the short SHA for the latest commit
		# Otherwise, just give up.
		branchName="$(git symbolic-ref --quiet --short HEAD 2> /dev/null || \
			git rev-parse --short HEAD 2> /dev/null || \
			echo '(unknown)')";

		[ -n "${s}" ] && s=" [${s}]";

		echo -e "${1}${branchName}${Cya}${s}";
	else
		return;
	fi;
}

# -------------------------------------------------------------- PROMPT OUTPUT
prompt() {
  local LAST_COMMAND_FAILED=$(mitsuhikos_lastcommandfailed)
  local SAVE_CURSOR='\033[s'
  local RESTORE_CURSOR='\033[u'
  local MOVE_CURSOR_RIGHTMOST='\033[500C'
  local MOVE_CURSOR_5_LEFT='\033[5D'

  if [ $(uname) = "Linux" ];
  then
    PS1="${TITLEBAR}
${SAVE_CURSOR}${MOVE_CURSOR_RIGHTMOST}${MOVE_CURSOR_5_LEFT}\
$(safe_battery_charge)${RESTORE_CURSOR}\
${D_USER_COLOR}\u ${D_INTERMEDIATE_COLOR}\
at ${D_MACHINE_COLOR}\h ${D_INTERMEDIATE_COLOR}\
in ${D_DIR_COLOR}\w ${D_INTERMEDIATE_COLOR}\
$(prompt_git "$D_INTERMEDIATE_COLOR on $D_GIT_COLOR")\
${LAST_COMMAND_FAILED}\
$(demula_vcprompt)\
$(is_vim_shell)
${D_INTERMEDIATE_COLOR}$ ${D_DEFAULT_COLOR}"
  else
    PS1="${TITLEBAR}
${D_USER_COLOR}\u ${D_INTERMEDIATE_COLOR}\
at ${D_MACHINE_COLOR}\h ${D_INTERMEDIATE_COLOR}\
in ${D_DIR_COLOR}\w ${D_INTERMEDIATE_COLOR}\
$(prompt_git "$D_INTERMEDIATE_COLOR on $D_GIT_COLOR")\
${LAST_COMMAND_FAILED}\
$(demula_vcprompt)\
$(is_vim_shell)\
$(safe_battery_charge)
${D_INTERMEDIATE_COLOR}$ ${D_DEFAULT_COLOR}"
  fi

  PS2="${D_INTERMEDIATE_COLOR}$ ${D_DEFAULT_COLOR}"
# Modified version of the original modern theme in bash-it
# Removes the battery charge and adds the current time

SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

case $TERM in
	xterm*)
	TITLEBAR="\[\033]0;\w\007\]"
	;;
	*)
	TITLEBAR=""
	;;
esac

PS3=">> "

is_vim_shell() {
	if [ ! -z "$VIMRUNTIME" ]
	then
		echo "[${cyan}vim shell${normal}]"
	fi
}

modern_scm_prompt() {
	CHAR=$(scm_char)
	if [ $CHAR = $SCM_NONE_CHAR ]
	then
		return
	else
		echo "[$(scm_char)][$(scm_prompt_info)]"
	fi
}

modern_current_time_prompt() {
	echo "[$(date '+%l:%M%p')]"
}

prompt() {
	if [ $? -ne 0 ]
	then
		# Yes, the indenting on these is weird, but it has to be like
		# this otherwise it won't display properly.

		PS1="${TITLEBAR}${bold_red}┌─${reset_color}$(modern_scm_prompt)$(modern_current_time_prompt)[${cyan}\W${normal}]$(is_vim_shell)
${bold_red}└─▪${normal} "
	else
		PS1="${TITLEBAR}┌─$(modern_scm_prompt)$(modern_current_time_prompt)[${cyan}\W${normal}]$(is_vim_shell)
└─▪ "
	fi
}

PS2="└─▪ "

#!/usr/bin/env bash
# Power-Turk theme for bash-it
# Author (C) 2015 Ahmed Seref Guneysu

THEME_PROMPT_SEPARATOR=""

SHELL_SSH_CHAR=" "
SHELL_THEME_PROMPT_COLOR=2
SHELL_SSH_THEME_PROMPT_COLOR=208

VIRTUALENV_CHAR="ⓔ "
VIRTUALENV_THEME_PROMPT_COLOR=35

SCM_NONE_CHAR=""

SCM_GIT_CHAR=" " # " "

SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_DIRTY=""

SCM_THEME_PROMPT_COLOR=16
SCM_THEME_PROMPT_CLEAN_COLOR=231
SCM_THEME_PROMPT_DIRTY_COLOR=196
SCM_THEME_PROMPT_STAGED_COLOR=220
SCM_THEME_PROMPT_UNSTAGED_COLOR=166

CWD_THEME_PROMPT_COLOR=240

LAST_STATUS_THEME_PROMPT_COLOR=52

_collapsed_wd() {
  # echo -e "\u2771\u276d\u276f"
  echo $(pwd | perl -pe "
   BEGIN {
      binmode STDIN,  ':encoding(UTF-8)';
      binmode STDOUT, ':encoding(UTF-8)';
   }; s|^$HOME|<HOME>|g; s|/([^/])[^/]*(?=/)|/\$1|g") | \
    sed -re "s/\//  /g"
}

_swd(){
# Adapted from http://stackoverflow.com/a/2951707/1766716
    begin="" # The unshortened beginning of the path.
    shortbegin="" # The shortened beginning of the path.
    current="" # The section of the path we're currently working on.
    end="${2:-$(pwd)}/" # The unmodified rest of the path.

    if [[ "$end" =~ "$HOME" ]]; then
        INHOME=1
        end="${end#$HOME}" #strip /home/username from start of string
        begin="$HOME"      #start expansion from the right spot
    else
        INHOME=0
    fi

    end="${end#/}" # Strip the first /
    shortenedpath="$end" # The whole path, to check the length.
    maxlength="${1:-0}"

    shopt -q nullglob && NGV="-s" || NGV="-u" # Store the value for later.
    shopt -s nullglob    # Without this, anything that doesn't exist in the filesystem turns into */*/*/...

    while [[ "$end" ]] && (( ${#shortenedpath} > maxlength ))
        do
        current="${end%%/*}" # everything before the first /
        end="${end#*/}"    # everything after the first /

        shortcur="$current"
        shortcurstar="$current" # No star if we don't shorten it.

        for ((i=${#current}-2; i>=0; i--)); do
            subcurrent="${current:0:i}"
            matching=("$begin/$subcurrent"*) # Array of all files that start with $subcurrent.
            (( ${#matching[*]} != 1 )) && break # Stop shortening if more than one file matches.
            shortcur="$subcurrent"
            shortcurstar="$subcurrent*"
        done

    #advance
    begin="$begin/$current"
    shortbegin="$shortbegin/$shortcurstar"
    shortenedpath="$shortbegin/$end"
    done

    shortenedpath="${shortenedpath%/}" # strip trailing /
    shortenedpath="${shortenedpath#/}" # strip leading /

    # Replaces slashes with  except first occurence.
    if [ $INHOME -eq 1 ]; then
        echo "~/$shortenedpath" | sed "s/\///2g" # make sure it starts with ~/
    else
        echo "/$shortenedpath"  | sed "s/\///2g" # Make sure it starts with /
    fi

    shopt "$NGV" nullglob # Reset nullglob in case this is being used as a function.

}
function set_rgb_color {
    if [[ "${1}" != "-" ]]; then
        fg="38;5;${1}"
    fi
    if [[ "${2}" != "-" ]]; then
        bg="48;5;${2}"
        [[ -n "${fg}" ]] && bg=";${bg}"
    fi
    echo -e "\[\033[${fg}${bg}m\]"
}

function powerline_shell_prompt {
    if [[ -n "${SSH_CLIENT}" ]]; then
        SHELL_PROMPT="${bold_white}$(set_rgb_color - ${SHELL_SSH_THEME_PROMPT_COLOR}) ${SHELL_SSH_CHAR}\u@\h ${normal}"
        LAST_THEME_COLOR=${SHELL_SSH_THEME_PROMPT_COLOR}
    else
        SHELL_PROMPT="${bold_white}$(set_rgb_color - ${SHELL_THEME_PROMPT_COLOR}) ${normal}"
        LAST_THEME_COLOR=${SHELL_THEME_PROMPT_COLOR}
    fi
}

function powerline_virtualenv_prompt {
    local environ=""

    if [[ -n "$CONDA_DEFAULT_ENV" ]]; then
        environ="conda: $CONDA_DEFAULT_ENV"
    elif [[ -n "$VIRTUAL_ENV" ]]; then
        environ=$(basename "$VIRTUAL_ENV")
    fi

    if [[ -n "$environ" ]]; then
        VIRTUALENV_PROMPT="$(set_rgb_color ${LAST_THEME_COLOR} ${VIRTUALENV_THEME_PROMPT_COLOR})${THEME_PROMPT_SEPARATOR}${normal}$(set_rgb_color - ${VIRTUALENV_THEME_PROMPT_COLOR}) ${VIRTUALENV_CHAR}$environ ${normal}"
        LAST_THEME_COLOR=${VIRTUALENV_THEME_PROMPT_COLOR}
    else
        VIRTUALENV_PROMPT=""
    fi
}

function powerline_scm_prompt {
    scm_prompt_vars

    if [[ "${SCM_NONE_CHAR}" != "${SCM_CHAR}" ]]; then
        if [[ "${SCM_DIRTY}" -eq 3 ]]; then
            SCM_PROMPT="$(set_rgb_color ${SCM_THEME_PROMPT_STAGED_COLOR} ${SCM_THEME_PROMPT_COLOR})"
        elif [[ "${SCM_DIRTY}" -eq 2 ]]; then
            SCM_PROMPT="$(set_rgb_color ${SCM_THEME_PROMPT_UNSTAGED_COLOR} ${SCM_THEME_PROMPT_COLOR})"
        elif [[ "${SCM_DIRTY}" -eq 1 ]]; then
            SCM_PROMPT="$(set_rgb_color ${SCM_THEME_PROMPT_DIRTY_COLOR} ${SCM_THEME_PROMPT_COLOR})"
        else
            SCM_PROMPT="$(set_rgb_color ${SCM_THEME_PROMPT_CLEAN_COLOR} ${SCM_THEME_PROMPT_COLOR})"
        fi
        if [[ "${SCM_GIT_CHAR}" == "${SCM_CHAR}" ]]; then
            SCM_PROMPT+=" ${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
        fi
        SCM_PROMPT="$(set_rgb_color ${LAST_THEME_COLOR} ${SCM_THEME_PROMPT_COLOR})${THEME_PROMPT_SEPARATOR}${normal}${SCM_PROMPT} ${normal}"
        LAST_THEME_COLOR=${SCM_THEME_PROMPT_COLOR}
    else
        SCM_PROMPT=""
    fi
}

function powerline_cwd_prompt {
CWD_PROMPT="$(set_rgb_color ${LAST_THEME_COLOR} ${CWD_THEME_PROMPT_COLOR})${THEME_PROMPT_SEPARATOR}$(set_rgb_color 0 ${CWD_THEME_PROMPT_COLOR}) $(_swd)${normal}$(set_rgb_color ${CWD_THEME_PROMPT_COLOR} -)${normal}"
    LAST_THEME_COLOR=${CWD_THEME_PROMPT_COLOR}
}

function powerline_last_status_prompt {
    if [[ "$1" -eq 0 ]]; then
        LAST_STATUS_PROMPT="$(set_rgb_color ${LAST_THEME_COLOR} -)${THEME_PROMPT_SEPARATOR}${normal}"
    else
        LAST_STATUS_PROMPT="$(set_rgb_color ${LAST_THEME_COLOR} ${LAST_STATUS_THEME_PROMPT_COLOR})${THEME_PROMPT_SEPARATOR}${normal}$(set_rgb_color - ${LAST_STATUS_THEME_PROMPT_COLOR}) ${LAST_STATUS} ${normal}$(set_rgb_color ${LAST_STATUS_THEME_PROMPT_COLOR} -)${THEME_PROMPT_SEPARATOR}${normal}"
    fi
}

function powerline_prompt_command() {
    local LAST_STATUS="$?"

    powerline_shell_prompt
    powerline_virtualenv_prompt
    powerline_scm_prompt
    powerline_cwd_prompt
    powerline_last_status_prompt LAST_STATUS

#!/usr/bin/env bash
SCM_GIT_CHAR="± "
SCM_HG_CHAR="☿ "
SCM_SVN_CHAR="⑆ "
SCM_NONE_CHAR=""
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX="|"
SCM_THEME_PROMPT_SUFFIX="${green}| "
SCM_GIT_AHEAD_CHAR="${green}+"
SCM_GIT_BEHIND_CHAR="${red}-"

GIT_THEME_PROMPT_DIRTY=" ${bold_red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX="${cyan}|"
GIT_THEME_PROMPT_SUFFIX="${cyan}| "

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX="| "

VIRTUALENV_THEME_PROMPT_PREFIX="|"
VIRTUALENV_THEME_PROMPT_SUFFIX="| "

RBENV_THEME_PROMPT_PREFIX="|"
RBENV_THEME_PROMPT_SUFFIX="| "

RBFU_THEME_PROMPT_PREFIX="|"
RBFU_THEME_PROMPT_SUFFIX="| "

function rvm_version_prompt {
  if which rvm &> /dev/null; then
    rvm_current=$(rvm tools identifier) || return
    rvm_default=$(rvm strings default) || return
    [ "$rvm_current" !=  "$rvm_default" ] && ( echo -e "$RVM_THEME_PROMPT_PREFIX$rvm_current$RVM_THEME_PROMPT_SUFFIX" )
  fi
}

function git_prompt_info {
  git_prompt_vars
  echo -e "$SCM_PREFIX$SCM_BRANCH$SCM_STATE$SCM_GIT_AHEAD$SCM_GIT_BEHIND$SCM_GIT_STASH$SCM_SUFFIX"
}

LAST_PROMPT=""
function prompt_command() {
    local new_PS1="${bold_cyan}$(scm_char)${yellow}$(ruby_version_prompt)${green}\w $(scm_prompt_info)"
    local new_prompt=$(PS1="$new_PS1" "$BASH" --norc -i </dev/null 2>&1 | sed -n '${s/^\(.*\)exit$/\1/p;}')

    if [ "$LAST_PROMPT" = "$new_prompt" ]; then
        new_PS1=""
    else
        LAST_PROMPT="$new_prompt"
    fi

    local wrap_char=""
    [[ $COLUMNS && ${#new_PS1} > $(($COLUMNS/1)) ]] && wrap_char="\n"
# port of zork theme

# set colors for use throughout the prompt
# i like things consistent
BRACKET_COLOR=${blue}
STRING_COLOR=${green}

SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${STRING_COLOR}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

#Mysql Prompt
export MYSQL_PS1="(\u@\h) [\d]> "

case $TERM in
        xterm*)
        TITLEBAR="\[\033]0;\w\007\]"
        ;;
        *)
        TITLEBAR=""
        ;;
esac

PS3=">> "

__my_rvm_ruby_version() {
    local gemset=$(echo $GEM_HOME | awk -F'@' '{print $2}')
  [ "$gemset" != "" ] && gemset="@$gemset"
    local version=$(echo $MY_RUBY_HOME | awk -F'-' '{print $2}')
    local full="$version$gemset"
  [ "$full" != "" ] && echo "${BRACKET_COLOR}[${STRING_COLOR}$full${BRACKET_COLOR}]${normal}"
}

is_vim_shell() {
        if [ ! -z "$VIMRUNTIME" ]
        then
                echo "${BRACKET_COLOR}[${STRING_COLOR}vim shell${BRACKET_COLOR}]${normal}"
        fi
}

function is_integer() { # helper function for todo-txt-count
    [ "$1" -eq "$1" ] > /dev/null 2>&1
        return $?
}

todo_txt_count() {
    if `hash todo.sh 2>&-`; then # is todo.sh installed
        count=`todo.sh ls | egrep "TODO: [0-9]+ of ([0-9]+) tasks shown" | awk '{ print $4 }'`
        if is_integer $count; then # did we get a sane answer back
            echo "${BRACKET_COLOR}[${STRING_COLOR}T:$count${BRACKET_COLOR}]$normal"
        fi
    fi
}

modern_scm_prompt() {
        CHAR=$(scm_char)
        if [ $CHAR = $SCM_NONE_CHAR ]
        then
                return
        else
                echo "${BRACKET_COLOR}[${CHAR}${BRACKET_COLOR}][${STRING_COLOR}$(scm_prompt_info)${BRACKET_COLOR}]$normal"
        fi
}

my_prompt_char() {
    if [[ $OSTYPE =~ "darwin" ]]; then
        echo "${BRACKET_COLOR}➞  ${normal}"
    else
        echo "${BRACKET_COLOR}➞ ${normal}"
    fi
}

prompt() {

    my_ps_host="${STRING_COLOR}\h${normal}";
    my_ps_user="${STRING_COLOR}\u${normal}";
    my_ps_root="${bold_red}\u${normal}";
    my_ps_path="${STRING_COLOR}\w${normal}";

    # nice prompt
    case "`id -u`" in
        0) PS1="${TITLEBAR}${BRACKET_COLOR}┌─[$my_ps_root${BRACKET_COLOR}][$my_ps_host${BRACKET_COLOR}]$(modern_scm_prompt)$(__my_rvm_ruby_version)${BRACKET_COLOR}[${STRING_COLOR}\w${BRACKET_COLOR}]$(is_vim_shell)
${BRACKET_COLOR}└─$(my_prompt_char)${normal}"
        ;;
        *) PS1="${TITLEBAR}${BRACKET_COLOR}┌─[$my_ps_user${BRACKET_COLOR}][$my_ps_host${BRACKET_COLOR}]$(modern_scm_prompt)$(__my_rvm_ruby_version)${BRACKET_COLOR}[${STRING_COLOR}\w${BRACKET_COLOR}]$(is_vim_shell)
${BRACKET_COLOR}└─$(todo_txt_count)$(my_prompt_char)"
        ;;
    esac
}

#!/usr/bin/env bash

GIT_THEME_PROMPT_DIRTY="${red}✗"
GIT_THEME_PROMPT_CLEAN="${bold_green}✓"
GIT_THEME_PROMPT_PREFIX="${bold_cyan}["
GIT_THEME_PROMPT_SUFFIX="${bold_cyan}]"

VIRTUALENV_THEME_PROMPT_PREFIX="${bold_green}["
VIRTUALENV_THEME_PROMPT_SUFFIX="${bold_green}]"
CONDAENV_THEME_PROMPT_PREFIX="${bold_green}["
CONDAENV_THEME_PROMPT_SUFFIX="${bold_green}]"
PYTHON_THEME_PROMPT_PREFIX="${bold_green}["
PYTHON_THEME_PROMPT_SUFFIX="${bold_green}]"

function prompt_command() {
#!/usr/bin/env bash

source "$BASH_IT/themes/doubletime/doubletime.theme.bash"

function prompt_setter() {
  # Save history
  history -a
  history -c
  history -r
  PS1="
$(clock_prompt) $(scm_char) [$THEME_PROMPT_HOST_COLOR\u@${THEME_PROMPT_HOST}$reset_color] $(virtualenv_prompt)$(ruby_version_prompt)
\w
$(doubletime_scm_prompt)$reset_color $ "
  PS2='> '
  PS4='+ '
# ------------------------------------------------------------------#
#          FILE: cooperkid.zsh-theme                                #
#            BY: Alfredo Bejarano                                   #
#      BASED ON: Mr Briggs by Matt Brigg (matt@mattbriggs.net)      #
# ------------------------------------------------------------------#

SCM_THEME_PROMPT_DIRTY="${red} ✗${reset_color}"
SCM_THEME_PROMPT_AHEAD="${yellow} ↑${reset_color}"
SCM_THEME_PROMPT_CLEAN="${green} ✓${reset_color}"
SCM_THEME_PROMPT_PREFIX=" "
SCM_THEME_PROMPT_SUFFIX=""
GIT_SHA_PREFIX="${blue}"
GIT_SHA_SUFFIX="${reset_color}"

function rvm_version_prompt {
  if which rvm &> /dev/null; then
    rvm=$(rvm-prompt) || return
    if [ -n "$rvm" ]; then
      echo -e "$rvm"
    fi
  fi
}

function git_short_sha() {
  SHA=$(git rev-parse --short HEAD 2> /dev/null) && echo "$GIT_SHA_PREFIX$SHA$GIT_SHA_SUFFIX"
}

function prompt() {
    local return_status=""
    local ruby="${red}$(ruby_version_prompt)${reset_color}"
    local user_host="${green}\h @ \w${reset_color}"
    local git_branch="$(git_short_sha)${cyan}$(scm_prompt_info)${reset_color}"
    local prompt_symbol=' '
    local prompt_char="${purple}>_${reset_color} "

# shellcheck shell=bash

# Brainy Bash Prompt for Bash-it
# by MunifTanjim

#############
## Parsers ##
#############

____brainy_top_left_parse() {
	ifs_old="${IFS}"
	IFS="|"
	read -r -a args <<< "$@"
	IFS="${ifs_old}"
	if [ -n "${args[3]}" ]; then
		_TOP_LEFT+="${args[2]}${args[3]}"
	fi
	_TOP_LEFT+="${args[0]}${args[1]}"
	if [ -n "${args[4]}" ]; then
		_TOP_LEFT+="${args[2]}${args[4]}"
	fi
	_TOP_LEFT+=" "
}

____brainy_top_right_parse() {
	ifs_old="${IFS}"
	IFS="|"
	read -r -a args <<< "$@"
	IFS="${ifs_old}"
	_TOP_RIGHT+=" "
	if [ -n "${args[3]}" ]; then
		_TOP_RIGHT+="${args[2]}${args[3]}"
	fi
	_TOP_RIGHT+="${args[0]}${args[1]}"
	if [ -n "${args[4]}" ]; then
		_TOP_RIGHT+="${args[2]}${args[4]}"
	fi
	__TOP_RIGHT_LEN=$((__TOP_RIGHT_LEN + ${#args[1]} + ${#args[3]} + ${#args[4]} + 1))
	((__SEG_AT_RIGHT += 1))
}

____brainy_bottom_parse() {
	ifs_old="${IFS}"
	IFS="|"
	read -r -a args <<< "$@"
	IFS="${ifs_old}"
	_BOTTOM+="${args[0]}${args[1]}"
	[ ${#args[1]} -gt 0 ] && _BOTTOM+=" "
}

____brainy_top() {
	_TOP_LEFT=""
	_TOP_RIGHT=""
	__TOP_RIGHT_LEN=0
	__SEG_AT_RIGHT=0

	for seg in ${___BRAINY_TOP_LEFT}; do
		info="$(___brainy_prompt_"${seg}")"
		[ -n "${info}" ] && ____brainy_top_left_parse "${info}"
	done

	___cursor_right="\033[500C"
	_TOP_LEFT+="${___cursor_right}"

	for seg in ${___BRAINY_TOP_RIGHT}; do
		info="$(___brainy_prompt_"${seg}")"
		[ -n "${info}" ] && ____brainy_top_right_parse "${info}"
	done

	[ $__TOP_RIGHT_LEN -gt 0 ] && __TOP_RIGHT_LEN=$((__TOP_RIGHT_LEN - 1))
	___cursor_adjust="\033[${__TOP_RIGHT_LEN}D"
	_TOP_LEFT+="${___cursor_adjust}"

	printf "%s%s" "${_TOP_LEFT}" "${_TOP_RIGHT}"
}

____brainy_bottom() {
	_BOTTOM=""
	for seg in $___BRAINY_BOTTOM; do
		info="$(___brainy_prompt_"${seg}")"
		[ -n "${info}" ] && ____brainy_bottom_parse "${info}"
	done
	printf "\n%s" "${_BOTTOM}"
}

##############
## Segments ##
##############

___brainy_prompt_user_info() {
	color=$bold_blue
	if [ "${THEME_SHOW_SUDO}" == "true" ]; then
		if sudo -vn 1> /dev/null 2>&1; then
			color=$bold_red
		fi
	fi
	box="[|]"
	info="\u@\H"
	if [ -n "${SSH_CLIENT}" ]; then
		printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
	else
		printf "%s|%s" "${color}" "${info}"
	fi
}

___brainy_prompt_dir() {
	color=$bold_yellow
	box="[|]"
	info="\w"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
}

___brainy_prompt_scm() {
	[ "${THEME_SHOW_SCM}" != "true" ] && return
	color=$bold_green
	box="$(scm_char) "
	info="$(scm_prompt_info)"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
}

___brainy_prompt_python() {
	[ "${THEME_SHOW_PYTHON}" != "true" ] && return
	color=$bold_yellow
	box="[|]"
	info="$(python_version_prompt)"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_blue}" "${box}"
}

___brainy_prompt_ruby() {
	[ "${THEME_SHOW_RUBY}" != "true" ] && return
	color=$bold_white
	box="[|]"
	info="rb-$(ruby_version_prompt)"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_red}" "${box}"
}

___brainy_prompt_todo() {
	[ "${THEME_SHOW_TODO}" != "true" ] \
		|| [ -z "$(which todo.sh)" ] && return
	color=$bold_white
	box="[|]"
	info="t:$(todo.sh ls | grep -E "TODO: [0-9]+ of ([0-9]+)" | awk '{ print $4 }')"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_green}" "${box}"
}

___brainy_prompt_clock() {
	[ "${THEME_SHOW_CLOCK}" != "true" ] && return
	color=$THEME_CLOCK_COLOR
	box="[|]"
	info="$(date +"${THEME_CLOCK_FORMAT}")"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_purple}" "${box}"
}

___brainy_prompt_battery() {
	! _command_exists battery_percentage \
		|| [ "${THEME_SHOW_BATTERY}" != "true" ] \
		|| [ "$(battery_percentage)" = "no" ] && return

	info=$(battery_percentage)
	color=$bold_green
	if [ "$info" -lt 50 ]; then
		color=$bold_yellow
	elif [ "$info" -lt 25 ]; then
		color=$bold_red
	fi
	box="[|]"
	ac_adapter_connected && charging="+"
	ac_adapter_disconnected && charging="-"
	info+=$charging
	[ "$info" == "100+" ] && info="AC"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
}

___brainy_prompt_exitcode() {
	[ "${THEME_SHOW_EXITCODE}" != "true" ] && return
	color=$bold_purple
	[ "$exitcode" -ne 0 ] && printf "%s|%s" "${color}" "${exitcode}"
}

___brainy_prompt_char() {
	color=$bold_white
	prompt_char="${__BRAINY_PROMPT_CHAR_PS1}"
	printf "%s|%s" "${color}" "${prompt_char}"
}

#########
## cli ##
#########

__brainy_show() {
	typeset _seg=${1:-}
	shift
	export "THEME_SHOW_${_seg}"=true
}

__brainy_hide() {
	typeset _seg=${1:-}
	shift
	export "THEME_SHOW_${_seg}"=false
}

_brainy_completion() {
	local cur _action actions segments
	COMPREPLY=()
	cur="${COMP_WORDS[COMP_CWORD]}"
	_action="${COMP_WORDS[1]}"
	actions="show hide"
	segments="battery clock exitcode python ruby scm sudo todo"
	case "${_action}" in
		show | hide)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "${segments}" -- "${cur}"))
			return 0
			;;
	esac

	# shellcheck disable=SC2207
	COMPREPLY=($(compgen -W "${actions}" -- "${cur}"))
	return 0
}

brainy() {
	typeset action=${1:-}
	shift
	typeset segs=${*:-}
	typeset func
	case $action in
		show)
			func=__brainy_show
			;;
		hide)
			func=__brainy_hide
			;;
	esac
	for seg in ${segs}; do
		seg=$(printf "%s" "${seg}" | tr '[:lower:]' '[:upper:]')
		$func "${seg}"
	done
}

complete -F _brainy_completion brainy

###############
## Variables ##
###############

export SCM_THEME_PROMPT_PREFIX=""
export SCM_THEME_PROMPT_SUFFIX=""

export RBENV_THEME_PROMPT_PREFIX=""
export RBENV_THEME_PROMPT_SUFFIX=""
export RBFU_THEME_PROMPT_PREFIX=""
export RBFU_THEME_PROMPT_SUFFIX=""
export RVM_THEME_PROMPT_PREFIX=""
export RVM_THEME_PROMPT_SUFFIX=""
export VIRTUALENV_THEME_PROMPT_PREFIX=""
export VIRTUALENV_THEME_PROMPT_SUFFIX=""

export SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
export SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"

THEME_SHOW_SUDO=${THEME_SHOW_SUDO:-"true"}
THEME_SHOW_SCM=${THEME_SHOW_SCM:-"true"}
THEME_SHOW_RUBY=${THEME_SHOW_RUBY:-"false"}
THEME_SHOW_PYTHON=${THEME_SHOW_PYTHON:-"false"}
THEME_SHOW_CLOCK=${THEME_SHOW_CLOCK:-"true"}
THEME_SHOW_TODO=${THEME_SHOW_TODO:-"false"}
THEME_SHOW_BATTERY=${THEME_SHOW_BATTERY:-"false"}
THEME_SHOW_EXITCODE=${THEME_SHOW_EXITCODE:-"true"}

THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"$bold_white"}
THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:-"%H:%M:%S"}

__BRAINY_PROMPT_CHAR_PS1=${THEME_PROMPT_CHAR_PS1:-">"}
__BRAINY_PROMPT_CHAR_PS2=${THEME_PROMPT_CHAR_PS2:-"\\"}

___BRAINY_TOP_LEFT=${___BRAINY_TOP_LEFT:-"user_info dir scm"}
___BRAINY_TOP_RIGHT=${___BRAINY_TOP_RIGHT:-"python ruby todo clock battery"}
___BRAINY_BOTTOM=${___BRAINY_BOTTOM:-"exitcode char"}

############
## Prompt ##
############

__brainy_ps1() {
	printf "%s%s%s" "$(____brainy_top)" "$(____brainy_bottom)" "${normal}"
}

__brainy_ps2() {
	color=$bold_white
	printf "%s%s%s" "${color}" "${__BRAINY_PROMPT_CHAR_PS2}  " "${normal}"
}

_brainy_prompt() {
	exitcode="$?"

	PS1="$(__brainy_ps1)"
	PS2="$(__brainy_ps2)"
}


# prompt theming

# added TITLEBAR for updating the tab and window titles with the pwd
case $TERM in
	xterm*)
		TITLEBAR=$(printf "\033]0;%s@%s:%s\007" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/~}")
		;;
	screen)
		TITLEBAR=$(printf "\033]0;%s@%s:%s\033\\" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/~}")
		;;
	*)
		TITLEBAR=""
		;;
esac

function prompt_command() {
	PS1="${TITLEBAR}[\u@\h \W $(scm_prompt_info)]\$ "
}

# scm theming
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX="${green}("
SCM_THEME_PROMPT_SUFFIX="${green})${reset_color}"
#!/usr/bin/env bash

# Simplistic one-liner theme to display source control management info beside
# the ordinary Linux bash prompt.
#
# Demo:
#
# [ritola@localhost ~]$ cd .bash-it/themes/dulcie
# [ritola@localhost |master ✓| dulcie]$ # This is single line mode
# |bash-it|± master ✓|
# [ritola@localhost dulcie]$ # In multi line, the SCM info is in the separate line
#
# Configuration. Change these by adding them in your .bash_profile

DULCIE_COLOR=${DULCIE_COLOR:=1} # 0 = monochrome, 1 = colorful
DULCIE_MULTILINE=${DULCIE_MULTILINE:=1} # 0 = Single line, 1 = SCM in separate line

dulcie_color() {
  echo -en "\[\e[38;5;${1}m\]"
}

dulcie_background() {
  echo -en "\[\e[48;5;${1}m\]"
}

dulcie_prompt() {
  color_user_root=$(dulcie_color 169)
  color_user_nonroot="${green}"
  color_host_local=$(dulcie_color 230)
  color_host_remote=$(dulcie_color 214)
  color_rootdir=$(dulcie_color 117)
  color_workingdir=$(dulcie_color 117)
  background_scm=$(dulcie_background 238)

  SCM_THEME_ROOT_SUFFIX="|$(scm_char) "

  # Set colors
  if [ "${DULCIE_COLOR}" -eq "1" ]; then
    if [[ $EUID -ne 0 ]]; then
      color_user="${color_user_nonroot}"
    else
      color_user="${color_user_root}"
    fi

    if [[ -n "${SSH_CLIENT}" ]]; then
      color_host="${color_host_remote}"
    else
      color_host="${color_host_local}"
    fi

    DULCIE_USER="${color_user}\u${reset_color}"
    DULCIE_HOST="${color_host}\h${reset_color}"
    DULCIE_WORKINGDIR="${color_workingdir}\W${reset_color}"
    DULCIE_PROMPTCHAR="${color_user}"'\$'"${reset_color}"

    SCM_THEME_PROMPT_DIRTY=" ${red}✗${reset_color}"
    SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
    DULCIE_SCM_BACKGROUND="${background_scm}"
    DULCIE_SCM_DIR_COLOR="${color_rootdir}"
    SCM_THEME_ROOT_SUFFIX="${reset_color}${SCM_THEME_ROOT_SUFFIX}"
    SCM_THEME_PROMPT_DIRTY=" $(dulcie_color 1)✗${reset_color}"
    SCM_THEME_PROMPT_CLEAN=" $(dulcie_color 10)✓${reset_color}"
  else
    DULCIE_USER='\u'
    DULCIE_HOST='\h'
    DULCIE_WORKINGDIR='\W'
    DULCIE_PROMPTCHAR='\$'

    DULCIE_SCM_BACKGROUND=""
    DULCIE_SCM_DIR_COLOR=""
    SCM_THEME_DIR_COLOR=""
    SCM_THEME_PROMPT_DIRTY=" ✗"
    SCM_THEME_PROMPT_CLEAN=" ✓"
  fi

  # Change terminal title
  printf "\033]0;%s@%s:%s\007" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/\~}"

  # Open the new terminal in the same directory
  declare -f __vte_osc7 > /dev/null && __vte_osc7

  PS1="${reset_color}[${DULCIE_USER}@${DULCIE_HOST}$(scm_prompt_info)${reset_color} ${DULCIE_WORKINGDIR}]"
  if [[ "${DULCIE_MULTILINE}" -eq "1" ]]; then
    PS1="${reset_color}[${DULCIE_USER}@${DULCIE_HOST}${reset_color} ${DULCIE_WORKINGDIR}]"
    if [[ "$(scm_prompt_info)" ]]; then
      SCM_THEME_PROMPT_PREFIX="${DULCIE_SCM_BACKGROUND}|${DULCIE_SCM_DIR_COLOR}"
      SCM_THEME_PROMPT_SUFFIX="|${normal}"
      PS1="$(scm_prompt_info)\n${PS1}"
    fi
  else
    SCM_THEME_PROMPT_PREFIX=" ${DULCIE_SCM_BACKGROUND}|${DULCIE_SCM_DIR_COLOR}"
    SCM_THEME_PROMPT_SUFFIX="|${normal}"
    PS1="${reset_color}[${DULCIE_USER}@${DULCIE_HOST}$(scm_prompt_info)${reset_color} ${DULCIE_WORKINGDIR}]"
  fi
  PS1="${PS1}${DULCIE_PROMPTCHAR} "
#!/usr/bin/env bash
# n0qorg theme by Florian Baumann <flo@noqqe.de>

## look-a-like
# host directory (branch*)»
# for example:
# ananas ~/Code/bash-it/themes (master*)»
function prompt_command() {
    PS1="${bold_blue}[$(hostname)]${normal} \w${normal} ${bold_white}[$(git_prompt_info)]${normal}» "
}

safe_append_prompt_command prompt_command

## git-theme
# feel free to change git chars.
GIT_THEME_PROMPT_DIRTY="${bold_blue}*${bold_white}"
GIT_THEME_PROMPT_CLEAN=""
GIT_THEME_PROMPT_PREFIX="${bold_blue}(${bold_white}"
GIT_THEME_PROMPT_SUFFIX="${bold_blue})"

## alternate chars
#
SCM_THEME_PROMPT_DIRTY="*"
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_PREFIX="("
#!/usr/bin/env bash

export GIT_PS1_SHOWDIRTYSTATE=true
export GIT_PS1_SHOWUNTRACKEDFILES=true
export GIT_PS1_SHOWSTASHSTATE=true

export PROMPT_DIRTRIM=3

function prompt_command() {
    if [[ ${EUID} == 0 ]] ; then
        PS1="[$(clock_prompt)]${yellow}[${red}\u@\h ${green}\w${yellow}]${red}$(__git_ps1 "(%s)")${normal}\\$ "
    else
        PS1="[$(clock_prompt)]${yellow}[${cyan}\u@\h ${green}\w${yellow}]${red}$(__git_ps1 "(%s)")${normal}\\$ "
    fi
}
#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" ${green}| "
SCM_THEME_PROMPT_SUFFIX="${green} |"
SCM_NONE_CHAR='◐ '
SCM_GIT_SHOW_MINIMAL_INFO=true
GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX=" d|"

BOLD="\[\e[1m\]"

function prompt_command() {
  PS1="\n${bold_cyan}$(scm_prompt_char_info)$(virtualenv_prompt) ${bold_cyan}\w :${reset_color}${normal}${BOLD} "
#!/usr/bin/env bash

. "$BASH_IT/themes/powerline/powerline.base.bash"

PROMPT_DISTRO_LOGO=" "
PROMPT_DISTRO_LOGO_COLOR=15
PROMPT_DISTRO_LOGO_COLORBG=52

PROMPT_CHAR=${POWERLINE_PROMPT_CHAR:=""}
POWERLINE_LEFT_SEPARATOR=${POWERLINE_LEFT_SEPARATOR:=""}

USER_INFO_SSH_CHAR=${POWERLINE_USER_INFO_SSH_CHAR:=" "}
USER_INFO_SUDO_CHAR=${POWERLINE_USER_INFO_SUDO_CHAR:=" "}
USER_INFO_THEME_PROMPT_COLOR=52
USER_INFO_THEME_PROMPT_COLOR_SUDO=52

PYTHON_VENV_CHAR=${POWERLINE_PYTHON_VENV_CHAR:=" "}
CONDA_PYTHON_VENV_CHAR=${POWERLINE_CONDA_PYTHON_VENV_CHAR:="❲c❳ "}
PYTHON_VENV_THEME_PROMPT_COLOR=23

SCM_NONE_CHAR=""
SCM_GIT_CHAR=${POWERLINE_SCM_GIT_CHAR:=" "}
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_DIRTY=""
SCM_THEME_PROMPT_CLEAN_COLOR=235
SCM_THEME_PROMPT_DIRTY_COLOR=235 #124
SCM_THEME_PROMPT_STAGED_COLOR=235 #52
SCM_THEME_PROMPT_UNSTAGED_COLOR=88
SCM_THEME_PROMPT_COLOR=${SCM_THEME_PROMPT_CLEAN_COLOR}

RVM_THEME_PROMPT_PREFIX=""
RVM_THEME_PROMPT_SUFFIX=""
RBENV_THEME_PROMPT_PREFIX=""
RBENV_THEME_PROMPT_SUFFIX=""
RUBY_THEME_PROMPT_COLOR=161
RUBY_CHAR=${POWERLINE_RUBY_CHAR:=" "}

CWD_THEME_DIR_SEPARATOR=""
CWD_THEME_DIR_SEPARATOR_COLOR=52

CWD_THEME_PROMPT_COLOR=238
HOST_THEME_PROMPT_COLOR=88

LAST_STATUS_THEME_PROMPT_COLOR=52

CLOCK_THEME_PROMPT_COLOR=240

BATTERY_AC_CHAR=${BATTERY_AC_CHAR:="⚡"}
BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR=70
BATTERY_STATUS_THEME_PROMPT_LOW_COLOR=208
BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR=160

THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:="%H:%M:%S"}

IN_VIM_THEME_PROMPT_COLOR=245
IN_VIM_THEME_PROMPT_TEXT="vim"

IN_TOOLBOX_THEME_PROMPT_COLOR=125
IN_TOOLBOX_THEME_PROMPT_TEXT="⬢ "

#!/usr/bin/env bash

function __ {
  echo "$@"
}

function __make_ansi {
  next=$1; shift
  echo "\[\e[$(__$next $@)m\]"
}

function __make_echo {
  next=$1; shift
  echo "\033[$(__$next $@)m"
}


function __reset {
  next=$1; shift
  out="$(__$next $@)"
  echo "0${out:+;${out}}"
}

function __bold {
  next=$1; shift
  out="$(__$next $@)"
  echo "${out:+${out};}1"
}

function __faint {
  next=$1; shift
  out="$(__$next $@)"
  echo "${out:+${out};}2"
}

function __italic {
  next=$1; shift
  out="$(__$next $@)"
  echo "${out:+${out};}3"
}

function __underline {
  next=$1; shift
  out="$(__$next $@)"
  echo "${out:+${out};}4"
}

function __negative {
  next=$1; shift
  out="$(__$next $@)"
  echo "${out:+${out};}7"
}

function __crossed {
  next=$1; shift
  out="$(__$next $@)"
  echo "${out:+${out};}8"
}


function __color_normal_fg {
  echo "3$1"
}

function __color_normal_bg {
  echo "4$1"
}

function __color_bright_fg {
  echo "9$1"
}

function __color_bright_bg {
  echo "10$1"
}


function __color_black   {
  echo "0"
}

function __color_red   {
  echo "1"
}

function __color_green   {
  echo "2"
}

function __color_yellow  {
  echo "3"
}

function __color_blue  {
  echo "4"
}

function __color_magenta {
  echo "5"
}

function __color_cyan  {
  echo "6"
}

function __color_white   {
  echo "7"
}

function __color_rgb {
  r=$1 && g=$2 && b=$3
  [[ $r == $g && $g == $b ]] && echo $(( $r / 11 + 232 )) && return # gray range above 232
  echo "8;5;$(( ($r * 36  + $b * 6 + $g) / 51 + 16 ))"
}

function __color {
  color=$1; shift
  case "$1" in
    fg|bg) side="$1"; shift ;;
    *) side=fg;;
  esac
  case "$1" in
    normal|bright) mode="$1"; shift;;
    *) mode=normal;;
  esac
  [[ $color == "rgb" ]] && rgb="$1 $2 $3"; shift 3

  next=$1; shift
  out="$(__$next $@)"
  echo "$(__color_${mode}_${side} $(__color_${color} $rgb))${out:+;${out}}"
}


function __black   {
  echo "$(__color black $@)"
}

function __red   {
  echo "$(__color red $@)"
}

function __green   {
  echo "$(__color green $@)"
}

function __yellow  {
  echo "$(__color yellow $@)"
}

function __blue  {
  echo "$(__color blue $@)"
}

function __magenta {
  echo "$(__color magenta $@)"
}

function __cyan  {
  echo "$(__color cyan $@)"
}

function __white   {
  echo "$(__color white $@)"
}

function __rgb {
  echo "$(__color rgb $@)"
}


function __color_parse {
  next=$1; shift
  echo "$(__$next $@)"
}

function color {
  echo "$(__color_parse make_ansi $@)"
}

function echo_color {
  echo "$(__color_parse make_echo $@)"
}


black="\[\e[0;30m\]"
red="\[\e[0;31m\]"
green="\[\e[0;32m\]"
yellow="\[\e[0;33m\]"
blue="\[\e[0;34m\]"
purple="\[\e[0;35m\]"
cyan="\[\e[0;36m\]"
white="\[\e[0;37m\]"
orange="\[\e[0;91m\]"

bold_black="\[\e[30;1m\]"
bold_red="\[\e[31;1m\]"
bold_green="\[\e[32;1m\]"
bold_yellow="\[\e[33;1m\]"
bold_blue="\[\e[34;1m\]"
bold_purple="\[\e[35;1m\]"
bold_cyan="\[\e[36;1m\]"
bold_white="\[\e[37;1m\]"
bold_orange="\[\e[91;1m\]"

underline_black="\[\e[30;4m\]"
underline_red="\[\e[31;4m\]"
underline_green="\[\e[32;4m\]"
underline_yellow="\[\e[33;4m\]"
underline_blue="\[\e[34;4m\]"
underline_purple="\[\e[35;4m\]"
underline_cyan="\[\e[36;4m\]"
underline_white="\[\e[37;4m\]"
underline_orange="\[\e[91;4m\]"

background_black="\[\e[40m\]"
background_red="\[\e[41m\]"
background_green="\[\e[42m\]"
background_yellow="\[\e[43m\]"
background_blue="\[\e[44m\]"
background_purple="\[\e[45m\]"
background_cyan="\[\e[46m\]"
background_white="\[\e[47;1m\]"
background_orange="\[\e[101m\]"

normal="\[\e[0m\]"
reset_color="\[\e[39m\]"

# These colors are meant to be used with `echo -e`
echo_black="\033[0;30m"
echo_red="\033[0;31m"
echo_green="\033[0;32m"
echo_yellow="\033[0;33m"
echo_blue="\033[0;34m"
echo_purple="\033[0;35m"
echo_cyan="\033[0;36m"
echo_white="\033[0;37;1m"
echo_orange="\033[0;91m"

echo_bold_black="\033[30;1m"
echo_bold_red="\033[31;1m"
echo_bold_green="\033[32;1m"
echo_bold_yellow="\033[33;1m"
echo_bold_blue="\033[34;1m"
echo_bold_purple="\033[35;1m"
echo_bold_cyan="\033[36;1m"
echo_bold_white="\033[37;1m"
echo_bold_orange="\033[91;1m"

echo_underline_black="\033[30;4m"
echo_underline_red="\033[31;4m"
echo_underline_green="\033[32;4m"
echo_underline_yellow="\033[33;4m"
echo_underline_blue="\033[34;4m"
echo_underline_purple="\033[35;4m"
echo_underline_cyan="\033[36;4m"
echo_underline_white="\033[37;4m"
echo_underline_orange="\033[91;4m"

echo_background_black="\033[40m"
echo_background_red="\033[41m"
echo_background_green="\033[42m"
echo_background_yellow="\033[43m"
echo_background_blue="\033[44m"
echo_background_purple="\033[45m"
echo_background_cyan="\033[46m"
#!/usr/bin/env bash

__tonka_time() {
  THEME_CLOCK_FORMAT="%H%M"
  clock_prompt
}

__tonka_date() {
  THEME_CLOCK_FORMAT="%a,%d %b %y"
  clock_prompt
}

__tonka_clock() {
  local LIGHT_BLUE="\[\033[1;34m\]"
  if [[ "${THEME_SHOW_CLOCK}" = "true" ]]; then
    echo "$(__tonka_time)${LIGHT_BLUE}:$(__tonka_date)${LIGHT_BLUE}:"
  fi
}

prompt_setter() {

#   Named "Tonka" because of the colour scheme
local WHITE="\[\033[1;37m\]"
local LIGHT_BLUE="\[\033[1;34m\]"
local YELLOW="\[\033[1;33m\]"
local NO_COLOUR="\[\033[0m\]"

case $TERM in
    xterm*|rxvt*)
        TITLEBAR='\[\033]0;\u@\h:\w\007\]'
        ;;
    *)
        TITLEBAR=""
        ;;
esac

PS1="$TITLEBAR\
$YELLOW-$LIGHT_BLUE-(\
$YELLOW\u$LIGHT_BLUE@$YELLOW\h\
$LIGHT_BLUE)-(\
$YELLOW\$PWD\
$LIGHT_BLUE)-$YELLOW-\
\n\
$YELLOW-$LIGHT_BLUE-(\
$(__tonka_clock)\
$WHITE\$ $LIGHT_BLUE)-$YELLOW-$NO_COLOUR "

PS2="$LIGHT_BLUE-$YELLOW-$YELLOW-$NO_COLOUR "

}

safe_append_prompt_command prompt_setter

THEME_SHOW_CLOCK=${THEME_SHOW_CLOCK:-"true"}
THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"\[\033[1;33m\]"}

export PS3=">> "

LS_COLORS='no=00:fi=00:di=00;33:ln=01;36:pi=40;34:so=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.gz=01;31:*.deb=01;31:*.jpg=01;35:*.gif=01;35:*.bmp=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.mpg=01;37:*.avi=01;37:*.gl=01;37:*.dl=01;37:';

# shellcheck shell=bash

if [ -z "$BASH_IT_COMMAND_DURATION" ] || [ "$BASH_IT_COMMAND_DURATION" != true ]; then
	_command_duration() {
		echo -n
	}
	return
fi

# Define tmp dir and file
COMMAND_DURATION_TMPDIR="${TMPDIR:-/tmp}"
COMMAND_DURATION_FILE="${COMMAND_DURATION_FILE:-$COMMAND_DURATION_TMPDIR/bashit_theme_execution_$BASHPID}"

COMMAND_DURATION_ICON=${COMMAND_DURATION_ICON:-'  '}
COMMAND_DURATION_MIN_SECONDS=${COMMAND_DURATION_MIN_SECONDS:-'1'}

trap _command_duration_delete_temp_file EXIT HUP INT TERM

_command_duration_delete_temp_file() {
	if [[ -f "$COMMAND_DURATION_FILE" ]]; then
		rm -f "$COMMAND_DURATION_FILE"
	fi
}

_command_duration_pre_exec() {
	date +%s.%1N > "$COMMAND_DURATION_FILE"
}

_command_duration() {
	local command_duration command_start current_time
	local minutes seconds deciseconds
	local command_start_sseconds current_time_seconds command_start_deciseconds current_time_deciseconds
	current_time=$(date +%s.%1N)

	if [[ -f "$COMMAND_DURATION_FILE" ]]; then
		command_start=$(< "$COMMAND_DURATION_FILE")
		command_start_sseconds=${command_start%.*}
		current_time_seconds=${current_time%.*}

		command_start_deciseconds=$((10#${command_start#*.}))
		current_time_deciseconds=$((10#${current_time#*.}))

		# seconds
		command_duration=$((current_time_seconds - command_start_sseconds))

		if ((current_time_deciseconds >= command_start_deciseconds)); then
			deciseconds=$(((current_time_deciseconds - command_start_deciseconds)))
		else
			((command_duration -= 1))
			deciseconds=$((10 - ((command_start_deciseconds - current_time_deciseconds))))
		fi
		command rm "$COMMAND_DURATION_FILE"
	else
		command_duration=0
	fi

	if ((command_duration > 0)); then
		minutes=$((command_duration / 60))
		seconds=$((command_duration % 60))
	fi

	if ((minutes > 0)); then
		printf "%s%s%dm %ds" "$COMMAND_DURATION_ICON" "$COMMAND_DURATION_COLOR" "$minutes" "$seconds"
	elif ((seconds >= COMMAND_DURATION_MIN_SECONDS)); then
		printf "%s%s%d.%01ds" "$COMMAND_DURATION_ICON" "$COMMAND_DURATION_COLOR" "$seconds" "$deciseconds"
# shellcheck shell=bash

SCM_THEME_PROMPT_PREFIX=" ${yellow}‹"
SCM_THEME_PROMPT_SUFFIX="›${reset_color}"

VIRTUALENV_THEME_PROMPT_PREFIX=" ${cyan}‹"
VIRTUALENV_THEME_PROMPT_SUFFIX="›${reset_color}"

bold="\[\e[1m\]"

if [ ${UID} -eq 0 ]; then
	user_host="${bold_red}\u@\h${normal}${reset_color}"
else
	user_host="${bold_green}\u@\h${normal}${reset_color}"
fi

function prompt_command() {
	local current_dir=" ${bold_blue}\w${normal}${reset_color}"
	PS1="╭─${user_host}${current_dir}$(virtualenv_prompt)$(scm_prompt_info)\n╰─${bold}\\$ ${normal}"
}
#!/usr/bin/env bash

# Emoji-based theme to display source control management and
# virtual environment info beside the ordinary bash prompt.

# Theme inspired by:
#  - Naming your Terminal tabs in OSX Lion - http://thelucid.com/2012/01/04/naming-your-terminal-tabs-in-osx-lion/
#  - Bash_it sexy theme

# inspired by previous bash_it theme : cupcake

# Demo:
# ┌ⓔ virtualenv 🐲🤘user @ 💻 host in 🗂️ directory on 🌵 branch {1} ↑1 ↓1 +1 •1 ⌀1 ✗
# └❯ cd .bash-it/themes/cupcake

# virtualenv prompts
VIRTUALENV_CHAR="ⓔ "
VIRTUALENV_THEME_PROMPT_PREFIX=""
VIRTUALENV_THEME_PROMPT_SUFFIX=""

# SCM prompts
SCM_NONE_CHAR=""
SCM_GIT_CHAR="[±] "
SCM_GIT_BEHIND_CHAR="${red}↓${normal}"
SCM_GIT_AHEAD_CHAR="${bold_green}↑${normal}"
SCM_GIT_UNTRACKED_CHAR="⌀"
SCM_GIT_UNSTAGED_CHAR="${bold_yellow}•${normal}"
SCM_GIT_STAGED_CHAR="${bold_green}+${normal}"

SCM_THEME_PROMPT_DIRTY=""
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

# Git status prompts
GIT_THEME_PROMPT_DIRTY=" ${red}✗${normal}"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
GIT_THEME_PROMPT_PREFIX=""
GIT_THEME_PROMPT_SUFFIX=""

# ICONS =======================================================================

icon_start="┌"
icon_user="🤘-🐧"
icon_host="@ 💻 "
icon_directory=" - 🧱 "
icon_branch="🌵"
icon_end="└🤘-> "

# extra spaces ensure legiblity in prompt

# FUNCTIONS ===================================================================

# Display virtual environment info
function virtualenv_prompt {
  if [[ -n "$VIRTUAL_ENV" ]]; then
    virtualenv=`basename "$VIRTUAL_ENV"`
    echo -e "$VIRTUALENV_CHAR$virtualenv "
  fi
}

# Rename tab
function tabname {
  printf "\e]1;$1\a"
}

# Rename window
function winname {
  printf "\e]2;$1\a"
}

# PROMPT OUTPUT ===============================================================

# Displays the current prompt
function prompt_command() {
  PS1="\n${icon_start}$(virtualenv_prompt)${icon_user}${bold_green}\u${normal}${icon_host}${bold_cyan}\h${normal}${icon_directory}${bold_purple}\W${normal}\$([[ -n \$(git branch 2> /dev/null) ]] && echo \" on ${icon_branch}  \")${white}$(scm_prompt_info)${normal}\n${icon_end}"
  PS2="${icon_end}"
}

# Runs prompt (this bypasses bash_it $PROMPT setting)
# shellcheck shell=bash
# vim: ft=bash ts=2 sw=2 sts=2
#
# agnoster's Theme - https://gist.github.com/3712874
# A Powerline-inspired theme for BASH
#
# (Converted from ZSH theme by Kenny Root)
# https://gist.github.com/kruton/8345450
#
# Updated & fixed by Erik Selberg erik@selberg.org 1/14/17
# Tested on MacOSX, Ubuntu, Amazon Linux
# Bash v3 and v4
#
# # README
#
# In order for this theme to render correctly, you will need a
# [Powerline-patched font](https://gist.github.com/1595572).
# I recommend: https://github.com/powerline/fonts.git
# > git clone https://github.com/powerline/fonts.git fonts
# > cd fonts
# > install.sh

# In addition, I recommend the
# [Solarized theme](https://github.com/altercation/solarized/) and, if you're
# using it on Mac OS X, [iTerm 2](http://www.iterm2.com/) over Terminal.app -
# it has significantly better color fidelity.

# Install:

# I recommend the following:
# $ cd home
# $ mkdir -p .bash/themes/agnoster-bash
# $ git clone https://github.com/speedenator/agnoster-bash.git .bash/themes/agnoster-bash

# then add the following to your .bashrc:

# export THEME=$HOME/.bash/themes/agnoster-bash/agnoster.bash
# if [[ -f $THEME ]]; then
#     export DEFAULT_USER=`whoami`
#     source $THEME
# fi

#
# # Goals
#
# The aim of this theme is to only show you *relevant* information. Like most
# prompts, it will only show git information when in a git working directory.
# However, it goes a step further: everything from the current user and
# hostname to whether the last call exited with an error to whether background
# jobs are running in this shell will all be displayed automatically when
# appropriate.

# Generally speaking, this script has limited support for right
# prompts (ala powerlevel9k on zsh), but it's pretty problematic in Bash.
# The general pattern is to write out the right prompt, hit \r, then
# write the left. This is problematic for the following reasons:
# - Doesn't properly resize dynamically when you resize the terminal
# - Changes to the prompt (like clearing and re-typing, super common) deletes the prompt
# - Getting the right alignment via columns / tput cols is pretty problematic (and is a bug in this version)
# - Bash prompt escapes (like \h or \w) don't get interpolated
#
# all in all, if you really, really want right-side prompts without a
# ton of work, recommend going to zsh for now. If you know how to fix this,
# would appreciate it!

# note: requires bash v4+... Mac users - you often have bash3.
# 'brew install bash' will set you free
PROMPT_DIRTRIM=2 # bash4 and above

######################################################################
DEBUG=0
debug() {
	if [[ ${DEBUG} -ne 0 ]]; then
		echo >&2 -e "$@"
	fi
}

######################################################################
### Segment drawing
# A few utility functions to make it easy and re-usable to draw segmented prompts

CURRENT_BG='NONE'
CURRENT_RBG='NONE'
SEGMENT_SEPARATOR=''
RIGHT_SEPARATOR=''
LEFT_SUBSEG=''
RIGHT_SUBSEG=''

text_effect() {
	case "$1" in
		reset) echo 0 ;;
		bold) echo 1 ;;
		underline) echo 4 ;;
	esac
}

# to add colors, see
# http://bitmote.com/index.php?post/2012/11/19/Using-ANSI-Color-Codes-to-Colorize-Your-Bash-Prompt-on-Linux
# under the "256 (8-bit) Colors" section, and follow the example for orange below
fg_color() {
	case "$1" in
		black) echo 30 ;;
		red) echo 31 ;;
		green) echo 32 ;;
		yellow) echo 33 ;;
		blue) echo 34 ;;
		magenta) echo 35 ;;
		cyan) echo 36 ;;
		white) echo 37 ;;
		orange) echo 38\;5\;166 ;;
	esac
}

bg_color() {
	case "$1" in
		black) echo 40 ;;
		red) echo 41 ;;
		green) echo 42 ;;
		yellow) echo 43 ;;
		blue) echo 44 ;;
		magenta) echo 45 ;;
		cyan) echo 46 ;;
		white) echo 47 ;;
		orange) echo 48\;5\;166 ;;
	esac
}

# TIL: declare is global not local, so best use a different name
# for codes (mycodes) as otherwise it'll clobber the original.
# this changes from BASH v3 to BASH v4.
ansi() {
	local seq
	declare -a mycodes=("${!1}")

	debug "ansi: ${!1} all: $* aka " "${mycodes[@]}"

	seq=""
	for ((i = 0; i < ${#mycodes[@]}; i++)); do
		if [[ -n $seq ]]; then
			seq="${seq};"
		fi
		seq="${seq}${mycodes[$i]}"
	done
	debug "ansi debug:" '\\[\\033['"${seq}"'m\\]'
	echo -ne '\[\033['"${seq}"'m\]'
	# PR="$PR\[\033[${seq}m\]"
}

ansi_single() {
	echo -ne '\[\033['"$1"'m\]'
}

# Begin a segment
# Takes two arguments, background and foreground. Both can be omitted,
# rendering default background/foreground.
prompt_segment() {
	local bg fg
	declare -a codes

	debug "Prompting $1 $2 $3"

	# if commented out from kruton's original... I'm not clear
	# if it did anything, but it messed up things like
	# prompt_status - Erik 1/14/17

	#    if [[ -z $1 || ( -z $2 && $2 != default ) ]]; then
	codes=("${codes[@]}" "$(text_effect reset)")
	#    fi
	if [[ -n $1 ]]; then
		bg=$(bg_color "$1")
		codes=("${codes[@]}" "$bg")
		debug "Added $bg as background to codes"
	fi
	if [[ -n $2 ]]; then
		fg=$(fg_color "$2")
		codes=("${codes[@]}" "$fg")
		debug "Added $fg as foreground to codes"
	fi

	debug "Codes: "
	# declare -p codes

	if [[ $CURRENT_BG != NONE && $1 != "$CURRENT_BG" ]]; then
		declare -a intermediate=("$(fg_color $CURRENT_BG)" "$(bg_color "$1")")
		debug "pre prompt " "$(ansi intermediate[@])"
		PR="$PR $(ansi intermediate[@])$SEGMENT_SEPARATOR"
		debug "post prompt " "$(ansi codes[@])"
		PR="$PR$(ansi codes[@]) "
	else
		debug "no current BG, codes is " "${codes[@]}"
		PR="$PR$(ansi codes[@]) "
	fi
	CURRENT_BG=$1
	[[ -n $3 ]] && PR="$PR$3"
}

# End the prompt, closing any open segments
prompt_end() {
	if [[ -n $CURRENT_BG ]]; then
		declare -a codes=("$(text_effect reset)" "$(fg_color "$CURRENT_BG")")
		PR="$PR $(ansi codes[@])$SEGMENT_SEPARATOR"
	fi
	declare -a reset=("$(text_effect reset)")
	PR="$PR $(ansi reset[@])"
	CURRENT_BG=''
}

### virtualenv prompt
prompt_virtualenv() {
	if [[ -n $VIRTUAL_ENV ]]; then
		color=cyan
		prompt_segment $color "$PRIMARY_FG"
		ve=$(basename "$VIRTUAL_ENV")
		prompt_segment $color white "$ve"
	fi
}

### Prompt components
# Each component will draw itself, and hide itself if no information needs to be shown

# Context: user@hostname (who am I and where am I)
prompt_context() {
	local user=$(whoami)

	if [[ $user != "$DEFAULT_USER" || -n $SSH_CLIENT ]]; then
		prompt_segment black default "$user@\h"
	fi
}

# prints history followed by HH:MM, useful for remembering what
# we did previously
prompt_histdt() {
	prompt_segment black default "\! [\A]"
}

git_status_dirty() {
	dirty=$(git status -s 2> /dev/null | tail -n 1)
	[[ -n $dirty ]] && echo " ●"
}

# Git: branch/detached head, dirty status
prompt_git() {
	local ref dirty
	if git rev-parse --is-inside-work-tree > /dev/null 2>&1; then
		ZSH_THEME_GIT_PROMPT_DIRTY='±'
		dirty=$(git_status_dirty)
		ref=$(git symbolic-ref HEAD 2> /dev/null) || ref="➦ $(git show-ref --head -s --abbrev | head -n1 2> /dev/null)"
		if [[ -n $dirty ]]; then
			prompt_segment yellow black
		else
			prompt_segment green black
		fi
		PR="$PR${ref/refs\/heads\// }$dirty"
	fi
}

# Dir: current working directory
prompt_dir() {
	prompt_segment blue black '\w'
}

# Status:
# - was there an error
# - am I root
# - are there background jobs?
prompt_status() {
	local symbols
	symbols=()
	[[ $RETVAL -ne 0 ]] && symbols+=("$(ansi_single "$(fg_color red)")✘")
	[[ $UID -eq 0 ]] && symbols+=("$(ansi_single "$(fg_color yellow)")⚡")
	[[ $(jobs -l | wc -l) -gt 0 ]] && symbols+=("$(ansi_single "$(fg_color cyan)")⚙")

	[[ -n "${symbols[*]}" ]] && prompt_segment black default "${symbols[@]}"
}

######################################################################
#
# experimental right prompt stuff
# requires setting prompt_foo to use PRIGHT vs PR
# doesn't quite work per above

rightprompt() {
	printf "%*s" $COLUMNS "$PRIGHT"
}

# quick right prompt I grabbed to test things.
__command_rprompt() {
	local times=n=$COLUMNS tz
	for tz in ZRH:Europe/Zurich PIT:US/Eastern \
		MTV:US/Pacific TOK:Asia/Tokyo; do
		[ "$n" -gt 40 ] || break
		times="$times ${tz%%:*}\e[30;1m:\e[0;36;1m"
		times="$times$(TZ=${tz#*:} date +%H:%M)\e[0m"
		n=$(("$n" - 10))
	done
	[ -z "$times" ] || printf "%${n}s$times\\r" ''
}
# PROMPT_COMMAND=__command_rprompt

# this doens't wrap code in \[ \]
ansi_r() {
	local seq
	declare -a mycodes2=("${!1}")

	debug "ansi: ${!1} all: $* aka " "${mycodes2[@]}"

	seq=""
	for ((i = 0; i < ${#mycodes2[@]}; i++)); do
		if [[ -n $seq ]]; then
			seq="${seq};"
		fi
		seq="${seq}${mycodes2[$i]}"
	done
	debug "ansi debug:" '\\[\\033['"${seq}"'m\\]'
	echo -ne '\033['"${seq}"'m'
	# PR="$PR\[\033[${seq}m\]"
}

# Begin a segment on the right
# Takes two arguments, background and foreground. Both can be omitted,
# rendering default background/foreground.
prompt_right_segment() {
	local bg fg
	declare -a codes

	debug "Prompt right"
	debug "Prompting $1 $2 $3"

	# if commented out from kruton's original... I'm not clear
	# if it did anything, but it messed up things like
	# prompt_status - Erik 1/14/17

	#    if [[ -z $1 || ( -z $2 && $2 != default ) ]]; then
	codes=("${codes[@]}" "$(text_effect reset)")
	#    fi
	if [[ -n $1 ]]; then
		bg=$(bg_color "$1")
		codes=("${codes[@]}" "$bg")
		debug "Added $bg as background to codes"
	fi
	if [[ -n $2 ]]; then
		fg=$(fg_color "$2")
		codes=("${codes[@]}" "$fg")
		debug "Added $fg as foreground to codes"
	fi

	debug "Right Codes: "
	# declare -p codes

	# right always has a separator
	# if [[ $CURRENT_RBG != NONE && $1 != $CURRENT_RBG ]]; then
	#     $CURRENT_RBG=
	# fi
	declare -a intermediate2=("$(fg_color "$1")" "$(bg_color $CURRENT_RBG)")
	# PRIGHT="$PRIGHT---"
	debug "pre prompt " "$(ansi_r intermediate2[@])"
	PRIGHT="$PRIGHT$(ansi_r intermediate2[@])$RIGHT_SEPARATOR"
	debug "post prompt " "$(ansi_r codes[@])"
	PRIGHT="$PRIGHT$(ansi_r codes[@]) "
	# else
	#     debug "no current BG, codes is $codes[@]"
	#     PRIGHT="$PRIGHT$(ansi codes[@]) "
	# fi
	CURRENT_RBG=$1
	[[ -n $3 ]] && PRIGHT="$PRIGHT$3"
}

######################################################################
## Emacs prompt --- for dir tracking
# stick the following in your .emacs if you use this:

# (setq dirtrack-list '(".*DIR *\\([^ ]*\\) DIR" 1 nil))
# (defun dirtrack-filter-out-pwd-prompt (string)
#   "dirtrack-mode doesn't remove the PWD match from the prompt.  This does."
#   ;; TODO: support dirtrack-mode's multiline regexp.
#   (if (and (stringp string) (string-match (first dirtrack-list) string))
#       (replace-match "" t t string 0)
#     string))
# (add-hook 'shell-mode-hook
#           #'(lambda ()
#               (dirtrack-mode 1)
#               (add-hook 'comint-preoutput-filter-functions
#                         'dirtrack-filter-out-pwd-prompt t t)))

prompt_emacsdir() {
	# no color or other setting... this will be deleted per above
	PR="DIR \w DIR$PR"
}

######################################################################
## Main prompt

build_prompt() {
	[[ -n ${AG_EMACS_DIR+x} ]] && prompt_emacsdir
	prompt_status
	#[[ -z ${AG_NO_HIST+x} ]] && prompt_histdt
	[[ -z ${AG_NO_CONTEXT+x} ]] && prompt_context
	prompt_virtualenv
	prompt_dir
	prompt_git
	prompt_end
}

# from orig...
# export PS1='$(ansi_single $(text_effect reset)) $(build_prompt) '
# this doesn't work... new model: create a prompt via a PR variable and
# use that.

set_bash_prompt() {
	RETVAL=$?
	PR=""
	PRIGHT=""
	CURRENT_BG=NONE
	PR="$(ansi_single "$(text_effect reset)")"
	build_prompt

	# uncomment below to use right prompt
	#     PS1='\[$(tput sc; printf "%*s" $COLUMNS "$PRIGHT"; tput rc)\]'$PR
	PS1=$PR
}
#!/usr/bin/env bash

prompt_setter() {
  # Save history
  history -a
  history -c
  history -r
  PS1="($(clock_prompt)) $(scm_char) [$blue\u$reset_color@$green\H$reset_color] $yellow\w${reset_color}$(scm_prompt_info)$(ruby_version_prompt) $reset_color "
  PS2='> '
  PS4='+ '
}

safe_append_prompt_command prompt_setter

SCM_THEME_PROMPT_DIRTY=" ✗"
#!/usr/bin/env bash
# zitron theme by Florian Baumann <flo@noqqe.de>

## git-theme
# feel free to change git chars.
GIT_THEME_PROMPT_DIRTY="${bold_yellow}*${normal}"
GIT_THEME_PROMPT_CLEAN=""
GIT_THEME_PROMPT_PREFIX=""
GIT_THEME_PROMPT_SUFFIX=""

## ls colors
# thanks a lot to http://geoff.greer.fm/lscolors/
export LSCOLORS="Gxfxcxdxbxegedabagacad"
export LS_COLORS="no=00:fi=00:di=01;33:ln=01;36:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:ex=01;32:*.tar=01;31:*.tgz=01;31:*.svgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;34:*.svg=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:"

function prompt_command() {
    ## look-a-like
    # user:host:pwd git-branch(*)$
    # for example:
    # noqqe:deathstar:themes master*$
#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${green}✓"
SCM_THEME_PROMPT_PREFIX=" ${blue}scm:( "
SCM_THEME_PROMPT_SUFFIX="${blue} )"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${green}✓"
GIT_THEME_PROMPT_PREFIX="${green}git:( "
GIT_THEME_PROMPT_SUFFIX="${green} )"

function git_prompt_info {
  git_prompt_vars
  echo -e "$SCM_PREFIX$SCM_BRANCH$SCM_STATE$SCM_SUFFIX"
}

function prompt() {
  PS1="\h: \W $(scm_prompt_info)${reset_color} $ "
}
#!/usr/bin/env bash

. "$BASH_IT/themes/powerline-plain/powerline-plain.base.bash"

USER_INFO_SSH_CHAR=${POWERLINE_USER_INFO_SSH_CHAR:="⌁ "}
USER_INFO_THEME_PROMPT_COLOR=${POWERLINE_USER_INFO_COLOR:=32}
USER_INFO_THEME_PROMPT_COLOR_SUDO=${POWERLINE_USER_INFO_COLOR_SUDO:=202}

POWERLINE_COMPACT=${POWERLINE_COMPACT:=0}
POWERLINE_COMPACT_BEFORE_SEPARATOR=${POWERLINE_COMPACT_BEFORE_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_SEPARATOR=${POWERLINE_COMPACT_AFTER_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_BEFOR_FIRST_SEGMENT=${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_LAST_SEGMENT=${POWERLINE_COMPACT_AFTER_LAST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_PROMPT=${POWERLINE_COMPACT_PROMPT:=${POWERLINE_COMPACT}}
POWERLINE_PROMPT_AFTER=${POWERLINE_PROMPT_AFTER:-""}

PYTHON_VENV_CHAR=${POWERLINE_PYTHON_VENV_CHAR:="ⓔ "}
CONDA_PYTHON_VENV_CHAR=${POWERLINE_CONDA_PYTHON_VENV_CHAR:="ⓔ "}
PYTHON_VENV_THEME_PROMPT_COLOR=${POWERLINE_PYTHON_VENV_COLOR:=35}

SCM_NONE_CHAR=""
SCM_GIT_CHAR=${POWERLINE_SCM_GIT_CHAR:="⎇  "}
SCM_HG_CHAR=${POWERLINE_SCM_HG_CHAR:="☿ "}
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_DIRTY=""
SCM_THEME_PROMPT_CLEAN_COLOR=${POWERLINE_SCM_CLEAN_COLOR:=25}
SCM_THEME_PROMPT_DIRTY_COLOR=${POWERLINE_SCM_DIRTY_COLOR:=88}
SCM_THEME_PROMPT_STAGED_COLOR=${POWERLINE_SCM_STAGED_COLOR:=30}
SCM_THEME_PROMPT_UNSTAGED_COLOR=${POWERLINE_SCM_UNSTAGED_COLOR:=92}
SCM_THEME_PROMPT_COLOR=${SCM_THEME_PROMPT_CLEAN_COLOR}

NVM_THEME_PROMPT_PREFIX=""
NVM_THEME_PROMPT_SUFFIX=""
NODE_CHAR=${POWERLINE_NODE_CHAR:="❲n❳ "}
NODE_THEME_PROMPT_COLOR=${POWERLINE_NODE_COLOR:=22}

RVM_THEME_PROMPT_PREFIX=""
RVM_THEME_PROMPT_SUFFIX=""
RBENV_THEME_PROMPT_PREFIX=""
RBENV_THEME_PROMPT_SUFFIX=""
RUBY_THEME_PROMPT_COLOR=${POWERLINE_RUBY_COLOR:=161}
RUBY_CHAR=${POWERLINE_RUBY_CHAR:="💎 "}

TERRAFORM_THEME_PROMPT_COLOR=${POWERLINE_TERRAFORM_COLOR:=161}
TERRAFORM_CHAR=${POWERLINE_TERRAFORM_CHAR:="❲t❳ "}

KUBERNETES_CONTEXT_THEME_CHAR=${POWERLINE_KUBERNETES_CONTEXT_CHAR:="⎈ "}
KUBERNETES_CONTEXT_THEME_PROMPT_COLOR=${POWERLINE_KUBERNETES_CONTEXT_COLOR:=26}

AWS_PROFILE_CHAR=${POWERLINE_AWS_PROFILE_CHAR:="❲aws❳ "}
AWS_PROFILE_PROMPT_COLOR=${POWERLINE_AWS_PROFILE_COLOR:=208}

CWD_THEME_PROMPT_COLOR=${POWERLINE_CWD_COLOR:=240}

LAST_STATUS_THEME_PROMPT_COLOR=${POWERLINE_LAST_STATUS_COLOR:=52}

CLOCK_THEME_PROMPT_COLOR=${POWERLINE_CLOCK_COLOR:=240}

BATTERY_AC_CHAR=${BATTERY_AC_CHAR:="+ "}
BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR=${POWERLINE_BATTERY_GOOD_COLOR:=70}
BATTERY_STATUS_THEME_PROMPT_LOW_COLOR=${POWERLINE_BATTERY_LOW_COLOR:=208}
BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR=${POWERLINE_BATTERY_CRITICAL_COLOR:=160}

THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:="%H:%M:%S"}

IN_VIM_THEME_PROMPT_COLOR=${POWERLINE_IN_VIM_COLOR:=245}
IN_VIM_THEME_PROMPT_TEXT=${POWERLINE_IN_VIM_TEXT:="vim"}

IN_TOOLBOX_THEME_PROMPT_COLOR=${POWERLINE_IN_TOOLBOX_COLOR:=125}
IN_TOOLBOX_THEME_PROMPT_TEXT=${POWERLINE_IN_TOOLBOX_TEXT:="⬢ "}

HOST_THEME_PROMPT_COLOR=${POWERLINE_HOST_COLOR:=0}

SHLVL_THEME_PROMPT_COLOR=${POWERLINE_SHLVL_COLOR:=${HOST_THEME_PROMPT_COLOR}}
SHLVL_THEME_PROMPT_CHAR=${POWERLINE_SHLVL_CHAR:="§"}

DIRSTACK_THEME_PROMPT_COLOR=${POWERLINE_DIRSTACK_COLOR:=${CWD_THEME_PROMPT_COLOR}}
DIRSTACK_THEME_PROMPT_CHAR=${POWERLINE_DIRSTACK_CHAR:="←"}

HISTORY_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_HISTORY_NUMBER_COLOR:=0}
HISTORY_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_HISTORY_NUMBER_CHAR:="#"}

COMMAND_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_COMMAND_NUMBER_COLOR:=0}
COMMAND_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_COMMAND_NUMBER_CHAR:="#"}

. "$BASH_IT/themes/powerline/powerline.base.bash"

function __powerline_left_segment {
  local OLD_IFS="${IFS}"; IFS="|"
  local params=( $1 )
  IFS="${OLD_IFS}"
  local pad_before_segment=" "

  if [[ "${SEGMENTS_AT_LEFT}" -eq 0 ]]; then
    if [[ "${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT}" -ne 0 ]]; then
      pad_before_segment=""
    fi
  else
    if [[ "${POWERLINE_COMPACT_AFTER_SEPARATOR}" -ne 0 ]]; then
      pad_before_segment=""
    fi
    # Since the previous segment wasn't the last segment, add padding, if needed
    #
    if [[ "${POWERLINE_COMPACT_BEFORE_SEPARATOR}" -eq 0 ]]; then
      LEFT_PROMPT+="$(set_color - ${LAST_SEGMENT_COLOR}) ${normal}"
    fi
  fi

  LEFT_PROMPT+="$(set_color - ${params[1]})${pad_before_segment}${params[0]}${normal}"
  LAST_SEGMENT_COLOR=${params[1]}
  (( SEGMENTS_AT_LEFT += 1 ))
}

function __powerline_prompt_command {
  local last_status="$?" ## always the first

  LEFT_PROMPT=""
  SEGMENTS_AT_LEFT=0
  LAST_SEGMENT_COLOR=""
  PROMPT_AFTER="${POWERLINE_PROMPT_AFTER}"

  _save-and-reload-history "${HISTORY_AUTOSAVE:-0}"

  ## left prompt ##
  for segment in $POWERLINE_PROMPT; do
    local info="$(__powerline_${segment}_prompt)"
    [[ -n "${info}" ]] && __powerline_left_segment "${info}"
  done

  [[ "${last_status}" -ne 0 ]] && __powerline_left_segment $(__powerline_last_status_prompt ${last_status})

  if [[ -n "${LEFT_PROMPT}" ]] && [[ "${POWERLINE_COMPACT_AFTER_LAST_SEGMENT}" -eq 0 ]]; then
    __powerline_left_last_segment_padding
  fi

  if [[ "${POWERLINE_COMPACT_PROMPT}" -eq 0 ]]; then
    LEFT_PROMPT+=" "
  fi

  PS1="${LEFT_PROMPT}${PROMPT_AFTER}"

  ## cleanup ##
  unset LAST_SEGMENT_COLOR \
        LEFT_PROMPT \
        SEGMENTS_AT_LEFT
#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" |"
SCM_THEME_PROMPT_SUFFIX="${green}|"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX="|"

function get_hour_color {
    hour_color=$red
    min=$(date +%M)
    if [ "$min" -lt "15" ]; then
        hour_color=$white
    elif [ "$min" -lt "30" ]; then
        hour_color=$green
    elif [ "$min" -lt "45" ]; then
        hour_color=$yellow
    else
        hour_color=$red
    fi
    echo "$hour_color"
}

__emperor_clock() {
  THEME_CLOCK_COLOR=$(get_hour_color)
  clock_prompt
}

function prompt_command() {
    PS1="\n$(__emperor_clock)${purple}\h ${reset_color}in ${prompt_color}\w\n${bold_cyan}$(scm_char)${green}$(scm_prompt_info) ${green}→${reset_color} "
}

THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:-"%H "}
# Mairan Bash Prompt, inspired by "Zork"

if tput setaf 1 &> /dev/null; then
    if [[ $(tput colors) -ge 256 ]] 2>/dev/null; then
      MAGENTA=$(tput setaf 9)
      ORANGE=$(tput setaf 172)
      GREEN=$(tput setaf 190)
      PURPLE=$(tput setaf 141)
      WHITE=$(tput setaf 0)
    else
      MAGENTA=$(tput setaf 5)
      ORANGE=$(tput setaf 4)
      GREEN=$(tput setaf 2)
      PURPLE=$(tput setaf 1)
      WHITE=$(tput setaf 7)
    fi
    BOLD=$(tput bold)
    RESET=$(tput sgr0)
else
    MAGENTA="\033[1;31m"
    ORANGE="\033[1;33m"
    GREEN="\033[1;32m"
    PURPLE="\033[1;35m"
    WHITE="\033[1;37m"
    BOLD=""
    RESET="\033[m"
fi

# prompt_symbol='λ'
# prompt_symbol='⚡'
prompt_symbol=''
BRACKET_COLOR=$ORANGE

SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

#Mysql Prompt
export MYSQL_PS1="(\u@\h) [\d]> "

case $TERM in
        xterm*)
        TITLEBAR="\[\033]0;\w\007\]"
        ;;
        *)
        TITLEBAR=""
        ;;
esac

PS3=">> "

__my_rvm_ruby_version() {
    local gemset=$(echo $GEM_HOME | awk -F'@' '{print $2}')
  [ "$gemset" != "" ] && gemset="@$gemset"
    local version=$(echo $MY_RUBY_HOME | awk -F'-' '{print $2}')
    local full="$version$gemset"
  [ "$full" != "" ] && echo "[$full]"
}

is_vim_shell() {
        if [ ! -z "$VIMRUNTIME" ]
        then
                echo "[${cyan}vim shell${normal}]"
        fi
}

modern_scm_prompt() {
        CHAR=$(scm_char)
        if [ $CHAR = $SCM_NONE_CHAR ]
        then
                return
        else
                echo "[$(scm_char)][$GREEN$(scm_prompt_info)]"
        fi
}

# show chroot if exist
chroot(){
    if [ -n "$debian_chroot" ]
    then
        my_ps_chroot="${bold_cyan}$debian_chroot${normal}";
        echo "($my_ps_chroot)";
    fi
    }

# show virtualenvwrapper
my_ve(){
    if [ -n "$VIRTUAL_ENV" ]
    then
        my_ps_ve="${bold_purple}$ve${normal}";
        echo "($my_ps_ve)";
    fi
    echo "";
    }

prompt() {

    my_ps_host="$BOLD$ORANGE\h${normal}";
    # yes, these are the the same for now ...
    my_ps_host_root="$ORANGE\h${normal}";

    my_ps_user="$BOLD$GREEN\u${normal}"
    my_ps_root="${bold_red}\u${normal}";

    if [ -n "$VIRTUAL_ENV" ]
    then
        ve=`basename "$VIRTUAL_ENV"`;
    fi

    # nice prompt
    case "`id -u`" in
        0) PS1="\n${TITLEBAR}${BRACKET_COLOR}┌─${normal}$(my_ve)$(chroot)[$my_ps_root][$my_ps_host_root]$(modern_scm_prompt)$(__my_rvm_ruby_version)[${green}\w${normal}]$(is_vim_shell)${BRACKET_COLOR}
└─▪ ${prompt_symbol} ${normal}"
        ;;
        *) PS1="\n${TITLEBAR}${BRACKET_COLOR}┌─${normal}$(my_ve)$(chroot)[$my_ps_user][$my_ps_host]$(modern_scm_prompt)${normal}$(__my_rvm_ruby_version)[${green}\w${normal}]$(is_vim_shell)${BRACKET_COLOR}
└─▪ ${prompt_symbol} ${normal}"
        ;;
    esac
}

#!/usr/bin/env bash

source "$BASH_IT/themes/doubletime/doubletime.theme.bash"

function prompt_setter() {
  # Save history
  history -a
  history -c
  history -r
  PS1="
$(clock_prompt) $(scm_char) [$THEME_PROMPT_HOST_COLOR\u@${THEME_PROMPT_HOST}$reset_color] $(virtualenv_prompt)
\w
$(doubletime_scm_prompt)$reset_color $ "
  PS2='> '
  PS4='+ '
# shellcheck shell=bash
# Define this here so it can be used by all of the Powerline themes
THEME_CHECK_SUDO=${THEME_CHECK_SUDO:=true}

function set_color() {
	set +u
	if [[ "${1}" != "-" ]]; then
		fg="38;5;${1}"
	fi
	if [[ "${2}" != "-" ]]; then
		bg="48;5;${2}"
		[[ -n "${fg}" ]] && bg=";${bg}"
	fi
	echo -e "\[\033[${fg}${bg}m\]"
}

function __powerline_user_info_prompt() {
	local user_info=""
	local color=${USER_INFO_THEME_PROMPT_COLOR}

	if [[ "${THEME_CHECK_SUDO}" = true ]]; then
		sudo -vn 1> /dev/null 2>&1 && color=${USER_INFO_THEME_PROMPT_COLOR_SUDO}
	fi

	case "${POWERLINE_PROMPT_USER_INFO_MODE}" in
		"sudo")
			if [[ "${color}" = "${USER_INFO_THEME_PROMPT_COLOR_SUDO}" ]]; then
				user_info="!"
			fi
			;;
		*)
			local user=${SHORT_USER:-${USER}}
			if [[ -n "${SSH_CLIENT}" ]] || [[ -n "${SSH_CONNECTION}" ]]; then
				user_info="${USER_INFO_SSH_CHAR}${user}"
			else
				user_info="${user}"
			fi
			;;
	esac
	[[ -n "${user_info}" ]] && echo "${user_info}|${color}"
}

function __powerline_terraform_prompt() {
	local terraform_workspace=""

	if [ -d .terraform ]; then
		terraform_workspace="$(terraform_workspace_prompt)"
		[[ -n "${terraform_workspace}" ]] && echo "${TERRAFORM_CHAR}${terraform_workspace}|${TERRAFORM_THEME_PROMPT_COLOR}"
	fi
}

function __powerline_node_prompt() {
	local node_version=""

	node_version="$(node_version_prompt)"
	[[ -n "${node_version}" ]] && echo "${NODE_CHAR}${node_version}|${NODE_THEME_PROMPT_COLOR}"
}

function __powerline_ruby_prompt() {
	local ruby_version=""

	if _command_exists rvm; then
		ruby_version="$(rvm_version_prompt)"
	elif _command_exists rbenv; then
		ruby_version=$(rbenv_version_prompt)
	fi

	[[ -n "${ruby_version}" ]] && echo "${RUBY_CHAR}${ruby_version}|${RUBY_THEME_PROMPT_COLOR}"
}

function __powerline_k8s_context_prompt() {
	local kubernetes_context=""

	if _command_exists kubectl; then
		kubernetes_context="$(k8s_context_prompt)"
	fi

	[[ -n "${kubernetes_context}" ]] && echo "${KUBERNETES_CONTEXT_THEME_CHAR}${kubernetes_context}|${KUBERNETES_CONTEXT_THEME_PROMPT_COLOR}"
}

function __powerline_python_venv_prompt() {
	set +u
	local python_venv=""

	if [[ -n "${CONDA_DEFAULT_ENV}" ]]; then
		python_venv="${CONDA_DEFAULT_ENV}"
		PYTHON_VENV_CHAR=${CONDA_PYTHON_VENV_CHAR}
	elif [[ -n "${VIRTUAL_ENV}" ]]; then
		python_venv=$(basename "${VIRTUAL_ENV}")
	fi

	[[ -n "${python_venv}" ]] && echo "${PYTHON_VENV_CHAR}${python_venv}|${PYTHON_VENV_THEME_PROMPT_COLOR}"
}

function __powerline_scm_prompt() {
	local color=""
	local scm_prompt=""

	scm_prompt_vars

	if [[ "${SCM_NONE_CHAR}" != "${SCM_CHAR}" ]]; then
		if [[ "${SCM_DIRTY}" -eq 3 ]]; then
			color=${SCM_THEME_PROMPT_STAGED_COLOR}
		elif [[ "${SCM_DIRTY}" -eq 2 ]]; then
			color=${SCM_THEME_PROMPT_UNSTAGED_COLOR}
		elif [[ "${SCM_DIRTY}" -eq 1 ]]; then
			color=${SCM_THEME_PROMPT_DIRTY_COLOR}
		else
			color=${SCM_THEME_PROMPT_CLEAN_COLOR}
		fi
		if [[ "${SCM_GIT_CHAR}" == "${SCM_CHAR}" ]]; then
			scm_prompt+="${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
		elif [[ "${SCM_P4_CHAR}" == "${SCM_CHAR}" ]]; then
			scm_prompt+="${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
		elif [[ "${SCM_HG_CHAR}" == "${SCM_CHAR}" ]]; then
			scm_prompt+="${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
		elif [[ "${SCM_SVN_CHAR}" == "${SCM_CHAR}" ]]; then
			scm_prompt+="${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
		fi
		echo "$(eval "echo ${scm_prompt}")${scm}|${color}"
	fi
}

function __powerline_cwd_prompt() {
	local cwd=$(pwd | sed "s|^${HOME}|~|")

	echo "${cwd}|${CWD_THEME_PROMPT_COLOR}"
}

function __powerline_hostname_prompt() {
	echo "${SHORT_HOSTNAME:-$(hostname -s)}|${HOST_THEME_PROMPT_COLOR}"
}

function __powerline_wd_prompt() {
	echo "\W|${CWD_THEME_PROMPT_COLOR}"
}

function __powerline_clock_prompt() {
	echo "$(date +"${THEME_CLOCK_FORMAT}")|${CLOCK_THEME_PROMPT_COLOR}"
}

function __powerline_battery_prompt() {
	local color=""
	local battery_status="$(battery_percentage 2> /dev/null)"

	if [[ -z "${battery_status}" ]] || [[ "${battery_status}" = "-1" ]] || [[ "${battery_status}" = "no" ]]; then
		true
	else
		if [[ "$((10#${battery_status}))" -le 5 ]]; then
			color="${BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR}"
		elif [[ "$((10#${battery_status}))" -le 25 ]]; then
			color="${BATTERY_STATUS_THEME_PROMPT_LOW_COLOR}"
		else
			color="${BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR}"
		fi
		ac_adapter_connected && battery_status="${BATTERY_AC_CHAR}${battery_status}"
		echo "${battery_status}%|${color}"
	fi
}

function __powerline_in_vim_prompt() {
	if [ -n "$VIMRUNTIME" ]; then
		echo "${IN_VIM_THEME_PROMPT_TEXT}|${IN_VIM_THEME_PROMPT_COLOR}"
	fi
}

function __powerline_aws_profile_prompt() {
	if [[ -n "${AWS_PROFILE}" ]]; then
		echo "${AWS_PROFILE_CHAR}${AWS_PROFILE}|${AWS_PROFILE_PROMPT_COLOR}"
	fi
}

function __powerline_in_toolbox_prompt() {
	if [ -f /run/.containerenv ] && [ -f /run/.toolboxenv ]; then
		echo "${IN_TOOLBOX_THEME_PROMPT_TEXT}|${IN_TOOLBOX_THEME_PROMPT_COLOR}"
	fi
}

function __powerline_shlvl_prompt() {
	if [[ "${SHLVL}" -gt 1 ]]; then
		local prompt="${SHLVL_THEME_PROMPT_CHAR}"
		local level=$((SHLVL - 1))
		echo "${prompt}${level}|${SHLVL_THEME_PROMPT_COLOR}"
	fi
}

function __powerline_dirstack_prompt() {
	if [[ "${#DIRSTACK[@]}" -gt 1 ]]; then
		local depth=$((${#DIRSTACK[@]} - 1))
		local prompt="${DIRSTACK_THEME_PROMPT_CHAR}"
		if [[ "${depth}" -ge 2 ]]; then
			prompt+="${depth}"
		fi
		echo "${prompt}|${DIRSTACK_THEME_PROMPT_COLOR}"
	fi
}

function __powerline_history_number_prompt() {
	echo "${HISTORY_NUMBER_THEME_PROMPT_CHAR}\!|${HISTORY_NUMBER_THEME_PROMPT_COLOR}"
}

function __powerline_command_number_prompt() {
	echo "${COMMAND_NUMBER_THEME_PROMPT_CHAR}\#|${COMMAND_NUMBER_THEME_PROMPT_COLOR}"
}

function __powerline_left_segment() {
	local params
	IFS="|" read -ra params <<< "${1}"
	local pad_before_segment=" "

	if [[ "${SEGMENTS_AT_LEFT}" -eq 0 ]]; then
		if [[ "${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT}" -ne 0 ]]; then
			pad_before_segment=""
		fi
	else
		if [[ "${POWERLINE_COMPACT_AFTER_SEPARATOR}" -ne 0 ]]; then
			pad_before_segment=""
		fi
		# Since the previous segment wasn't the last segment, add padding, if needed
		#
		if [[ "${POWERLINE_COMPACT_BEFORE_SEPARATOR}" -eq 0 ]]; then
			LEFT_PROMPT+="$(set_color - "${LAST_SEGMENT_COLOR}") ${normal}"
		fi
		if [[ "${LAST_SEGMENT_COLOR}" -eq "${params[1]}" ]]; then
			LEFT_PROMPT+="$(set_color - "${LAST_SEGMENT_COLOR}")${POWERLINE_LEFT_SEPARATOR_SOFT}${normal}"
		else
			LEFT_PROMPT+="$(set_color "${LAST_SEGMENT_COLOR}" "${params[1]}")${POWERLINE_LEFT_SEPARATOR}${normal}"
		fi
	fi

	LEFT_PROMPT+="$(set_color - "${params[1]}")${pad_before_segment}${params[0]}${normal}"
	LAST_SEGMENT_COLOR=${params[1]}
	((SEGMENTS_AT_LEFT += 1))
}

function __powerline_left_last_segment_padding() {
	LEFT_PROMPT+="$(set_color - "${LAST_SEGMENT_COLOR}") ${normal}"
}

function __powerline_last_status_prompt() {
	[[ "$1" -ne 0 ]] && echo "${1}|${LAST_STATUS_THEME_PROMPT_COLOR}"
}

function __powerline_prompt_command() {
	local last_status="$?" ## always the first
	local separator_char="${POWERLINE_PROMPT_CHAR}"

	LEFT_PROMPT=""
	SEGMENTS_AT_LEFT=0
	LAST_SEGMENT_COLOR=""

	if [[ -n "${POWERLINE_PROMPT_DISTRO_LOGO}" ]]; then
		LEFT_PROMPT+="$(set_color "${PROMPT_DISTRO_LOGO_COLOR}" "${PROMPT_DISTRO_LOGO_COLORBG}")${PROMPT_DISTRO_LOGO}$(set_color - -)"
	fi

	## left prompt ##
	for segment in $POWERLINE_PROMPT; do
		local info="$(__powerline_"${segment}"_prompt)"
		[[ -n "${info}" ]] && __powerline_left_segment "${info}"
	done

	[[ "${last_status}" -ne 0 ]] && __powerline_left_segment "$(__powerline_last_status_prompt ${last_status})"

	if [[ -n "${LEFT_PROMPT}" ]] && [[ "${POWERLINE_COMPACT_AFTER_LAST_SEGMENT}" -eq 0 ]]; then
		__powerline_left_last_segment_padding
	fi

	# By default we try to match the prompt to the adjacent segment's background color,
	# but when part of the prompt exists within that segment, we instead match the foreground color.
	local prompt_color="$(set_color "${LAST_SEGMENT_COLOR}" -)"
	if [[ -n "${LEFT_PROMPT}" ]] && [[ -n "${POWERLINE_LEFT_LAST_SEGMENT_PROMPT_CHAR}" ]]; then
		LEFT_PROMPT+="$(set_color - "${LAST_SEGMENT_COLOR}")${POWERLINE_LEFT_LAST_SEGMENT_PROMPT_CHAR}"
		prompt_color="${normal}"
	fi
	[[ -n "${LEFT_PROMPT}" ]] && LEFT_PROMPT+="${prompt_color}${separator_char}${normal}"

	if [[ "${POWERLINE_COMPACT_PROMPT}" -eq 0 ]]; then
		LEFT_PROMPT+=" "
	fi

	PS1="${LEFT_PROMPT}"

	## cleanup ##
	unset LAST_SEGMENT_COLOR \
		LEFT_PROMPT \
# shellcheck shell=bash

# shellcheck source=../../themes/powerline/powerline.base.bash
. "$BASH_IT/themes/powerline/powerline.base.bash"

PROMPT_CHAR=${POWERLINE_PROMPT_CHAR:=""}
POWERLINE_LEFT_SEPARATOR=${POWERLINE_LEFT_SEPARATOR:=""}
POWERLINE_LEFT_SEPARATOR_SOFT=${POWERLINE_LEFT_SEPARATOR_SOFT:=""}
POWERLINE_LEFT_LAST_SEGMENT_PROMPT_CHAR=${POWERLINE_LEFT_LAST_SEGMENT_PROMPT_CHAR:=""}

POWERLINE_COMPACT=${POWERLINE_COMPACT:=0}
POWERLINE_COMPACT_BEFORE_SEPARATOR=${POWERLINE_COMPACT_BEFORE_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_SEPARATOR=${POWERLINE_COMPACT_AFTER_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_BEFOR_FIRST_SEGMENT=${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_LAST_SEGMENT=${POWERLINE_COMPACT_AFTER_LAST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_PROMPT=${POWERLINE_COMPACT_PROMPT:=${POWERLINE_COMPACT}}

USER_INFO_SSH_CHAR=${POWERLINE_USER_INFO_SSH_CHAR:=" "}
USER_INFO_THEME_PROMPT_COLOR=${POWERLINE_USER_INFO_COLOR:=32}
USER_INFO_THEME_PROMPT_COLOR_SUDO=${POWERLINE_USER_INFO_COLOR_SUDO:=202}

PYTHON_VENV_CHAR=${POWERLINE_PYTHON_VENV_CHAR:="❲p❳ "}
CONDA_PYTHON_VENV_CHAR=${POWERLINE_CONDA_PYTHON_VENV_CHAR:="❲c❳ "}
PYTHON_VENV_THEME_PROMPT_COLOR=${POWERLINE_PYTHON_VENV_COLOR:=35}

SCM_NONE_CHAR=""
SCM_GIT_CHAR=${POWERLINE_SCM_GIT_CHAR:=" "}
SCM_HG_CHAR=${POWERLINE_SCM_HG_CHAR:="☿ "}
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_DIRTY=""
SCM_THEME_PROMPT_CLEAN_COLOR=${POWERLINE_SCM_CLEAN_COLOR:=25}
SCM_THEME_PROMPT_DIRTY_COLOR=${POWERLINE_SCM_DIRTY_COLOR:=88}
SCM_THEME_PROMPT_STAGED_COLOR=${POWERLINE_SCM_STAGED_COLOR:=30}
SCM_THEME_PROMPT_UNSTAGED_COLOR=${POWERLINE_SCM_UNSTAGED_COLOR:=92}
SCM_THEME_PROMPT_COLOR=${SCM_THEME_PROMPT_CLEAN_COLOR}

NVM_THEME_PROMPT_PREFIX=""
NVM_THEME_PROMPT_SUFFIX=""
NODE_CHAR=${POWERLINE_NODE_CHAR:="❲n❳ "}
NODE_THEME_PROMPT_COLOR=${POWERLINE_NODE_COLOR:=22}

RVM_THEME_PROMPT_PREFIX=""
RVM_THEME_PROMPT_SUFFIX=""
RBENV_THEME_PROMPT_PREFIX=""
RBENV_THEME_PROMPT_SUFFIX=""
RUBY_THEME_PROMPT_COLOR=${POWERLINE_RUBY_COLOR:=161}
RUBY_CHAR=${POWERLINE_RUBY_CHAR:="❲r❳ "}

TERRAFORM_THEME_PROMPT_COLOR=${POWERLINE_TERRAFORM_COLOR:=161}
TERRAFORM_CHAR=${POWERLINE_TERRAFORM_CHAR:="❲t❳ "}

KUBERNETES_CONTEXT_THEME_CHAR=${POWERLINE_KUBERNETES_CONTEXT_CHAR:="⎈ "}
KUBERNETES_CONTEXT_THEME_PROMPT_COLOR=${POWERLINE_KUBERNETES_CONTEXT_COLOR:=26}

AWS_PROFILE_CHAR=${POWERLINE_AWS_PROFILE_CHAR:="❲aws❳ "}
AWS_PROFILE_PROMPT_COLOR=${POWERLINE_AWS_PROFILE_COLOR:=208}

CWD_THEME_PROMPT_COLOR=${POWERLINE_CWD_COLOR:=240}

LAST_STATUS_THEME_PROMPT_COLOR=${POWERLINE_LAST_STATUS_COLOR:=52}

CLOCK_THEME_PROMPT_COLOR=${POWERLINE_CLOCK_COLOR:=240}

BATTERY_AC_CHAR=${BATTERY_AC_CHAR:="⚡"}
BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR=${POWERLINE_BATTERY_GOOD_COLOR:=70}
BATTERY_STATUS_THEME_PROMPT_LOW_COLOR=${POWERLINE_BATTERY_LOW_COLOR:=208}
BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR=${POWERLINE_BATTERY_CRITICAL_COLOR:=160}

THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:="%H:%M:%S"}

IN_VIM_THEME_PROMPT_COLOR=${POWERLINE_IN_VIM_COLOR:=245}
IN_VIM_THEME_PROMPT_TEXT=${POWERLINE_IN_VIM_TEXT:="vim"}

IN_TOOLBOX_THEME_PROMPT_COLOR=${POWERLINE_IN_TOOLBOX_COLOR:=125}
IN_TOOLBOX_THEME_PROMPT_TEXT=${POWERLINE_IN_TOOLBOX_TEXT:="⬢ "}

HOST_THEME_PROMPT_COLOR=${POWERLINE_HOST_COLOR:=0}

SHLVL_THEME_PROMPT_COLOR=${POWERLINE_SHLVL_COLOR:=${HOST_THEME_PROMPT_COLOR}}
SHLVL_THEME_PROMPT_CHAR=${POWERLINE_SHLVL_CHAR:="§"}

DIRSTACK_THEME_PROMPT_COLOR=${POWERLINE_DIRSTACK_COLOR:=${CWD_THEME_PROMPT_COLOR}}
DIRSTACK_THEME_PROMPT_CHAR=${POWERLINE_DIRSTACK_CHAR:="←"}

HISTORY_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_HISTORY_NUMBER_COLOR:=0}
HISTORY_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_HISTORY_NUMBER_CHAR:="#"}

COMMAND_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_COMMAND_NUMBER_COLOR:=0}
COMMAND_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_COMMAND_NUMBER_CHAR:="#"}

#!/usr/bin/env bash
#
# One line prompt showing the following configurable information
# for git:
# time (virtual_env) username@hostname pwd git_char|git_branch git_dirty_status|→
#
# The → arrow shows the exit status of the last command:
# - bold green: 0 exit status
# - bold red: non-zero exit status
#
# Example outside git repo:
# 07:45:05 user@host ~ →
#
# Example inside clean git repo:
# 07:45:05 user@host .bash_it ±|master|→
#
# Example inside dirty git repo:
# 07:45:05 user@host .bash_it ±|master ✗|→
#
# Example with virtual environment:
# 07:45:05 (venv) user@host ~ →
#

SCM_NONE_CHAR=''
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_PREFIX="${green}|"
SCM_THEME_PROMPT_SUFFIX="${green}|"
SCM_GIT_SHOW_MINIMAL_INFO=true

CLOCK_THEME_PROMPT_PREFIX=''
CLOCK_THEME_PROMPT_SUFFIX=' '
THEME_SHOW_CLOCK=false
THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"$bold_blue"}
THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:-"%I:%M:%S"}

THEME_SHOW_USER_HOST=true
USER_HOST_THEME_PROMPT_PREFIX="${bold_black}"
USER_HOST_THEME_PROMPT_SUFFIX=" "

VIRTUALENV_THEME_PROMPT_PREFIX='('
VIRTUALENV_THEME_PROMPT_SUFFIX=') '

function prompt_command() {
    # This needs to be first to save last command return code
    local RC="$?"

    hostname="${bold_black}\u@\h"
    virtualenv="${white}$(virtualenv_prompt)"

    # Set return status color
    if [[ ${RC} == 0 ]]; then
        ret_status="${bold_green}"
    else
        ret_status="${bold_red}"
    fi

    # Append new history lines to history file
    history -a

# shellcheck shell=bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" ${green}|"
SCM_THEME_PROMPT_SUFFIX="${green}|"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX="|"

__bobby_clock() {
	printf '%s' "$(clock_prompt) "

	if [ "${THEME_SHOW_CLOCK_CHAR}" == "true" ]; then
		printf '%s' "$(clock_char) "
	fi
}

function prompt_command() {
	PS1="\n$(battery_char) $(__bobby_clock)"
	PS1+="${yellow}$(ruby_version_prompt) "
	PS1+="${purple}\h "
	PS1+="${reset_color}in "
	PS1+="${green}\w\n"
	PS1+="${bold_cyan}$(scm_prompt_char_info) "
	PS1+="${green}→${reset_color} "
}

THEME_SHOW_CLOCK_CHAR=${THEME_SHOW_CLOCK_CHAR:-"true"}
THEME_CLOCK_CHAR_COLOR=${THEME_CLOCK_CHAR_COLOR:-"$red"}
#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${green}✓"
SCM_THEME_PROMPT_PREFIX=" ${purple}|${green} "
SCM_THEME_PROMPT_SUFFIX="${purple} |"

prompt() {
    exit_code=$?
    PS1="$(if [[ ${exit_code} = 0 ]]; then echo "${green}${exit_code}"; else echo "${red}${exit_code}"; fi) ${yellow}\t ${cyan}\w$(scm_prompt_info)${reset_color}\n${orange}$ ${reset_color}"
# shellcheck shell=bash

# Axin Bash Prompt, inspired by theme "Sexy" and "Bobby"
# thanks to them

if tput setaf 1 &> /dev/null; then
	if [[ $(tput colors) -ge 256 ]] 2> /dev/null; then
		MAGENTA=$(tput setaf 9)
		ORANGE=$(tput setaf 172)
		GREEN=$(tput setaf 190)
		PURPLE=$(tput setaf 141)
		WHITE=$(tput setaf 0)
	else
		MAGENTA=$(tput setaf 5)
		ORANGE=$(tput setaf 4)
		GREEN=$(tput setaf 2)
		PURPLE=$(tput setaf 1)
		WHITE=$(tput setaf 7)
	fi
	BOLD=$(tput bold)
	RESET=$(tput sgr0)
else
	MAGENTA="\033[1;31m"
	ORANGE="\033[1;33m"
	GREEN="\033[1;32m"
	PURPLE="\033[1;35m"
	WHITE="\033[1;37m"
	BOLD=""
	RESET="\033[m"
fi

function prompt_command() {
	PS1="\[${BOLD}${MAGENTA}\]\u \[$WHITE\]@ \[$ORANGE\]\h \[$WHITE\]in \[$GREEN\]\w\[$WHITE\]\[$SCM_THEME_PROMPT_PREFIX\]$(clock_prompt) \[$PURPLE\]$(scm_prompt_info) \n\$ \[$RESET\]"
}

# shellcheck shell=bash
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" |"
SCM_THEME_PROMPT_SUFFIX="${green}|"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

# Nicely formatted terminal prompt
function prompt_command() {
	export PS1="\n${bold_black}[${blue}\@${bold_black}]-${bold_black}[${green}\u${yellow}@${green}\h${bold_black}]-${bold_black}[${purple}\w${bold_black}]-$(scm_prompt_info)\n${reset_color}\$ "
}
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

#Mysql Prompt
export MYSQL_PS1="(\u@\h) [\d]> "

case $TERM in
        xterm*)
        TITLEBAR="\[\033]0;\w\007\]"
        ;;
        *)
        TITLEBAR=""
        ;;
esac

PS3=">> "

__my_rvm_ruby_version() {
    local gemset=$(echo $GEM_HOME | awk -F'@' '{print $2}')
  [ "$gemset" != "" ] && gemset="@$gemset"
    local version=$(echo $MY_RUBY_HOME | awk -F'-' '{print $2}')
    local full="$version$gemset"
  [ "$full" != "" ] && echo "[$full]"
}

is_vim_shell() {
        if [ ! -z "$VIMRUNTIME" ]
        then
                echo "[${cyan}vim shell${normal}]"
        fi
}

modern_scm_prompt() {
        CHAR=$(scm_char)
        if [ $CHAR = $SCM_NONE_CHAR ]
        then
                return
        else
                echo "[$(scm_char)][$(scm_prompt_info)]"
        fi
}

# show chroot if exist
chroot(){
    if [ -n "$debian_chroot" ]
    then
        my_ps_chroot="${bold_cyan}$debian_chroot${normal}";
        echo "($my_ps_chroot)";
    fi
    }

# show virtualenvwrapper
my_ve(){

    if [ -n "$CONDA_DEFAULT_ENV" ]
    then
        my_ps_ve="${bold_purple}${CONDA_DEFAULT_ENV}${normal}";
        echo "($my_ps_ve)";
    elif [ -n "$VIRTUAL_ENV" ]
    then
        my_ps_ve="${bold_purple}$ve${normal}";
        echo "($my_ps_ve)";
    fi
    echo "";
    }

prompt() {

    my_ps_host="${green}\h${normal}";
    # yes, these are the the same for now ...
    my_ps_host_root="${green}\h${normal}";

    my_ps_user="${bold_green}\u${normal}"
    my_ps_root="${bold_red}\u${normal}";

    if [ -n "$VIRTUAL_ENV" ]
    then
        ve=`basename "$VIRTUAL_ENV"`;
    fi

    # nice prompt
    case "`id -u`" in
        0) PS1="${TITLEBAR}┌─$(my_ve)$(chroot)[$my_ps_root][$my_ps_host_root]$(modern_scm_prompt)$(__my_rvm_ruby_version)[${cyan}\w${normal}]
▪ "
        ;;
        *) PS1="${TITLEBAR}┌─$(my_ve)$(chroot)[$my_ps_user][$my_ps_host]$(modern_scm_prompt)$(__my_rvm_ruby_version)
|─[${bold_purple}\w${normal}]
▪ "
        ;;
    esac
}

PS2="▪ "

# vi mode
set -o vi
bind 'set vi-ins-mode-string "└+"'
bind 'set vi-cmd-mode-string "└─"'
bind 'set show-mode-in-prompt on'
# This is combination of works from two different people which I combined for my requirement.
# Original PS1 was from reddit user /u/Allevil669 which I found in thread: https://www.reddit.com/r/linux/comments/1z33lj/linux_users_whats_your_favourite_bash_prompt/
# I used that PS1 to the bash-it theme 'morris', and customized it to my liking. All credits to /u/Allevil669 and morris.
#
# prompt theming

# added TITLEBAR for updating the tab and window titles with the pwd
case $TERM in
	xterm*)
		TITLEBAR=$(printf "\033]0;%s@%s:%s\007" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/~}")
		;;
	screen)
		TITLEBAR=$(printf "\033]0;%s@%s:%s\033\\" "${USER}" "${HOSTNAME%%.*}" "${PWD/#$HOME/~}")
		;;
	*)
		TITLEBAR=""
		;;
esac
if [ "$?" == "0" ]
then
		SC="${green}^_^";
else
		SC="${red}T_T";
fi
BC=`battery_percentage`
function prompt_command() {
	#PS1="${TITLEBAR}[\u@\h \W $(scm_prompt_info)]\$ "
	PS1="\n${cyan}┌─${bold_white}[\u@\h]${cyan}─${bold_yellow}(\w)$(scm_prompt_info)\n${cyan}└─${bold_green}[\A]-${green}($BC%)${bold_cyan}-[${green}${bold_green}\$${bold_cyan}]${green} "
}

# scm theming
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX="${bold_cyan}("
SCM_THEME_PROMPT_SUFFIX="${bold_cyan})${reset_color}"
# shellcheck shell=bash

# Theme custom glyphs
SCM_GIT_CHAR_GITLAB=${BARBUK_GITLAB_CHAR:='  '}
SCM_GIT_CHAR_BITBUCKET=${BARBUK_BITBUCKET_CHAR:='  '}
SCM_GIT_CHAR_GITHUB=${BARBUK_GITHUB_CHAR:='  '}
SCM_GIT_CHAR_DEFAULT=${BARBUK_GIT_DEFAULT_CHAR:='  '}
SCM_GIT_CHAR_ICON_BRANCH=${BARBUK_GIT_BRANCH_ICON:=''}
SCM_HG_CHAR=${BARBUK_HG_CHAR:='☿ '}
SCM_SVN_CHAR=${BARBUK_SVN_CHAR:='⑆ '}
EXIT_CODE_ICON=${BARBUK_EXIT_CODE_ICON:=' '}
PYTHON_VENV_CHAR=${BARBUK_PYTHON_VENV_CHAR:=' '}
COMMAND_DURATION_ICON=${BARBUK_COMMAND_DURATION_ICON:-"$bold_blue  "}

# Command duration
COMMAND_DURATION_MIN_SECONDS=${COMMAND_DURATION_MIN_SECONDS:-1}
COMMAND_DURATION_COLOR="$normal"

# Ssh user and hostname display
SSH_INFO=${BARBUK_SSH_INFO:=true}
HOST_INFO=${BARBUK_HOST_INFO:=long}

# Bash-it default glyphs customization
SCM_NONE_CHAR=
SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX="|"
SCM_THEME_PROMPT_SUFFIX="${green}| "
SCM_GIT_BEHIND_CHAR="${bold_red}↓${normal}"
SCM_GIT_AHEAD_CHAR="${bold_green}↑${normal}"
SCM_GIT_UNTRACKED_CHAR="⌀"
SCM_GIT_UNSTAGED_CHAR="${bold_yellow}•${normal}"
SCM_GIT_STAGED_CHAR="${bold_green}+${normal}"
GIT_THEME_PROMPT_DIRTY=" ${bold_red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX="${cyan}"
GIT_THEME_PROMPT_SUFFIX="${cyan}"
SCM_THEME_BRANCH_TRACK_PREFIX="${normal} ⤏  ${cyan}"
SCM_THEME_CURRENT_USER_PREFFIX='  '
SCM_GIT_SHOW_CURRENT_USER=false

function _git-uptream-remote-logo {
	[[ "$(_git-upstream)" == "" ]] && SCM_GIT_CHAR="$SCM_GIT_CHAR_DEFAULT"

	local remote remote_domain
	remote=$(_git-upstream-remote)
	remote_domain=$(git config --get remote."$remote".url | awk -F'[@:.]' '{print $2}')

	# remove // suffix for https:// url
	remote_domain=${remote_domain//\//}

	case $remote_domain in
		github) SCM_GIT_CHAR="$SCM_GIT_CHAR_GITHUB" ;;
		gitlab) SCM_GIT_CHAR="$SCM_GIT_CHAR_GITLAB" ;;
		bitbucket) SCM_GIT_CHAR="$SCM_GIT_CHAR_BITBUCKET" ;;
		*) SCM_GIT_CHAR="$SCM_GIT_CHAR_DEFAULT" ;;
	esac
}

function git_prompt_info {
	git_prompt_vars
	echo -e " on $SCM_GIT_CHAR_ICON_BRANCH $SCM_PREFIX$SCM_BRANCH$SCM_STATE$SCM_GIT_AHEAD$SCM_GIT_BEHIND$SCM_GIT_STASH$SCM_SUFFIX"
}

function _exit-code {
	if [[ "$1" -ne 0 ]]; then
		exit_code=" ${purple}${EXIT_CODE_ICON}${yellow}${exit_code}${bold_orange}"
	else
		exit_code="${bold_green}"
	fi
}

function _prompt {
	local exit_code="$?" wrap_char=' ' dir_color=$green ssh_info='' python_venv='' host command_duration=

	command_duration=$(_command_duration)

	_exit-code exit_code
	_git-uptream-remote-logo

	history -a

	# Detect root shell
	if [ "$(whoami)" = root ]; then
		dir_color=$red
	fi

	# Detect ssh
	if [[ -n "${SSH_CONNECTION}" ]] && [ "$SSH_INFO" = true ]; then
		if [ "$HOST_INFO" = long ]; then
			host="\H"
		else
			host="\h"
		fi
		ssh_info="${bold_blue}\u${bold_orange}@${cyan}$host ${bold_orange}in"
	fi

	# Detect python venv
	if [[ -n "${CONDA_DEFAULT_ENV}" ]]; then
		python_venv="$PYTHON_VENV_CHAR${CONDA_DEFAULT_ENV} "
	elif [[ -n "${VIRTUAL_ENV}" ]]; then
		python_venv="$PYTHON_VENV_CHAR$(basename "${VIRTUAL_ENV}") "
	fi

	PS1="\\n${ssh_info} ${purple}$(scm_char)${python_venv}${dir_color}\\w${normal}$(scm_prompt_info)${command_duration}${exit_code}"
# git theming
SCM_THEME_PROMPT_PREFIX="${bold_blue}(${yellow}"
SCM_THEME_PROMPT_SUFFIX="${bold_blue})${reset_color} "
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_DIRTY="${bold_red}✗"


# LS colors, made with http://geoff.greer.fm/lscolors/
export LSCOLORS="Gxfxcxdxbxegedabagacad"
export LS_COLORS='no=00:fi=00:di=01;34:ln=00;36:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=41;33;01:ex=00;32:*.cmd=00;32:*.exe=01;32:*.com=01;32:*.bat=01;32:*.btm=01;32:*.dll=01;32:*.tar=00;31:*.tbz=00;31:*.tgz=00;31:*.rpm=00;31:*.deb=00;31:*.arj=00;31:*.taz=00;31:*.lzh=00;31:*.lzma=00;31:*.zip=00;31:*.zoo=00;31:*.z=00;31:*.Z=00;31:*.gz=00;31:*.bz2=00;31:*.tb2=00;31:*.tz2=00;31:*.tbz2=00;31:*.avi=01;35:*.bmp=01;35:*.fli=01;35:*.gif=01;35:*.jpg=01;35:*.jpeg=01;35:*.mng=01;35:*.mov=01;35:*.mpg=01;35:*.pcx=01;35:*.pbm=01;35:*.pgm=01;35:*.png=01;35:*.ppm=01;35:*.tga=01;35:*.tif=01;35:*.xbm=01;35:*.xpm=01;35:*.dl=01;35:*.gl=01;35:*.wmv=01;35:*.aiff=00;32:*.au=00;32:*.mid=00;32:*.mp3=00;32:*.ogg=00;32:*.voc=00;32:*.wav=00;32:'

function prompt_command() {

    if [ "$(whoami)" = root ]; then no_color=$red; else no_color=$white; fi

#!/usr/bin/env bash

# Two line prompt showing the following information:
# (time) SCM [username@hostname] pwd (SCM branch SCM status)
# →
#
# Example:
# (14:00:26) ± [foo@bar] ~/.bash_it (master ✓)
# →
#
# The arrow on the second line is showing the exit status of the last command:
# * Green: 0 exit status
# * Red: non-zero exit status
#
# The exit code functionality currently doesn't work if you are using the 'fasd' plugin,
# since 'fasd' is messing with the $PROMPT_COMMAND


PROMPT_END_CLEAN="${green}→${reset_color}"
PROMPT_END_DIRTY="${red}→${reset_color}"

function prompt_end() {
  echo -e "$PROMPT_END"
}

prompt_setter() {
  local exit_status=$?
  if [[ $exit_status -eq 0 ]]; then PROMPT_END=$PROMPT_END_CLEAN
    else PROMPT_END=$PROMPT_END_DIRTY
  fi
  # Save history
  history -a
  history -c
  history -r
  PS1="($(clock_prompt)) $(scm_char) [${blue}\u${reset_color}@${green}\H${reset_color}] ${yellow}\w${reset_color}$(scm_prompt_info) ${reset_color}\n$(prompt_end) "
  PS2='> '
  PS4='+ '
}

safe_append_prompt_command prompt_setter

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_THEME_PROMPT_PREFIX=" ("
SCM_THEME_PROMPT_SUFFIX=")"
#!/usr/bin/env bash

function set_prompt_symbol () {
    if test $1 -eq 0 ; then
	PROMPT_SYMBOL=">_"
    else
	PROMPT_SYMBOL="${orange}>_${normal}"
    fi
}
function prompt_command() {
    set_prompt_symbol $?
    if test -z "$VIRTUAL_ENV" ; then
	PYTHON_VIRTUALENV=""
    else
	PYTHON_VIRTUALENV="${bold_yellow}[`basename \"$VIRTUAL_ENV\"`]"
    fi

    PS1="${bold_orange}${PYTHON_VIRTUALENV}${reset_color}${bold_green}[\w]${bold_blue}\[$(scm_prompt_info)\]${normal} \n${PROMPT_SYMBOL} "
}

# scm themeing
SCM_THEME_PROMPT_DIRTY=" ✗"
SCM_THEME_PROMPT_CLEAN=" ✓"
SCM_THEME_PROMPT_PREFIX="["
SCM_THEME_PROMPT_SUFFIX="]"
. "$BASH_IT/themes/powerline/powerline.base.bash"

function __powerline_left_segment {
  local OLD_IFS="${IFS}"; IFS="|"
  local params=( $1 )
  IFS="${OLD_IFS}"
  local separator=""
  local pad_before_segment=" "

  if [[ "${SEGMENTS_AT_LEFT}" -eq 0 ]]; then
    if [[ "${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT}" -ne 0 ]]; then
      pad_before_segment=""
    fi
  else
    if [[ "${POWERLINE_COMPACT_AFTER_SEPARATOR}" -ne 0 ]]; then
      pad_before_segment=""
    fi
    # Since the previous segment wasn't the last segment, add padding, if needed
    #
    if [[ "${POWERLINE_COMPACT_BEFORE_SEPARATOR}" -eq 0 ]]; then
      LEFT_PROMPT+=" "
    fi
    LEFT_PROMPT+="${POWERLINE_LEFT_SEPARATOR}"
  fi

  LEFT_PROMPT+="$(set_color ${params[1]} -)${pad_before_segment}${params[0]}${normal}"
  LAST_SEGMENT_COLOR=${params[1]}
  (( SEGMENTS_AT_LEFT += 1 ))
}

#!/usr/bin/env bash

. "$BASH_IT/themes/powerline-naked/powerline-naked.base.bash"

PROMPT_CHAR=${POWERLINE_PROMPT_CHAR:=""}
POWERLINE_LEFT_SEPARATOR=${POWERLINE_LEFT_SEPARATOR:=""}
POWERLINE_LEFT_LAST_SEGMENT_PROMPT_CHAR=""

POWERLINE_COMPACT=${POWERLINE_COMPACT:=0}
POWERLINE_COMPACT_BEFORE_SEPARATOR=${POWERLINE_COMPACT_BEFORE_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_SEPARATOR=${POWERLINE_COMPACT_AFTER_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_BEFOR_FIRST_SEGMENT=${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_LAST_SEGMENT=${POWERLINE_COMPACT_AFTER_LAST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_PROMPT=${POWERLINE_COMPACT_PROMPT:=${POWERLINE_COMPACT}}

USER_INFO_SSH_CHAR=${POWERLINE_USER_INFO_SSH_CHAR:=" "}
USER_INFO_THEME_PROMPT_COLOR=${POWERLINE_USER_INFO_COLOR:=240}
USER_INFO_THEME_PROMPT_COLOR_SUDO=${POWERLINE_USER_INFO_COLOR_SUDO:=202}

PYTHON_VENV_CHAR=${POWERLINE_PYTHON_VENV_CHAR:="❲p❳ "}
CONDA_PYTHON_VENV_CHAR=${POWERLINE_CONDA_PYTHON_VENV_CHAR:="❲c❳ "}
PYTHON_VENV_THEME_PROMPT_COLOR=${POWERLINE_PYTHON_VENV_COLOR:=35}

SCM_NONE_CHAR=""
SCM_GIT_CHAR=${POWERLINE_SCM_GIT_CHAR:=" "}
SCM_HG_CHAR=${POWERLINE_SCM_HG_CHAR:="☿ "}
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_DIRTY=""
SCM_THEME_PROMPT_CLEAN_COLOR=${POWERLINE_SCM_CLEAN_COLOR:=25}
SCM_THEME_PROMPT_DIRTY_COLOR=${POWERLINE_SCM_DIRTY_COLOR:=88}
SCM_THEME_PROMPT_STAGED_COLOR=${POWERLINE_SCM_STAGED_COLOR:=30}
SCM_THEME_PROMPT_UNSTAGED_COLOR=${POWERLINE_SCM_UNSTAGED_COLOR:=92}
SCM_THEME_PROMPT_COLOR=${SCM_THEME_PROMPT_CLEAN_COLOR}

NVM_THEME_PROMPT_PREFIX=""
NVM_THEME_PROMPT_SUFFIX=""
NODE_CHAR=${POWERLINE_NODE_CHAR:="❲n❳ "}
NODE_THEME_PROMPT_COLOR=${POWERLINE_NODE_COLOR:=22}

RVM_THEME_PROMPT_PREFIX=""
RVM_THEME_PROMPT_SUFFIX=""
RBENV_THEME_PROMPT_PREFIX=""
RBENV_THEME_PROMPT_SUFFIX=""
RUBY_THEME_PROMPT_COLOR=${POWERLINE_RUBY_COLOR:=161}
RUBY_CHAR=${POWERLINE_RUBY_CHAR:="❲r❳ "}

TERRAFORM_THEME_PROMPT_COLOR=${POWERLINE_TERRAFORM_COLOR:=161}
TERRAFORM_CHAR=${POWERLINE_TERRAFORM_CHAR:="❲t❳ "}

KUBERNETES_CONTEXT_THEME_CHAR=${POWERLINE_KUBERNETES_CONTEXT_CHAR:="⎈ "}
KUBERNETES_CONTEXT_THEME_PROMPT_COLOR=${POWERLINE_KUBERNETES_CONTEXT_COLOR:=26}

AWS_PROFILE_CHAR=${POWERLINE_AWS_PROFILE_CHAR:="❲aws❳ "}
AWS_PROFILE_PROMPT_COLOR=${POWERLINE_AWS_PROFILE_COLOR:=208}

CWD_THEME_PROMPT_COLOR=${POWERLINE_CWD_COLOR:=254}

LAST_STATUS_THEME_PROMPT_COLOR=${POWERLINE_LAST_STATUS_COLOR:=124}

CLOCK_THEME_PROMPT_COLOR=${POWERLINE_CLOCK_COLOR:=240}

BATTERY_AC_CHAR=${BATTERY_AC_CHAR:="⚡"}
BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR=${POWERLINE_BATTERY_GOOD_COLOR:=70}
BATTERY_STATUS_THEME_PROMPT_LOW_COLOR=${POWERLINE_BATTERY_LOW_COLOR:=208}
BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR=${POWERLINE_BATTERY_CRITICAL_COLOR:=160}

THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:="%H:%M:%S"}

IN_VIM_THEME_PROMPT_COLOR=${POWERLINE_IN_VIM_COLOR:=245}
IN_VIM_THEME_PROMPT_TEXT=${POWERLINE_IN_VIM_TEXT:="vim"}

IN_TOOLBOX_THEME_PROMPT_COLOR=${POWERLINE_IN_TOOLBOX_COLOR:=125}
IN_TOOLBOX_THEME_PROMPT_TEXT=${POWERLINE_IN_TOOLBOX_TEXT:="⬢ "}

HOST_THEME_PROMPT_COLOR=${POWERLINE_HOST_COLOR:=254}

SHLVL_THEME_PROMPT_COLOR=${POWERLINE_SHLVL_COLOR:=${HOST_THEME_PROMPT_COLOR}}
SHLVL_THEME_PROMPT_CHAR=${POWERLINE_SHLVL_CHAR:="§"}

DIRSTACK_THEME_PROMPT_COLOR=${POWERLINE_DIRSTACK_COLOR:=${CWD_THEME_PROMPT_COLOR}}
DIRSTACK_THEME_PROMPT_CHAR=${POWERLINE_DIRSTACK_CHAR:="←"}

HISTORY_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_HISTORY_NUMBER_COLOR:=254}
HISTORY_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_HISTORY_NUMBER_CHAR:="#"}

COMMAND_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_COMMAND_NUMBER_COLOR:=254}
COMMAND_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_COMMAND_NUMBER_CHAR:="#"}

POWERLINE_PROMPT=${POWERLINE_PROMPT:="user_info scm python_venv ruby node cwd"}

#!/usr/bin/env bash

function _p4-opened {
  timeout 2.0s p4 opened -s 2> /dev/null
}

function _p4-opened-counts {
  # Return the following counts seperated by tabs:
  #  - count of opened files
  #  - count of pending changesets (other than defaults)
  #  - count of files in the default changeset
  #  - count of opened files in add mode
  #  - count of opened files in edit mode
  #  - count of opened files in delete mode
  _p4-opened | awk '
  BEGIN {
    opened=0;
    type_array["edit"]=0;
    type_array["add"]=0;
    type_array["delete"]=0;
    change_array["change"]=0;
  }
  {
    # p4 opened prints one file per line, and all lines begin with "//"
    # Here is an examples:
    #
    #   $ p4 opened
    #   //depot/some/file.py#4 - edit change 716431 (text)
    #   //depot/another/file.py - edit default change (text)
    #   //now/add/a/newfile.sh -  add change 435645 (text+k)
    #
    #
    if ($1 ~ /^\/\//) {
        opened += 1
        change_array[$5] += 1
        type_array[$3] += 1
    }
  }
  END {
    default_changes=change_array["change"];
# shellcheck shell=bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" |"
SCM_THEME_PROMPT_SUFFIX="${green}|"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX="|"

function prompt_command() {
	#PS1="${bold_cyan}$(scm_char)${green}$(scm_prompt_info)${purple}$(ruby_version_prompt) ${yellow}\h ${reset_color}in ${green}\w ${reset_color}\n${green}→${reset_color} "
	#PS1="\n${purple}\h: ${reset_color} ${green}\w\n${bold_cyan}$(scm_char)${green}$(scm_prompt_info) ${green}→${reset_color} "
	#PS1="\n${cyan}\h: ${reset_color} ${yellow}\w\n${red}$(scm_char)${red}$(scm_prompt_info) ${green}→${reset_color} "
	PS1="\n${cyan}\h:$(virtualenv_prompt) ${reset_color} ${yellow}\w ${green}$(scm_prompt_info)\n${reset_color}→ "
#!/usr/bin/env bash
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" |"
SCM_THEME_PROMPT_SUFFIX="${green}|"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX="|"

function prompt_command() {
    if [ $? -eq 0 ]; then
      status=❤️
    else
      status=💔
    fi
    PS1="\n${yellow}$(ruby_version_prompt) ${purple}\h ${reset_color}in ${green}\w $status \n${bold_cyan} ${blue}|$(clock_prompt)|${green}$(scm_prompt_info) ${green}→${reset_color} "
}

THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"$blue"}

# ------------------------------------------------------------------#
#          FILE: mbriggs.zsh-theme                                  #
#            BY: Matt Briggs (matt@mattbriggs.net)                  #
#      BASED ON: smt by Stephen Tudor (stephen@tudorstudio.com)     #
# ------------------------------------------------------------------#

SCM_THEME_PROMPT_DIRTY="${red}⚡${reset_color}"
SCM_THEME_PROMPT_AHEAD="${red}!${reset_color}"
SCM_THEME_PROMPT_CLEAN="${green}✓${reset_color}"
SCM_THEME_PROMPT_PREFIX=" "
SCM_THEME_PROMPT_SUFFIX=""
GIT_SHA_PREFIX=" ${yellow}"
GIT_SHA_SUFFIX="${reset_color}"

function git_short_sha() {
  SHA=$(git rev-parse --short HEAD 2> /dev/null) && echo "$GIT_SHA_PREFIX$SHA$GIT_SHA_SUFFIX"
}

function prompt() {
    local return_status=""
    local ruby="${red}$(ruby_version_prompt)${reset_color}"
    local user_host="${green}\h${reset_color}"
    local current_path="\w"
    local n_commands="\!"
    local git_branch="$(git_short_sha)$(scm_prompt_info)"
    local prompt_symbol='λ'
    local open='('
    local close=')'
    local prompt_char=' \$ '

# shellcheck shell=bash

# Atomic Bash Prompt for Bash-it
# By lfelipe base on the theme brainy of MunifTanjim

############
## Colors ##
############
IRed="\e[1;49;31m"
IGreen="\e[1;49;32m"
IYellow="\e[1;49;33m"
IWhite="\e[1;49;37m"
BIWhite="\e[1;49;37m"
BICyan="\e[1;49;36m"

#############
## Symbols ##
#############
Line="\342\224\200"
LineA="\342\224\214\342\224\200"
SX="\342\234\227"
LineB="\342\224\224\342\224\200\342\224\200"
Circle="\342\227\217"
Face="\342\230\273"

#############
## Parsers ##
#############

____atomic_top_left_parse() {
	ifs_old="${IFS}"
	IFS="|"
	read -r -a args <<< "$@"
	IFS="${ifs_old}"
	if [ -n "${args[3]}" ]; then
		_TOP_LEFT+="${args[2]}${args[3]}"
	fi
	_TOP_LEFT+="${args[0]}${args[1]}"
	if [ -n "${args[4]}" ]; then
		_TOP_LEFT+="${args[2]}${args[4]}"
	fi
	_TOP_LEFT+=""
}

____atomic_top_right_parse() {
	ifs_old="${IFS}"
	IFS="|"
	read -r -a args <<< "$@"
	IFS="${ifs_old}"
	_TOP_RIGHT+=" "
	if [ -n "${args[3]}" ]; then
		_TOP_RIGHT+="${args[2]}${args[3]}"
	fi
	_TOP_RIGHT+="${args[0]}${args[1]}"
	if [ -n "${args[4]}" ]; then
		_TOP_RIGHT+="${args[2]}${args[4]}"
	fi
	__TOP_RIGHT_LEN=$((__TOP_RIGHT_LEN + ${#args[1]} + ${#args[3]} + ${#args[4]} + 1))
	((__SEG_AT_RIGHT += 1))
}

____atomic_bottom_parse() {
	ifs_old="${IFS}"
	IFS="|"
	read -r -a args <<< "$@"
	IFS="${ifs_old}"
	_BOTTOM+="${args[0]}${args[1]}"
	[ ${#args[1]} -gt 0 ] && _BOTTOM+=" "
}

____atomic_top() {
	_TOP_LEFT=""
	_TOP_RIGHT=""
	__TOP_RIGHT_LEN=0
	__SEG_AT_RIGHT=0

	for seg in ${___ATOMIC_TOP_LEFT}; do
		info="$(___atomic_prompt_"${seg}")"
		[ -n "${info}" ] && ____atomic_top_left_parse "${info}"
	done

	___cursor_right="\e[500C"
	_TOP_LEFT+="${___cursor_right}"

	for seg in ${___ATOMIC_TOP_RIGHT}; do
		info="$(___atomic_prompt_"${seg}")"
		[ -n "${info}" ] && ____atomic_top_right_parse "${info}"
	done

	[ $__TOP_RIGHT_LEN -gt 0 ] && __TOP_RIGHT_LEN=$((__TOP_RIGHT_LEN - 0))
	___cursor_adjust="\e[${__TOP_RIGHT_LEN}D"
	_TOP_LEFT+="${___cursor_adjust}"

	printf "%s%s" "${_TOP_LEFT}" "${_TOP_RIGHT}"
}

____atomic_bottom() {
	_BOTTOM=""
	for seg in $___ATOMIC_BOTTOM; do
		info="$(___atomic_prompt_"${seg}")"
		[ -n "${info}" ] && ____atomic_bottom_parse "${info}"
	done
	printf "\n%s" "${_BOTTOM}"
}

##############
## Segments ##
##############

___atomic_prompt_user_info() {
	color=$white
	box="${normal}${LineA}\$([[ \$? != 0 ]] && echo \"${BIWhite}[${IRed}${SX}${BIWhite}]${normal}${Line}\")${Line}${BIWhite}[|${BIWhite}]${normal}${Line}"
	info="${IYellow}\u${IRed}@${IGreen}\h"

	printf "%s|%s|%s|%s" "${color}" "${info}" "${white}" "${box}"
}

___atomic_prompt_dir() {
	color=${IRed}
	box="[|]${normal}"
	info="\w"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
}

___atomic_prompt_scm() {
	[ "${THEME_SHOW_SCM}" != "true" ] && return
	color=$bold_green
	box="${Line}[${IWhite}$(scm_char)] "
	info="$(scm_prompt_info)"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
}

___atomic_prompt_python() {
	[ "${THEME_SHOW_PYTHON}" != "true" ] && return
	color=$bold_yellow
	box="[|]"
	info="$(python_version_prompt)"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_blue}" "${box}"
}

___atomic_prompt_ruby() {
	[ "${THEME_SHOW_RUBY}" != "true" ] && return
	color=$bold_white
	box="[|]"
	info="rb-$(ruby_version_prompt)"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_red}" "${box}"
}

___atomic_prompt_todo() {
	[ "${THEME_SHOW_TODO}" != "true" ] \
		|| [ -z "$(which todo.sh)" ] && return
	color=$bold_white
	box="[|]"
	info="t:$(todo.sh ls | grep -E "TODO: [0-9]+ of ([0-9]+)" | awk '{ print $4 }')"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_green}" "${box}"
}

___atomic_prompt_clock() {
	[ "${THEME_SHOW_CLOCK}" != "true" ] && return
	color=$THEME_CLOCK_COLOR
	box="[|]"
	info="$(date +"${THEME_CLOCK_FORMAT}")"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
}

___atomic_prompt_battery() {
	! _command_exists battery_percentage \
		|| [ "${THEME_SHOW_BATTERY}" != "true" ] \
		|| [ "$(battery_percentage)" = "no" ] && return

	batp=$(battery_percentage)
	if [ "$batp" -eq 50 ] || [ "$batp" -gt 50 ]; then
		color=$bold_green
	elif [ "$batp" -lt 50 ] && [ "$batp" -gt 25 ]; then
		color=$bold_yellow
	elif [ "$batp" -eq 25 ] || [ "$batp" -lt 25 ]; then
		color=$IRed
	fi
	box="[|]"
	ac_adapter_connected && info="+"
	ac_adapter_disconnected && info="-"
	info+=$batp
	[ "$batp" -eq 100 ] || [ "$batp" -gt 100 ] && info="AC"
	printf "%s|%s|%s|%s" "${color}" "${info}" "${bold_white}" "${box}"
}

___atomic_prompt_exitcode() {
	[ "${THEME_SHOW_EXITCODE}" != "true" ] && return
	color=$bold_purple
	[ "$exitcode" -ne 0 ] && printf "%s|%s" "${color}" "${exitcode}"
}

___atomic_prompt_char() {
	color=$white
	prompt_char="${__ATOMIC_PROMPT_CHAR_PS1}"
	if [ "${THEME_SHOW_SUDO}" == "true" ]; then
		if sudo -vn 1> /dev/null 2>&1; then
			prompt_char="${__ATOMIC_PROMPT_CHAR_PS1_SUDO}"
		fi
	fi
	printf "%s|%s" "${color}" "${prompt_char}"
}

#########
## cli ##
#########

__atomic_show() {
	typeset _seg=${1:-}
	shift
	export "THEME_SHOW_${_seg}"=true
}

__atomic_hide() {
	typeset _seg=${1:-}
	shift
	export "THEME_SHOW_${_seg}"=false
}

_atomic_completion() {
	local cur _action actions segments
	COMPREPLY=()
	cur="${COMP_WORDS[COMP_CWORD]}"
	_action="${COMP_WORDS[1]}"
	actions="show hide"
	segments="battery clock exitcode python ruby scm sudo todo"
	case "${_action}" in
		show | hide)
			# shellcheck disable=SC2207
			COMPREPLY=($(compgen -W "${segments}" -- "${cur}"))
			return 0
			;;
	esac

	# shellcheck disable=SC2207
	COMPREPLY=($(compgen -W "${actions}" -- "${cur}"))
	return 0
}

atomic() {
	typeset action=${1:-}
	shift
	typeset segs=${*:-}
	typeset func
	case $action in
		show)
			func=__atomic_show
			;;
		hide)
			func=__atomic_hide
			;;
	esac
	for seg in ${segs}; do
		seg=$(printf "%s" "${seg}" | tr '[:lower:]' '[:upper:]')
		$func "${seg}"
	done
}

complete -F _atomic_completion atomic

###############
## Variables ##
###############

export SCM_THEME_PROMPT_PREFIX=""
export SCM_THEME_PROMPT_SUFFIX=""

export RBENV_THEME_PROMPT_PREFIX=""
export RBENV_THEME_PROMPT_SUFFIX=""
export RBFU_THEME_PROMPT_PREFIX=""
export RBFU_THEME_PROMPT_SUFFIX=""
export RVM_THEME_PROMPT_PREFIX=""
export RVM_THEME_PROMPT_SUFFIX=""

export SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
export SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"

THEME_SHOW_SUDO=${THEME_SHOW_SUDO:-"true"}
THEME_SHOW_SCM=${THEME_SHOW_SCM:-"true"}
THEME_SHOW_RUBY=${THEME_SHOW_RUBY:-"false"}
THEME_SHOW_PYTHON=${THEME_SHOW_PYTHON:-"false"}
THEME_SHOW_CLOCK=${THEME_SHOW_CLOCK:-"true"}
THEME_SHOW_TODO=${THEME_SHOW_TODO:-"false"}
THEME_SHOW_BATTERY=${THEME_SHOW_BATTERY:-"true"}
THEME_SHOW_EXITCODE=${THEME_SHOW_EXITCODE:-"false"}

THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"${BICyan}"}
THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:-"%a %b %d - %H:%M"}

__ATOMIC_PROMPT_CHAR_PS1=${THEME_PROMPT_CHAR_PS1:-"${normal}${LineB}${bold_white}${Circle}"}
__ATOMIC_PROMPT_CHAR_PS2=${THEME_PROMPT_CHAR_PS2:-"${normal}${LineB}${bold_white}${Circle}"}

__ATOMIC_PROMPT_CHAR_PS1_SUDO=${THEME_PROMPT_CHAR_PS1_SUDO:-"${normal}${LineB}${bold_red}${Face}"}
__ATOMIC_PROMPT_CHAR_PS2_SUDO=${THEME_PROMPT_CHAR_PS2_SUDO:-"${normal}${LineB}${bold_red}${Face}"}

___ATOMIC_TOP_LEFT=${___ATOMIC_TOP_LEFT:-"user_info dir scm"}
___ATOMIC_TOP_RIGHT=${___ATOMIC_TOP_RIGHT:-"exitcode python ruby todo clock battery"}
___ATOMIC_BOTTOM=${___ATOMIC_BOTTOM:-"char"}

############
## Prompt ##
############

__atomic_ps1() {
	printf "%s%s%s" "$(____atomic_top)" "$(____atomic_bottom)" "${normal}"
}

__atomic_ps2() {
	color=$bold_white
	printf "%s%s%s" "${color}" "${__ATOMIC_PROMPT_CHAR_PS2}  " "${normal}"
}

_atomic_prompt() {
	exitcode="$?"

#!/usr/bin/env bash

SCM_THEME_PROMPT_PREFIX="${cyan} on ${green}"
SCM_THEME_PROMPT_SUFFIX=""
SCM_THEME_PROMPT_DIRTY=" ${red}with changes"
SCM_THEME_PROMPT_CLEAN=""

venv() {
  if [ ! -z "$VIRTUAL_ENV" ]
  then
    local env=$VIRTUAL_ENV
    echo "${gray} in ${orange}${env##*/} "
  fi
}

last_two_dirs() {
  pwd|rev|awk -F / '{print $1,$2}'|rev|sed s_\ _/_|sed "s|$(sed 's,\/,,'<<<$HOME)|~|g"
}

prompt() {
#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=''
SCM_THEME_PROMPT_CLEAN=''
SCM_GIT_CHAR="${bold_cyan}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""
if [ ! -z $RVM_THEME_PROMPT_COLOR ]; then
    RVM_THEME_PROMPT_COLOR=$(eval echo $`echo ${RVM_THEME_PROMPT_COLOR}`);
else
    RVM_THEME_PROMPT_COLOR="${red}"
fi
RVM_THEME_PROMPT_PREFIX="(${RVM_THEME_PROMPT_COLOR}rb${normal}: "
RVM_THEME_PROMPT_SUFFIX=") "
if [ ! -z $VIRTUALENV_THEME_PROMPT_COLOR ]; then
    VIRTUALENV_THEME_PROMPT_COLOR=$(eval echo $`echo ${VIRTUALENV_THEME_PROMPT_COLOR}`);
else
    VIRTUALENV_THEME_PROMPT_COLOR="${green}"
fi
VIRTUALENV_THEME_PROMPT_PREFIX="(${VIRTUALENV_THEME_PROMPT_COLOR}py${normal}: "
VIRTUALENV_THEME_PROMPT_SUFFIX=") "

if [ ! -z $THEME_PROMPT_HOST_COLOR ]; then
    THEME_PROMPT_HOST_COLOR=$(eval echo $`echo ${THEME_PROMPT_HOST_COLOR}`);
else
    THEME_PROMPT_HOST_COLOR="$blue"
fi

doubletime_scm_prompt() {
  CHAR=$(scm_char)
  if [ $CHAR = $SCM_NONE_CHAR ]; then
    return
  elif [ $CHAR = $SCM_GIT_CHAR ]; then
    echo "$(git_prompt_status)"
  else
    echo "[$(scm_prompt_info)]"
  fi
}

function prompt_setter() {
  # Save history
  history -a
  history -c
  history -r
  PS1="
$(clock_prompt) $(scm_char) [${THEME_PROMPT_HOST_COLOR}\u@${THEME_PROMPT_HOST}$reset_color] $(virtualenv_prompt)$(ruby_version_prompt)\w
$(doubletime_scm_prompt)$reset_color $ "
  PS2='> '
  PS4='+ '
}

safe_append_prompt_command prompt_setter

git_prompt_status() {
  local git_status_output
  git_status_output=$(git status 2> /dev/null )
  if [ -n "$(echo $git_status_output | grep 'Changes not staged')" ]; then
    git_status="${bold_red}$(scm_prompt_info) ✗"
  elif [ -n "$(echo $git_status_output | grep 'Changes to be committed')" ]; then
     git_status="${bold_yellow}$(scm_prompt_info) ^"
  elif [ -n "$(echo $git_status_output | grep 'Untracked files')" ]; then
     git_status="${bold_cyan}$(scm_prompt_info) +"
  elif [ -n "$(echo $git_status_output | grep 'nothing to commit')" ]; then
     git_status="${bold_green}$(scm_prompt_info) ${green}✓"
  else
    git_status="$(scm_prompt_info)"
  fi
  echo "[$git_status${normal}]"
# scm themeing
SCM_THEME_PROMPT_DIRTY="×"
SCM_THEME_PROMPT_CLEAN="✓"
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

# TODO: need a check for OS before adding this to the prompt
# ${debian_chroot:+($debian_chroot)}

#added TITLEBAR for updating the tab and window titles with the pwd
case $TERM in
	xterm*)
	TITLEBAR='\[\033]0;\w\007\]'
	;;
	*)
	TITLEBAR=""
	;;
esac

function prompt_command() {
# The "modern-t" theme is a "modern" theme variant with support
# for "t", the minimalist python todo list utility by Steve Losh.
# Get and install "t" at https://github.com/sjl/t#installing-t
#
# Warning: The Bash-it plugin "todo.plugin" breaks the "t"
# prompt integration, please disable it while using this theme.

SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

case $TERM in
	xterm*)
	TITLEBAR="\[\033]0;\w\007\]"
	;;
	*)
	TITLEBAR=""
	;;
esac

PS3=">> "

is_vim_shell() {
	if [ ! -z "$VIMRUNTIME" ]
	then
		echo "[${cyan}vim shell${normal}]"
	fi
}

modern_scm_prompt() {
	CHAR=$(scm_char)
	if [ $CHAR = $SCM_NONE_CHAR ]
	then
		return
	else
		echo "[$(scm_char)][$(scm_prompt_info)]"
	fi
}

prompt() {
	if [ $? -ne 0 ]
	then
		# Yes, the indenting on these is weird, but it has to be like
		# this otherwise it won't display properly.

		PS1="${TITLEBAR}${bold_red}┌─[${cyan}$(t | wc -l | sed -e's/ *//')${reset_color}]${reset_color}$(modern_scm_prompt)[${cyan}\W${normal}]$(is_vim_shell)
${bold_red}└─▪${normal} "
	else
		PS1="${TITLEBAR}┌─[${cyan}$(t | wc -l | sed -e's/ *//')${reset_color}]$(modern_scm_prompt)[${cyan}\W${normal}]$(is_vim_shell)
└─▪ "
	fi
}

PS2="└─▪ "

#!/usr/bin/env bash

# Emoji-based theme to display source control management and
# virtual environment info beside the ordinary bash prompt.

# Theme inspired by:
#  - Naming your Terminal tabs in OSX Lion - http://thelucid.com/2012/01/04/naming-your-terminal-tabs-in-osx-lion/
#  - Bash_it sexy theme

# Demo:
# ┌ⓔ virtualenv 💁user @ 💻 host in 📁directory on 🌿branch {1} ↑1 ↓1 +1 •1 ⌀1 ✗
# └❯ cd .bash-it/themes/cupcake

# virtualenv prompts
VIRTUALENV_CHAR="ⓔ "
VIRTUALENV_THEME_PROMPT_PREFIX=""
VIRTUALENV_THEME_PROMPT_SUFFIX=""

# SCM prompts
SCM_NONE_CHAR=""
SCM_GIT_CHAR="[±] "
SCM_GIT_BEHIND_CHAR="${red}↓${normal}"
SCM_GIT_AHEAD_CHAR="${bold_green}↑${normal}"
SCM_GIT_UNTRACKED_CHAR="⌀"
SCM_GIT_UNSTAGED_CHAR="${bold_yellow}•${normal}"
SCM_GIT_STAGED_CHAR="${bold_green}+${normal}"

SCM_THEME_PROMPT_DIRTY=""
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

# Git status prompts
GIT_THEME_PROMPT_DIRTY=" ${red}✗${normal}"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
GIT_THEME_PROMPT_PREFIX=""
GIT_THEME_PROMPT_SUFFIX=""

# ICONS =======================================================================

icon_start="┌"
icon_user="💁  "
icon_host=" @ 💻  "
icon_directory=" in 📁  "
icon_branch="🌿"
icon_end="└❯ "

# extra spaces ensure legiblity in prompt

# FUNCTIONS ===================================================================

# Display virtual environment info
function virtualenv_prompt {
  if [[ -n "$VIRTUAL_ENV" ]]; then
    virtualenv=`basename "$VIRTUAL_ENV"`
    echo -e "$VIRTUALENV_CHAR$virtualenv "
  fi
}

# Rename tab
function tabname {
  printf "\e]1;$1\a"
}

# Rename window
function winname {
  printf "\e]2;$1\a"
}

# PROMPT OUTPUT ===============================================================

# Displays the current prompt
function prompt_command() {
  PS1="\n${icon_start}$(virtualenv_prompt)${icon_user}${bold_red}\u${normal}${icon_host}${bold_cyan}\h${normal}${icon_directory}${bold_purple}\W${normal}\$([[ -n \$(git branch 2> /dev/null) ]] && echo \" on ${icon_branch}  \")${white}$(scm_prompt_info)${normal}\n${icon_end}"
  PS2="${icon_end}"
# shellcheck shell=bash

# Detect whether a reboot is required
function show_reboot_required() {
	if [ -n "$_bf_prompt_reboot_info" ]; then
		if [ -f /var/run/reboot-required ]; then
			printf "Reboot required!"
		fi
	fi
}

# Set different host color for local and remote sessions
function set_host_color() {
	# Detect if connection is through SSH
	if [[ -n $SSH_CLIENT ]]; then
		printf '%s' "${lime_yellow}"
	else
		printf '%s' "${light_orange}"
	fi
}

# Set different username color for users and root
function set_user_color() {
	case $(id -u) in
		0)
			printf '%s' "${red}"
			;;
		*)
			printf '%s' "${cyan}"
			;;
	esac
}

scm_prompt() {
	CHAR=$(scm_char)
	if [ "$CHAR" = "$SCM_NONE_CHAR" ]; then
		return
	else
		echo "[$(scm_char)$(scm_prompt_info)]"
	fi
}

# Define custom colors we need
# non-printable bytes in PS1 need to be contained within \[ \].
# Otherwise, bash will count them in the length of the prompt
function set_custom_colors() {
	dark_grey="\[$(tput setaf 8)\]"
	light_grey="\[$(tput setaf 248)\]"

	light_orange="\[$(tput setaf 172)\]"
	bright_yellow="\[$(tput setaf 220)\]"
	lime_yellow="\[$(tput setaf 190)\]"

	powder_blue="\[$(tput setaf 153)\]"
}

__ps_time() {
	printf '%s' "$(clock_prompt)${normal}\n"
}

function prompt_command() {
	ps_reboot="${bright_yellow}$(show_reboot_required)${normal}\n"

	ps_username="$(set_user_color)\u${normal}"
	ps_uh_separator="${dark_grey}@${normal}"
	ps_hostname="$(set_host_color)\h${normal}"

	ps_path="${yellow}\w${normal}"
	ps_scm_prompt="${light_grey}$(scm_prompt)"

	ps_user_mark="${normal} ${normal}"
	ps_user_input="${normal}"

	# Set prompt
	PS1="$ps_reboot$(__ps_time)$ps_username$ps_uh_separator$ps_hostname $ps_path $ps_scm_prompt$ps_user_mark$ps_user_input"
}

# Initialize custom colors
set_custom_colors

THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"$dark_grey"}

# scm theming
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${light_grey}"
SCM_THEME_PROMPT_CLEAN=" ${green}✓${light_grey}"
SCM_GIT_CHAR="${green}±${light_grey}"
SCM_SVN_CHAR="${bold_cyan}⑆${light_grey}"
#!/usr/bin/env bash
#
# Based on 'bobby' theme with the addition of virtualenv_prompt
#

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${green}✓"
SCM_THEME_PROMPT_PREFIX=" ${yellow}|${reset_color}"
SCM_THEME_PROMPT_SUFFIX="${yellow}|"

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX="|"
VIRTUALENV_THEME_PROMPT_PREFIX='|'
VIRTUALENV_THEME_PROMPT_SUFFIX='|'

# shellcheck shell=bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" |"
SCM_THEME_PROMPT_SUFFIX="${green}|"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${green}|"
GIT_THEME_PROMPT_SUFFIX="${green}|"

CONDAENV_THEME_PROMPT_SUFFIX="|"

function prompt_command() {
	PS1="\n${yellow}$(python_version_prompt) " # Name of virtual env followed by python version
	PS1+="${purple}\h "
	PS1+="${reset_color}in "
	PS1+="${green}\w\n"
	PS1+="${bold_cyan}$(scm_char)"
SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

#Mysql Prompt
export MYSQL_PS1="(\u@\h) [\d]> "

case $TERM in
        xterm*)
        TITLEBAR="\[\033]0;\w\007\]"
        ;;
        *)
        TITLEBAR=""
        ;;
esac

PS3=">> "

__my_rvm_ruby_version() {
    local gemset=$(echo $GEM_HOME | awk -F'@' '{print $2}')
  [ "$gemset" != "" ] && gemset="@$gemset"
    local version=$(echo $MY_RUBY_HOME | awk -F'-' '{print $2}')
    local full="$version$gemset"
  [ "$full" != "" ] && echo "[$full]"
}

is_vim_shell() {
        if [ ! -z "$VIMRUNTIME" ]
        then
                echo "[${cyan}vim shell${normal}]"
        fi
}

modern_scm_prompt() {
        CHAR=$(scm_char)
        if [ $CHAR = $SCM_NONE_CHAR ]
        then
                return
        else
                echo "[$(scm_char)][$(scm_prompt_info)]"
        fi
}

# show chroot if exist
chroot(){
    if [ -n "$debian_chroot" ]
    then
        my_ps_chroot="${bold_cyan}$debian_chroot${normal}";
        echo "($my_ps_chroot)";
    fi
    }

# show virtualenvwrapper
my_ve(){

    if [ -n "$CONDA_DEFAULT_ENV" ]
    then
        my_ps_ve="${bold_purple}${CONDA_DEFAULT_ENV}${normal}";
        echo "($my_ps_ve)";
    elif [ -n "$VIRTUAL_ENV" ]
    then
        my_ps_ve="${bold_purple}$ve${normal}";
        echo "($my_ps_ve)";
    fi
    echo "";
    }

prompt() {

    my_ps_host="${green}\h${normal}";
    # yes, these are the the same for now ...
    my_ps_host_root="${green}\h${normal}";

    my_ps_user="${bold_green}\u${normal}"
    my_ps_root="${bold_red}\u${normal}";

    if [ -n "$VIRTUAL_ENV" ]
    then
        ve=`basename "$VIRTUAL_ENV"`;
    fi

    # nice prompt
    case "`id -u`" in
        0) PS1="${TITLEBAR}┌─$(my_ve)$(chroot)[$my_ps_root][$my_ps_host_root]$(modern_scm_prompt)$(__my_rvm_ruby_version)[${cyan}\w${normal}]$(is_vim_shell)
└─▪ "
        ;;
        *) PS1="${TITLEBAR}┌─$(my_ve)$(chroot)[$my_ps_user][$my_ps_host]$(modern_scm_prompt)$(__my_rvm_ruby_version)[${cyan}\w${normal}]$(is_vim_shell)
└─▪ "
        ;;
    esac
}

PS2="└─▪ "


#!/usr/bin/env bash
# Wrapper to use liquidprompt with bashit

targetdir="$BASH_IT/themes/liquidprompt/liquidprompt"
gray="\[\e[1;90m\]"

cwd="$PWD"
if cd "$targetdir" &>/dev/null && git rev-parse --is-inside-work-tree &>/dev/null; then
    true
else
    git clone https://github.com/nojhan/liquidprompt.git "$targetdir" && \
    echo -e "Successfully cloned liquidprompt!\n More configuration in '$targetdir/liquid.theme'."
fi
cd "$cwd"

export LP_ENABLE_TIME=1
export LP_HOSTNAME_ALWAYS=1
export LP_USER_ALWAYS=1
export LP_MARK_LOAD="📈 "
export LP_BATTERY_THRESHOLD=${LP_BATTERY_THRESHOLD:-75}
export LP_LOAD_THRESHOLD=${LP_LOAD_THRESHOLD:-60}
export LP_TEMP_THRESHOLD=${LP_TEMP_THRESHOLD:-80}


source "$targetdir/liquidprompt"
prompt() { true; }
export PS2=" ┃ "
export LP_PS1_PREFIX="┌─"
export LP_PS1_POSTFIX="\n└▪ "
export LP_ENABLE_RUNTIME=0

_lp_git_branch()
{
    (( LP_ENABLE_GIT )) || return

    \git rev-parse --is-inside-work-tree >/dev/null 2>&1 || return

    local branch
    # Recent versions of Git support the --short option for symbolic-ref, but
    # not 1.7.9 (Ubuntu 12.04)
    if branch="$(\git symbolic-ref -q HEAD)"; then
        _lp_escape "$(\git rev-parse --short=5 -q HEAD 2>/dev/null):${branch#refs/heads/}"
    else
        # In detached head state, use commit instead
        # No escape needed
        \git rev-parse --short -q HEAD 2>/dev/null
    fi
}

_lp_time() {
    if (( LP_ENABLE_TIME )) && (( ! LP_TIME_ANALOG )); then
        LP_TIME="${gray}$(date +%d-%H:%M)${normal}"
    else
        LP_TIME=""
    fi
}

# Implementation using lm-sensors
_lp_temp_sensors()
{
    local -i i
    for i in $(sensors -u |
            sed -n 's/^  temp[0-9][0-9]*_input: \([0-9]*\)\..*$/\1/p'); do
            (( $i > ${temperature:-0} )) && (( $i != 127 )) && temperature=i
    done
}

# Implementation using 'acpi -t'
_lp_temp_acpi()
{
    local -i i
    for i in $(LANG=C acpi -t |
            sed 's/.* \(-\?[0-9]*\)\.[0-9]* degrees C$/\1/p'); do
        (( $i > ${temperature:-0} )) && (( $i != 127 )) && temperature=i
    done
#!/usr/bin/env bash

# based off of n0qorg
# looks like, if you're in a git repo:
# ± ~/path/to (branch ✓) $
# in glorious red / blue / yellow color scheme

prompt_setter() {
  # Save history
  history -a
  history -c
  history -r
  # displays user@server in purple
  # PS1="$red$(scm_char) $purple\u@\h$reset_color:$blue\w$yellow$(scm_prompt_info)$(ruby_version_prompt) $black\$$reset_color "
  # no user@server
  PS1="$red$(scm_char) $blue\w$yellow$(scm_prompt_info)$(ruby_version_prompt) $black\$$reset_color "
  PS2='> '
  PS4='+ '
}

safe_append_prompt_command prompt_setter

SCM_NONE_CHAR='·'
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${green}✓"
# scm theming
SCM_THEME_PROMPT_PREFIX="${yellow}("
SCM_THEME_PROMPT_SUFFIX=")${normal}"

SCM_THEME_PROMPT_DIRTY="*"
SCM_THEME_PROMPT_CLEAN=""
SCM_GIT_CHAR="g"
SCM_SVN_CHAR="s"
SCM_HG_CHAR="h"

### TODO: openSUSE has already colors enabled, check if those differs from stock
# LS colors, made with http://geoff.greer.fm/lscolors/
# export LSCOLORS="Gxfxcxdxbxegedabagacad"
# export LS_COLORS='no=00:fi=00:di=01;34:ln=00;36:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=41;33;01:ex=00;32:*.cmd=00;32:*.exe=01;32:*.com=01;32:*.bat=01;32:*.btm=01;32:*.dll=01;32:*.tar=00;31:*.tbz=00;31:*.tgz=00;31:*.rpm=00;31:*.deb=00;31:*.arj=00;31:*.taz=00;31:*.lzh=00;31:*.lzma=00;31:*.zip=00;31:*.zoo=00;31:*.z=00;31:*.Z=00;31:*.gz=00;31:*.bz2=00;31:*.tb2=00;31:*.tz2=00;31:*.tbz2=00;31:*.avi=01;35:*.bmp=01;35:*.fli=01;35:*.gif=01;35:*.jpg=01;35:*.jpeg=01;35:*.mng=01;35:*.mov=01;35:*.mpg=01;35:*.pcx=01;35:*.pbm=01;35:*.pgm=01;35:*.png=01;35:*.ppm=01;35:*.tga=01;35:*.tif=01;35:*.xbm=01;35:*.xpm=01;35:*.dl=01;35:*.gl=01;35:*.wmv=01;35:*.aiff=00;32:*.au=00;32:*.mid=00;32:*.mp3=00;32:*.ogg=00;32:*.voc=00;32:*.wav=00;32:'

scm_prompt() {
    CHAR=$(scm_char)
    if [ $CHAR = $SCM_NONE_CHAR ]
        then
            return
        else
            echo "$(scm_prompt_info) "
    fi
}

pure_prompt() {
    ps_host="${green}\h${normal}";
    ps_user_mark="${bold}\$${normal}";
    ps_root_mark="${normal}§"
    ps_path="${normal}\w";

    # make it work
    case $(id -u) in
        0) PS1="$ps_host $ps_path $(scm_prompt)$ps_root_mark "
            ;;
        *) PS1="$ps_host $ps_path $(scm_prompt)$ps_user_mark "
            ;;
    esac
}

#!/usr/bin/env bash

SCM_THEME_PROMPT_PREFIX="${cyan}(${green}"
SCM_THEME_PROMPT_SUFFIX="${cyan})"
SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${green}✓"

prompt() {
  PS1="$(scm_prompt_info)${reset_color} ${cyan}\W${reset_color} "
}
#!/usr/bin/env bash

# prompt themeing

#added TITLEBAR for updating the tab and window titles with the pwd
case $TERM in
	xterm*)
	TITLEBAR="\[\033]0;\w\007\]"
	;;
	*)
	TITLEBAR=""
	;;
esac

function prompt_command() {
	PS1="${TITLEBAR}${orange}${reset_color}${green}\w${bold_blue}\[$(scm_prompt_info)\]${normal} "
}

# scm themeing
SCM_THEME_PROMPT_DIRTY=" ✗"
# shellcheck shell=bash

SCM_THEME_PROMPT_PREFIX=""
SCM_THEME_PROMPT_SUFFIX=""

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_GIT_CHAR="${bold_green}±${normal}"
SCM_SVN_CHAR="${bold_cyan}⑆${normal}"
SCM_HG_CHAR="${bold_red}☿${normal}"

case $TERM in
	xterm*)
		TITLEBAR="\[\033]0;\w\007\]"
		;;
	*)
		TITLEBAR=""
		;;
esac

PS3=">> "

is_vim_shell() {
	if [ -n "$VIMRUNTIME" ]; then
		echo "[${cyan}vim shell${normal}]"
	fi
}

modern_scm_prompt() {
	CHAR=$(scm_char)
	if [ "$CHAR" = "$SCM_NONE_CHAR" ]; then
		return
	else
		echo "[$(scm_char)][$(scm_prompt_info)]"
	fi
}

detect_venv() {
	python_venv=""
	# Detect python venv
	if [[ -n "${CONDA_DEFAULT_ENV}" ]]; then
		python_venv="($PYTHON_VENV_CHAR${CONDA_DEFAULT_ENV}) "
	elif [[ -n "${VIRTUAL_ENV}" ]]; then
		python_venv="($PYTHON_VENV_CHAR$(basename "${VIRTUAL_ENV}")) "
	fi
}

prompt() {
	retval=$?
	if [[ retval -ne 0 ]]; then
		PS1="${TITLEBAR}${bold_red}┌─${reset_color}$(modern_scm_prompt)[${cyan}\u${normal}][${cyan}\w${normal}]$(is_vim_shell)\n${bold_red}└─▪${normal} "
	else
		PS1="${TITLEBAR}┌─$(modern_scm_prompt)[${cyan}\u${normal}][${cyan}\w${normal}]$(is_vim_shell)\n└─▪ "
	fi
	detect_venv
	PS1+="${python_venv}${dir_color}"
}

PS2="└─▪ "

#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=" ${bold_yellow}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX=" ${bold_blue}scm:("
SCM_THEME_PROMPT_SUFFIX="${bold_blue})"

GIT_THEME_PROMPT_DIRTY=" ${bold_yellow}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX=" ${bold_blue}git:("
GIT_THEME_PROMPT_SUFFIX="${bold_blue})"

RVM_THEME_PROMPT_PREFIX="|"
RVM_THEME_PROMPT_SUFFIX="|"

function git_prompt_info() {
  git_prompt_vars
  echo -e "$SCM_PREFIX${bold_red}$SCM_BRANCH$SCM_STATE$SCM_SUFFIX"
}

. "$BASH_IT/themes/powerline/powerline.base.bash"

function __powerline_last_status_prompt {
  [[ "$1" -ne 0 ]] && echo "$(set_color ${LAST_STATUS_THEME_PROMPT_COLOR} -) ${1} ${normal}"
}

function __powerline_right_segment {
  local OLD_IFS="${IFS}"; IFS="|"
  local params=( $1 )
  IFS="${OLD_IFS}"
  local padding=0
  local pad_before_segment=" "

  if [[ "${SEGMENTS_AT_RIGHT}" -eq 0 ]]; then
    if [[ "${POWERLINE_COMPACT_AFTER_LAST_SEGMENT}" -ne 0 ]]; then
      pad_before_segment=""
    fi
    RIGHT_PROMPT+="$(set_color ${params[1]} -)${POWERLINE_RIGHT_END}${normal}"
    (( padding += 1 ))
  else
    if [[ "${POWERLINE_COMPACT_BEFORE_SEPARATOR}" -ne 0 ]]; then
      pad_before_segment=""
    fi
    # Since the previous segment wasn't the last segment, add padding, if needed
    #
    if [[ "${POWERLINE_COMPACT_AFTER_SEPARATOR}" -eq 0 ]]; then
      RIGHT_PROMPT+="$(set_color - ${LAST_SEGMENT_COLOR}) ${normal}"
      (( padding += 1 ))
    fi
    if [[ "${LAST_SEGMENT_COLOR}" -eq "${params[1]}" ]]; then
      RIGHT_PROMPT+="$(set_color - ${LAST_SEGMENT_COLOR})${POWERLINE_RIGHT_SEPARATOR_SOFT}${normal}"
    else
      RIGHT_PROMPT+="$(set_color ${params[1]} ${LAST_SEGMENT_COLOR})${POWERLINE_RIGHT_SEPARATOR}${normal}"
    fi
    (( padding += 1 ))
  fi

  RIGHT_PROMPT+="$(set_color - ${params[1]})${pad_before_segment}${params[0]}${normal}"

  (( padding += ${#pad_before_segment} ))
  (( padding += ${#params[0]} ))

  (( RIGHT_PROMPT_LENGTH += padding ))
  LAST_SEGMENT_COLOR="${params[1]}"
  (( SEGMENTS_AT_RIGHT += 1 ))
}

function __powerline_right_first_segment_padding {
  RIGHT_PROMPT+="$(set_color - ${LAST_SEGMENT_COLOR}) ${normal}"
  (( RIGHT_PROMPT_LENGTH += 1 ))
}

function __powerline_prompt_command {
  local last_status="$?" ## always the first
  local move_cursor_rightmost='\033[500C'

  LEFT_PROMPT=""
  RIGHT_PROMPT=""
  RIGHT_PROMPT_LENGTH=${POWERLINE_PADDING}
  SEGMENTS_AT_LEFT=0
  SEGMENTS_AT_RIGHT=0
  LAST_SEGMENT_COLOR=""

  ## left prompt ##
  for segment in $POWERLINE_LEFT_PROMPT; do
    local info="$(__powerline_${segment}_prompt)"
    [[ -n "${info}" ]] && __powerline_left_segment "${info}"
  done

  if [[ -n "${LEFT_PROMPT}" ]] && [[ "${POWERLINE_COMPACT_AFTER_LAST_SEGMENT}" -eq 0 ]]; then
    __powerline_left_last_segment_padding
  fi

  [[ -n "${LEFT_PROMPT}" ]] && LEFT_PROMPT+="$(set_color ${LAST_SEGMENT_COLOR} -)${POWERLINE_LEFT_END}${normal}"

  ## right prompt ##
  if [[ -n "${POWERLINE_RIGHT_PROMPT}" ]]; then
    # LEFT_PROMPT+="${move_cursor_rightmost}"
    for segment in $POWERLINE_RIGHT_PROMPT; do
      local info="$(__powerline_${segment}_prompt)"
      [[ -n "${info}" ]] && __powerline_right_segment "${info}"
    done

    if [[ -n "${RIGHT_PROMPT}" ]] && [[ "${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT}" -eq 0 ]]; then
      __powerline_right_first_segment_padding
    fi

    RIGHT_PAD=$(printf "%.s " $(seq 1 $RIGHT_PROMPT_LENGTH))
    LEFT_PROMPT+="${RIGHT_PAD}${move_cursor_rightmost}"
    LEFT_PROMPT+="\033[$(( ${#RIGHT_PAD} - 1 ))D"
  fi

  local prompt="${PROMPT_CHAR}"
  if [[ "${POWERLINE_COMPACT_PROMPT}" -eq 0 ]]; then
    prompt+=" "
  fi

  PS1="${LEFT_PROMPT}${RIGHT_PROMPT}\n$(__powerline_last_status_prompt ${last_status})${prompt}"

  ## cleanup ##
#!/usr/bin/env bash

. "$BASH_IT/themes/powerline-multiline/powerline-multiline.base.bash"

PROMPT_CHAR=${POWERLINE_PROMPT_CHAR:="❯"}
POWERLINE_LEFT_SEPARATOR=${POWERLINE_LEFT_SEPARATOR:=""}
POWERLINE_LEFT_SEPARATOR_SOFT=${POWERLINE_LEFT_SEPARATOR_SOFT:=""}
POWERLINE_RIGHT_SEPARATOR=${POWERLINE_RIGHT_SEPARATOR:=""}
POWERLINE_RIGHT_SEPARATOR_SOFT=${POWERLINE_RIGHT_SEPARATOR_SOFT:=""}
POWERLINE_LEFT_END=${POWERLINE_LEFT_END:=""}
POWERLINE_RIGHT_END=${POWERLINE_RIGHT_END:=""}
POWERLINE_PADDING=${POWERLINE_PADDING:=2}

POWERLINE_COMPACT=${POWERLINE_COMPACT:=0}
POWERLINE_COMPACT_BEFORE_SEPARATOR=${POWERLINE_COMPACT_BEFORE_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_SEPARATOR=${POWERLINE_COMPACT_AFTER_SEPARATOR:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_BEFOR_FIRST_SEGMENT=${POWERLINE_COMPACT_BEFORE_FIRST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_AFTER_LAST_SEGMENT=${POWERLINE_COMPACT_AFTER_LAST_SEGMENT:=${POWERLINE_COMPACT}}
POWERLINE_COMPACT_PROMPT=${POWERLINE_COMPACT_PROMPT:=${POWERLINE_COMPACT}}

USER_INFO_SSH_CHAR=${POWERLINE_USER_INFO_SSH_CHAR:=" "}
USER_INFO_THEME_PROMPT_COLOR=${POWERLINE_USER_INFO_COLOR:=32}
USER_INFO_THEME_PROMPT_COLOR_SUDO=${POWERLINE_USER_INFO_COLOR_SUDO:=202}

PYTHON_VENV_CHAR=${POWERLINE_PYTHON_VENV_CHAR:="❲p❳ "}
CONDA_PYTHON_VENV_CHAR=${POWERLINE_CONDA_PYTHON_VENV_CHAR:="❲c❳ "}
PYTHON_VENV_THEME_PROMPT_COLOR=${POWERLINE_PYTHON_VENV_COLOR:=35}

SCM_NONE_CHAR=""
SCM_GIT_CHAR=${POWERLINE_SCM_GIT_CHAR:=" "}
SCM_HG_CHAR=${POWERLINE_SCM_HG_CHAR:="☿ "}
SCM_THEME_PROMPT_CLEAN=""
SCM_THEME_PROMPT_DIRTY=""
SCM_THEME_PROMPT_CLEAN_COLOR=${POWERLINE_SCM_CLEAN_COLOR:=25}
SCM_THEME_PROMPT_DIRTY_COLOR=${POWERLINE_SCM_DIRTY_COLOR:=88}
SCM_THEME_PROMPT_STAGED_COLOR=${POWERLINE_SCM_STAGED_COLOR:=30}
SCM_THEME_PROMPT_UNSTAGED_COLOR=${POWERLINE_SCM_UNSTAGED_COLOR:=92}
SCM_THEME_PROMPT_COLOR=${SCM_THEME_PROMPT_CLEAN_COLOR}

NVM_THEME_PROMPT_PREFIX=""
NVM_THEME_PROMPT_SUFFIX=""
NODE_CHAR=${POWERLINE_NODE_CHAR:="❲n❳ "}
NODE_THEME_PROMPT_COLOR=${POWERLINE_NODE_COLOR:=22}

RVM_THEME_PROMPT_PREFIX=""
RVM_THEME_PROMPT_SUFFIX=""
RBENV_THEME_PROMPT_PREFIX=""
RBENV_THEME_PROMPT_SUFFIX=""
RUBY_THEME_PROMPT_COLOR=${POWERLINE_RUBY_COLOR:=161}
RUBY_CHAR=${POWERLINE_RUBY_CHAR:="❲r❳ "}

TERRAFORM_THEME_PROMPT_COLOR=${POWERLINE_TERRAFORM_COLOR:=161}
TERRAFORM_CHAR=${POWERLINE_TERRAFORM_CHAR:="❲t❳ "}

KUBERNETES_CONTEXT_THEME_CHAR=${POWERLINE_KUBERNETES_CONTEXT_CHAR:="⎈ "}
KUBERNETES_CONTEXT_THEME_PROMPT_COLOR=${POWERLINE_KUBERNETES_CONTEXT_COLOR:=26}

AWS_PROFILE_CHAR=${POWERLINE_AWS_PROFILE_CHAR:="❲aws❳ "}
AWS_PROFILE_PROMPT_COLOR=${POWERLINE_AWS_PROFILE_COLOR:=208}

CWD_THEME_PROMPT_COLOR=${POWERLINE_CWD_COLOR:=240}

LAST_STATUS_THEME_PROMPT_COLOR=${POWERLINE_LAST_STATUS_COLOR:=196}

CLOCK_THEME_PROMPT_COLOR=${POWERLINE_CLOCK_COLOR:=240}

BATTERY_AC_CHAR=${BATTERY_AC_CHAR:="⚡"}
BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR=${POWERLINE_BATTERY_GOOD_COLOR:=70}
BATTERY_STATUS_THEME_PROMPT_LOW_COLOR=${POWERLINE_BATTERY_LOW_COLOR:=208}
BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR=${POWERLINE_BATTERY_CRITICAL_COLOR:=160}

THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:="%H:%M:%S"}

IN_VIM_THEME_PROMPT_COLOR=${POWERLINE_IN_VIM_COLOR:=245}
IN_VIM_THEME_PROMPT_TEXT=${POWERLINE_IN_VIM_TEXT:="vim"}

IN_TOOLBOX_THEME_PROMPT_COLOR=${POWERLINE_IN_TOOLBOX_COLOR:=125}
IN_TOOLBOX_THEME_PROMPT_TEXT=${POWERLINE_IN_TOOLBOX_TEXT:="⬢ "}

HOST_THEME_PROMPT_COLOR=${POWERLINE_HOST_COLOR:=0}

SHLVL_THEME_PROMPT_COLOR=${POWERLINE_SHLVL_COLOR:=${HOST_THEME_PROMPT_COLOR}}
SHLVL_THEME_PROMPT_CHAR=${POWERLINE_SHLVL_CHAR:="§"}

DIRSTACK_THEME_PROMPT_COLOR=${POWERLINE_DIRSTACK_COLOR:=${CWD_THEME_PROMPT_COLOR}}
DIRSTACK_THEME_PROMPT_CHAR=${POWERLINE_DIRSTACK_CHAR:="←"}

HISTORY_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_HISTORY_NUMBER_COLOR:=0}
HISTORY_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_HISTORY_NUMBER_CHAR:="#"}

COMMAND_NUMBER_THEME_PROMPT_COLOR=${POWERLINE_COMMAND_NUMBER_COLOR:=0}
COMMAND_NUMBER_THEME_PROMPT_CHAR=${POWERLINE_COMMAND_NUMBER_CHAR:="#"}

POWERLINE_LEFT_PROMPT=${POWERLINE_LEFT_PROMPT:="scm python_venv ruby node cwd"}
POWERLINE_RIGHT_PROMPT=${POWERLINE_RIGHT_PROMPT:="in_vim clock battery user_info"}
#!/usr/bin/env bash

. "$BASH_IT/themes/gitline/powerline.base.bash"

#For the logo(Uncomment if you want a logo before your name)
#PROMPT_DISTRO_LOGO="💻"
PROMPT_DISTRO_LOGO_COLOR=15
PROMPT_DISTRO_LOGO_COLORBG=52

#Prompt Seperator Charactors
PROMPT_CHAR=${POWERLINE_PROMPT_CHAR:=""}
POWERLINE_LEFT_SEPARATOR=${POWERLINE_LEFT_SEPARATOR:=""}

#USER INFO CHARACTERS
USER_INFO_SSH_CHAR=${POWERLINE_USER_INFO_SSH_CHAR:=" "}
USER_INFO_SUDO_CHAR=${POWERLINE_USER_INFO_SUDO_CHAR:=" "}
USER_INFO_THEME_PROMPT_COLOR=91
USER_INFO_THEME_PROMPT_COLOR_SUDO=1

#PYTHON VENV
PYTHON_VENV_CHAR=${POWERLINE_PYTHON_VENV_CHAR:=" "}
CONDA_PYTHON_VENV_CHAR=${POWERLINE_CONDA_PYTHON_VENV_CHAR:="❲c❳ "}
PYTHON_VENV_THEME_PROMPT_COLOR=17

#GIT Prompt Symbols
SCM_NONE_CHAR=""
SCM_GIT_CHAR=${POWERLINE_SCM_GIT_CHAR:=" "}
SCM_HG_CHAR=${POWERLINE_SCM_HG_CHAR:="☿ "}
SCM_THEME_PROMPT_CLEAN=" ✓ "
SCM_THEME_PROMPT_DIRTY=" ⨯ "
SCM_THEME_PROMPT_COLOR=91
SCM_THEME_PROMPT_CLEAN_COLOR=41
SCM_THEME_PROMPT_DIRTY_COLOR=94
SCM_THEME_PROMPT_STAGED_COLOR=220 #52
SCM_THEME_PROMPT_UNSTAGED_COLOR=81

#Ruby Prompt Symbols
RVM_THEME_PROMPT_PREFIX=""
RVM_THEME_PROMPT_SUFFIX=""
RBENV_THEME_PROMPT_PREFIX=""
RBENV_THEME_PROMPT_SUFFIX=""
RUBY_THEME_PROMPT_COLOR=161
RUBY_CHAR=${POWERLINE_RUBY_CHAR:="❲r❳ "}

CWD_THEME_DIR_SEPARATOR=""
CWD_THEME_DIR_SEPARATOR_COLOR=52
CWD_THEME_PROMPT_COLOR=252

HOST_THEME_PROMPT_COLOR=88

LAST_STATUS_THEME_PROMPT_COLOR=52

#Clock
CLOCK_THEME_PROMPT_COLOR=240

#For Battery Plugin
BATTERY_AC_CHAR=${BATTERY_AC_CHAR:="⚡"}
BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR=70
BATTERY_STATUS_THEME_PROMPT_LOW_COLOR=208
BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR=160

THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:="%H:%M:%S"}

IN_VIM_THEME_PROMPT_COLOR=245
IN_VIM_THEME_PROMPT_TEXT="vim"

IN_TOOLBOX_THEME_PROMPT_COLOR=125
IN_TOOLBOX_THEME_PROMPT_TEXT="⬢ "


# Sudo check after every command
THEME_CHECK_SUDO=${THEME_CHECK_SUDO:=true}

#To set color for foreground and background
function set_color {
  set +u
  if [[ "${1}" != "-" ]]; then
    fg="38;5;${1}"
  fi
  if [[ "${2}" != "-" ]]; then
    bg="48;5;${2}"
    [[ -n "${fg}" ]] && bg=";${bg}"
  fi
  echo -e "\[\033[${fg}${bg}m\]"
}

#Customising User Info Segment
function __powerline_user_info_prompt {
  local user_info="${USER}"
  local color=${USER_INFO_THEME_PROMPT_COLOR}
  local fg_color=15

  if [[ "${THEME_CHECK_SUDO}" = true ]]; then
    if sudo -n uptime 2>&1 | grep -q "load"; then
      color=${USER_INFO_THEME_PROMPT_COLOR_SUDO}
    fi
  fi

  case "${POWERLINE_PROMPT_USER_INFO_MODE}" in
    "sudo")
      if [[ "${color}" = "${USER_INFO_THEME_PROMPT_COLOR_SUDO}" ]]; then
        user_info="👑 ${USER}"
        fg_color=227
        color=${USER_INFO_THEME_PROMPT_COLOR_SUDO}
      fi
      ;;
    *)
      if [[ -n "${SSH_CLIENT}" ]] || [[ -n "${SSH_CONNECTION}" ]]; then
        user_info="${USER_INFO_SSH_CHAR}${USER}"
      else
        user_info="${USER}"
      fi
      ;;
  esac
  [[ -n "${user_info}" ]] && echo "${user_info}|${color}|${fg_color}"
}

#Customising Ruby Prompt
function __powerline_ruby_prompt {
  local ruby_version=""
  local fg_color=206

  if _command_exists rvm; then
    ruby_version="$(rvm_version_prompt)"
  elif _command_exists rbenv; then
    ruby_version=$(rbenv_version_prompt)
  fi

  [[ -n "${ruby_version}" ]] && echo "${RUBY_CHAR}${ruby_version}|${RUBY_THEME_PROMPT_COLOR}|${fg_color}"
}

#Customising Python (venv) Prompt
function __powerline_python_venv_prompt {
  set +u
  local python_venv=""
  local fg_color=206

  if [[ -n "${CONDA_DEFAULT_ENV}" ]]; then
    python_venv="${CONDA_DEFAULT_ENV}"
    PYTHON_VENV_CHAR=${CONDA_PYTHON_VENV_CHAR}
  elif [[ -n "${VIRTUAL_ENV}" ]]; then
    python_venv=$(basename "${VIRTUAL_ENV}")
  fi

  [[ -n "${python_venv}" ]] && echo "${PYTHON_VENV_CHAR}${python_venv}|${PYTHON_VENV_THEME_PROMPT_COLOR}|${fg_color}"
}

#Customising SCM(GIT) Prompt
function __powerline_scm_prompt {
  local color=""
  local scm_prompt=""
  local fg_color=206

  scm_prompt_vars


  if [[ "${SCM_NONE_CHAR}" != "${SCM_CHAR}" ]]; then
    if [[ "${SCM_DIRTY}" -eq 3 ]]; then
      color=${SCM_THEME_PROMPT_STAGED_COLOR}
      fg_color=124
    elif [[ "${SCM_DIRTY}" -eq 2 ]]; then
      color=${SCM_THEME_PROMPT_UNSTAGED_COLOR}
      fg_color=56
    elif [[ "${SCM_DIRTY}" -eq 1 ]]; then
      color=${SCM_THEME_PROMPT_DIRTY_COLOR}
      fg_color=118
    elif [[ "${SCM_DIRTY}" -eq 0 ]]; then
      color=${SCM_THEME_PROMPT_CLEAN_COLOR}
      fg_color=16
    else
      color=${SCM_THEME_PROMPT_COLOR}
      fg_color=255
    fi
    if [[ "${SCM_GIT_CHAR}" == "${SCM_CHAR}" ]]; then
      scm_prompt+="${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
    elif [[ "${SCM_P4_CHAR}" == "${SCM_CHAR}" ]]; then
      scm_prompt+="${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
    elif [[ "${SCM_HG_CHAR}" == "${SCM_CHAR}" ]]; then
      scm_prompt+="${SCM_CHAR}${SCM_BRANCH}${SCM_STATE}"
    fi
    echo "${scm_prompt}${scm}|${color}|${fg_color}"
  fi
}

function __powerline_cwd_prompt {
  local cwd=$(pwd | sed "s|^${HOME}|~|")
  local fg_color=16

  echo "${cwd}|${CWD_THEME_PROMPT_COLOR}|${fg_color}"
}

function __powerline_hostname_prompt {
  local fg_color=206

  echo "$(hostname -s)|${HOST_THEME_PROMPT_COLOR}|${fg_color}"
}

function __powerline_wd_prompt {
  local fg_color=206

  echo "\W|${CWD_THEME_PROMPT_COLOR}|${fg_color}"
}

function __powerline_clock_prompt {
    local fg_color=206

  echo "$(date +"${THEME_CLOCK_FORMAT}")|${CLOCK_THEME_PROMPT_COLOR}|${fg_color}"
}

function __powerline_battery_prompt {
  local color=""
  local battery_status="$(battery_percentage 2> /dev/null)"
  local fg_color=255

  if [[ -z "${battery_status}" ]] || [[ "${battery_status}" = "-1" ]] || [[ "${battery_status}" = "no" ]]; then
    true
  else
    if [[ "$((10#${battery_status}))" -le 5 ]]; then
      color="${BATTERY_STATUS_THEME_PROMPT_CRITICAL_COLOR}"
    elif [[ "$((10#${battery_status}))" -le 25 ]]; then
      color="${BATTERY_STATUS_THEME_PROMPT_LOW_COLOR}"
    else
      color="${BATTERY_STATUS_THEME_PROMPT_GOOD_COLOR}"
    fi
    ac_adapter_connected && battery_status="${BATTERY_AC_CHAR}${battery_status}"
    echo "${battery_status}%|${color}|${fg_color}"
  fi
}

function __powerline_in_vim_prompt {
  local fg_color=206

  if [ -n "$VIMRUNTIME" ]; then
    echo "${IN_VIM_THEME_PROMPT_TEXT}|${IN_VIM_THEME_PROMPT_COLOR}|${fg_color}"
  fi
}

function __powerline_aws_profile_prompt {
  local fg_color=206

  if [[ -n "${AWS_PROFILE}" ]]; then
    echo "${AWS_PROFILE_CHAR}${AWS_PROFILE}|${AWS_PROFILE_PROMPT_COLOR}|${fg_color}"
  fi
}

function __powerline_in_toolbox_prompt {
  local fg_color=206

  if [ -f /run/.containerenv ] && [ -f /run/.toolboxenv ]; then
    echo "${IN_TOOLBOX_THEME_PROMPT_TEXT}|${IN_TOOLBOX_THEME_PROMPT_COLOR}|${fg_color}"
  fi
}

function __powerline_left_segment {
  local OLD_IFS="${IFS}"; IFS="|"
  local params=( $1 )
  IFS="${OLD_IFS}"
  local separator_char="${POWERLINE_LEFT_SEPARATOR}"
  local separator=""
  local fg_color=206

  #for seperator character
  if [[ "${SEGMENTS_AT_LEFT}" -gt 0 ]]; then
    separator="$(set_color ${LAST_SEGMENT_COLOR} ${params[1]})${separator_char}${normal}"
  fi
  #change here to cahnge fg color
  LEFT_PROMPT+="${separator}$(set_color ${params[2]} ${params[1]}) ${params[0]} ${normal}"
  #seperator char color = current bg
  LAST_SEGMENT_COLOR=${params[1]}
  (( SEGMENTS_AT_LEFT += 1 ))
}

function __powerline_last_status_prompt {
  [[ "$1" -ne 0 ]] && echo "${1}|${LAST_STATUS_THEME_PROMPT_COLOR}"
}

function __powerline_prompt_command {
  local last_status="$?" ## always the first
  local separator_char="${POWERLINE_PROMPT_CHAR}"

  LEFT_PROMPT=""
  SEGMENTS_AT_LEFT=0
  LAST_SEGMENT_COLOR=""


  if [[ -n "${POWERLINE_PROMPT_DISTRO_LOGO}" ]]; then
      LEFT_PROMPT+="$(set_color ${PROMPT_DISTRO_LOGO_COLOR} ${PROMPT_DISTRO_LOGO_COLORBG})${PROMPT_DISTRO_LOGO}$(set_color - -)"
  fi

  ## left prompt ##
  for segment in $POWERLINE_PROMPT; do
    local info="$(__powerline_${segment}_prompt)"
    [[ -n "${info}" ]] && __powerline_left_segment "${info}"
  done

  [[ "${last_status}" -ne 0 ]] && __powerline_left_segment $(__powerline_last_status_prompt ${last_status})
  [[ -n "${LEFT_PROMPT}" ]] && LEFT_PROMPT+="$(set_color ${LAST_SEGMENT_COLOR} -)${separator_char}${normal}"

  PS1="${LEFT_PROMPT} "

# shellcheck shell=bash

CLOCK_CHAR_THEME_PROMPT_PREFIX=''
CLOCK_CHAR_THEME_PROMPT_SUFFIX=''
CLOCK_THEME_PROMPT_PREFIX=''
CLOCK_THEME_PROMPT_SUFFIX=''

THEME_PROMPT_HOST='\H'

SCM=

SCM_CHECK=${SCM_CHECK:=true}

SCM_THEME_PROMPT_DIRTY=' ✗'
SCM_THEME_PROMPT_CLEAN=' ✓'
SCM_THEME_PROMPT_PREFIX=' |'
SCM_THEME_PROMPT_SUFFIX='|'
SCM_THEME_BRANCH_PREFIX=''
SCM_THEME_TAG_PREFIX='tag:'
SCM_THEME_DETACHED_PREFIX='detached:'
SCM_THEME_BRANCH_TRACK_PREFIX=' → '
SCM_THEME_BRANCH_GONE_PREFIX=' ⇢ '
SCM_THEME_CURRENT_USER_PREFFIX=' ☺︎ '
SCM_THEME_CURRENT_USER_SUFFIX=''
SCM_THEME_CHAR_PREFIX=''
SCM_THEME_CHAR_SUFFIX=''

THEME_BATTERY_PERCENTAGE_CHECK=${THEME_BATTERY_PERCENTAGE_CHECK:=true}

SCM_GIT_SHOW_DETAILS=${SCM_GIT_SHOW_DETAILS:=true}
SCM_GIT_SHOW_REMOTE_INFO=${SCM_GIT_SHOW_REMOTE_INFO:=auto}
SCM_GIT_IGNORE_UNTRACKED=${SCM_GIT_IGNORE_UNTRACKED:=false}
SCM_GIT_SHOW_CURRENT_USER=${SCM_GIT_SHOW_CURRENT_USER:=false}
SCM_GIT_SHOW_MINIMAL_INFO=${SCM_GIT_SHOW_MINIMAL_INFO:=false}
SCM_GIT_SHOW_STASH_INFO=${SCM_GIT_SHOW_STASH_INFO:=true}
SCM_GIT_SHOW_COMMIT_COUNT=${SCM_GIT_SHOW_COMMIT_COUNT:=true}
SCM_GIT_USE_GITSTATUS=${SCM_GIT_USE_GITSTATUS:=false}
SCM_GIT_GITSTATUS_RAN=${SCM_GIT_GITSTATUS_RAN:=false}

SCM_GIT='git'
SCM_GIT_CHAR='±'
SCM_GIT_DETACHED_CHAR='⌿'
SCM_GIT_AHEAD_CHAR="↑"
SCM_GIT_BEHIND_CHAR="↓"
SCM_GIT_AHEAD_BEHIND_PREFIX_CHAR=" "
SCM_GIT_UNTRACKED_CHAR="?:"
SCM_GIT_UNSTAGED_CHAR="U:"
SCM_GIT_STAGED_CHAR="S:"
SCM_GIT_STASH_CHAR_PREFIX="{"
SCM_GIT_STASH_CHAR_SUFFIX="}"

SCM_P4='p4'
SCM_P4_CHAR='⌛'
SCM_P4_CHANGES_CHAR='C:'
SCM_P4_DEFAULT_CHAR='D:'
SCM_P4_OPENED_CHAR='O:'

SCM_HG='hg'
SCM_HG_CHAR='☿'

SCM_SVN='svn'
SCM_SVN_CHAR='⑆'

SCM_NONE='NONE'
SCM_NONE_CHAR='○'

NVM_THEME_PROMPT_PREFIX=' |'
NVM_THEME_PROMPT_SUFFIX='|'

RVM_THEME_PROMPT_PREFIX=' |'
RVM_THEME_PROMPT_SUFFIX='|'

THEME_SHOW_RUBY_PROMPT=${THEME_SHOW_RUBY_PROMPT:=true}

THEME_SHOW_USER_HOST=${THEME_SHOW_USER_HOST:=false}
USER_HOST_THEME_PROMPT_PREFIX=''
USER_HOST_THEME_PROMPT_SUFFIX=''

VIRTUALENV_THEME_PROMPT_PREFIX=' |'
VIRTUALENV_THEME_PROMPT_SUFFIX='|'

RBENV_THEME_PROMPT_PREFIX=' |'
RBENV_THEME_PROMPT_SUFFIX='|'

RBFU_THEME_PROMPT_PREFIX=' |'
RBFU_THEME_PROMPT_SUFFIX='|'

GIT_EXE=$(which git 2> /dev/null || true)
P4_EXE=$(which p4 2> /dev/null || true)
HG_EXE=$(which hg 2> /dev/null || true)
SVN_EXE=$(which svn 2> /dev/null || true)

# Check for broken SVN exe that is caused by some versions of Xcode.
# See https://github.com/Bash-it/bash-it/issues/1612 for more details.
if [[ -x "$SVN_EXE" ]]; then
	if ! "$SVN_EXE" --version > /dev/null 2>&1; then
		# Unset the SVN exe variable so that SVN commands are avoided.
		SVN_EXE=""
	fi
fi

function scm {
	if [[ "$SCM_CHECK" = false ]]; then
		SCM=$SCM_NONE
	elif [[ -f .git/HEAD ]] && [[ -x "$GIT_EXE" ]]; then
		SCM=$SCM_GIT
	elif [[ -x "$GIT_EXE" ]] && [[ -n "$(git rev-parse --is-inside-work-tree 2> /dev/null)" ]]; then
		SCM=$SCM_GIT
	elif [[ -x "$P4_EXE" ]] && [[ -n "$(p4 set P4CLIENT 2> /dev/null)" ]]; then
		SCM=$SCM_P4
	elif [[ -d .hg ]] && [[ -x "$HG_EXE" ]]; then
		SCM=$SCM_HG
	elif [[ -x "$HG_EXE" ]] && [[ -n "$(hg root 2> /dev/null)" ]]; then
		SCM=$SCM_HG
	elif [[ -d .svn ]] && [[ -x "$SVN_EXE" ]]; then
		SCM=$SCM_SVN
	elif [[ -x "$SVN_EXE" ]] && [[ -n "$(svn info --show-item wc-root 2> /dev/null)" ]]; then
		SCM=$SCM_SVN
	else
		SCM=$SCM_NONE
	fi
}

function scm_prompt_char {
	if [[ -z $SCM ]]; then scm; fi
	if [[ $SCM == "$SCM_GIT" ]]; then
		SCM_CHAR=$SCM_GIT_CHAR
	elif [[ $SCM == "$SCM_P4" ]]; then
		SCM_CHAR=$SCM_P4_CHAR
	elif [[ $SCM == "$SCM_HG" ]]; then
		SCM_CHAR=$SCM_HG_CHAR
	elif [[ $SCM == "$SCM_SVN" ]]; then
		SCM_CHAR=$SCM_SVN_CHAR
	else
		SCM_CHAR=$SCM_NONE_CHAR
	fi
}

function scm_prompt_vars {
	scm
	scm_prompt_char
	SCM_DIRTY=0
	SCM_STATE=''
	[[ $SCM == "$SCM_GIT" ]] && git_prompt_vars && return
	[[ $SCM == "$SCM_P4" ]] && p4_prompt_vars && return
	[[ $SCM == "$SCM_HG" ]] && hg_prompt_vars && return
	[[ $SCM == "$SCM_SVN" ]] && svn_prompt_vars && return
}

function scm_prompt_info {
	scm
	scm_prompt_char
	scm_prompt_info_common
}

function scm_prompt_char_info {
	scm_prompt_char
	echo -ne "${SCM_THEME_CHAR_PREFIX}${SCM_CHAR}${SCM_THEME_CHAR_SUFFIX}"
	scm_prompt_info_common
}

function scm_prompt_info_common {
	SCM_DIRTY=0
	SCM_STATE=''

	if [[ ${SCM} == "${SCM_GIT}" ]]; then
		if [[ ${SCM_GIT_SHOW_MINIMAL_INFO} == true ]]; then
			# user requests minimal git status information
			git_prompt_minimal_info
		else
			# more detailed git status
			git_prompt_info
		fi
		return
	fi

	# TODO: consider adding minimal status information for hg and svn
	{ [[ ${SCM} == "${SCM_P4}" ]] && p4_prompt_info && return; } || true
	{ [[ ${SCM} == "${SCM_HG}" ]] && hg_prompt_info && return; } || true
	{ [[ ${SCM} == "${SCM_SVN}" ]] && svn_prompt_info && return; } || true
}

function terraform_workspace_prompt {
	if _command_exists terraform; then
		if [ -d .terraform ]; then
			echo -e "$(terraform workspace show 2> /dev/null)"
		fi
	fi
}

function git_prompt_minimal_info {
	SCM_STATE=${SCM_THEME_PROMPT_CLEAN}

	_git-hide-status && return

	SCM_BRANCH="${SCM_THEME_BRANCH_PREFIX}\$(_git-friendly-ref)"

	if [[ -n "$(_git-status | tail -n1)" ]]; then
		SCM_DIRTY=1
		SCM_STATE=${SCM_THEME_PROMPT_DIRTY}
	fi

	# Output the git prompt
	SCM_PREFIX=${SCM_THEME_PROMPT_PREFIX}
	SCM_SUFFIX=${SCM_THEME_PROMPT_SUFFIX}
	echo -e "${SCM_PREFIX}${SCM_BRANCH}${SCM_STATE}${SCM_SUFFIX}"
}

function git_prompt_vars {
	if ${SCM_GIT_USE_GITSTATUS} && _command_exists gitstatus_query && gitstatus_query && [[ "${VCS_STATUS_RESULT}" == "ok-sync" ]]; then
		# we can use faster gitstatus
		# use this variable in githelpers and below to choose gitstatus output
		SCM_GIT_GITSTATUS_RAN=true
	else
		SCM_GIT_GITSTATUS_RAN=false
	fi

	if _git-branch &> /dev/null; then
		SCM_GIT_DETACHED="false"
		SCM_BRANCH="${SCM_THEME_BRANCH_PREFIX}\$(_git-friendly-ref)$(_git-remote-info)"
	else
		SCM_GIT_DETACHED="true"

		local detached_prefix
		if _git-tag &> /dev/null; then
			detached_prefix=${SCM_THEME_TAG_PREFIX}
		else
			detached_prefix=${SCM_THEME_DETACHED_PREFIX}
		fi
		SCM_BRANCH="${detached_prefix}\$(_git-friendly-ref)"
	fi

	if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
		commits_behind=${VCS_STATUS_COMMITS_BEHIND}
		commits_ahead=${VCS_STATUS_COMMITS_AHEAD}
	else
		IFS=$'\t' read -r commits_behind commits_ahead <<< "$(_git-upstream-behind-ahead)"
	fi
	if [[ "${commits_ahead}" -gt 0 ]]; then
		SCM_BRANCH+="${SCM_GIT_AHEAD_BEHIND_PREFIX_CHAR}${SCM_GIT_AHEAD_CHAR}"
		[[ "${SCM_GIT_SHOW_COMMIT_COUNT}" = "true" ]] && SCM_BRANCH+="${commits_ahead}"
	fi
	if [[ "${commits_behind}" -gt 0 ]]; then
		SCM_BRANCH+="${SCM_GIT_AHEAD_BEHIND_PREFIX_CHAR}${SCM_GIT_BEHIND_CHAR}"
		[[ "${SCM_GIT_SHOW_COMMIT_COUNT}" = "true" ]] && SCM_BRANCH+="${commits_behind}"
	fi

	if [[ "${SCM_GIT_SHOW_STASH_INFO}" = "true" ]]; then
		local stash_count
		if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
			stash_count=${VCS_STATUS_STASHES}
		else
			stash_count="$(git stash list 2> /dev/null | wc -l | tr -d ' ')"
		fi
		[[ "${stash_count}" -gt 0 ]] && SCM_BRANCH+=" ${SCM_GIT_STASH_CHAR_PREFIX}${stash_count}${SCM_GIT_STASH_CHAR_SUFFIX}"
	fi

	SCM_STATE=${GIT_THEME_PROMPT_CLEAN:-$SCM_THEME_PROMPT_CLEAN}
	if ! _git-hide-status; then
		if [[ "${SCM_GIT_GITSTATUS_RAN}" == "true" ]]; then
			untracked_count=${VCS_STATUS_NUM_UNTRACKED}
			unstaged_count=${VCS_STATUS_NUM_UNSTAGED}
			staged_count=${VCS_STATUS_NUM_STAGED}
		else
			IFS=$'\t' read -r untracked_count unstaged_count staged_count <<< "$(_git-status-counts)"
		fi
		if [[ "${untracked_count}" -gt 0 || "${unstaged_count}" -gt 0 || "${staged_count}" -gt 0 ]]; then
			SCM_DIRTY=1
			if [[ "${SCM_GIT_SHOW_DETAILS}" = "true" ]]; then
				[[ "${staged_count}" -gt 0 ]] && SCM_BRANCH+=" ${SCM_GIT_STAGED_CHAR}${staged_count}" && SCM_DIRTY=3
				[[ "${unstaged_count}" -gt 0 ]] && SCM_BRANCH+=" ${SCM_GIT_UNSTAGED_CHAR}${unstaged_count}" && SCM_DIRTY=2
				[[ "${untracked_count}" -gt 0 ]] && SCM_BRANCH+=" ${SCM_GIT_UNTRACKED_CHAR}${untracked_count}" && SCM_DIRTY=1
			fi
			SCM_STATE=${GIT_THEME_PROMPT_DIRTY:-$SCM_THEME_PROMPT_DIRTY}
		fi
	fi

	# no if for gitstatus here, user extraction is not supported by it
	[[ "${SCM_GIT_SHOW_CURRENT_USER}" == "true" ]] && SCM_BRANCH+="$(git_user_info)"

	SCM_PREFIX=${GIT_THEME_PROMPT_PREFIX:-$SCM_THEME_PROMPT_PREFIX}
	SCM_SUFFIX=${GIT_THEME_PROMPT_SUFFIX:-$SCM_THEME_PROMPT_SUFFIX}

	SCM_CHANGE=$(_git-short-sha 2> /dev/null || echo "")
}

function p4_prompt_vars {
	IFS=$'\t' read -r \
		opened_count non_default_changes default_count \
		add_file_count edit_file_count delete_file_count \
		<<< "$(_p4-opened-counts)"
	if [[ "${opened_count}" -gt 0 ]]; then
		SCM_DIRTY=1
		SCM_STATE=${SCM_THEME_PROMPT_DIRTY}
		[[ "${opened_count}" -gt 0 ]] && SCM_BRANCH+=" ${SCM_P4_OPENED_CHAR}${opened_count}"
		[[ "${non_default_changes}" -gt 0 ]] && SCM_BRANCH+=" ${SCM_P4_CHANGES_CHAR}${non_default_changes}"
		[[ "${default_count}" -gt 0 ]] && SCM_BRANCH+=" ${SCM_P4_DEFAULT_CHAR}${default_count}"
	else
		SCM_DIRTY=0
		SCM_STATE=${SCM_THEME_PROMPT_DIRTY}
	fi

	SCM_PREFIX=${P4_THEME_PROMPT_PREFIX:-$SCM_THEME_PROMPT_PREFIX}
	SCM_SUFFIX=${P4_THEME_PROMPT_SUFFIX:-$SCM_THEME_PROMPT_SUFFIX}
}

function svn_prompt_vars {
	if [[ -n $(svn status | head -c1 2> /dev/null) ]]; then
		SCM_DIRTY=1
		SCM_STATE=${SVN_THEME_PROMPT_DIRTY:-$SCM_THEME_PROMPT_DIRTY}
	else
		SCM_DIRTY=0
		SCM_STATE=${SVN_THEME_PROMPT_CLEAN:-$SCM_THEME_PROMPT_CLEAN}
	fi
	SCM_PREFIX=${SVN_THEME_PROMPT_PREFIX:-$SCM_THEME_PROMPT_PREFIX}
	SCM_SUFFIX=${SVN_THEME_PROMPT_SUFFIX:-$SCM_THEME_PROMPT_SUFFIX}
	SCM_BRANCH=$(svn info --show-item=url 2> /dev/null | awk -F/ '{ for (i=0; i<=NF; i++) { if ($i == "branches" || $i == "tags" ) { print $(i+1); break }; if ($i == "trunk") { print $i; break } } }') || return
	SCM_CHANGE=$(svn info --show-item=revision 2> /dev/null)
}

# this functions returns absolute location of .hg directory if one exists
# It starts in the current directory and moves its way up until it hits /.
# If we get to / then no Mercurial repository was found.
# Example:
# - lets say we cd into ~/Projects/Foo/Bar
# - .hg is located in ~/Projects/Foo/.hg
# - get_hg_root starts at ~/Projects/Foo/Bar and sees that there is no .hg directory, so then it goes into ~/Projects/Foo
function get_hg_root {
	local CURRENT_DIR=$(pwd)

	while [ "$CURRENT_DIR" != "/" ]; do
		if [ -d "$CURRENT_DIR/.hg" ]; then
			echo "$CURRENT_DIR/.hg"
			return
		fi

		CURRENT_DIR=$(dirname "$CURRENT_DIR")
	done
}

function hg_prompt_vars {
	if [[ -n $(hg status 2> /dev/null) ]]; then
		SCM_DIRTY=1
		SCM_STATE=${HG_THEME_PROMPT_DIRTY:-$SCM_THEME_PROMPT_DIRTY}
	else
		SCM_DIRTY=0
		SCM_STATE=${HG_THEME_PROMPT_CLEAN:-$SCM_THEME_PROMPT_CLEAN}
	fi
	SCM_PREFIX=${HG_THEME_PROMPT_PREFIX:-$SCM_THEME_PROMPT_PREFIX}
	SCM_SUFFIX=${HG_THEME_PROMPT_SUFFIX:-$SCM_THEME_PROMPT_SUFFIX}

	HG_ROOT=$(get_hg_root)

	if [ -f "$HG_ROOT/branch" ]; then
		# Mercurial holds it's current branch in .hg/branch file
		SCM_BRANCH=$(cat "$HG_ROOT/branch")
	else
		SCM_BRANCH=$(hg summary 2> /dev/null | grep branch: | awk '{print $2}')
	fi

	if [ -f "$HG_ROOT/dirstate" ]; then
		# Mercurial holds various information about the working directory in .hg/dirstate file. More on http://mercurial.selenic.com/wiki/DirState
		SCM_CHANGE=$(hexdump -vn 10 -e '1/1 "%02x"' "$HG_ROOT/dirstate" | cut -c-12)
	else
		SCM_CHANGE=$(hg summary 2> /dev/null | grep parent: | awk '{print $2}')
	fi
}

function nvm_version_prompt {
	local node
	if declare -f -F nvm &> /dev/null; then
		node=$(nvm current 2> /dev/null)
		[[ "${node}" == "system" ]] && return
		echo -e "${NVM_THEME_PROMPT_PREFIX}${node}${NVM_THEME_PROMPT_SUFFIX}"
	fi
}

function node_version_prompt {
	echo -e "$(nvm_version_prompt)"
}

function rvm_version_prompt {
	if which rvm &> /dev/null; then
		rvm=$(rvm-prompt) || return
		if [ -n "$rvm" ]; then
			echo -e "$RVM_THEME_PROMPT_PREFIX$rvm$RVM_THEME_PROMPT_SUFFIX"
		fi
	fi
}

function rbenv_version_prompt {
	if which rbenv &> /dev/null; then
		rbenv=$(rbenv version-name) || return
		rbenv commands | grep -q gemset && gemset=$(rbenv gemset active 2> /dev/null) && rbenv="$rbenv@${gemset%% *}"
		if [ "$rbenv" != "system" ]; then
			echo -e "$RBENV_THEME_PROMPT_PREFIX$rbenv$RBENV_THEME_PROMPT_SUFFIX"
		fi
	fi
}

function rbfu_version_prompt {
	if [[ $RBFU_RUBY_VERSION ]]; then
		echo -e "${RBFU_THEME_PROMPT_PREFIX}${RBFU_RUBY_VERSION}${RBFU_THEME_PROMPT_SUFFIX}"
	fi
}

function chruby_version_prompt {
	if declare -f -F chruby &> /dev/null; then
		if declare -f -F chruby_auto &> /dev/null; then
			chruby_auto
		fi

		ruby_version=$(ruby --version | awk '{print $1, $2;}') || return

		if ! chruby | grep -q '\*'; then
			ruby_version="${ruby_version} (system)"
		fi
		echo -e "${CHRUBY_THEME_PROMPT_PREFIX}${ruby_version}${CHRUBY_THEME_PROMPT_SUFFIX}"
	fi
}

function ruby_version_prompt {
	if [[ "${THEME_SHOW_RUBY_PROMPT}" = "true" ]]; then
		echo -e "$(rbfu_version_prompt)$(rbenv_version_prompt)$(rvm_version_prompt)$(chruby_version_prompt)"
	fi
}

function k8s_context_prompt {
	echo -e "$(kubectl config current-context 2> /dev/null)"
}

function virtualenv_prompt {
	if [[ -n "$VIRTUAL_ENV" ]]; then
		virtualenv=$(basename "$VIRTUAL_ENV")
		echo -e "$VIRTUALENV_THEME_PROMPT_PREFIX$virtualenv$VIRTUALENV_THEME_PROMPT_SUFFIX"
	fi
}

function condaenv_prompt {
	if [[ $CONDA_DEFAULT_ENV ]]; then
		echo -e "${CONDAENV_THEME_PROMPT_PREFIX}${CONDA_DEFAULT_ENV}${CONDAENV_THEME_PROMPT_SUFFIX}"
	fi
}

function py_interp_prompt {
	py_version=$(python --version 2>&1 | awk 'NR==1{print "py-"$2;}') || return
	echo -e "${PYTHON_THEME_PROMPT_PREFIX}${py_version}${PYTHON_THEME_PROMPT_SUFFIX}"
}

function python_version_prompt {
	echo -e "$(virtualenv_prompt)$(condaenv_prompt)$(py_interp_prompt)"
}

function git_user_info {
	# support two or more initials, set by 'git pair' plugin
	SCM_CURRENT_USER=$(git config user.initials | sed 's% %+%')
	# if `user.initials` weren't set, attempt to extract initials from `user.name`
	[[ -z "${SCM_CURRENT_USER}" ]] && SCM_CURRENT_USER=$(printf "%s" "$(for word in $(git config user.name | PERLIO=:utf8 perl -pe '$_=lc'); do printf "%s" "${word:0:1}"; done)")
	[[ -n "${SCM_CURRENT_USER}" ]] && printf "%s" "$SCM_THEME_CURRENT_USER_PREFFIX$SCM_CURRENT_USER$SCM_THEME_CURRENT_USER_SUFFIX"
}

function clock_char {
	CLOCK_CHAR=${THEME_CLOCK_CHAR:-"⌚"}
	CLOCK_CHAR_COLOR=${THEME_CLOCK_CHAR_COLOR:-"$normal"}
	SHOW_CLOCK_CHAR=${THEME_SHOW_CLOCK_CHAR:-"true"}

	if [[ "${SHOW_CLOCK_CHAR}" = "true" ]]; then
		echo -e "${CLOCK_CHAR_COLOR}${CLOCK_CHAR_THEME_PROMPT_PREFIX}${CLOCK_CHAR}${CLOCK_CHAR_THEME_PROMPT_SUFFIX}"
	fi
}

function clock_prompt {
	CLOCK_COLOR=${THEME_CLOCK_COLOR:-"$normal"}
	CLOCK_FORMAT=${THEME_CLOCK_FORMAT:-"%H:%M:%S"}
	[ -z "$THEME_SHOW_CLOCK" ] && THEME_SHOW_CLOCK=${THEME_CLOCK_CHECK:-"true"}
	SHOW_CLOCK=$THEME_SHOW_CLOCK

	if [[ "${SHOW_CLOCK}" = "true" ]]; then
		CLOCK_STRING=$(date +"${CLOCK_FORMAT}")
		echo -e "${CLOCK_COLOR}${CLOCK_THEME_PROMPT_PREFIX}${CLOCK_STRING}${CLOCK_THEME_PROMPT_SUFFIX}"
	fi
}

function user_host_prompt {
	if [[ "${THEME_SHOW_USER_HOST}" = "true" ]]; then
		echo -e "${USER_HOST_THEME_PROMPT_PREFIX}\u@\h${USER_HOST_THEME_PROMPT_SUFFIX}"
	fi
}

# backwards-compatibility
function git_prompt_info {
	_git-hide-status && return
	git_prompt_vars
	echo -e "${SCM_PREFIX}${SCM_BRANCH}${SCM_STATE}${SCM_SUFFIX}"
}

function p4_prompt_info() {
	p4_prompt_vars
	echo -e "${SCM_PREFIX}${SCM_BRANCH}:${SCM_CHANGE}${SCM_STATE}${SCM_SUFFIX}"
}

function svn_prompt_info {
	svn_prompt_vars
	echo -e "${SCM_PREFIX}${SCM_BRANCH}${SCM_STATE}${SCM_SUFFIX}"
}

function hg_prompt_info() {
	hg_prompt_vars
	echo -e "${SCM_PREFIX}${SCM_BRANCH}:${SCM_CHANGE#*:}${SCM_STATE}${SCM_SUFFIX}"
}

function scm_char {
	scm_prompt_char
	echo -e "${SCM_THEME_CHAR_PREFIX}${SCM_CHAR}${SCM_THEME_CHAR_SUFFIX}"
}

function prompt_char {
	scm_char
}

function battery_char {
	if [[ "${THEME_BATTERY_PERCENTAGE_CHECK}" = true ]]; then
		echo -e "${bold_red}$(battery_percentage)%"
	fi
}

if ! _command_exists battery_charge; then
	# if user has installed battery plugin, skip this...
	function battery_charge() {
		# no op
		echo -n
	}
fi

# The battery_char function depends on the presence of the battery_percentage function.
# If battery_percentage is not defined, then define battery_char as a no-op.
if ! _command_exists battery_percentage; then
	function battery_char() {
		# no op
		echo -n
	}
fi

function aws_profile {
	if [[ $AWS_DEFAULT_PROFILE ]]; then
		echo -e "${AWS_DEFAULT_PROFILE}"
	else
		echo -e "default"
	fi
}

function __check_precmd_conflict() {
	local f
	for f in "${precmd_functions[@]}"; do
		if [[ "${f}" == "${1}" ]]; then
			return 0
		fi
	done
	return 1
}

function safe_append_prompt_command {
	local prompt_re

	if [ "${__bp_imported}" == "defined" ]; then
		# We are using bash-preexec
		if ! __check_precmd_conflict "${1}"; then
			precmd_functions+=("${1}")
		fi
	else
		# Set OS dependent exact match regular expression
		if [[ ${OSTYPE} == darwin* ]]; then
			# macOS
			prompt_re="[[:<:]]${1}[[:>:]]"
		else
			# Linux, FreeBSD, etc.
			prompt_re="\<${1}\>"
		fi

		if [[ ${PROMPT_COMMAND} =~ ${prompt_re} ]]; then
			return
		elif [[ -z ${PROMPT_COMMAND} ]]; then
			PROMPT_COMMAND="${1}"
		else
			PROMPT_COMMAND="${1};${PROMPT_COMMAND}"
		fi
	fi
}

function _save-and-reload-history() {
#!/usr/bin/env bash

SCM_THEME_PROMPT_DIRTY=" ${red}✗"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓"
SCM_THEME_PROMPT_PREFIX="(${yellow}"
SCM_THEME_PROMPT_SUFFIX="${normal})"

GIT_THEME_PROMPT_DIRTY=" ${red}✗"
GIT_THEME_PROMPT_CLEAN=" ${bold_green}✓"
GIT_THEME_PROMPT_PREFIX="(${yellow}"
GIT_THEME_PROMPT_SUFFIX="${normal})"

RVM_THEME_PROMPT_PREFIX=""
RVM_THEME_PROMPT_SUFFIX=""

function prompt_command() {
    dtime="$(clock_prompt)"
    user_host="${green}\u@${cyan}\h${normal}"
    current_dir="${bold_blue}\w${normal}"
    rvm_ruby="${bold_red}$(ruby_version_prompt)${normal}"
    git_branch="$(scm_prompt_info)${normal}"
    prompt="${bold_green}\$${normal} "
    arrow="${bold_white}▶${normal} "
    prompt="${bold_green}\$${normal} "

    PS1="${dtime}${user_host}:${current_dir} ${rvm_ruby} ${git_branch}
      $arrow $prompt"
}

THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"$yellow"}
#!/usr/bin/env bash
#
# This theme was obviously inspired a lot by
#
# - Demula theme
#
# which in itself was inspired by :
#
# - Ronacher's dotfiles (mitsuhikos) - http://github.com/mitsuhiko/dotfiles/tree/master/bash/
# - Glenbot - http://theglenbot.com/custom-bash-shell-for-development/
# - My extravagant zsh - http://stevelosh.com/blog/2010/02/my-extravagant-zsh-prompt/
# - Monokai colors - http://monokai.nl/blog/2006/07/15/textmate-color-theme/
# - Bash_it modern theme
#
# Hawaii50 theme supports :
#
# - configurable directory length
# - hg, svn, git detection (I work in all of them)
# - virtualenv, rvm + gemsets
#
# Screenshot: http://i.imgur.com/4IAMJ.png
#
# by Ryan Kanno <ryankanno@localkinegrinds.com>
#
# And yes, we code out in Hawaii. :D
#
# Note: I also am really new to this bash scripting game, so if you see things
# that are flat out wrong, or if you think of something neat, just send a pull
# request.  This probably only works on a Mac - as some functions are OS
# specific like getting ip, etc.
#

# IMPORTANT THINGS TO CHANGE ==================================================

# Show IP in prompt
# One thing to be weary about if you have slow Internets
IP_ENABLED=1

# virtual prompts
VIRTUAL_PROMPT_ENABLED=1

# COLORS ======================================================================
ORANGE='\[\e[0;33m\]'

DEFAULT_COLOR="${white}"

USER_COLOR="${purple}"
SUPERUSER_COLOR="${red}"
MACHINE_COLOR=$ORANGE
IP_COLOR=$ORANGE
DIRECTORY_COLOR="${green}"

VE_COLOR="${cyan}"
RVM_COLOR="${cyan}"

REF_COLOR="${purple}"

# SCM prompts
SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
SCM_THEME_PROMPT_PREFIX=' on '
SCM_THEME_PROMPT_SUFFIX=''

# rvm prompts
RVM_THEME_PROMPT_PREFIX=''
RVM_THEME_PROMPT_SUFFIX=''

# virtualenv prompts
VIRTUALENV_THEME_PROMPT_PREFIX=''
VIRTUALENV_THEME_PROMPT_SUFFIX=''

VIRTUAL_THEME_PROMPT_PREFIX=' using '
VIRTUAL_THEME_PROMPT_SUFFIX=''

# Max length of PWD to display
MAX_PWD_LENGTH=20

# Max length of Git Hex to display
MAX_GIT_HEX_LENGTH=5

# IP address
IP_SEPARATOR=', '

# FUNCS =======================================================================

function get_ip_info {
    myip=$(curl -s checkip.dyndns.org | grep -Eo '[0-9\.]+')
    echo -e "$(ips | sed -e :a -e '$!N;s/\n/${IP_SEPARATOR}/;ta' | sed -e 's/127\.0\.0\.1\${IP_SEPARATOR}//g'), ${myip}"
}

# Displays ip prompt
function ip_prompt_info() {
    if [[ $IP_ENABLED == 1 ]]; then
        echo -e " ${DEFAULT_COLOR}(${IP_COLOR}$(get_ip_info)${DEFAULT_COLOR})"
    fi
}

# Displays virtual info prompt (virtualenv/rvm)
function virtual_prompt_info() {
    local virtual_env_info=$(virtualenv_prompt)
    local rvm_info=$(ruby_version_prompt)
    local virtual_prompt=""

    local prefix=${VIRTUAL_THEME_PROMPT_PREFIX}
    local suffix=${VIRTUAL_THEME_PROMPT_SUFFIX}

    # If no virtual info, just return
    [[ -z "$virtual_env_info" && -z "$rvm_info" ]] && return

    # If virtual_env info present, append to prompt
    [[ -n "$virtual_env_info" ]] && virtual_prompt="virtualenv: ${VE_COLOR}$virtual_env_info${DEFAULT_COLOR}"

    if [[ -n "$rvm_info" ]]
    then
        [[ -n "$virtual_env_info" ]] && virtual_prompt="$virtual_prompt, "
        virtual_prompt="${virtual_prompt}rvm: ${RVM_COLOR}$rvm_info${DEFAULT_COLOR}"
    fi
    echo -e "$prefix$virtual_prompt$suffix"
}

# Parse git info
function git_prompt_info() {
    if [[ -n $(git status -s 2> /dev/null |grep -v ^# |grep -v "working directory clean") ]]; then
        state=${GIT_THEME_PROMPT_DIRTY:-$SCM_THEME_PROMPT_DIRTY}
    else
        state=${GIT_THEME_PROMPT_CLEAN:-$SCM_THEME_PROMPT_CLEAN}
    fi
    prefix=${GIT_THEME_PROMPT_PREFIX:-$SCM_THEME_PROMPT_PREFIX}
    suffix=${GIT_THEME_PROMPT_SUFFIX:-$SCM_THEME_PROMPT_SUFFIX}
    ref=$(git symbolic-ref HEAD 2> /dev/null) || return
    commit_id=$(git rev-parse HEAD 2>/dev/null) || return

    echo -e "$prefix${REF_COLOR}${ref#refs/heads/}${DEFAULT_COLOR}:${commit_id:0:$MAX_GIT_HEX_LENGTH}$state$suffix"
}

# Parse hg info
function hg_prompt_info() {
    if [[ -n $(hg status 2> /dev/null) ]]; then
        state=${HG_THEME_PROMPT_DIRTY:-$SCM_THEME_PROMPT_DIRTY}
    else
        state=${HG_THEME_PROMPT_CLEAN:-$SCM_THEME_PROMPT_CLEAN}
    fi
    prefix=${HG_THEME_PROMPT_PREFIX:-$SCM_THEME_PROMPT_PREFIX}
    suffix=${HG_THEME_PROMPT_SUFFIX:-$SCM_THEME_PROMPT_SUFFIX}
    branch=$(hg summary 2> /dev/null | grep branch | awk '{print $2}')
    changeset=$(hg summary 2> /dev/null | grep parent | awk '{print $2}')

    echo -e "$prefix${REF_COLOR}${branch}${DEFAULT_COLOR}:${changeset#*:}$state$suffix"
}

# Parse svn info
function svn_prompt_info() {
    if [[ -n $(svn status --ignore-externals -q 2> /dev/null) ]]; then
        state=${SVN_THEME_PROMPT_DIRTY:-$SCM_THEME_PROMPT_DIRTY}
    else
        state=${SVN_THEME_PROMPT_CLEAN:-$SCM_THEME_PROMPT_CLEAN}
    fi
    prefix=${SVN_THEME_PROMPT_PREFIX:-$SCM_THEME_PROMPT_PREFIX}
    suffix=${SVN_THEME_PROMPT_SUFFIX:-$SCM_THEME_PROMPT_SUFFIX}
    ref=$(svn info 2> /dev/null | awk -F/ '/^URL:/ { for (i=0; i<=NF; i++) { if ($i == "branches" || $i == "tags" ) { print $(i+1); break }; if ($i == "trunk") { print $i; break } } }') || return
    [[ -z $ref ]] && return

    revision=$(svn info 2> /dev/null | sed -ne 's#^Revision: ##p' )

    echo -e "$prefix${REF_COLOR}$ref${DEFAULT_COLOR}:$revision$state$suffix"
}

# Displays last X characters of pwd
function limited_pwd() {

    # Replace $HOME with ~ if possible
    RELATIVE_PWD=${PWD/#$HOME/\~}

    local offset=$((${#RELATIVE_PWD}-$MAX_PWD_LENGTH))

    if [ $offset -gt "0" ]
    then
        local truncated_symbol="..."
        TRUNCATED_PWD=${RELATIVE_PWD:$offset:$MAX_PWD_LENGTH}
        echo -e "${truncated_symbol}/${TRUNCATED_PWD#*/}"
    else
        echo -e "${RELATIVE_PWD}"
    fi
}

# Displays the current prompt
function prompt() {
    local UC=$USER_COLOR
    [ $UID -eq "0" ] && UC=$SUPERUSER_COLOR

    if [[ $VIRTUAL_PROMPT_ENABLED == 1 ]]; then
        PS1="$(scm_char) ${UC}\u ${DEFAULT_COLOR}at ${MACHINE_COLOR}\h$(ip_prompt_info) ${DEFAULT_COLOR}in ${DIRECTORY_COLOR}$(limited_pwd)${DEFAULT_COLOR}$(virtual_prompt_info)$(scm_prompt_info)${reset_color} \$ "
    else
        PS1="$(scm_char) ${UC}\u ${DEFAULT_COLOR}at ${MACHINE_COLOR}\h$(ip_prompt_info) ${DEFAULT_COLOR}in ${DIRECTORY_COLOR}$(limited_pwd)${DEFAULT_COLOR}$(scm_prompt_info)${reset_color} \$ "
    fi
#!/usr/bin/env bash

# based of the candy theme, but minimized by odbol
function prompt_command() {
    PS1="$(clock_prompt) ${reset_color}${white}\w${reset_color}$(scm_prompt_info)${blue} →${bold_blue} ${reset_color} ";
}

THEME_CLOCK_COLOR=${THEME_CLOCK_COLOR:-"$blue"}
THEME_CLOCK_FORMAT=${THEME_CLOCK_FORMAT:-"%I:%M:%S"}

#!/usr/bin/env bash

# https://github.com/koalaman/shellcheck/wiki/Sc2154
# shellcheck disable=SC2154

function _user-prompt() {
  local -r user='\\u'

  if [[ "${EUID}" -eq 0 ]]; then
    # Privileged users:
    local -r user_color="${bold_red}"
  else
    # Standard users:
    local -r user_color="${bold_green}"
  fi

  # Print the current user's name (colored according to their current EUID):
  echo -e "${user_color}${user}${normal}"
}

function _host-prompt() {
  local -r host='\\h'

  # Check whether or not $SSH_TTY is set:
  if [[ -z "${SSH_TTY}" ]]; then
    # For local hosts, set the host's prompt color to blue:
    local -r host_color="${bold_blue}"
  else
    # For remote hosts, set the host's prompt color to red:
    local -r host_color="${bold_red}"
  fi

  # Print the current hostname (colored according to $SSH_TTY's status):
  echo -e "${host_color}${host}${normal}"
}

function _user-at-host-prompt() {
  # Concatenate the user and host prompts into: user@host:
  echo -e "$(_user-prompt)${bold_white}@$(_host-prompt)"
}

function _exit-status-prompt() {
  local -r prompt_string="${1}"
  local -r exit_status="${2}"

  # Check the exit status of the last command captured by $exit_status:
  if [[ "${exit_status}" -eq 0 ]]; then
    # For commands that return an exit status of zero, set the exit status's
    # notifier to green:
    local -r exit_status_color="${bold_green}"
  else
    # For commands that return a non-zero exit status, set the exit status's
    # notifier to red:
    local -r exit_status_color="${bold_red}"
  fi

  echo -ne "${exit_status_color}"
  if [[ "${prompt_string}" -eq 1 ]]; then
    # $PS1:
    echo -e " +${normal} "
  elif [[ "${prompt_string}" -eq 2 ]]; then
    # $PS2:
    echo -e " |${normal} "
  else
    # Default:
    echo -e " ?${normal} "
  fi
}

function _ps1() {
  local -r time='\\t'

  echo -ne "${bold_white}${time} "
  echo -ne "$(_user-at-host-prompt)"
  echo -e "${bold_white}:${normal}${PWD}"
  echo -e "$(_exit-status-prompt 1 "${exit_status}")"
}

function _ps2() {
  echo -e "$(_exit-status-prompt 2 "${exit_status}")"
}

function prompt_command() {
  # Capture the exit status of the last command:
  local -r exit_status="${?}"

  # Build the $PS1 prompt:
  PS1="$(_ps1)"

  # Build the $PS2 prompt:
  PS2="$(_ps2)"
}

safe_append_prompt_command prompt_command

#!/bin/bash

# Two line prompt showing the following information:
# (time) SCM [username@hostname] pwd (SCM branch SCM status)
# →
#
# Example:
# (14:00:26) ± [foo@bar] ~/.bash_it (master ✓)
# →
#
# The arrow on the second line is showing the exit status of the last command:
# * Green: 0 exit status
# * Red: non-zero exit status
#
# The exit code functionality currently doesn't work if you are using the 'fasd' plugin,
# since 'fasd' is messing with the $PROMPT_COMMAND

RANDOM_COLOR_FILE=$HOME/.nwinkler_random_colors

function randomize_nwinkler {
  declare -a AVAILABLE_COLORS

  AVAILABLE_COLORS=(
    $black
    $red
    $green
    $yellow
    $blue
    $purple
    $cyan
    $white
    $orange
    $bold_black
    $bold_red
    $bold_green
    $bold_yellow
    $bold_blue
    $bold_purple
    $bold_cyan
    $bold_white
    $bold_orange
  )
  # Uncomment these to allow underlines:
    #$underline_black
    #$underline_red
    #$underline_green
    #$underline_yellow
    #$underline_blue
    #$underline_purple
    #$underline_cyan
    #$underline_white
    #$underline_orange
  #)

  USERNAME_COLOR=${AVAILABLE_COLORS[$RANDOM % ${#AVAILABLE_COLORS[@]} ]}
  HOSTNAME_COLOR=${AVAILABLE_COLORS[$RANDOM % ${#AVAILABLE_COLORS[@]} ]}
  TIME_COLOR=${AVAILABLE_COLORS[$RANDOM % ${#AVAILABLE_COLORS[@]} ]}
  THEME_CLOCK_COLOR=$TIME_COLOR
  PATH_COLOR=${AVAILABLE_COLORS[$RANDOM % ${#AVAILABLE_COLORS[@]} ]}

  echo "$USERNAME_COLOR,$HOSTNAME_COLOR,$TIME_COLOR,$PATH_COLOR," > $RANDOM_COLOR_FILE
}

if [ -f $RANDOM_COLOR_FILE ];
then
  # read the colors already stored in the file
  IFS=',' read -ra COLORS < $RANDOM_COLOR_FILE
  USERNAME_COLOR=${COLORS[0]}
  HOSTNAME_COLOR=${COLORS[1]}
  TIME_COLOR=${COLORS[2]}
  THEME_CLOCK_COLOR=$TIME_COLOR
  PATH_COLOR=${COLORS[3]}
else
  # No colors stored yet. Generate them!
  randomize_nwinkler

  echo
  echo "Looks like you are using the nwinkler_random_color bashit theme for the first time."
  echo "Random colors have been generated to be used in your prompt."
  echo "If you don't like them, run the command:"
  echo "  randomize_nwinkler"
  echo "until you get a combination that you like."
  echo
fi

PROMPT_END_CLEAN="${green}→${reset_color}"
PROMPT_END_DIRTY="${red}→${reset_color}"

function prompt_end() {
  echo -e "$PROMPT_END"
}

prompt_setter() {
  local exit_status=$?
  if [[ $exit_status -eq 0 ]]; then PROMPT_END=$PROMPT_END_CLEAN
    else PROMPT_END=$PROMPT_END_DIRTY
  fi
  # Save history
  history -a
  history -c
  history -r
  PS1="($(clock_prompt)${reset_color}) $(scm_char) [${USERNAME_COLOR}\u${reset_color}@${HOSTNAME_COLOR}\H${reset_color}] ${PATH_COLOR}\w${reset_color}$(scm_prompt_info) ${reset_color}\n$(prompt_end) "
  PS2='> '
  PS4='+ '
}

safe_append_prompt_command prompt_setter

SCM_THEME_PROMPT_DIRTY=" ${bold_red}✗${normal}"
SCM_THEME_PROMPT_CLEAN=" ${bold_green}✓${normal}"
# For unstaged(*) and staged(+) values next to branch name in __git_ps1
GIT_PS1_SHOWDIRTYSTATE="enabled"

function rvm_version_prompt {
  local gemset=$(echo $GEM_HOME | awk -F'@' '{print $2}')

  [ "$gemset" != "" ] && gemset="@$gemset"
  local version=$(echo $MY_RUBY_HOME | awk -F'-' '{print $2}')

  [ "$version" == "1.9.2" ] && version=""

  local full="$version$gemset"

  [ "$full" != "" ] && echo "$full"
}

function prompt_command() {
    # Check http://github.com/Sirupsen/dotfiles for screenshot
    PS1="$blue\W/$bold_blue$(rvm_version_prompt)$bold_green$(__git_ps1 " (%s)") ${normal}$ "
}
# We use PROMPT_COMMAND and the DEBUG trap to generate timing information. We try
# to avoid clobbering what we can, and try to give the user ways around our
# clobbers, if it's unavoidable. For example, PROMPT_COMMAND is appended to,
# and the DEBUG trap is layered with other traps, if it exists.

# A bash quirk is that the DEBUG trap is fired every time a command runs, even
# if it's later on in the pipeline. If uncorrected, this could cause bad timing
# data for commands like `slow | slow | fast`, since the timer starts at the start
# of the "fast" command.

# To solve this, we set a flag `STARSHIP_PREEXEC_READY` when the prompt is
# drawn, and only start the timer if this flag is present. That way, timing is
# for the entire command, and not just a portion of it.

# Will be run before *every* command (even ones in pipes!)
starship_preexec() {
    # Save previous command's last argument, otherwise it will be set to "starship_preexec"
    local PREV_LAST_ARG=$1

    # Avoid restarting the timer for commands in the same pipeline
    if [ "$STARSHIP_PREEXEC_READY" = "true" ]; then
        STARSHIP_PREEXEC_READY=false
        STARSHIP_START_TIME=$(::STARSHIP:: time)
    fi

    : "$PREV_LAST_ARG"
}

# Will be run before the prompt is drawn
starship_precmd() {
    # Save the status, because commands in this pipeline will change $?
    STARSHIP_CMD_STATUS=$?

    local NUM_JOBS=0
    # Evaluate the number of jobs before running the preseved prompt command, so that tools
    # like z/autojump, which background certain jobs, do not cause spurious background jobs
    # to be displayed by starship. Also avoids forking to run `wc`, slightly improving perf.
    for job in $(jobs -p); do [[ $job ]] && ((NUM_JOBS++)); done

    # Run the bash precmd function, if it's set. If not set, evaluates to no-op
    "${starship_precmd_user_func-:}"

    eval "$_PRESERVED_PROMPT_COMMAND"

    # Prepare the timer data, if needed.
    if [[ $STARSHIP_START_TIME ]]; then
        STARSHIP_END_TIME=$(::STARSHIP:: time)
        STARSHIP_DURATION=$((STARSHIP_END_TIME - STARSHIP_START_TIME))
        PS1="$(::STARSHIP:: prompt --status=$STARSHIP_CMD_STATUS --jobs="$NUM_JOBS" --cmd-duration=$STARSHIP_DURATION)"
        unset STARSHIP_START_TIME
    else
        PS1="$(::STARSHIP:: prompt --status=$STARSHIP_CMD_STATUS --jobs="$NUM_JOBS")"
    fi
    STARSHIP_PREEXEC_READY=true  # Signal that we can safely restart the timer
}

# If the user appears to be using https://github.com/rcaloras/bash-preexec,
# then hook our functions into their framework.
if [[ "${__bp_imported:-}" == "defined" || $preexec_functions || $precmd_functions ]]; then
    # bash-preexec needs a single function--wrap the args into a closure and pass
    starship_preexec_all(){ starship_preexec "$_"; }
    preexec_functions+=(starship_preexec_all)
    precmd_functions+=(starship_precmd)
else
    # We want to avoid destroying an existing DEBUG hook. If we detect one, create
    # a new function that runs both the existing function AND our function, then
    # re-trap DEBUG to use this new function. This prevents a trap clobber.
    dbg_trap="$(trap -p DEBUG | cut -d' ' -f3 | tr -d \')"
    if [[ -z "$dbg_trap" ]]; then
        trap 'starship_preexec "$_"' DEBUG
    elif [[ "$dbg_trap" != 'starship_preexec "$_"' && "$dbg_trap" != 'starship_preexec_all "$_"' ]]; then
        starship_preexec_all() {
            local PREV_LAST_ARG=$1 ; $dbg_trap; starship_preexec; : "$PREV_LAST_ARG";
        }
        trap 'starship_preexec_all "$_"' DEBUG
    fi

    # Finally, prepare the precmd function and set up the start time. We will avoid to
    # add multiple instances of the starship function and keep other user functions if any.
    if [[ -z "$PROMPT_COMMAND" ]]; then
        PROMPT_COMMAND="starship_precmd"
    elif [[ "$PROMPT_COMMAND" != *"starship_precmd"* ]]; then
        # Appending to PROMPT_COMMAND breaks exit status ($?) checking.
        # Prepending to PROMPT_COMMAND breaks "command duration" module.
        # So, we are preserving the existing PROMPT_COMMAND
        # which will be executed later in the starship_precmd function
        _PRESERVED_PROMPT_COMMAND="$PROMPT_COMMAND"
        PROMPT_COMMAND="starship_precmd"
    fi
fi

# Set up the start time and STARSHIP_SHELL, which controls shell-specific sequences
STARSHIP_START_TIME=$(::STARSHIP:: time)
export STARSHIP_SHELL="bash"

sudo: required
language: java
dist: trusty
jdk:
  - openjdk8

cache:
  directories:
  - $HOME/.m2
  - $HOME/.ivy2

services:
  - docker

addons:
  hosts:
    - petstore.swagger.io

before_install:
  # to run petstore server locally via docker
  - docker pull swaggerapi/petstore
  - docker run -d -e SWAGGER_HOST=http://petstore.swagger.io -e SWAGGER_BASE_PATH=/v2 -p 80:8080 swaggerapi/petstore
  - docker ps -a
  # Add bats test framework and cURL for Bash script integration tests
  - sudo add-apt-repository ppa:duggan/bats --yes
  - sudo apt-get update -qq
  - sudo apt-get install -qq bats
  - sudo apt-get install -qq curl

  # show host table to confirm petstore.swagger.io is mapped to localhost
  - cat /etc/hosts

script:
  # fail fast
  - set -e
<project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://maven.apache.org/POM/4.0.0" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
    <parent>
        <groupId>org.sonatype.oss</groupId>
        <artifactId>oss-parent</artifactId>
        <version>5</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>
    <groupId>io.swagger</groupId>
    <artifactId>swagger-codegen-project</artifactId>
    <packaging>pom</packaging>
    <name>swagger-codegen-project</name>
    <version>2.4.19-SNAPSHOT</version>
    <url>https://github.com/swagger-api/swagger-codegen</url>
    <scm>
        <connection>scm:git:git@github.com:swagger-api/swagger-codegen.git</connection>
        <developerConnection>scm:git:git@github.com:swagger-api/swagger-codegen.git</developerConnection>
        <url>https://github.com/swagger-api/swagger-codegen</url>
    </scm>
    <developers>
        <developer>
            <id>fehguy</id>
            <name>Tony Tam</name>
            <email>fehguy@gmail.com</email>
        </developer>
        <developer>
            <id>wing328</id>
            <name>William Cheng</name>
            <email>wing328hk@gmail.com</email>
        </developer>
    </developers>
    <issueManagement>
        <system>github</system>
        <url>https://github.com/swagger-api/swagger-codegen/issues</url>
    </issueManagement>
    <mailingLists>
        <mailingList>
            <name>swagger-swaggersocket</name>
            <archive>https://groups.google.com/forum/#!forum/swagger-swaggersocket</archive>
        </mailingList>
    </mailingLists>
    <licenses>
        <license>
            <name>Apache License 2.0</name>
            <url>http://www.apache.org/licenses/LICENSE-2.0.html</url>
            <distribution>repo</distribution>
        </license>
    </licenses>
    <build>
        <sourceDirectory>src/main/java</sourceDirectory>
        <outputDirectory>target/classes</outputDirectory>
        <extensions>
            <extension>
                <groupId>org.jvnet.wagon-svn</groupId>
                <artifactId>wagon-svn</artifactId>
                <version>1.8</version>
            </extension>
            <extension>
                <groupId>org.apache.maven.wagon</groupId>
                <artifactId>wagon-ssh-external</artifactId>
                <version>1.0-alpha-6</version>
            </extension>
            <extension>
                <groupId>org.apache.maven.wagon</groupId>
                <artifactId>wagon-webdav</artifactId>
                <version>1.0-beta-1</version>
            </extension>
        </extensions>
        <defaultGoal>install</defaultGoal>
        <directory>target</directory>
        <finalName>${project.artifactId}-${project.version}</finalName>
        <plugins>
            <plugin>
                <groupId>net.revelc.code</groupId>
                <artifactId>formatter-maven-plugin</artifactId>
                <!-- Uncomment this to format before checkstyle -->
                <!-- <executions>
                    <execution>
                        <id>format</id>
                        <phase>validate</phase>
                        <goals>
                            <goal>format</goal>
                        </goals>
                    </execution>
                </executions> -->
                <configuration>
                    <compilerSource>1.8</compilerSource>
                    <compilerCompliance>1.8</compilerCompliance>
                    <compilerTargetPlatform>1.8</compilerTargetPlatform>
                    <lineEnding>LF</lineEnding>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-checkstyle-plugin</artifactId>
                <version>2.17</version>
                <executions>
                    <execution>
                        <id>validate</id>
                        <phase>validate</phase>
                        <configuration>
                            <configLocation>google_checkstyle.xml</configLocation>
                            <!-- Don't include generated sources a la http://stackoverflow.com/a/30406454 -->
                            <sourceDirectory>${project.build.sourceDirectory}</sourceDirectory>
                            <encoding>UTF-8</encoding>
                            <consoleOutput>true</consoleOutput>
                            <failsOnError>true</failsOnError>
                            <linkXRef>false</linkXRef>
                        </configuration>
                        <goals>
                            <goal>check</goal>
                        </goals>
                    </execution>
                </executions>
                <dependencies>
                    <dependency>
                        <groupId>com.puppycrawl.tools</groupId>
                        <artifactId>checkstyle</artifactId>
                        <version>6.19</version>
                    </dependency>
                </dependencies>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>${surefire-version}</version>
                <configuration>
                    <testNGArtifactName>none:none</testNGArtifactName>
                    <argLine>-XX:+StartAttachListener</argLine>
                </configuration>
                <executions>
                    <execution>
                        <id>test-testng</id>
                        <phase>test</phase>
                        <goals>
                            <goal>test</goal>
                        </goals>
                        <configuration>
                            <junitArtifactName>none:none</junitArtifactName>
                            <testNGArtifactName>org.testng:testng</testNGArtifactName>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <artifactId>maven-dependency-plugin</artifactId>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>copy-dependencies</goal>
                        </goals>
                        <configuration>
                            <outputDirectory>${project.build.directory}/lib</outputDirectory>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.6.1</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <version>3.0.2</version>
                <configuration>
                    <archive>
                        <manifestEntries>
                            <mode>development</mode>
                            <url>${project.url}</url>
                            <implementation-version>${project.version}</implementation-version>
                            <package>io.swagger</package>
                        </manifestEntries>
                    </archive>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-site-plugin</artifactId>
                <version>3.5.1</version>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-release-plugin</artifactId>
                <version>2.5.3</version>
            </plugin>

            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-javadoc-plugin</artifactId>
                <version>2.10.4</version>
                <configuration>
                    <aggregate>true</aggregate>
                    <source>1.8</source>
                    <encoding>UTF-8</encoding>
                    <maxmemory>1g</maxmemory>
                    <excludePackageNames>${javadoc.package.exclude}</excludePackageNames>
                </configuration>
                <executions>
                    <execution>
                        <id>attach-javadocs</id>
                        <phase>verify</phase>
                        <goals>
                            <goal>jar</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-source-plugin</artifactId>
                <version>3.0.1</version>
                <executions>
                    <execution>
                        <id>attach-sources</id>
                        <phase>verify</phase>
                        <goals>
                            <goal>jar-no-fork</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-enforcer-plugin</artifactId>
                <version>1.4.1</version>
                <executions>
                    <execution>
                        <id>enforce-versions</id>
                        <goals>
                            <goal>enforce</goal>
                        </goals>
                        <configuration>
                            <rules>
                                <requireMavenVersion>
                                    <version>3.2.5</version>
                                </requireMavenVersion>
                            </rules>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
        <pluginManagement>
            <plugins>
                <plugin>
                    <groupId>net.revelc.code</groupId>
                    <artifactId>formatter-maven-plugin</artifactId>
                    <version>0.5.2</version>
                </plugin>
            </plugins>
        </pluginManagement>
    </build>
    <profiles>
        <profile>
            <id>release-profile</id>
            <properties>
                <skipTests>true</skipTests>
            </properties>
            <build>
                <plugins>
                    <plugin>
                        <groupId>net.alchim31.maven</groupId>
                        <artifactId>scala-maven-plugin</artifactId>
                        <executions>
                            <execution>
                                <goals>
                                    <goal>compile</goal>
                                    <goal>testCompile</goal>
                                </goals>
                            </execution>
                        </executions>
                        <configuration/>
                    </plugin>
                    <plugin>
                        <groupId>org.codehaus.mojo</groupId>
                        <artifactId>build-helper-maven-plugin</artifactId>
                        <executions>
                            <execution>
                                <id>add-source</id>
                                <phase>prepare-package</phase>
                                <goals>
                                    <goal>add-source</goal>
                                </goals>
                                <configuration>
                                    <sources>
                                        <source>src/main/scala</source>
                                    </sources>
                                </configuration>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
        <profile>
            <id>release-sign-artifacts</id>
            <activation>
                <property>
                    <name>performRelease</name>
                    <value>true</value>
                </property>
            </activation>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-gpg-plugin</artifactId>
                        <executions>
                            <execution>
                                <id>sign-artifacts</id>
                                <phase>verify</phase>
                                <goals>
                                    <goal>sign</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
        <!-- Samples -->
        <profile>
            <id>android-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/android/volley</module>
            </modules>
        </profile>
        <profile>
            <id>bash-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/bash</module>
            </modules>
        </profile>
        <profile>
            <id>clojure-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>clojure</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/clojure</module>
            </modules>
        </profile>
        <profile>
            <id>haskell-http-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>haskell-http-client</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/haskell-http-client</module>
            </modules>
        </profile>
        <profile>
            <id>haskell-http-client-integration-test</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>haskell-http-client</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/haskell-http-client/tests-integration</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-jersey1</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/jersey1</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-jersey2</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/jersey2</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-jersey2-java6</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/jersey2-java6</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-okhttp-gson</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/okhttp-gson</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-okhttp-gson-parcelable</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/okhttp-gson/parcelableModel</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-retrofit</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/retrofit</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-retrofit2</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/retrofit2</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-retrofit2-rx</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/retrofit2rx</module>
            </modules>
        </profile>
        <profile>
            <id>java-client-feign</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/java/feign</module>
            </modules>
        </profile>
        <profile>
            <id>javascript-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>javascript</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/javascript</module>
            </modules>
        </profile>
        <profile>
            <id>scala-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>scala</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/scala</module>
            </modules>
        </profile>
        <profile>
            <id>objc-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>objc</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/objc/default/SwaggerClientTests</module>
            </modules>
        </profile>
        <profile>
            <id>swift-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>swift</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/swift/default/SwaggerClientTests</module>
            </modules>
        </profile>
        <profile>
            <id>java-msf4j-server</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/java-msf4/</module>
            </modules>
        </profile>
        <profile>
            <id>jaxrs-cxf-server</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/jaxrs-cxf</module>
            </modules>
        </profile>
        <profile>
            <id>jaxrs-resteasy-server</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/jaxrs-resteasy/default</module>
            </modules>
        </profile>
        <profile>
            <id>jaxrs-resteasy-server-joda</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/jaxrs-resteasy/joda</module>
            </modules>
        </profile>
        <profile>
            <id>jaxrs-resteasy-eap-server</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/jaxrs-resteasy/eap</module>
            </modules>
        </profile>
        <profile>
            <id>jaxrs-resteasy-eap-server-joda</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/jaxrs-resteasy/eap-joda</module>
            </modules>
        </profile>
        <profile>
            <id>jaxrs-server</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/jaxrs/jersey2</module>
            </modules>
        </profile>
        <profile>
            <id>jaxrs-server-jersey1</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/jaxrs/jersey1</module>
            </modules>
        </profile>
        <profile>
            <id>typescript-fetch-client-tests-default</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/typescript-fetch/tests/default</module>
            </modules>
        </profile>
        <profile>
            <id>typescript-fetch-client-builds-default</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/typescript-fetch/builds/default</module>
            </modules>
        </profile>
        <profile>
            <id>typescript-fetch-client-builds-es6-target</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/typescript-fetch/builds/es6-target</module>
            </modules>
        </profile>
        <profile>
            <id>typescript-fetch-client-builds-with-npm-version</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/typescript-fetch/builds/with-npm-version</module>
            </modules>
        </profile>
        <profile>
            <id>typescript-angularjs-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/typescript-angularjs/npm</module>
            </modules>
        </profile>
        <profile>
            <id>typescript-node-npm-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/typescript-node/npm</module>
            </modules>
        </profile>
        <profile>
            <id>python-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/python</module>
            </modules>
        </profile>
        <profile>
            <id>ruby-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/ruby</module>
            </modules>
        </profile>
        <profile>
            <id>go-client</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/go</module>
            </modules>
        </profile>
        <profile>
            <id>spring-mvc</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/spring-mvc</module>
            </modules>
        </profile>
        <profile>
            <id>springboot-beanvalidation</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/springboot-beanvalidation</module>
            </modules>
        </profile>
        <profile>
            <id>springboot</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/springboot</module>
            </modules>
        </profile>
        <profile>
            <id>spring-cloud</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/spring-cloud</module>
            </modules>
        </profile>
        <profile>
            <id>scalatra-server</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/scalatra</module>
            </modules>
        </profile>
        <profile>
            <id>java-inflector</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/java-inflector</module>
            </modules>
        </profile>
        <profile>
            <id>java-undertowr</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>java</value>
                </property>
            </activation>
            <modules>
                <module>samples/server/petstore/undertow</module>
            </modules>
        </profile>
        <profile>
            <id>samples</id>
            <activation>
                <property>
                    <name>env</name>
                    <value>samples</value>
                </property>
            </activation>
            <modules>
                <module>samples/client/petstore/bash</module>
            </modules>
        </profile>
    </profiles>
    <modules>
        <module>modules/swagger-codegen</module>
        <module>modules/swagger-codegen-cli</module>
        <module>modules/swagger-codegen-maven-plugin</module>
        <module>modules/swagger-generator</module>
    </modules>
    <reporting>
        <outputDirectory>target/site</outputDirectory>
        <plugins>
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>${scala-maven-plugin-version}</version>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jxr-plugin</artifactId>
                <version>2.5</version>
                <configuration>
                    <aggregate>true</aggregate>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-project-info-reports-plugin</artifactId>
                <version>2.9</version>
                <reportSets>
                    <reportSet>
                        <reports>
                            <report>project-team</report>
                        </reports>
                    </reportSet>
                </reportSets>
            </plugin>
        </plugins>
    </reporting>
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.yaml</groupId>
                <artifactId>snakeyaml</artifactId>
                <version>${snakeyaml-version}</version>
            </dependency>
            <dependency>
                <groupId>junit</groupId>
                <artifactId>junit</artifactId>
                <version>${junit-version}</version>
                <scope>test</scope>
            </dependency>
            <dependency>
                <groupId>org.testng</groupId>
                <artifactId>testng</artifactId>
                <version>${testng-version}</version>
                <scope>test</scope>
            </dependency>
            <dependency>
                <groupId>org.jmockit</groupId>
                <artifactId>jmockit</artifactId>
                <version>${jmockit-version}</version>
                <scope>test</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
    <repositories>
        <repository>
            <id>sonatype-snapshots</id>
            <url>https://oss.sonatype.org/content/repositories/snapshots</url>
            <snapshots>
                <enabled>true</enabled>
            </snapshots>
        </repository>
    </repositories>
    <properties>
        <swagger-parser-version>1.0.54</swagger-parser-version>
        <scala-version>2.11.1</scala-version>
        <felix-version>3.3.0</felix-version>
        <swagger-core-version>1.6.1</swagger-core-version>
        <commons-io-version>2.4</commons-io-version>
        <commons-cli-version>1.2</commons-cli-version>
        <junit-version>4.13.1</junit-version>
        <jackson-version>2.10.1</jackson-version>
        <maven-plugin-version>1.0.0</maven-plugin-version>
        <commons-lang-version>3.4</commons-lang-version>
        <slf4j-version>1.7.12</slf4j-version>
        <scala-maven-plugin-version>3.2.1</scala-maven-plugin-version>
        <jmustache-version>1.12</jmustache-version>
        <testng-version>6.9.6</testng-version>
        <surefire-version>2.19.1</surefire-version>
        <jmockit-version>1.25</jmockit-version>
        <reflections-version>0.9.11</reflections-version>
        <snakeyaml-version>1.24</snakeyaml-version>
    </properties>
# bash/zsh completion support for core Git.
#
# Copyright (C) 2006,2007 Shawn O. Pearce <spearce@spearce.org>
# Conceptually based on gitcompletion (http://gitweb.hawaga.org.uk/).
# Distributed under the GNU General Public License, version 2.0.
#
# The contained completion routines provide support for completing:
#
#    *) local and remote branch names
#    *) local and remote tag names
#    *) .git/remotes file names
#    *) git 'subcommands'
#    *) git email aliases for git-send-email
#    *) tree paths within 'ref:path/to/file' expressions
#    *) file paths within current working directory and index
#    *) common --long-options
#
# To use these routines:
#
#    1) Copy this file to somewhere (e.g. ~/.git-completion.bash).
#    2) Add the following line to your .bashrc/.zshrc:
#        source ~/.git-completion.bash
#    3) Consider changing your PS1 to also show the current branch,
#       see git-prompt.sh for details.
#
# If you use complex aliases of form '!f() { ... }; f', you can use the null
# command ':' as the first command in the function body to declare the desired
# completion style.  For example '!f() { : git commit ; ... }; f' will
# tell the completion to use commit completion.  This also works with aliases
# of form "!sh -c '...'".  For example, "!sh -c ': git commit ; ... '".
#
# If you have a command that is not part of git, but you would still
# like completion, you can use __git_complete:
#
#   __git_complete gl git_log
#
# Or if it's a main command (i.e. git or gitk):
#
#   __git_complete gk gitk
#
# Compatible with bash 3.2.57.
#
# You can set the following environment variables to influence the behavior of
# the completion routines:
#
#   GIT_COMPLETION_CHECKOUT_NO_GUESS
#
#     When set to "1", do not include "DWIM" suggestions in git-checkout
#     and git-switch completion (e.g., completing "foo" when "origin/foo"
#     exists).
#
#   GIT_COMPLETION_SHOW_ALL
#
#     When set to "1" suggest all options, including options which are
#     typically hidden (e.g. '--allow-empty' for 'git commit').

case "$COMP_WORDBREAKS" in
*:*) : great ;;
*)   COMP_WORDBREAKS="$COMP_WORDBREAKS:"
esac

# Discovers the path to the git repository taking any '--git-dir=<path>' and
# '-C <path>' options into account and stores it in the $__git_repo_path
# variable.
__git_find_repo_path ()
{
	if [ -n "${__git_repo_path-}" ]; then
		# we already know where it is
		return
	fi

	if [ -n "${__git_C_args-}" ]; then
		__git_repo_path="$(git "${__git_C_args[@]}" \
			${__git_dir:+--git-dir="$__git_dir"} \
			rev-parse --absolute-git-dir 2>/dev/null)"
	elif [ -n "${__git_dir-}" ]; then
		test -d "$__git_dir" &&
		__git_repo_path="$__git_dir"
	elif [ -n "${GIT_DIR-}" ]; then
		test -d "${GIT_DIR-}" &&
		__git_repo_path="$GIT_DIR"
	elif [ -d .git ]; then
		__git_repo_path=.git
	else
		__git_repo_path="$(git rev-parse --git-dir 2>/dev/null)"
	fi
}

# Deprecated: use __git_find_repo_path() and $__git_repo_path instead
# __gitdir accepts 0 or 1 arguments (i.e., location)
# returns location of .git repo
__gitdir ()
{
	if [ -z "${1-}" ]; then
		__git_find_repo_path || return 1
		echo "$__git_repo_path"
	elif [ -d "$1/.git" ]; then
		echo "$1/.git"
	else
		echo "$1"
	fi
}

# Runs git with all the options given as argument, respecting any
# '--git-dir=<path>' and '-C <path>' options present on the command line
__git ()
{
	git ${__git_C_args:+"${__git_C_args[@]}"} \
		${__git_dir:+--git-dir="$__git_dir"} "$@" 2>/dev/null
}

# Removes backslash escaping, single quotes and double quotes from a word,
# stores the result in the variable $dequoted_word.
# 1: The word to dequote.
__git_dequote ()
{
	local rest="$1" len ch

	dequoted_word=""

	while test -n "$rest"; do
		len=${#dequoted_word}
		dequoted_word="$dequoted_word${rest%%[\\\'\"]*}"
		rest="${rest:$((${#dequoted_word}-$len))}"

		case "${rest:0:1}" in
		\\)
			ch="${rest:1:1}"
			case "$ch" in
			$'\n')
				;;
			*)
				dequoted_word="$dequoted_word$ch"
				;;
			esac
			rest="${rest:2}"
			;;
		\')
			rest="${rest:1}"
			len=${#dequoted_word}
			dequoted_word="$dequoted_word${rest%%\'*}"
			rest="${rest:$((${#dequoted_word}-$len+1))}"
			;;
		\")
			rest="${rest:1}"
			while test -n "$rest" ; do
				len=${#dequoted_word}
				dequoted_word="$dequoted_word${rest%%[\\\"]*}"
				rest="${rest:$((${#dequoted_word}-$len))}"
				case "${rest:0:1}" in
				\\)
					ch="${rest:1:1}"
					case "$ch" in
					\"|\\|\$|\`)
						dequoted_word="$dequoted_word$ch"
						;;
					$'\n')
						;;
					*)
						dequoted_word="$dequoted_word\\$ch"
						;;
					esac
					rest="${rest:2}"
					;;
				\")
					rest="${rest:1}"
					break
					;;
				esac
			done
			;;
		esac
	done
}

# The following function is based on code from:
#
#   bash_completion - programmable completion functions for bash 3.2+
#
#   Copyright © 2006-2008, Ian Macdonald <ian@caliban.org>
#             © 2009-2010, Bash Completion Maintainers
#                     <bash-completion-devel@lists.alioth.debian.org>
#
#   This program is free software; you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation; either version 2, or (at your option)
#   any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, see <http://www.gnu.org/licenses/>.
#
#   The latest version of this software can be obtained here:
#
#   http://bash-completion.alioth.debian.org/
#
#   RELEASE: 2.x

# This function can be used to access a tokenized list of words
# on the command line:
#
#	__git_reassemble_comp_words_by_ref '=:'
#	if test "${words_[cword_-1]}" = -w
#	then
#		...
#	fi
#
# The argument should be a collection of characters from the list of
# word completion separators (COMP_WORDBREAKS) to treat as ordinary
# characters.
#
# This is roughly equivalent to going back in time and setting
# COMP_WORDBREAKS to exclude those characters.  The intent is to
# make option types like --date=<type> and <rev>:<path> easy to
# recognize by treating each shell word as a single token.
#
# It is best not to set COMP_WORDBREAKS directly because the value is
# shared with other completion scripts.  By the time the completion
# function gets called, COMP_WORDS has already been populated so local
# changes to COMP_WORDBREAKS have no effect.
#
# Output: words_, cword_, cur_.

__git_reassemble_comp_words_by_ref()
{
	local exclude i j first
	# Which word separators to exclude?
	exclude="${1//[^$COMP_WORDBREAKS]}"
	cword_=$COMP_CWORD
	if [ -z "$exclude" ]; then
		words_=("${COMP_WORDS[@]}")
		return
	fi
	# List of word completion separators has shrunk;
	# re-assemble words to complete.
	for ((i=0, j=0; i < ${#COMP_WORDS[@]}; i++, j++)); do
		# Append each nonempty word consisting of just
		# word separator characters to the current word.
		first=t
		while
			[ $i -gt 0 ] &&
			[ -n "${COMP_WORDS[$i]}" ] &&
			# word consists of excluded word separators
			[ "${COMP_WORDS[$i]//[^$exclude]}" = "${COMP_WORDS[$i]}" ]
		do
			# Attach to the previous token,
			# unless the previous token is the command name.
			if [ $j -ge 2 ] && [ -n "$first" ]; then
				((j--))
			fi
			first=
			words_[$j]=${words_[j]}${COMP_WORDS[i]}
			if [ $i = $COMP_CWORD ]; then
				cword_=$j
			fi
			if (($i < ${#COMP_WORDS[@]} - 1)); then
				((i++))
			else
				# Done.
				return
			fi
		done
		words_[$j]=${words_[j]}${COMP_WORDS[i]}
		if [ $i = $COMP_CWORD ]; then
			cword_=$j
		fi
	done
}

if ! type _get_comp_words_by_ref >/dev/null 2>&1; then
_get_comp_words_by_ref ()
{
	local exclude cur_ words_ cword_
	if [ "$1" = "-n" ]; then
		exclude=$2
		shift 2
	fi
	__git_reassemble_comp_words_by_ref "$exclude"
	cur_=${words_[cword_]}
	while [ $# -gt 0 ]; do
		case "$1" in
		cur)
			cur=$cur_
			;;
		prev)
			prev=${words_[$cword_-1]}
			;;
		words)
			words=("${words_[@]}")
			;;
		cword)
			cword=$cword_
			;;
		esac
		shift
	done
}
fi

# Fills the COMPREPLY array with prefiltered words without any additional
# processing.
# Callers must take care of providing only words that match the current word
# to be completed and adding any prefix and/or suffix (trailing space!), if
# necessary.
# 1: List of newline-separated matching completion words, complete with
#    prefix and suffix.
__gitcomp_direct ()
{
	local IFS=$'\n'

	COMPREPLY=($1)
}

# Similar to __gitcomp_direct, but appends to COMPREPLY instead.
# Callers must take care of providing only words that match the current word
# to be completed and adding any prefix and/or suffix (trailing space!), if
# necessary.
# 1: List of newline-separated matching completion words, complete with
#    prefix and suffix.
__gitcomp_direct_append ()
{
	local IFS=$'\n'

	COMPREPLY+=($1)
}

__gitcompappend ()
{
	local x i=${#COMPREPLY[@]}
	for x in $1; do
		if [[ "$x" == "$3"* ]]; then
			COMPREPLY[i++]="$2$x$4"
		fi
	done
}

__gitcompadd ()
{
	COMPREPLY=()
	__gitcompappend "$@"
}

# Generates completion reply, appending a space to possible completion words,
# if necessary.
# It accepts 1 to 4 arguments:
# 1: List of possible completion words.
# 2: A prefix to be added to each possible completion word (optional).
# 3: Generate possible completion matches for this word (optional).
# 4: A suffix to be appended to each possible completion word (optional).
__gitcomp ()
{
	local cur_="${3-$cur}"

	case "$cur_" in
	--*=)
		;;
	--no-*)
		local c i=0 IFS=$' \t\n'
		for c in $1; do
			if [[ $c == "--" ]]; then
				continue
			fi
			c="$c${4-}"
			if [[ $c == "$cur_"* ]]; then
				case $c in
				--*=|*.) ;;
				*) c="$c " ;;
				esac
				COMPREPLY[i++]="${2-}$c"
			fi
		done
		;;
	*)
		local c i=0 IFS=$' \t\n'
		for c in $1; do
			if [[ $c == "--" ]]; then
				c="--no-...${4-}"
				if [[ $c == "$cur_"* ]]; then
					COMPREPLY[i++]="${2-}$c "
				fi
				break
			fi
			c="$c${4-}"
			if [[ $c == "$cur_"* ]]; then
				case $c in
				*=|*.) ;;
				*) c="$c " ;;
				esac
				COMPREPLY[i++]="${2-}$c"
			fi
		done
		;;
	esac
}

# Clear the variables caching builtins' options when (re-)sourcing
# the completion script.
if [[ -n ${ZSH_VERSION-} ]]; then
	unset ${(M)${(k)parameters[@]}:#__gitcomp_builtin_*} 2>/dev/null
else
	unset $(compgen -v __gitcomp_builtin_)
fi

# This function is equivalent to
#
#    __gitcomp "$(git xxx --git-completion-helper) ..."
#
# except that the output is cached. Accept 1-3 arguments:
# 1: the git command to execute, this is also the cache key
# 2: extra options to be added on top (e.g. negative forms)
# 3: options to be excluded
__gitcomp_builtin ()
{
	# spaces must be replaced with underscore for multi-word
	# commands, e.g. "git remote add" becomes remote_add.
	local cmd="$1"
	local incl="${2-}"
	local excl="${3-}"

	local var=__gitcomp_builtin_"${cmd/-/_}"
	local options
	eval "options=\${$var-}"

	if [ -z "$options" ]; then
		local completion_helper
		if [ "$GIT_COMPLETION_SHOW_ALL" = "1" ]; then
			completion_helper="--git-completion-helper-all"
		else
			completion_helper="--git-completion-helper"
		fi
		# leading and trailing spaces are significant to make
		# option removal work correctly.
		options=" $incl $(__git ${cmd/_/ } $completion_helper) " || return

		for i in $excl; do
			options="${options/ $i / }"
		done
		eval "$var=\"$options\""
	fi

	__gitcomp "$options"
}

# Variation of __gitcomp_nl () that appends to the existing list of
# completion candidates, COMPREPLY.
__gitcomp_nl_append ()
{
	local IFS=$'\n'
	__gitcompappend "$1" "${2-}" "${3-$cur}" "${4- }"
}

# Generates completion reply from newline-separated possible completion words
# by appending a space to all of them.
# It accepts 1 to 4 arguments:
# 1: List of possible completion words, separated by a single newline.
# 2: A prefix to be added to each possible completion word (optional).
# 3: Generate possible completion matches for this word (optional).
# 4: A suffix to be appended to each possible completion word instead of
#    the default space (optional).  If specified but empty, nothing is
#    appended.
__gitcomp_nl ()
{
	COMPREPLY=()
	__gitcomp_nl_append "$@"
}

# Fills the COMPREPLY array with prefiltered paths without any additional
# processing.
# Callers must take care of providing only paths that match the current path
# to be completed and adding any prefix path components, if necessary.
# 1: List of newline-separated matching paths, complete with all prefix
#    path components.
__gitcomp_file_direct ()
{
	local IFS=$'\n'

	COMPREPLY=($1)

	# use a hack to enable file mode in bash < 4
	compopt -o filenames +o nospace 2>/dev/null ||
	compgen -f /non-existing-dir/ >/dev/null ||
	true
}

# Generates completion reply with compgen from newline-separated possible
# completion filenames.
# It accepts 1 to 3 arguments:
# 1: List of possible completion filenames, separated by a single newline.
# 2: A directory prefix to be added to each possible completion filename
#    (optional).
# 3: Generate possible completion matches for this word (optional).
__gitcomp_file ()
{
	local IFS=$'\n'

	# XXX does not work when the directory prefix contains a tilde,
	# since tilde expansion is not applied.
	# This means that COMPREPLY will be empty and Bash default
	# completion will be used.
	__gitcompadd "$1" "${2-}" "${3-$cur}" ""

	# use a hack to enable file mode in bash < 4
	compopt -o filenames +o nospace 2>/dev/null ||
	compgen -f /non-existing-dir/ >/dev/null ||
	true
}

# Execute 'git ls-files', unless the --committable option is specified, in
# which case it runs 'git diff-index' to find out the files that can be
# committed.  It return paths relative to the directory specified in the first
# argument, and using the options specified in the second argument.
__git_ls_files_helper ()
{
	if [ "$2" == "--committable" ]; then
		__git -C "$1" -c core.quotePath=false diff-index \
			--name-only --relative HEAD -- "${3//\\/\\\\}*"
	else
		# NOTE: $2 is not quoted in order to support multiple options
		__git -C "$1" -c core.quotePath=false ls-files \
			--exclude-standard $2 -- "${3//\\/\\\\}*"
	fi
}


# __git_index_files accepts 1 or 2 arguments:
# 1: Options to pass to ls-files (required).
# 2: A directory path (optional).
#    If provided, only files within the specified directory are listed.
#    Sub directories are never recursed.  Path must have a trailing
#    slash.
# 3: List only paths matching this path component (optional).
__git_index_files ()
{
	local root="$2" match="$3"

	__git_ls_files_helper "$root" "$1" "${match:-?}" |
	awk -F / -v pfx="${2//\\/\\\\}" '{
		paths[$1] = 1
	}
	END {
		for (p in paths) {
			if (substr(p, 1, 1) != "\"") {
				# No special characters, easy!
				print pfx p
				continue
			}

			# The path is quoted.
			p = dequote(p)
			if (p == "")
				continue

			# Even when a directory name itself does not contain
			# any special characters, it will still be quoted if
			# any of its (stripped) trailing path components do.
			# Because of this we may have seen the same directory
			# both quoted and unquoted.
			if (p in paths)
				# We have seen the same directory unquoted,
				# skip it.
				continue
			else
				print pfx p
		}
	}
	function dequote(p,    bs_idx, out, esc, esc_idx, dec) {
		# Skip opening double quote.
		p = substr(p, 2)

		# Interpret backslash escape sequences.
		while ((bs_idx = index(p, "\\")) != 0) {
			out = out substr(p, 1, bs_idx - 1)
			esc = substr(p, bs_idx + 1, 1)
			p = substr(p, bs_idx + 2)

			if ((esc_idx = index("abtvfr\"\\", esc)) != 0) {
				# C-style one-character escape sequence.
				out = out substr("\a\b\t\v\f\r\"\\",
						 esc_idx, 1)
			} else if (esc == "n") {
				# Uh-oh, a newline character.
				# We cannot reliably put a pathname
				# containing a newline into COMPREPLY,
				# and the newline would create a mess.
				# Skip this path.
				return ""
			} else {
				# Must be a \nnn octal value, then.
				dec = esc             * 64 + \
				      substr(p, 1, 1) * 8  + \
				      substr(p, 2, 1)
				out = out sprintf("%c", dec)
				p = substr(p, 3)
			}
		}
		# Drop closing double quote, if there is one.
		# (There is not any if this is a directory, as it was
		# already stripped with the trailing path components.)
		if (substr(p, length(p), 1) == "\"")
			out = out substr(p, 1, length(p) - 1)
		else
			out = out p

		return out
	}'
}

# __git_complete_index_file requires 1 argument:
# 1: the options to pass to ls-file
#
# The exception is --committable, which finds the files appropriate commit.
__git_complete_index_file ()
{
	local dequoted_word pfx="" cur_

	__git_dequote "$cur"

	case "$dequoted_word" in
	?*/*)
		pfx="${dequoted_word%/*}/"
		cur_="${dequoted_word##*/}"
		;;
	*)
		cur_="$dequoted_word"
	esac

	__gitcomp_file_direct "$(__git_index_files "$1" "$pfx" "$cur_")"
}

# Lists branches from the local repository.
# 1: A prefix to be added to each listed branch (optional).
# 2: List only branches matching this word (optional; list all branches if
#    unset or empty).
# 3: A suffix to be appended to each listed branch (optional).
__git_heads ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"

	__git for-each-ref --format="${pfx//\%/%%}%(refname:strip=2)$sfx" \
			"refs/heads/$cur_*" "refs/heads/$cur_*/**"
}

# Lists branches from remote repositories.
# 1: A prefix to be added to each listed branch (optional).
# 2: List only branches matching this word (optional; list all branches if
#    unset or empty).
# 3: A suffix to be appended to each listed branch (optional).
__git_remote_heads ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"

	__git for-each-ref --format="${pfx//\%/%%}%(refname:strip=2)$sfx" \
			"refs/remotes/$cur_*" "refs/remotes/$cur_*/**"
}

# Lists tags from the local repository.
# Accepts the same positional parameters as __git_heads() above.
__git_tags ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"

	__git for-each-ref --format="${pfx//\%/%%}%(refname:strip=2)$sfx" \
			"refs/tags/$cur_*" "refs/tags/$cur_*/**"
}

# List unique branches from refs/remotes used for 'git checkout' and 'git
# switch' tracking DWIMery.
# 1: A prefix to be added to each listed branch (optional)
# 2: List only branches matching this word (optional; list all branches if
#    unset or empty).
# 3: A suffix to be appended to each listed branch (optional).
__git_dwim_remote_heads ()
{
	local pfx="${1-}" cur_="${2-}" sfx="${3-}"
	local fer_pfx="${pfx//\%/%%}" # "escape" for-each-ref format specifiers

	# employ the heuristic used by git checkout and git switch
	# Try to find a remote branch that cur_es the completion word
	# but only output if the branch name is unique
	__git for-each-ref --format="$fer_pfx%(refname:strip=3)$sfx" \
		--sort="refname:strip=3" \
		"refs/remotes/*/$cur_*" "refs/remotes/*/$cur_*/**" | \
	uniq -u
}

# Lists refs from the local (by default) or from a remote repository.
# It accepts 0, 1 or 2 arguments:
# 1: The remote to list refs from (optional; ignored, if set but empty).
#    Can be the name of a configured remote, a path, or a URL.
# 2: In addition to local refs, list unique branches from refs/remotes/ for
#    'git checkout's tracking DWIMery (optional; ignored, if set but empty).
# 3: A prefix to be added to each listed ref (optional).
# 4: List only refs matching this word (optional; list all refs if unset or
#    empty).
# 5: A suffix to be appended to each listed ref (optional; ignored, if set
#    but empty).
#
# Use __git_complete_refs() instead.
__git_refs ()
{
	local i hash dir track="${2-}"
	local list_refs_from=path remote="${1-}"
	local format refs
	local pfx="${3-}" cur_="${4-$cur}" sfx="${5-}"
	local match="${4-}"
	local fer_pfx="${pfx//\%/%%}" # "escape" for-each-ref format specifiers

	__git_find_repo_path
	dir="$__git_repo_path"

	if [ -z "$remote" ]; then
		if [ -z "$dir" ]; then
			return
		fi
	else
		if __git_is_configured_remote "$remote"; then
			# configured remote takes precedence over a
			# local directory with the same name
			list_refs_from=remote
		elif [ -d "$remote/.git" ]; then
			dir="$remote/.git"
		elif [ -d "$remote" ]; then
			dir="$remote"
		else
			list_refs_from=url
		fi
	fi

	if [ "$list_refs_from" = path ]; then
		if [[ "$cur_" == ^* ]]; then
			pfx="$pfx^"
			fer_pfx="$fer_pfx^"
			cur_=${cur_#^}
			match=${match#^}
		fi
		case "$cur_" in
		refs|refs/*)
			format="refname"
			refs=("$match*" "$match*/**")
			track=""
			;;
		*)
			for i in HEAD FETCH_HEAD ORIG_HEAD MERGE_HEAD REBASE_HEAD; do
				case "$i" in
				$match*)
					if [ -e "$dir/$i" ]; then
						echo "$pfx$i$sfx"
					fi
					;;
				esac
			done
			format="refname:strip=2"
			refs=("refs/tags/$match*" "refs/tags/$match*/**"
				"refs/heads/$match*" "refs/heads/$match*/**"
				"refs/remotes/$match*" "refs/remotes/$match*/**")
			;;
		esac
		__git_dir="$dir" __git for-each-ref --format="$fer_pfx%($format)$sfx" \
			"${refs[@]}"
		if [ -n "$track" ]; then
			__git_dwim_remote_heads "$pfx" "$match" "$sfx"
		fi
		return
	fi
	case "$cur_" in
	refs|refs/*)
		__git ls-remote "$remote" "$match*" | \
		while read -r hash i; do
			case "$i" in
			*^{}) ;;
			*) echo "$pfx$i$sfx" ;;
			esac
		done
		;;
	*)
		if [ "$list_refs_from" = remote ]; then
			case "HEAD" in
			$match*)	echo "${pfx}HEAD$sfx" ;;
			esac
			__git for-each-ref --format="$fer_pfx%(refname:strip=3)$sfx" \
				"refs/remotes/$remote/$match*" \
				"refs/remotes/$remote/$match*/**"
		else
			local query_symref
			case "HEAD" in
			$match*)	query_symref="HEAD" ;;
			esac
			__git ls-remote "$remote" $query_symref \
				"refs/tags/$match*" "refs/heads/$match*" \
				"refs/remotes/$match*" |
			while read -r hash i; do
				case "$i" in
				*^{})	;;
				refs/*)	echo "$pfx${i#refs/*/}$sfx" ;;
				*)	echo "$pfx$i$sfx" ;;  # symbolic refs
				esac
			done
		fi
		;;
	esac
}

# Completes refs, short and long, local and remote, symbolic and pseudo.
#
# Usage: __git_complete_refs [<option>]...
# --remote=<remote>: The remote to list refs from, can be the name of a
#                    configured remote, a path, or a URL.
# --dwim: List unique remote branches for 'git switch's tracking DWIMery.
# --pfx=<prefix>: A prefix to be added to each ref.
# --cur=<word>: The current ref to be completed.  Defaults to the current
#               word to be completed.
# --sfx=<suffix>: A suffix to be appended to each ref instead of the default
#                 space.
# --mode=<mode>: What set of refs to complete, one of 'refs' (the default) to
#                complete all refs, 'heads' to complete only branches, or
#                'remote-heads' to complete only remote branches. Note that
#                --remote is only compatible with --mode=refs.
__git_complete_refs ()
{
	local remote= dwim= pfx= cur_="$cur" sfx=" " mode="refs"

	while test $# != 0; do
		case "$1" in
		--remote=*)	remote="${1##--remote=}" ;;
		--dwim)		dwim="yes" ;;
		# --track is an old spelling of --dwim
		--track)	dwim="yes" ;;
		--pfx=*)	pfx="${1##--pfx=}" ;;
		--cur=*)	cur_="${1##--cur=}" ;;
		--sfx=*)	sfx="${1##--sfx=}" ;;
		--mode=*)	mode="${1##--mode=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	# complete references based on the specified mode
	case "$mode" in
		refs)
			__gitcomp_direct "$(__git_refs "$remote" "" "$pfx" "$cur_" "$sfx")" ;;
		heads)
			__gitcomp_direct "$(__git_heads "$pfx" "$cur_" "$sfx")" ;;
		remote-heads)
			__gitcomp_direct "$(__git_remote_heads "$pfx" "$cur_" "$sfx")" ;;
		*)
			return 1 ;;
	esac

	# Append DWIM remote branch names if requested
	if [ "$dwim" = "yes" ]; then
		__gitcomp_direct_append "$(__git_dwim_remote_heads "$pfx" "$cur_" "$sfx")"
	fi
}

# __git_refs2 requires 1 argument (to pass to __git_refs)
# Deprecated: use __git_complete_fetch_refspecs() instead.
__git_refs2 ()
{
	local i
	for i in $(__git_refs "$1"); do
		echo "$i:$i"
	done
}

# Completes refspecs for fetching from a remote repository.
# 1: The remote repository.
# 2: A prefix to be added to each listed refspec (optional).
# 3: The ref to be completed as a refspec instead of the current word to be
#    completed (optional)
# 4: A suffix to be appended to each listed refspec instead of the default
#    space (optional).
__git_complete_fetch_refspecs ()
{
	local i remote="$1" pfx="${2-}" cur_="${3-$cur}" sfx="${4- }"

	__gitcomp_direct "$(
		for i in $(__git_refs "$remote" "" "" "$cur_") ; do
			echo "$pfx$i:$i$sfx"
		done
		)"
}

# __git_refs_remotes requires 1 argument (to pass to ls-remote)
__git_refs_remotes ()
{
	local i hash
	__git ls-remote "$1" 'refs/heads/*' | \
	while read -r hash i; do
		echo "$i:refs/remotes/$1/${i#refs/heads/}"
	done
}

__git_remotes ()
{
	__git_find_repo_path
	test -d "$__git_repo_path/remotes" && ls -1 "$__git_repo_path/remotes"
	__git remote
}

# Returns true if $1 matches the name of a configured remote, false otherwise.
__git_is_configured_remote ()
{
	local remote
	for remote in $(__git_remotes); do
		if [ "$remote" = "$1" ]; then
			return 0
		fi
	done
	return 1
}

__git_list_merge_strategies ()
{
	LANG=C LC_ALL=C git merge -s help 2>&1 |
	sed -n -e '/[Aa]vailable strategies are: /,/^$/{
		s/\.$//
		s/.*://
		s/^[ 	]*//
		s/[ 	]*$//
		p
	}'
}

__git_merge_strategies=
# 'git merge -s help' (and thus detection of the merge strategy
# list) fails, unfortunately, if run outside of any git working
# tree.  __git_merge_strategies is set to the empty string in
# that case, and the detection will be repeated the next time it
# is needed.
__git_compute_merge_strategies ()
{
	test -n "$__git_merge_strategies" ||
	__git_merge_strategies=$(__git_list_merge_strategies)
}

__git_merge_strategy_options="ours theirs subtree subtree= patience
	histogram diff-algorithm= ignore-space-change ignore-all-space
	ignore-space-at-eol renormalize no-renormalize no-renames
	find-renames find-renames= rename-threshold="

__git_complete_revlist_file ()
{
	local dequoted_word pfx ls ref cur_="$cur"
	case "$cur_" in
	*..?*:*)
		return
		;;
	?*:*)
		ref="${cur_%%:*}"
		cur_="${cur_#*:}"

		__git_dequote "$cur_"

		case "$dequoted_word" in
		?*/*)
			pfx="${dequoted_word%/*}"
			cur_="${dequoted_word##*/}"
			ls="$ref:$pfx"
			pfx="$pfx/"
			;;
		*)
			cur_="$dequoted_word"
			ls="$ref"
			;;
		esac

		case "$COMP_WORDBREAKS" in
		*:*) : great ;;
		*)   pfx="$ref:$pfx" ;;
		esac

		__gitcomp_file "$(__git ls-tree "$ls" \
				| sed 's/^.*	//
				       s/$//')" \
			"$pfx" "$cur_"
		;;
	*...*)
		pfx="${cur_%...*}..."
		cur_="${cur_#*...}"
		__git_complete_refs --pfx="$pfx" --cur="$cur_"
		;;
	*..*)
		pfx="${cur_%..*}.."
		cur_="${cur_#*..}"
		__git_complete_refs --pfx="$pfx" --cur="$cur_"
		;;
	*)
		__git_complete_refs
		;;
	esac
}

__git_complete_file ()
{
	__git_complete_revlist_file
}

__git_complete_revlist ()
{
	__git_complete_revlist_file
}

__git_complete_remote_or_refspec ()
{
	local cur_="$cur" cmd="${words[1]}"
	local i c=2 remote="" pfx="" lhs=1 no_complete_refspec=0
	if [ "$cmd" = "remote" ]; then
		((c++))
	fi
	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		--mirror) [ "$cmd" = "push" ] && no_complete_refspec=1 ;;
		-d|--delete) [ "$cmd" = "push" ] && lhs=0 ;;
		--all)
			case "$cmd" in
			push) no_complete_refspec=1 ;;
			fetch)
				return
				;;
			*) ;;
			esac
			;;
		--multiple) no_complete_refspec=1; break ;;
		-*) ;;
		*) remote="$i"; break ;;
		esac
		((c++))
	done
	if [ -z "$remote" ]; then
		__gitcomp_nl "$(__git_remotes)"
		return
	fi
	if [ $no_complete_refspec = 1 ]; then
		return
	fi
	[ "$remote" = "." ] && remote=
	case "$cur_" in
	*:*)
		case "$COMP_WORDBREAKS" in
		*:*) : great ;;
		*)   pfx="${cur_%%:*}:" ;;
		esac
		cur_="${cur_#*:}"
		lhs=0
		;;
	+*)
		pfx="+"
		cur_="${cur_#+}"
		;;
	esac
	case "$cmd" in
	fetch)
		if [ $lhs = 1 ]; then
			__git_complete_fetch_refspecs "$remote" "$pfx" "$cur_"
		else
			__git_complete_refs --pfx="$pfx" --cur="$cur_"
		fi
		;;
	pull|remote)
		if [ $lhs = 1 ]; then
			__git_complete_refs --remote="$remote" --pfx="$pfx" --cur="$cur_"
		else
			__git_complete_refs --pfx="$pfx" --cur="$cur_"
		fi
		;;
	push)
		if [ $lhs = 1 ]; then
			__git_complete_refs --pfx="$pfx" --cur="$cur_"
		else
			__git_complete_refs --remote="$remote" --pfx="$pfx" --cur="$cur_"
		fi
		;;
	esac
}

__git_complete_strategy ()
{
	__git_compute_merge_strategies
	case "$prev" in
	-s|--strategy)
		__gitcomp "$__git_merge_strategies"
		return 0
		;;
	-X)
		__gitcomp "$__git_merge_strategy_options"
		return 0
		;;
	esac
	case "$cur" in
	--strategy=*)
		__gitcomp "$__git_merge_strategies" "" "${cur##--strategy=}"
		return 0
		;;
	--strategy-option=*)
		__gitcomp "$__git_merge_strategy_options" "" "${cur##--strategy-option=}"
		return 0
		;;
	esac
	return 1
}

__git_all_commands=
__git_compute_all_commands ()
{
	test -n "$__git_all_commands" ||
	__git_all_commands=$(__git --list-cmds=main,others,alias,nohelpers)
}

# Lists all set config variables starting with the given section prefix,
# with the prefix removed.
__git_get_config_variables ()
{
	local section="$1" i IFS=$'\n'
	for i in $(__git config --name-only --get-regexp "^$section\..*"); do
		echo "${i#$section.}"
	done
}

__git_pretty_aliases ()
{
	__git_get_config_variables "pretty"
}

# __git_aliased_command requires 1 argument
__git_aliased_command ()
{
	local cur=$1 last list word cmdline

	while [[ -n "$cur" ]]; do
		if [[ "$list" == *" $cur "* ]]; then
			# loop detected
			return
		fi

		cmdline=$(__git config --get "alias.$cur")
		list=" $cur $list"
		last=$cur
		cur=

		for word in $cmdline; do
			case "$word" in
			\!gitk|gitk)
				cur="gitk"
				break
				;;
			\!*)	: shell command alias ;;
			-*)	: option ;;
			*=*)	: setting env ;;
			git)	: git itself ;;
			\(\))   : skip parens of shell function definition ;;
			{)	: skip start of shell helper function ;;
			:)	: skip null command ;;
			\'*)	: skip opening quote after sh -c ;;
			*)
				cur="$word"
				break
			esac
		done
	done

	cur=$last
	if [[ "$cur" != "$1" ]]; then
		echo "$cur"
	fi
}

# Check whether one of the given words is present on the command line,
# and print the first word found.
#
# Usage: __git_find_on_cmdline [<option>]... "<wordlist>"
# --show-idx: Optionally show the index of the found word in the $words array.
__git_find_on_cmdline ()
{
	local word c=1 show_idx

	while test $# -gt 1; do
		case "$1" in
		--show-idx)	show_idx=y ;;
		*)		return 1 ;;
		esac
		shift
	done
	local wordlist="$1"

	while [ $c -lt $cword ]; do
		for word in $wordlist; do
			if [ "$word" = "${words[c]}" ]; then
				if [ -n "${show_idx-}" ]; then
					echo "$c $word"
				else
					echo "$word"
				fi
				return
			fi
		done
		((c++))
	done
}

# Similar to __git_find_on_cmdline, except that it loops backwards and thus
# prints the *last* word found. Useful for finding which of two options that
# supersede each other came last, such as "--guess" and "--no-guess".
#
# Usage: __git_find_last_on_cmdline [<option>]... "<wordlist>"
# --show-idx: Optionally show the index of the found word in the $words array.
__git_find_last_on_cmdline ()
{
	local word c=$cword show_idx

	while test $# -gt 1; do
		case "$1" in
		--show-idx)	show_idx=y ;;
		*)		return 1 ;;
		esac
		shift
	done
	local wordlist="$1"

	while [ $c -gt 1 ]; do
		((c--))
		for word in $wordlist; do
			if [ "$word" = "${words[c]}" ]; then
				if [ -n "$show_idx" ]; then
					echo "$c $word"
				else
					echo "$word"
				fi
				return
			fi
		done
	done
}

# Echo the value of an option set on the command line or config
#
# $1: short option name
# $2: long option name including =
# $3: list of possible values
# $4: config string (optional)
#
# example:
# result="$(__git_get_option_value "-d" "--do-something=" \
#     "yes no" "core.doSomething")"
#
# result is then either empty (no option set) or "yes" or "no"
#
# __git_get_option_value requires 3 arguments
__git_get_option_value ()
{
	local c short_opt long_opt val
	local result= values config_key word

	short_opt="$1"
	long_opt="$2"
	values="$3"
	config_key="$4"

	((c = $cword - 1))
	while [ $c -ge 0 ]; do
		word="${words[c]}"
		for val in $values; do
			if [ "$short_opt$val" = "$word" ] ||
			   [ "$long_opt$val"  = "$word" ]; then
				result="$val"
				break 2
			fi
		done
		((c--))
	done

	if [ -n "$config_key" ] && [ -z "$result" ]; then
		result="$(__git config "$config_key")"
	fi

	echo "$result"
}

__git_has_doubledash ()
{
	local c=1
	while [ $c -lt $cword ]; do
		if [ "--" = "${words[c]}" ]; then
			return 0
		fi
		((c++))
	done
	return 1
}

# Try to count non option arguments passed on the command line for the
# specified git command.
# When options are used, it is necessary to use the special -- option to
# tell the implementation were non option arguments begin.
# XXX this can not be improved, since options can appear everywhere, as
# an example:
#	git mv x -n y
#
# __git_count_arguments requires 1 argument: the git command executed.
__git_count_arguments ()
{
	local word i c=0

	# Skip "git" (first argument)
	for ((i=1; i < ${#words[@]}; i++)); do
		word="${words[i]}"

		case "$word" in
			--)
				# Good; we can assume that the following are only non
				# option arguments.
				((c = 0))
				;;
			"$1")
				# Skip the specified git command and discard git
				# main options
				((c = 0))
				;;
			?*)
				((c++))
				;;
		esac
	done

	printf "%d" $c
}

__git_whitespacelist="nowarn warn error error-all fix"
__git_patchformat="mbox stgit stgit-series hg mboxrd"
__git_showcurrentpatch="diff raw"
__git_am_inprogress_options="--skip --continue --resolved --abort --quit --show-current-patch"

_git_am ()
{
	__git_find_repo_path
	if [ -d "$__git_repo_path"/rebase-apply ]; then
		__gitcomp "$__git_am_inprogress_options"
		return
	fi
	case "$cur" in
	--whitespace=*)
		__gitcomp "$__git_whitespacelist" "" "${cur##--whitespace=}"
		return
		;;
	--patch-format=*)
		__gitcomp "$__git_patchformat" "" "${cur##--patch-format=}"
		return
		;;
	--show-current-patch=*)
		__gitcomp "$__git_showcurrentpatch" "" "${cur##--show-current-patch=}"
		return
		;;
	--*)
		__gitcomp_builtin am "" \
			"$__git_am_inprogress_options"
		return
	esac
}

_git_apply ()
{
	case "$cur" in
	--whitespace=*)
		__gitcomp "$__git_whitespacelist" "" "${cur##--whitespace=}"
		return
		;;
	--*)
		__gitcomp_builtin apply
		return
	esac
}

_git_add ()
{
	case "$cur" in
	--chmod=*)
		__gitcomp "+x -x" "" "${cur##--chmod=}"
		return
		;;
	--*)
		__gitcomp_builtin add
		return
	esac

	local complete_opt="--others --modified --directory --no-empty-directory"
	if test -n "$(__git_find_on_cmdline "-u --update")"
	then
		complete_opt="--modified"
	fi
	__git_complete_index_file "$complete_opt"
}

_git_archive ()
{
	case "$cur" in
	--format=*)
		__gitcomp "$(git archive --list)" "" "${cur##--format=}"
		return
		;;
	--remote=*)
		__gitcomp_nl "$(__git_remotes)" "" "${cur##--remote=}"
		return
		;;
	--*)
		__gitcomp_builtin archive "--format= --list --verbose --prefix= --worktree-attributes"
		return
		;;
	esac
	__git_complete_file
}

_git_bisect ()
{
	__git_has_doubledash && return

	local subcommands="start bad good skip reset visualize replay log run"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__git_find_repo_path
		if [ -f "$__git_repo_path"/BISECT_START ]; then
			__gitcomp "$subcommands"
		else
			__gitcomp "replay start"
		fi
		return
	fi

	case "$subcommand" in
	bad|good|reset|skip|start)
		__git_complete_refs
		;;
	*)
		;;
	esac
}

__git_ref_fieldlist="refname objecttype objectsize objectname upstream push HEAD symref"

_git_branch ()
{
	local i c=1 only_local_ref="n" has_r="n"

	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		-d|-D|--delete|-m|-M|--move|-c|-C|--copy)
			only_local_ref="y" ;;
		-r|--remotes)
			has_r="y" ;;
		esac
		((c++))
	done

	case "$cur" in
	--set-upstream-to=*)
		__git_complete_refs --cur="${cur##--set-upstream-to=}"
		;;
	--*)
		__gitcomp_builtin branch
		;;
	*)
		if [ $only_local_ref = "y" -a $has_r = "n" ]; then
			__gitcomp_direct "$(__git_heads "" "$cur" " ")"
		else
			__git_complete_refs
		fi
		;;
	esac
}

_git_bundle ()
{
	local cmd="${words[2]}"
	case "$cword" in
	2)
		__gitcomp "create list-heads verify unbundle"
		;;
	3)
		# looking for a file
		;;
	*)
		case "$cmd" in
			create)
				__git_complete_revlist
			;;
		esac
		;;
	esac
}

# Helper function to decide whether or not we should enable DWIM logic for
# git-switch and git-checkout.
#
# To decide between the following rules in decreasing priority order:
# - the last provided of "--guess" or "--no-guess" explicitly enable or
#   disable completion of DWIM logic respectively.
# - If checkout.guess is false, disable completion of DWIM logic.
# - If the --no-track option is provided, take this as a hint to disable the
#   DWIM completion logic
# - If GIT_COMPLETION_CHECKOUT_NO_GUESS is set, disable the DWIM completion
#   logic, as requested by the user.
# - Enable DWIM logic otherwise.
#
__git_checkout_default_dwim_mode ()
{
	local last_option dwim_opt="--dwim"

	if [ "${GIT_COMPLETION_CHECKOUT_NO_GUESS-}" = "1" ]; then
		dwim_opt=""
	fi

	# --no-track disables DWIM, but with lower priority than
	# --guess/--no-guess/checkout.guess
	if [ -n "$(__git_find_on_cmdline "--no-track")" ]; then
		dwim_opt=""
	fi

	# checkout.guess = false disables DWIM, but with lower priority than
	# --guess/--no-guess
	if [ "$(__git config --type=bool checkout.guess)" = "false" ]; then
		dwim_opt=""
	fi

	# Find the last provided --guess or --no-guess
	last_option="$(__git_find_last_on_cmdline "--guess --no-guess")"
	case "$last_option" in
		--guess)
			dwim_opt="--dwim"
			;;
		--no-guess)
			dwim_opt=""
			;;
	esac

	echo "$dwim_opt"
}

_git_checkout ()
{
	__git_has_doubledash && return

	local dwim_opt="$(__git_checkout_default_dwim_mode)"

	case "$prev" in
	-b|-B|--orphan)
		# Complete local branches (and DWIM branch
		# remote branch names) for an option argument
		# specifying a new branch name. This is for
		# convenience, assuming new branches are
		# possibly based on pre-existing branch names.
		__git_complete_refs $dwim_opt --mode="heads"
		return
		;;
	*)
		;;
	esac

	case "$cur" in
	--conflict=*)
		__gitcomp "diff3 merge" "" "${cur##--conflict=}"
		;;
	--*)
		__gitcomp_builtin checkout
		;;
	*)
		# At this point, we've already handled special completion for
		# the arguments to -b/-B, and --orphan. There are 3 main
		# things left we can possibly complete:
		# 1) a start-point for -b/-B, -d/--detach, or --orphan
		# 2) a remote head, for --track
		# 3) an arbitrary reference, possibly including DWIM names
		#

		if [ -n "$(__git_find_on_cmdline "-b -B -d --detach --orphan")" ]; then
			__git_complete_refs --mode="refs"
		elif [ -n "$(__git_find_on_cmdline "--track")" ]; then
			__git_complete_refs --mode="remote-heads"
		else
			__git_complete_refs $dwim_opt --mode="refs"
		fi
		;;
	esac
}

__git_sequencer_inprogress_options="--continue --quit --abort --skip"

__git_cherry_pick_inprogress_options=$__git_sequencer_inprogress_options

_git_cherry_pick ()
{
	__git_find_repo_path
	if [ -f "$__git_repo_path"/CHERRY_PICK_HEAD ]; then
		__gitcomp "$__git_cherry_pick_inprogress_options"
		return
	fi

	__git_complete_strategy && return

	case "$cur" in
	--*)
		__gitcomp_builtin cherry-pick "" \
			"$__git_cherry_pick_inprogress_options"
		;;
	*)
		__git_complete_refs
		;;
	esac
}

_git_clean ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin clean
		return
		;;
	esac

	# XXX should we check for -x option ?
	__git_complete_index_file "--others --directory"
}

_git_clone ()
{
	case "$prev" in
	-c|--config)
		__git_complete_config_variable_name_and_value
		return
		;;
	esac
	case "$cur" in
	--config=*)
		__git_complete_config_variable_name_and_value \
			--cur="${cur##--config=}"
		return
		;;
	--*)
		__gitcomp_builtin clone
		return
		;;
	esac
}

__git_untracked_file_modes="all no normal"

_git_commit ()
{
	case "$prev" in
	-c|-C)
		__git_complete_refs
		return
		;;
	esac

	case "$cur" in
	--cleanup=*)
		__gitcomp "default scissors strip verbatim whitespace
			" "" "${cur##--cleanup=}"
		return
		;;
	--reuse-message=*|--reedit-message=*|\
	--fixup=*|--squash=*)
		__git_complete_refs --cur="${cur#*=}"
		return
		;;
	--untracked-files=*)
		__gitcomp "$__git_untracked_file_modes" "" "${cur##--untracked-files=}"
		return
		;;
	--*)
		__gitcomp_builtin commit
		return
	esac

	if __git rev-parse --verify --quiet HEAD >/dev/null; then
		__git_complete_index_file "--committable"
	else
		# This is the first commit
		__git_complete_index_file "--cached"
	fi
}

_git_describe ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin describe
		return
	esac
	__git_complete_refs
}

__git_diff_algorithms="myers minimal patience histogram"

__git_diff_submodule_formats="diff log short"

__git_color_moved_opts="no default plain blocks zebra dimmed-zebra"

__git_color_moved_ws_opts="no ignore-space-at-eol ignore-space-change
			ignore-all-space allow-indentation-change"

__git_diff_common_options="--stat --numstat --shortstat --summary
			--patch-with-stat --name-only --name-status --color
			--no-color --color-words --no-renames --check
			--color-moved --color-moved= --no-color-moved
			--color-moved-ws= --no-color-moved-ws
			--full-index --binary --abbrev --diff-filter=
			--find-copies-harder --ignore-cr-at-eol
			--text --ignore-space-at-eol --ignore-space-change
			--ignore-all-space --ignore-blank-lines --exit-code
			--quiet --ext-diff --no-ext-diff
			--no-prefix --src-prefix= --dst-prefix=
			--inter-hunk-context=
			--patience --histogram --minimal
			--raw --word-diff --word-diff-regex=
			--dirstat --dirstat= --dirstat-by-file
			--dirstat-by-file= --cumulative
			--diff-algorithm=
			--submodule --submodule= --ignore-submodules
			--indent-heuristic --no-indent-heuristic
			--textconv --no-textconv
			--patch --no-patch
"

__git_diff_difftool_options="--cached --staged --pickaxe-all --pickaxe-regex
			--base --ours --theirs --no-index --relative --merge-base
			$__git_diff_common_options"

_git_diff ()
{
	__git_has_doubledash && return

	case "$cur" in
	--diff-algorithm=*)
		__gitcomp "$__git_diff_algorithms" "" "${cur##--diff-algorithm=}"
		return
		;;
	--submodule=*)
		__gitcomp "$__git_diff_submodule_formats" "" "${cur##--submodule=}"
		return
		;;
	--color-moved=*)
		__gitcomp "$__git_color_moved_opts" "" "${cur##--color-moved=}"
		return
		;;
	--color-moved-ws=*)
		__gitcomp "$__git_color_moved_ws_opts" "" "${cur##--color-moved-ws=}"
		return
		;;
	--*)
		__gitcomp "$__git_diff_difftool_options"
		return
		;;
	esac
	__git_complete_revlist_file
}

__git_mergetools_common="diffuse diffmerge ecmerge emerge kdiff3 meld opendiff
			tkdiff vimdiff nvimdiff gvimdiff xxdiff araxis p4merge
			bc codecompare smerge
"

_git_difftool ()
{
	__git_has_doubledash && return

	case "$cur" in
	--tool=*)
		__gitcomp "$__git_mergetools_common kompare" "" "${cur##--tool=}"
		return
		;;
	--*)
		__gitcomp_builtin difftool "$__git_diff_difftool_options"
		return
		;;
	esac
	__git_complete_revlist_file
}

__git_fetch_recurse_submodules="yes on-demand no"

_git_fetch ()
{
	case "$cur" in
	--recurse-submodules=*)
		__gitcomp "$__git_fetch_recurse_submodules" "" "${cur##--recurse-submodules=}"
		return
		;;
	--filter=*)
		__gitcomp "blob:none blob:limit= sparse:oid=" "" "${cur##--filter=}"
		return
		;;
	--*)
		__gitcomp_builtin fetch
		return
		;;
	esac
	__git_complete_remote_or_refspec
}

__git_format_patch_extra_options="
	--full-index --not --all --no-prefix --src-prefix=
	--dst-prefix= --notes
"

_git_format_patch ()
{
	case "$cur" in
	--thread=*)
		__gitcomp "
			deep shallow
			" "" "${cur##--thread=}"
		return
		;;
	--base=*|--interdiff=*|--range-diff=*)
		__git_complete_refs --cur="${cur#--*=}"
		return
		;;
	--*)
		__gitcomp_builtin format-patch "$__git_format_patch_extra_options"
		return
		;;
	esac
	__git_complete_revlist
}

_git_fsck ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin fsck
		return
		;;
	esac
}

_git_gitk ()
{
	__gitk_main
}

# Lists matching symbol names from a tag (as in ctags) file.
# 1: List symbol names matching this word.
# 2: The tag file to list symbol names from.
# 3: A prefix to be added to each listed symbol name (optional).
# 4: A suffix to be appended to each listed symbol name (optional).
__git_match_ctag () {
	awk -v pfx="${3-}" -v sfx="${4-}" "
		/^${1//\//\\/}/ { print pfx \$1 sfx }
		" "$2"
}

# Complete symbol names from a tag file.
# Usage: __git_complete_symbol [<option>]...
# --tags=<file>: The tag file to list symbol names from instead of the
#                default "tags".
# --pfx=<prefix>: A prefix to be added to each symbol name.
# --cur=<word>: The current symbol name to be completed.  Defaults to
#               the current word to be completed.
# --sfx=<suffix>: A suffix to be appended to each symbol name instead
#                 of the default space.
__git_complete_symbol () {
	local tags=tags pfx="" cur_="${cur-}" sfx=" "

	while test $# != 0; do
		case "$1" in
		--tags=*)	tags="${1##--tags=}" ;;
		--pfx=*)	pfx="${1##--pfx=}" ;;
		--cur=*)	cur_="${1##--cur=}" ;;
		--sfx=*)	sfx="${1##--sfx=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	if test -r "$tags"; then
		__gitcomp_direct "$(__git_match_ctag "$cur_" "$tags" "$pfx" "$sfx")"
	fi
}

_git_grep ()
{
	__git_has_doubledash && return

	case "$cur" in
	--*)
		__gitcomp_builtin grep
		return
		;;
	esac

	case "$cword,$prev" in
	2,*|*,-*)
		__git_complete_symbol && return
		;;
	esac

	__git_complete_refs
}

_git_help ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin help
		return
		;;
	esac
	if test -n "$GIT_TESTING_ALL_COMMAND_LIST"
	then
		__gitcomp "$GIT_TESTING_ALL_COMMAND_LIST $(__git --list-cmds=alias,list-guide) gitk"
	else
		__gitcomp "$(__git --list-cmds=main,nohelpers,alias,list-guide) gitk"
	fi
}

_git_init ()
{
	case "$cur" in
	--shared=*)
		__gitcomp "
			false true umask group all world everybody
			" "" "${cur##--shared=}"
		return
		;;
	--*)
		__gitcomp_builtin init
		return
		;;
	esac
}

_git_ls_files ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin ls-files
		return
		;;
	esac

	# XXX ignore options like --modified and always suggest all cached
	# files.
	__git_complete_index_file "--cached"
}

_git_ls_remote ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin ls-remote
		return
		;;
	esac
	__gitcomp_nl "$(__git_remotes)"
}

_git_ls_tree ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin ls-tree
		return
		;;
	esac

	__git_complete_file
}

# Options that go well for log, shortlog and gitk
__git_log_common_options="
	--not --all
	--branches --tags --remotes
	--first-parent --merges --no-merges
	--max-count=
	--max-age= --since= --after=
	--min-age= --until= --before=
	--min-parents= --max-parents=
	--no-min-parents --no-max-parents
"
# Options that go well for log and gitk (not shortlog)
__git_log_gitk_options="
	--dense --sparse --full-history
	--simplify-merges --simplify-by-decoration
	--left-right --notes --no-notes
"
# Options that go well for log and shortlog (not gitk)
__git_log_shortlog_options="
	--author= --committer= --grep=
	--all-match --invert-grep
"

__git_log_pretty_formats="oneline short medium full fuller reference email raw format: tformat: mboxrd"
__git_log_date_formats="relative iso8601 iso8601-strict rfc2822 short local default raw unix format:"

_git_log ()
{
	__git_has_doubledash && return
	__git_find_repo_path

	local merge=""
	if [ -f "$__git_repo_path/MERGE_HEAD" ]; then
		merge="--merge"
	fi
	case "$prev,$cur" in
	-L,:*:*)
		return	# fall back to Bash filename completion
		;;
	-L,:*)
		__git_complete_symbol --cur="${cur#:}" --sfx=":"
		return
		;;
	-G,*|-S,*)
		__git_complete_symbol
		return
		;;
	esac
	case "$cur" in
	--pretty=*|--format=*)
		__gitcomp "$__git_log_pretty_formats $(__git_pretty_aliases)
			" "" "${cur#*=}"
		return
		;;
	--date=*)
		__gitcomp "$__git_log_date_formats" "" "${cur##--date=}"
		return
		;;
	--decorate=*)
		__gitcomp "full short no" "" "${cur##--decorate=}"
		return
		;;
	--diff-algorithm=*)
		__gitcomp "$__git_diff_algorithms" "" "${cur##--diff-algorithm=}"
		return
		;;
	--submodule=*)
		__gitcomp "$__git_diff_submodule_formats" "" "${cur##--submodule=}"
		return
		;;
	--no-walk=*)
		__gitcomp "sorted unsorted" "" "${cur##--no-walk=}"
		return
		;;
	--*)
		__gitcomp "
			$__git_log_common_options
			$__git_log_shortlog_options
			$__git_log_gitk_options
			--root --topo-order --date-order --reverse
			--follow --full-diff
			--abbrev-commit --no-abbrev-commit --abbrev=
			--relative-date --date=
			--pretty= --format= --oneline
			--show-signature
			--cherry-mark
			--cherry-pick
			--graph
			--decorate --decorate= --no-decorate
			--walk-reflogs
			--no-walk --no-walk= --do-walk
			--parents --children
			--expand-tabs --expand-tabs= --no-expand-tabs
			$merge
			$__git_diff_common_options
			--pickaxe-all --pickaxe-regex
			"
		return
		;;
	-L:*:*)
		return	# fall back to Bash filename completion
		;;
	-L:*)
		__git_complete_symbol --cur="${cur#-L:}" --sfx=":"
		return
		;;
	-G*)
		__git_complete_symbol --pfx="-G" --cur="${cur#-G}"
		return
		;;
	-S*)
		__git_complete_symbol --pfx="-S" --cur="${cur#-S}"
		return
		;;
	esac
	__git_complete_revlist
}

_git_merge ()
{
	__git_complete_strategy && return

	case "$cur" in
	--*)
		__gitcomp_builtin merge
		return
	esac
	__git_complete_refs
}

_git_mergetool ()
{
	case "$cur" in
	--tool=*)
		__gitcomp "$__git_mergetools_common tortoisemerge" "" "${cur##--tool=}"
		return
		;;
	--*)
		__gitcomp "--tool= --prompt --no-prompt --gui --no-gui"
		return
		;;
	esac
}

_git_merge_base ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin merge-base
		return
		;;
	esac
	__git_complete_refs
}

_git_mv ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin mv
		return
		;;
	esac

	if [ $(__git_count_arguments "mv") -gt 0 ]; then
		# We need to show both cached and untracked files (including
		# empty directories) since this may not be the last argument.
		__git_complete_index_file "--cached --others --directory"
	else
		__git_complete_index_file "--cached"
	fi
}

_git_notes ()
{
	local subcommands='add append copy edit get-ref list merge prune remove show'
	local subcommand="$(__git_find_on_cmdline "$subcommands")"

	case "$subcommand,$cur" in
	,--*)
		__gitcomp_builtin notes
		;;
	,*)
		case "$prev" in
		--ref)
			__git_complete_refs
			;;
		*)
			__gitcomp "$subcommands --ref"
			;;
		esac
		;;
	*,--reuse-message=*|*,--reedit-message=*)
		__git_complete_refs --cur="${cur#*=}"
		;;
	*,--*)
		__gitcomp_builtin notes_$subcommand
		;;
	prune,*|get-ref,*)
		# this command does not take a ref, do not complete it
		;;
	*)
		case "$prev" in
		-m|-F)
			;;
		*)
			__git_complete_refs
			;;
		esac
		;;
	esac
}

_git_pull ()
{
	__git_complete_strategy && return

	case "$cur" in
	--recurse-submodules=*)
		__gitcomp "$__git_fetch_recurse_submodules" "" "${cur##--recurse-submodules=}"
		return
		;;
	--*)
		__gitcomp_builtin pull

		return
		;;
	esac
	__git_complete_remote_or_refspec
}

__git_push_recurse_submodules="check on-demand only"

__git_complete_force_with_lease ()
{
	local cur_=$1

	case "$cur_" in
	--*=)
		;;
	*:*)
		__git_complete_refs --cur="${cur_#*:}"
		;;
	*)
		__git_complete_refs --cur="$cur_"
		;;
	esac
}

_git_push ()
{
	case "$prev" in
	--repo)
		__gitcomp_nl "$(__git_remotes)"
		return
		;;
	--recurse-submodules)
		__gitcomp "$__git_push_recurse_submodules"
		return
		;;
	esac
	case "$cur" in
	--repo=*)
		__gitcomp_nl "$(__git_remotes)" "" "${cur##--repo=}"
		return
		;;
	--recurse-submodules=*)
		__gitcomp "$__git_push_recurse_submodules" "" "${cur##--recurse-submodules=}"
		return
		;;
	--force-with-lease=*)
		__git_complete_force_with_lease "${cur##--force-with-lease=}"
		return
		;;
	--*)
		__gitcomp_builtin push
		return
		;;
	esac
	__git_complete_remote_or_refspec
}

_git_range_diff ()
{
	case "$cur" in
	--*)
		__gitcomp "
			--creation-factor= --no-dual-color
			$__git_diff_common_options
		"
		return
		;;
	esac
	__git_complete_revlist
}

__git_rebase_inprogress_options="--continue --skip --abort --quit --show-current-patch"
__git_rebase_interactive_inprogress_options="$__git_rebase_inprogress_options --edit-todo"

_git_rebase ()
{
	__git_find_repo_path
	if [ -f "$__git_repo_path"/rebase-merge/interactive ]; then
		__gitcomp "$__git_rebase_interactive_inprogress_options"
		return
	elif [ -d "$__git_repo_path"/rebase-apply ] || \
	     [ -d "$__git_repo_path"/rebase-merge ]; then
		__gitcomp "$__git_rebase_inprogress_options"
		return
	fi
	__git_complete_strategy && return
	case "$cur" in
	--whitespace=*)
		__gitcomp "$__git_whitespacelist" "" "${cur##--whitespace=}"
		return
		;;
	--onto=*)
		__git_complete_refs --cur="${cur##--onto=}"
		return
		;;
	--*)
		__gitcomp_builtin rebase "" \
			"$__git_rebase_interactive_inprogress_options"

		return
	esac
	__git_complete_refs
}

_git_reflog ()
{
	local subcommands="show delete expire"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"

	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
	else
		__git_complete_refs
	fi
}

__git_send_email_confirm_options="always never auto cc compose"
__git_send_email_suppresscc_options="author self cc bodycc sob cccmd body all"

_git_send_email ()
{
	case "$prev" in
	--to|--cc|--bcc|--from)
		__gitcomp "$(__git send-email --dump-aliases)"
		return
		;;
	esac

	case "$cur" in
	--confirm=*)
		__gitcomp "
			$__git_send_email_confirm_options
			" "" "${cur##--confirm=}"
		return
		;;
	--suppress-cc=*)
		__gitcomp "
			$__git_send_email_suppresscc_options
			" "" "${cur##--suppress-cc=}"

		return
		;;
	--smtp-encryption=*)
		__gitcomp "ssl tls" "" "${cur##--smtp-encryption=}"
		return
		;;
	--thread=*)
		__gitcomp "
			deep shallow
			" "" "${cur##--thread=}"
		return
		;;
	--to=*|--cc=*|--bcc=*|--from=*)
		__gitcomp "$(__git send-email --dump-aliases)" "" "${cur#--*=}"
		return
		;;
	--*)
		__gitcomp_builtin send-email "--annotate --bcc --cc --cc-cmd --chain-reply-to
			--compose --confirm= --dry-run --envelope-sender
			--from --identity
			--in-reply-to --no-chain-reply-to --no-signed-off-by-cc
			--no-suppress-from --no-thread --quiet --reply-to
			--signed-off-by-cc --smtp-pass --smtp-server
			--smtp-server-port --smtp-encryption= --smtp-user
			--subject --suppress-cc= --suppress-from --thread --to
			--validate --no-validate
			$__git_format_patch_extra_options"
		return
		;;
	esac
	__git_complete_revlist
}

_git_stage ()
{
	_git_add
}

_git_status ()
{
	local complete_opt
	local untracked_state

	case "$cur" in
	--ignore-submodules=*)
		__gitcomp "none untracked dirty all" "" "${cur##--ignore-submodules=}"
		return
		;;
	--untracked-files=*)
		__gitcomp "$__git_untracked_file_modes" "" "${cur##--untracked-files=}"
		return
		;;
	--column=*)
		__gitcomp "
			always never auto column row plain dense nodense
			" "" "${cur##--column=}"
		return
		;;
	--*)
		__gitcomp_builtin status
		return
		;;
	esac

	untracked_state="$(__git_get_option_value "-u" "--untracked-files=" \
		"$__git_untracked_file_modes" "status.showUntrackedFiles")"

	case "$untracked_state" in
	no)
		# --ignored option does not matter
		complete_opt=
		;;
	all|normal|*)
		complete_opt="--cached --directory --no-empty-directory --others"

		if [ -n "$(__git_find_on_cmdline "--ignored")" ]; then
			complete_opt="$complete_opt --ignored --exclude=*"
		fi
		;;
	esac

	__git_complete_index_file "$complete_opt"
}

_git_switch ()
{
	local dwim_opt="$(__git_checkout_default_dwim_mode)"

	case "$prev" in
	-c|-C|--orphan)
		# Complete local branches (and DWIM branch
		# remote branch names) for an option argument
		# specifying a new branch name. This is for
		# convenience, assuming new branches are
		# possibly based on pre-existing branch names.
		__git_complete_refs $dwim_opt --mode="heads"
		return
		;;
	*)
		;;
	esac

	case "$cur" in
	--conflict=*)
		__gitcomp "diff3 merge" "" "${cur##--conflict=}"
		;;
	--*)
		__gitcomp_builtin switch
		;;
	*)
		# Unlike in git checkout, git switch --orphan does not take
		# a start point. Thus we really have nothing to complete after
		# the branch name.
		if [ -n "$(__git_find_on_cmdline "--orphan")" ]; then
			return
		fi

		# At this point, we've already handled special completion for
		# -c/-C, and --orphan. There are 3 main things left to
		# complete:
		# 1) a start-point for -c/-C or -d/--detach
		# 2) a remote head, for --track
		# 3) a branch name, possibly including DWIM remote branches

		if [ -n "$(__git_find_on_cmdline "-c -C -d --detach")" ]; then
			__git_complete_refs --mode="refs"
		elif [ -n "$(__git_find_on_cmdline "--track")" ]; then
			__git_complete_refs --mode="remote-heads"
		else
			__git_complete_refs $dwim_opt --mode="heads"
		fi
		;;
	esac
}

__git_config_get_set_variables ()
{
	local prevword word config_file= c=$cword
	while [ $c -gt 1 ]; do
		word="${words[c]}"
		case "$word" in
		--system|--global|--local|--file=*)
			config_file="$word"
			break
			;;
		-f|--file)
			config_file="$word $prevword"
			break
			;;
		esac
		prevword=$word
		c=$((--c))
	done

	__git config $config_file --name-only --list
}

__git_config_vars=
__git_compute_config_vars ()
{
	test -n "$__git_config_vars" ||
	__git_config_vars="$(git help --config-for-completion | sort -u)"
}

# Completes possible values of various configuration variables.
#
# Usage: __git_complete_config_variable_value [<option>]...
# --varname=<word>: The name of the configuration variable whose value is
#                   to be completed.  Defaults to the previous word on the
#                   command line.
# --cur=<word>: The current value to be completed.  Defaults to the current
#               word to be completed.
__git_complete_config_variable_value ()
{
	local varname="$prev" cur_="$cur"

	while test $# != 0; do
		case "$1" in
		--varname=*)	varname="${1##--varname=}" ;;
		--cur=*)	cur_="${1##--cur=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	if [ "${BASH_VERSINFO[0]:-0}" -ge 4 ]; then
		varname="${varname,,}"
	else
		varname="$(echo "$varname" |tr A-Z a-z)"
	fi

	case "$varname" in
	branch.*.remote|branch.*.pushremote)
		__gitcomp_nl "$(__git_remotes)" "" "$cur_"
		return
		;;
	branch.*.merge)
		__git_complete_refs --cur="$cur_"
		return
		;;
	branch.*.rebase)
		__gitcomp "false true merges preserve interactive" "" "$cur_"
		return
		;;
	remote.pushdefault)
		__gitcomp_nl "$(__git_remotes)" "" "$cur_"
		return
		;;
	remote.*.fetch)
		local remote="${varname#remote.}"
		remote="${remote%.fetch}"
		if [ -z "$cur_" ]; then
			__gitcomp_nl "refs/heads/" "" "" ""
			return
		fi
		__gitcomp_nl "$(__git_refs_remotes "$remote")" "" "$cur_"
		return
		;;
	remote.*.push)
		local remote="${varname#remote.}"
		remote="${remote%.push}"
		__gitcomp_nl "$(__git for-each-ref \
			--format='%(refname):%(refname)' refs/heads)" "" "$cur_"
		return
		;;
	pull.twohead|pull.octopus)
		__git_compute_merge_strategies
		__gitcomp "$__git_merge_strategies" "" "$cur_"
		return
		;;
	color.pager)
		__gitcomp "false true" "" "$cur_"
		return
		;;
	color.*.*)
		__gitcomp "
			normal black red green yellow blue magenta cyan white
			bold dim ul blink reverse
			" "" "$cur_"
		return
		;;
	color.*)
		__gitcomp "false true always never auto" "" "$cur_"
		return
		;;
	diff.submodule)
		__gitcomp "$__git_diff_submodule_formats" "" "$cur_"
		return
		;;
	help.format)
		__gitcomp "man info web html" "" "$cur_"
		return
		;;
	log.date)
		__gitcomp "$__git_log_date_formats" "" "$cur_"
		return
		;;
	sendemail.aliasfiletype)
		__gitcomp "mutt mailrc pine elm gnus" "" "$cur_"
		return
		;;
	sendemail.confirm)
		__gitcomp "$__git_send_email_confirm_options" "" "$cur_"
		return
		;;
	sendemail.suppresscc)
		__gitcomp "$__git_send_email_suppresscc_options" "" "$cur_"
		return
		;;
	sendemail.transferencoding)
		__gitcomp "7bit 8bit quoted-printable base64" "" "$cur_"
		return
		;;
	*.*)
		return
		;;
	esac
}

# Completes configuration sections, subsections, variable names.
#
# Usage: __git_complete_config_variable_name [<option>]...
# --cur=<word>: The current configuration section/variable name to be
#               completed.  Defaults to the current word to be completed.
# --sfx=<suffix>: A suffix to be appended to each fully completed
#                 configuration variable name (but not to sections or
#                 subsections) instead of the default space.
__git_complete_config_variable_name ()
{
	local cur_="$cur" sfx

	while test $# != 0; do
		case "$1" in
		--cur=*)	cur_="${1##--cur=}" ;;
		--sfx=*)	sfx="${1##--sfx=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	case "$cur_" in
	branch.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "remote pushRemote merge mergeOptions rebase" "$pfx" "$cur_" "$sfx"
		return
		;;
	branch.*)
		local pfx="${cur%.*}."
		cur_="${cur#*.}"
		__gitcomp_direct "$(__git_heads "$pfx" "$cur_" ".")"
		__gitcomp_nl_append $'autoSetupMerge\nautoSetupRebase\n' "$pfx" "$cur_" "$sfx"
		return
		;;
	guitool.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "
			argPrompt cmd confirm needsFile noConsole noRescan
			prompt revPrompt revUnmerged title
			" "$pfx" "$cur_" "$sfx"
		return
		;;
	difftool.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "cmd path" "$pfx" "$cur_" "$sfx"
		return
		;;
	man.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "cmd path" "$pfx" "$cur_" "$sfx"
		return
		;;
	mergetool.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "cmd path trustExitCode" "$pfx" "$cur_" "$sfx"
		return
		;;
	pager.*)
		local pfx="${cur_%.*}."
		cur_="${cur_#*.}"
		__git_compute_all_commands
		__gitcomp_nl "$__git_all_commands" "$pfx" "$cur_" "$sfx"
		return
		;;
	remote.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "
			url proxy fetch push mirror skipDefaultUpdate
			receivepack uploadpack tagOpt pushurl
			" "$pfx" "$cur_" "$sfx"
		return
		;;
	remote.*)
		local pfx="${cur_%.*}."
		cur_="${cur_#*.}"
		__gitcomp_nl "$(__git_remotes)" "$pfx" "$cur_" "."
		__gitcomp_nl_append "pushDefault" "$pfx" "$cur_" "$sfx"
		return
		;;
	url.*.*)
		local pfx="${cur_%.*}."
		cur_="${cur_##*.}"
		__gitcomp "insteadOf pushInsteadOf" "$pfx" "$cur_" "$sfx"
		return
		;;
	*.*)
		__git_compute_config_vars
		__gitcomp "$__git_config_vars" "" "$cur_" "$sfx"
		;;
	*)
		__git_compute_config_vars
		__gitcomp "$(echo "$__git_config_vars" |
				awk -F . '{
					sections[$1] = 1
				}
				END {
					for (s in sections)
						print s "."
				}
				')" "" "$cur_"
		;;
	esac
}

# Completes '='-separated configuration sections/variable names and values
# for 'git -c section.name=value'.
#
# Usage: __git_complete_config_variable_name_and_value [<option>]...
# --cur=<word>: The current configuration section/variable name/value to be
#               completed. Defaults to the current word to be completed.
__git_complete_config_variable_name_and_value ()
{
	local cur_="$cur"

	while test $# != 0; do
		case "$1" in
		--cur=*)	cur_="${1##--cur=}" ;;
		*)		return 1 ;;
		esac
		shift
	done

	case "$cur_" in
	*=*)
		__git_complete_config_variable_value \
			--varname="${cur_%%=*}" --cur="${cur_#*=}"
		;;
	*)
		__git_complete_config_variable_name --cur="$cur_" --sfx='='
		;;
	esac
}

_git_config ()
{
	case "$prev" in
	--get|--get-all|--unset|--unset-all)
		__gitcomp_nl "$(__git_config_get_set_variables)"
		return
		;;
	*.*)
		__git_complete_config_variable_value
		return
		;;
	esac
	case "$cur" in
	--*)
		__gitcomp_builtin config
		;;
	*)
		__git_complete_config_variable_name
		;;
	esac
}

_git_remote ()
{
	local subcommands="
		add rename remove set-head set-branches
		get-url set-url show prune update
		"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		case "$cur" in
		--*)
			__gitcomp_builtin remote
			;;
		*)
			__gitcomp "$subcommands"
			;;
		esac
		return
	fi

	case "$subcommand,$cur" in
	add,--*)
		__gitcomp_builtin remote_add
		;;
	add,*)
		;;
	set-head,--*)
		__gitcomp_builtin remote_set-head
		;;
	set-branches,--*)
		__gitcomp_builtin remote_set-branches
		;;
	set-head,*|set-branches,*)
		__git_complete_remote_or_refspec
		;;
	update,--*)
		__gitcomp_builtin remote_update
		;;
	update,*)
		__gitcomp "$(__git_remotes) $(__git_get_config_variables "remotes")"
		;;
	set-url,--*)
		__gitcomp_builtin remote_set-url
		;;
	get-url,--*)
		__gitcomp_builtin remote_get-url
		;;
	prune,--*)
		__gitcomp_builtin remote_prune
		;;
	*)
		__gitcomp_nl "$(__git_remotes)"
		;;
	esac
}

_git_replace ()
{
	case "$cur" in
	--format=*)
		__gitcomp "short medium long" "" "${cur##--format=}"
		return
		;;
	--*)
		__gitcomp_builtin replace
		return
		;;
	esac
	__git_complete_refs
}

_git_rerere ()
{
	local subcommands="clear forget diff remaining status gc"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if test -z "$subcommand"
	then
		__gitcomp "$subcommands"
		return
	fi
}

_git_reset ()
{
	__git_has_doubledash && return

	case "$cur" in
	--*)
		__gitcomp_builtin reset
		return
		;;
	esac
	__git_complete_refs
}

_git_restore ()
{
	case "$prev" in
	-s)
		__git_complete_refs
		return
		;;
	esac

	case "$cur" in
	--conflict=*)
		__gitcomp "diff3 merge" "" "${cur##--conflict=}"
		;;
	--source=*)
		__git_complete_refs --cur="${cur##--source=}"
		;;
	--*)
		__gitcomp_builtin restore
		;;
	esac
}

__git_revert_inprogress_options=$__git_sequencer_inprogress_options

_git_revert ()
{
	__git_find_repo_path
	if [ -f "$__git_repo_path"/REVERT_HEAD ]; then
		__gitcomp "$__git_revert_inprogress_options"
		return
	fi
	__git_complete_strategy && return
	case "$cur" in
	--*)
		__gitcomp_builtin revert "" \
			"$__git_revert_inprogress_options"
		return
		;;
	esac
	__git_complete_refs
}

_git_rm ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin rm
		return
		;;
	esac

	__git_complete_index_file "--cached"
}

_git_shortlog ()
{
	__git_has_doubledash && return

	case "$cur" in
	--*)
		__gitcomp "
			$__git_log_common_options
			$__git_log_shortlog_options
			--numbered --summary --email
			"
		return
		;;
	esac
	__git_complete_revlist
}

_git_show ()
{
	__git_has_doubledash && return

	case "$cur" in
	--pretty=*|--format=*)
		__gitcomp "$__git_log_pretty_formats $(__git_pretty_aliases)
			" "" "${cur#*=}"
		return
		;;
	--diff-algorithm=*)
		__gitcomp "$__git_diff_algorithms" "" "${cur##--diff-algorithm=}"
		return
		;;
	--submodule=*)
		__gitcomp "$__git_diff_submodule_formats" "" "${cur##--submodule=}"
		return
		;;
	--color-moved=*)
		__gitcomp "$__git_color_moved_opts" "" "${cur##--color-moved=}"
		return
		;;
	--color-moved-ws=*)
		__gitcomp "$__git_color_moved_ws_opts" "" "${cur##--color-moved-ws=}"
		return
		;;
	--*)
		__gitcomp "--pretty= --format= --abbrev-commit --no-abbrev-commit
			--oneline --show-signature
			--expand-tabs --expand-tabs= --no-expand-tabs
			$__git_diff_common_options
			"
		return
		;;
	esac
	__git_complete_revlist_file
}

_git_show_branch ()
{
	case "$cur" in
	--*)
		__gitcomp_builtin show-branch
		return
		;;
	esac
	__git_complete_revlist
}

_git_sparse_checkout ()
{
	local subcommands="list init set disable"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
		return
	fi

	case "$subcommand,$cur" in
	init,--*)
		__gitcomp "--cone"
		;;
	set,--*)
		__gitcomp "--stdin"
		;;
	*)
		;;
	esac
}

_git_stash ()
{
	local save_opts='--all --keep-index --no-keep-index --quiet --patch --include-untracked'
	local subcommands='push list show apply clear drop pop create branch'
	local subcommand="$(__git_find_on_cmdline "$subcommands save")"
	if [ -z "$subcommand" -a -n "$(__git_find_on_cmdline "-p")" ]; then
		subcommand="push"
	fi
	if [ -z "$subcommand" ]; then
		case "$cur" in
		--*)
			__gitcomp "$save_opts"
			;;
		sa*)
			if [ -z "$(__git_find_on_cmdline "$save_opts")" ]; then
				__gitcomp "save"
			fi
			;;
		*)
			if [ -z "$(__git_find_on_cmdline "$save_opts")" ]; then
				__gitcomp "$subcommands"
			fi
			;;
		esac
	else
		case "$subcommand,$cur" in
		push,--*)
			__gitcomp "$save_opts --message"
			;;
		save,--*)
			__gitcomp "$save_opts"
			;;
		apply,--*|pop,--*)
			__gitcomp "--index --quiet"
			;;
		drop,--*)
			__gitcomp "--quiet"
			;;
		list,--*)
			__gitcomp "--name-status --oneline --patch-with-stat"
			;;
		show,--*)
			__gitcomp "$__git_diff_common_options"
			;;
		branch,--*)
			;;
		branch,*)
			if [ $cword -eq 3 ]; then
				__git_complete_refs
			else
				__gitcomp_nl "$(__git stash list \
						| sed -n -e 's/:.*//p')"
			fi
			;;
		show,*|apply,*|drop,*|pop,*)
			__gitcomp_nl "$(__git stash list \
					| sed -n -e 's/:.*//p')"
			;;
		*)
			;;
		esac
	fi
}

_git_submodule ()
{
	__git_has_doubledash && return

	local subcommands="add status init deinit update set-branch set-url summary foreach sync absorbgitdirs"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		case "$cur" in
		--*)
			__gitcomp "--quiet"
			;;
		*)
			__gitcomp "$subcommands"
			;;
		esac
		return
	fi

	case "$subcommand,$cur" in
	add,--*)
		__gitcomp "--branch --force --name --reference --depth"
		;;
	status,--*)
		__gitcomp "--cached --recursive"
		;;
	deinit,--*)
		__gitcomp "--force --all"
		;;
	update,--*)
		__gitcomp "
			--init --remote --no-fetch
			--recommend-shallow --no-recommend-shallow
			--force --rebase --merge --reference --depth --recursive --jobs
		"
		;;
	set-branch,--*)
		__gitcomp "--default --branch"
		;;
	summary,--*)
		__gitcomp "--cached --files --summary-limit"
		;;
	foreach,--*|sync,--*)
		__gitcomp "--recursive"
		;;
	*)
		;;
	esac
}

_git_svn ()
{
	local subcommands="
		init fetch clone rebase dcommit log find-rev
		set-tree commit-diff info create-ignore propget
		proplist show-ignore show-externals branch tag blame
		migrate mkdirs reset gc
		"
	local subcommand="$(__git_find_on_cmdline "$subcommands")"
	if [ -z "$subcommand" ]; then
		__gitcomp "$subcommands"
	else
		local remote_opts="--username= --config-dir= --no-auth-cache"
		local fc_opts="
			--follow-parent --authors-file= --repack=
			--no-metadata --use-svm-props --use-svnsync-props
			--log-window-size= --no-checkout --quiet
			--repack-flags --use-log-author --localtime
			--add-author-from
			--recursive
			--ignore-paths= --include-paths= $remote_opts
			"
		local init_opts="
			--template= --shared= --trunk= --tags=
			--branches= --stdlayout --minimize-url
			--no-metadata --use-svm-props --use-svnsync-props
			--rewrite-root= --prefix= $remote_opts
			"
		local cmt_opts="
			--edit --rmdir --find-copies-harder --copy-similarity=
			"

		case "$subcommand,$cur" in
		fetch,--*)
			__gitcomp "--revision= --fetch-all $fc_opts"
			;;
		clone,--*)
			__gitcomp "--revision= $fc_opts $init_opts"
			;;
		init,--*)
			__gitcomp "$init_opts"
			;;
		dcommit,--*)
			__gitcomp "
				--merge --strategy= --verbose --dry-run
				--fetch-all --no-rebase --commit-url
				--revision --interactive $cmt_opts $fc_opts
				"
			;;
		set-tree,--*)
			__gitcomp "--stdin $cmt_opts $fc_opts"
			;;
		create-ignore,--*|propget,--*|proplist,--*|show-ignore,--*|\
		show-externals,--*|mkdirs,--*)
			__gitcomp "--revision="
			;;
		log,--*)
			__gitcomp "
				--limit= --revision= --verbose --incremental
				--oneline --show-commit --non-recursive
				--authors-file= --color
				"
			;;
		rebase,--*)
			__gitcomp "
				--merge --verbose --strategy= --local
				--fetch-all --dry-run $fc_opts
				"
			;;
		commit-diff,--*)
			__gitcomp "--message= --file= --revision= $cmt_opts"
			;;
		info,--*)
			__gitcomp "--url"
			;;
		branch,--*)
			__gitcomp "--dry-run --message --tag"
			;;
		tag,--*)
			__gitcomp "--dry-run --message"
			;;
		blame,--*)
			__gitcomp "--git-format"
			;;
		migrate,--*)
			__gitcomp "
				--config-dir= --ignore-paths= --minimize
				--no-auth-cache --username=
				"
			;;
		reset,--*)
			__gitcomp "--revision= --parent"
			;;
		*)
			;;
		esac
	fi
}

_git_tag ()
{
	local i c=1 f=0
	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		-d|--delete|-v|--verify)
			__gitcomp_direct "$(__git_tags "" "$cur" " ")"
			return
			;;
		-f)
			f=1
			;;
		esac
		((c++))
	done

	case "$prev" in
	-m|-F)
		;;
	-*|tag)
		if [ $f = 1 ]; then
			__gitcomp_direct "$(__git_tags "" "$cur" " ")"
		fi
		;;
	*)
		__git_complete_refs
		;;
	esac

	case "$cur" in
	--*)
		__gitcomp_builtin tag
		;;
	esac
}

_git_whatchanged ()
{
	_git_log
}

__git_complete_worktree_paths ()
{
	local IFS=$'\n'
	__gitcomp_nl "$(git worktree list --porcelain |
		# Skip the first entry: it's the path of the main worktree,
		# which can't be moved, removed, locked, etc.
		sed -n -e '2,$ s/^worktree //p')"
}

_git_worktree ()
{
	local subcommands="add list lock move prune remove unlock"
	local subcommand subcommand_idx

	subcommand="$(__git_find_on_cmdline --show-idx "$subcommands")"
	subcommand_idx="${subcommand% *}"
	subcommand="${subcommand#* }"

	case "$subcommand,$cur" in
	,*)
		__gitcomp "$subcommands"
		;;
	*,--*)
		__gitcomp_builtin worktree_$subcommand
		;;
	add,*)	# usage: git worktree add [<options>] <path> [<commit-ish>]
		# Here we are not completing an --option, it's either the
		# path or a ref.
		case "$prev" in
		-b|-B)	# Complete refs for branch to be created/reseted.
			__git_complete_refs
			;;
		-*)	# The previous word is an -o|--option without an
			# unstuck argument: have to complete the path for
			# the new worktree, so don't list anything, but let
			# Bash fall back to filename completion.
			;;
		*)	# The previous word is not an --option, so it must
			# be either the 'add' subcommand, the unstuck
			# argument of an option (e.g. branch for -b|-B), or
			# the path for the new worktree.
			if [ $cword -eq $((subcommand_idx+1)) ]; then
				# Right after the 'add' subcommand: have to
				# complete the path, so fall back to Bash
				# filename completion.
				:
			else
				case "${words[cword-2]}" in
				-b|-B)	# After '-b <branch>': have to
					# complete the path, so fall back
					# to Bash filename completion.
					;;
				*)	# After the path: have to complete
					# the ref to be checked out.
					__git_complete_refs
					;;
				esac
			fi
			;;
		esac
		;;
	lock,*|remove,*|unlock,*)
		__git_complete_worktree_paths
		;;
	move,*)
		if [ $cword -eq $((subcommand_idx+1)) ]; then
			# The first parameter must be an existing working
			# tree to be moved.
			__git_complete_worktree_paths
		else
			# The second parameter is the destination: it could
			# be any path, so don't list anything, but let Bash
			# fall back to filename completion.
			:
		fi
		;;
	esac
}

__git_complete_common () {
	local command="$1"

	case "$cur" in
	--*)
		__gitcomp_builtin "$command"
		;;
	esac
}

__git_cmds_with_parseopt_helper=
__git_support_parseopt_helper () {
	test -n "$__git_cmds_with_parseopt_helper" ||
		__git_cmds_with_parseopt_helper="$(__git --list-cmds=parseopt)"

	case " $__git_cmds_with_parseopt_helper " in
	*" $1 "*)
		return 0
		;;
	*)
		return 1
		;;
	esac
}

__git_have_func () {
	declare -f -- "$1" >/dev/null 2>&1
}

__git_complete_command () {
	local command="$1"
	local completion_func="_git_${command//-/_}"
	if ! __git_have_func $completion_func &&
		__git_have_func _completion_loader
	then
		_completion_loader "git-$command"
	fi
	if __git_have_func $completion_func
	then
		$completion_func
		return 0
	elif __git_support_parseopt_helper "$command"
	then
		__git_complete_common "$command"
		return 0
	else
		return 1
	fi
}

__git_main ()
{
	local i c=1 command __git_dir __git_repo_path
	local __git_C_args C_args_count=0

	while [ $c -lt $cword ]; do
		i="${words[c]}"
		case "$i" in
		--git-dir=*) __git_dir="${i#--git-dir=}" ;;
		--git-dir)   ((c++)) ; __git_dir="${words[c]}" ;;
		--bare)      __git_dir="." ;;
		--help) command="help"; break ;;
		-c|--work-tree|--namespace) ((c++)) ;;
		-C)	__git_C_args[C_args_count++]=-C
			((c++))
			__git_C_args[C_args_count++]="${words[c]}"
			;;
		-*) ;;
		*) command="$i"; break ;;
		esac
		((c++))
	done

	if [ -z "${command-}" ]; then
		case "$prev" in
		--git-dir|-C|--work-tree)
			# these need a path argument, let's fall back to
			# Bash filename completion
			return
			;;
		-c)
			__git_complete_config_variable_name_and_value
			return
			;;
		--namespace)
			# we don't support completing these options' arguments
			return
			;;
		esac
		case "$cur" in
		--*)   __gitcomp "
			--paginate
			--no-pager
			--git-dir=
			--bare
			--version
			--exec-path
			--exec-path=
			--html-path
			--man-path
			--info-path
			--work-tree=
			--namespace=
			--no-replace-objects
			--help
			"
			;;
		*)
			if test -n "${GIT_TESTING_PORCELAIN_COMMAND_LIST-}"
			then
				__gitcomp "$GIT_TESTING_PORCELAIN_COMMAND_LIST"
			else
				__gitcomp "$(__git --list-cmds=list-mainporcelain,others,nohelpers,alias,list-complete,config)"
			fi
			;;
		esac
		return
	fi

	__git_complete_command "$command" && return

	local expansion=$(__git_aliased_command "$command")
	if [ -n "$expansion" ]; then
		words[1]=$expansion
		__git_complete_command "$expansion"
	fi
}

__gitk_main ()
{
	__git_has_doubledash && return

	local __git_repo_path
	__git_find_repo_path

	local merge=""
	if [ -f "$__git_repo_path/MERGE_HEAD" ]; then
		merge="--merge"
	fi
	case "$cur" in
	--*)
		__gitcomp "
			$__git_log_common_options
			$__git_log_gitk_options
			$merge
			"
		return
		;;
	esac
	__git_complete_revlist
}

if [[ -n ${ZSH_VERSION-} && -z ${GIT_SOURCING_ZSH_COMPLETION-} ]]; then
	echo "ERROR: this script is obsolete, please see git-completion.zsh" 1>&2
	return
fi

__git_func_wrap ()
{
	local cur words cword prev
	_get_comp_words_by_ref -n =: cur words cword prev
	$1
}

___git_complete ()
{
	local wrapper="__git_wrap${2}"
	eval "$wrapper () { __git_func_wrap $2 ; }"
	complete -o bashdefault -o default -o nospace -F $wrapper $1 2>/dev/null \
		|| complete -o default -o nospace -F $wrapper $1
}

# Setup the completion for git commands
# 1: command or alias
# 2: function to call (e.g. `git`, `gitk`, `git_fetch`)
__git_complete ()
{
	local func

	if __git_have_func $2; then
		func=$2
	elif __git_have_func __$2_main; then
		func=__$2_main
	elif __git_have_func _$2; then
		func=_$2
	else
		echo "ERROR: could not find function '$2'" 1>&2
		return 1
	fi
	___git_complete $1 $func
}

___git_complete git __git_main
___git_complete gitk __gitk_main

# The following are necessary only for Cygwin, and only are needed
# when the user has tab-completed the executable name and consequently
# included the '.exe' suffix.
#
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/usr/bin/env bash
set -ex

# This script builds archiver for most common platforms.

export CGO_ENABLED=0

cd cmd/arc
GOOS=linux   GOARCH=amd64 go build -o ../../builds/arc_linux_amd64
GOOS=linux   GOARCH=arm   go build -o ../../builds/arc_linux_arm7
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/usr/bin/env bash

GOOSARCH="${GOOS}_${GOARCH}"
case "$GOOSARCH" in
_* | *_ | _)
	echo 'undefined $GOOS_$GOARCH:' "$GOOSARCH" 1>&2
	exit 1
	;;
esac

GODEFS="go tool cgo -godefs"

$GODEFS types.go |gofmt > ztypes_$GOARCH.go

case $GOOS in
#!/bin/bash
# 2018-04-06 Al Danial <al.danial@gmail.com>

# Create in the current directory a git repository
# called 'GitTestRepo' and populate it with a few
# files over several commits.  The repo is used to
# exercise some of cloc's git features.

G=`which git`
if test ! $G ; then 
    echo "git is unavailable, exit."
    exit
fi

function git_init_config {                                  # {{{
    reponame=$1
    git init --quiet "${reponame}"
    cd "${reponame}"
    # explicitly don't use --global; settings for this repo only
    git config user.email "cloc.tester@github.com"
    git config user.name  "Cloc Tester"
}
# 1}}}
function create_main_c {                                    # {{{
fname=$1
N=$2
cat <<EO_001 > "${fname}"
/*
 *               gcc hello.c -o hello
 */
main (int argc, char *argv[])
{
  printf("Hello. $N\n");
}
EO_001
}
# 1}}}
function create_py {                                        # {{{
fname=$1
cat <<EO_002 > "${fname}"
#!/usr/bin/env python

print('hi')
EO_002
}
# 1}}}
function mod_py_A {                                         # {{{
fname=$1
cat <<EO_003 > "${fname}"
#!/usr/bin/env python
print('hi')
print('hello')
EO_003
}
# 1}}}
function mod_py_B {                                         # {{{
fname=$1
cat <<EO_004 > "${fname}"
#!/usr/bin/env python

# five
for i in range(5):
    print('yo')  # print

EO_004
}
# 1}}}
function git_add_commit {                                   # {{{
    fname=$1
    comment=$2
    taglabel=$3
    git add "${fname}"
    git commit --quiet -m "${comment}" "${fname}"
    git tag "${taglabel}"
}
# 1}}}
function git_rm_commit {                                    # {{{
    fname=$1
    comment=$2
    taglabel=$3
    git rm --quiet "${fname}"
    git commit --quiet -m "${comment}" "${fname}"
    git tag "${taglabel}"
}
# 1}}}

# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - #
#                                    main                                 #

git_init_config GitTestRepo # side effect: cd into GitTestRepo

F1=main.c
F2='date;ls ?.c'
F3='$PWD.c'
F4="weird'name.c"
F5='ls -l .c'
F6='Weird"Name.c'

create_main_c  $F1  1
create_main_c "$F2" 2
create_main_c  $F3  3
create_main_c  $F4  4
create_main_c "$F5" 5
create_main_c  $F6  6
git_add_commit  $F1  "added $F1"  "Tag1"
    git add 'date;ls ?.c'
    git commit --quiet -m "${comment}" 'date;ls ?.c'
    git tag "Tag2"
git_add_commit  $F3  "added $F3"  "Tag3"
git_add_commit  $F4  "added $F4"  "Tag4"
    git add 'ls -l .c'
    git commit --quiet -m "${comment}" 'ls -l .c'
    git tag "Tag5"
git_add_commit  $F6  "added $F6"  "Tag6"

create_py      hello.py
git_add_commit hello.py "add hello.py"              "T2"
mod_py_A       hello.py
git_add_commit hello.py "mod A"                     "T3"
mod_py_B       hello.py
### GNU/LINUX
alias ng.status='systemctl status nginx'
alias ng.reload='systemctl reload nginx'
alias ng.restart='systemctl restart nginx'
alias ng.test='/usr/sbin/nginx -t -c /etc/nginx/nginx.conf'
alias ng.dump='/usr/sbin/nginx -T -c /etc/nginx/nginx.conf'

alias CD_NGX_ROOT="cd /etc/nginx && ls -lh"
alias CD_NGX_LOGS="cd /var/log/nginx && ls -lh"
alias CD_NGX_ACME="cd /var/www/acme/.well-known/acme-challenge && ls -lh"

### BSD
alias ng.status='/usr/local/etc/rc.d/nginx status'
alias ng.reload='/usr/local/etc/rc.d/nginx reload'
alias ng.restart='/usr/local/etc/rc.d/nginx restart'
alias ng.test='/usr/local/sbin/nginx -t -c /usr/local/etc/nginx/nginx.conf'
alias ng.dump='/usr/local/sbin/nginx -T -c /usr/local/etc/nginx/nginx.conf'

alias CD_NGX_ROOT="cd /usr/local/etc/nginx && ls -lh"
alias CD_NGX_LOGS="cd /var/log/nginx && ls -lh"
alias CD_NGX_ACME="cd /var/www/acme/.well-known/acme-challenge && ls -lh"

### GIT
alias git.log='git log --oneline --decorate --graph --all'
alias git.commit='git add . && git commit -m "uncommited changes"'
alias git.sync='git pull origin master && git fetch --all && git fetch --prune --tags'
alias git.push='git push origin master && git push origin --tags --force'
alias git.force='git push origin master --force && git push origin --tags --force'
alias git.remote='git remote update && git status -uno && git show-branch *master'
alias git.reset='git add . && git reset --hard HEAD'
_celery_completion() {
    local IFS=$'
'
    COMPREPLY=( $( env COMP_WORDS="${COMP_WORDS[*]}" \
                   COMP_CWORD=$COMP_CWORD \
                   _CELERY_COMPLETE=complete $1 ) )
    return 0
}

_celery_completionetup() {
    local COMPLETION_OPTIONS=""
    local BASH_VERSION_ARR=(${BASH_VERSION//./ })
    # Only BASH version 4.4 and later have the nosort option.
    if [ ${BASH_VERSION_ARR[0]} -gt 4 ] || ([ ${BASH_VERSION_ARR[0]} -eq 4 ] && [ ${BASH_VERSION_ARR[1]} -ge 4 ]); then
        COMPLETION_OPTIONS="-o nosort"
    fi

    complete $COMPLETION_OPTIONS -F _celery_completion celery
}

#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/bin/bash

set -e

# This script regenerates the flag list and checks for differences to ensure flags
# have been regenerated in case of changes to flags.yml.

make flags

if ! git --no-pager diff --exit-code -- ./kit/feature/list.go
# Let's verify that the tools we need are installed
verify_aws_cli() {
    declare -a required=(aws)
    for cmd in "${required[@]}"; do
        command -v $cmd >/dev/null 2>&1 || {
            echo "'$cmd' must be installed" >&2
            exit 1
        }
    done
}

#--------------------------------------------------------------------
# Bats modification
#--------------------------------------------------------------------
# This allows us to override a function in Bash
save_function() {
    local ORIG_FUNC=$(declare -f $1)
    local NEWNAME_FUNC="$2${ORIG_FUNC#$1}"
    eval "$NEWNAME_FUNC"
}

# Override the run function so that we always output the output
save_function run old_run
run() {
    old_run $@

    # Output the command we ran
    echo "Executing: " $@

    # "$output" gets rid of newlines. This will bring them back.
    for line in "${lines[@]}"; do
        echo $line
    done
}

#--------------------------------------------------------------------
# Helper functions
#--------------------------------------------------------------------
# This sets the directory for fixtures by specifying the name of
# the folder with fixtures.
fixtures() {
    FIXTURE_ROOT="$BATS_TEST_DIRNAME/fixtures/$1"
}

# This deletes any AMIs with a tag "packer-test" of "true"
aws_ami_cleanup() {
    local region=${1:-us-east-1}
    aws ec2 describe-images --region ${region} --owners self --output text \
        --filters 'Name=tag:packer-test,Values=true' \
        --query 'Images[*].ImageId' \
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
			fi
		fi

		echo "$key $vtype = $value"
	done < "$winerror"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

knownfolders="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/um/KnownFolders.h | sort -Vr | head -n 1)"
[[ -n $knownfolders ]] || { echo "Unable to find KnownFolders.h" >&2; exit 1; }

{
	echo "// Code generated by 'mkknownfolderids.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "type KNOWNFOLDERID GUID"
	echo "var ("
	while read -r line; do
		[[ $line =~ DEFINE_KNOWN_FOLDER\((FOLDERID_[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+),[\t\ ]*(0x[^,]+)\) ]] || continue
		printf "%s = &KNOWNFOLDERID{0x%08x, 0x%04x, 0x%04x, [8]byte{0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x, 0x%02x}}\n" \
			"${BASH_REMATCH[1]}" $(( "${BASH_REMATCH[2]}" )) $(( "${BASH_REMATCH[3]}" )) $(( "${BASH_REMATCH[4]}" )) \
			$(( "${BASH_REMATCH[5]}" )) $(( "${BASH_REMATCH[6]}" )) $(( "${BASH_REMATCH[7]}" )) $(( "${BASH_REMATCH[8]}" )) \
			$(( "${BASH_REMATCH[9]}" )) $(( "${BASH_REMATCH[10]}" )) $(( "${BASH_REMATCH[11]}" )) $(( "${BASH_REMATCH[12]}" ))
	done < "$knownfolders"
#!/bin/bash

# Copyright 2019 The Go Authors. All rights reserved.
# Use of this source code is governed by a BSD-style
# license that can be found in the LICENSE file.

set -e
shopt -s nullglob

winerror="$(printf '%s\n' "/mnt/c/Program Files (x86)/Windows Kits/"/*/Include/*/shared/winerror.h | sort -Vr | head -n 1)"
[[ -n $winerror ]] || { echo "Unable to find winerror.h" >&2; exit 1; }

declare -A errors

{
	echo "// Code generated by 'mkerrors.bash'; DO NOT EDIT."
	echo
	echo "package windows"
	echo "import \"syscall\""
	echo "const ("

	while read -r line; do
		unset vtype
		if [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?([A-Z][A-Z0-9_]+k?)\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +([A-Z0-9_]+\()?((0x)?[0-9A-Fa-f]+)L?\)? ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		elif [[ $line =~ ^#define\ +([A-Z0-9_]+k?)\ +\(\(([A-Z]+)\)((0x)?[0-9A-Fa-f]+)L?\) ]]; then
			key="${BASH_REMATCH[1]}"
			value="${BASH_REMATCH[3]}"
			vtype="${BASH_REMATCH[2]}"
		else
			continue
		fi
		[[ -n $key && -n $value ]] || continue
		[[ -z ${errors["$key"]} ]] || continue
		errors["$key"]="$value"
		if [[ -v vtype ]]; then
			if [[ $key == FACILITY_* || $key == NO_ERROR ]]; then
				vtype=""
			elif [[ $vtype == *HANDLE* || $vtype == *HRESULT* ]]; then
				vtype="Handle"
			else
				vtype="syscall.Errno"
			fi
			last_vtype="$vtype"
		else
			vtype=""
			if [[ $last_vtype == Handle && $value == NO_ERROR ]]; then
				value="S_OK"
			elif [[ $last_vtype == syscall.Errno && $value == NO_ERROR ]]; then
				value="ERROR_SUCCESS"
